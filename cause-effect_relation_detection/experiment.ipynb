{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Data-Pre-Processing\" data-toc-modified-id=\"Data-Pre-Processing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Pre-Processing</a></div><div class=\"lev2 toc-item\"><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Load Data</a></div><div class=\"lev2 toc-item\"><a href=\"#Word-Segmentation\" data-toc-modified-id=\"Word-Segmentation-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Word Segmentation</a></div><div class=\"lev2 toc-item\"><a href=\"#Explore-the-Data\" data-toc-modified-id=\"Explore-the-Data-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Explore the Data</a></div><div class=\"lev1 toc-item\"><a href=\"#Word-Embedding\" data-toc-modified-id=\"Word-Embedding-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Word Embedding</a></div><div class=\"lev2 toc-item\"><a href=\"#Tokenize-Text\" data-toc-modified-id=\"Tokenize-Text-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Tokenize Text</a></div><div class=\"lev2 toc-item\"><a href=\"#Create-Word-Embeddings-with-GloVe\" data-toc-modified-id=\"Create-Word-Embeddings-with-GloVe-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Create Word Embeddings with GloVe</a></div><div class=\"lev3 toc-item\"><a href=\"#Read-Glove\" data-toc-modified-id=\"Read-Glove-221\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Read Glove</a></div><div class=\"lev3 toc-item\"><a href=\"#Use-Glove-to-Initialize-Embedding-Matrix\" data-toc-modified-id=\"Use-Glove-to-Initialize-Embedding-Matrix-222\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Use Glove to Initialize Embedding Matrix</a></div><div class=\"lev1 toc-item\"><a href=\"#Build-Dateset\" data-toc-modified-id=\"Build-Dateset-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Build Dateset</a></div><div class=\"lev1 toc-item\"><a href=\"#Save-Dataset\" data-toc-modified-id=\"Save-Dataset-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Save Dataset</a></div><div class=\"lev1 toc-item\"><a href=\"#Checkpoint\" data-toc-modified-id=\"Checkpoint-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Checkpoint</a></div><div class=\"lev1 toc-item\"><a href=\"#Build-Model\" data-toc-modified-id=\"Build-Model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Build Model</a></div><div class=\"lev2 toc-item\"><a href=\"#Set-Hyperparameters\" data-toc-modified-id=\"Set-Hyperparameters-61\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Set Hyperparameters</a></div><div class=\"lev2 toc-item\"><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-62\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Import Libraries</a></div><div class=\"lev2 toc-item\"><a href=\"#Model-Visualization\" data-toc-modified-id=\"Model-Visualization-63\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Model Visualization</a></div><div class=\"lev2 toc-item\"><a href=\"#Train\" data-toc-modified-id=\"Train-64\"><span class=\"toc-item-num\">6.4&nbsp;&nbsp;</span>Train</a></div><div class=\"lev1 toc-item\"><a href=\"#Evaluate\" data-toc-modified-id=\"Evaluate-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Evaluate</a></div><div class=\"lev2 toc-item\"><a href=\"#Experiment-1\" data-toc-modified-id=\"Experiment-1-71\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Experiment 1</a></div><div class=\"lev2 toc-item\"><a href=\"#Experiment-2\" data-toc-modified-id=\"Experiment-2-72\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Experiment 2</a></div><div class=\"lev2 toc-item\"><a href=\"#Experiment-3\" data-toc-modified-id=\"Experiment-3-73\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Experiment 3</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Data Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load date from file\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_path = 'train_data.txt'\n",
    "train_data = load_data(train_data_path).strip().split('\\t')[1:]\n",
    "train_data = [line.split('\\n')[:2] for line in train_data]\n",
    "test_data_path = 'test_data.txt'\n",
    "test_data = load_data(test_data_path).strip().split('\\t')[1:]\n",
    "test_data = [line.split('\\n')[:2] for line in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_sent = [line[0] for line in train_data]\n",
    "test_sent = [line[0] for line in test_data]\n",
    "train_label = ['Causal' if line[-1] == 'Cause-Effect(e2,e1)' or line[-1] == 'Cause-Effect(e1,e2)' else 'Non-Causal' for line in train_data]\n",
    "test_label = ['Causal' if line[-1] == 'Cause-Effect(e2,e1)' or line[-1] == 'Cause-Effect(e1,e2)' else 'Non-Causal' for line in test_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"stopwords.txt\"\n",
    "stopWords = {w: None for w in open(filename).read().split()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut(s):\n",
    "    \"\"\"\n",
    "    Word segmentation\n",
    "    \"\"\"\n",
    "    pattern = r'''\n",
    "              (?x)                   # set flag to allow verbose regexps \n",
    "              (?:[A-Z]\\.)+           # abbreviations, e.g. U.S.A. \n",
    "              |\\d+(?:\\.\\d+)?%?       # numbers, incl. currency and percentages \n",
    "              |\\w+(?:[-&']\\w+)*      # words w/ optional internal hyphens/apostrophe \n",
    "           '''  \n",
    "    return regexp_tokenize(s, pattern=pattern)\n",
    "\n",
    "def find_pn(ws):\n",
    "    \"\"\"\n",
    "    Find paired nominals\n",
    "    \"\"\"\n",
    "    for i in range(len(ws)):\n",
    "        if ws[i] == 'e1':\n",
    "            for j in range(i+1, len(ws)):\n",
    "                if ws[j] == 'e1':\n",
    "                    pn1 = ws[i+1:j] \n",
    "        if ws[i] == 'e2':\n",
    "            for j in range(i+1, len(ws)):\n",
    "                if ws[j] == 'e2':\n",
    "                    pn2 = ws[i+1:j]\n",
    "    return pn1, pn2\n",
    "\n",
    "def del_stop(ws):\n",
    "    \"\"\"\n",
    "    Delete stopwords\n",
    "    \"\"\"\n",
    "    return [i for i in [stopWords.get(i.lower(), i) for i in ws] if i != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainWords = [cut(s) for s in train_sent] \n",
    "trainPn1 = [find_pn(ws)[0] for ws in trainWords] \n",
    "trainPn2 = [find_pn(ws)[-1] for ws in trainWords] \n",
    "trainWords = [del_stop(ws) for ws in trainWords]\n",
    "testWords = [cut(s) for s in test_sent] \n",
    "testPn1 = [find_pn(ws)[0] for ws in testWords] \n",
    "testPn2 = [find_pn(ws)[-1] for ws in testWords] \n",
    "testWords = [del_stop(ws) for ws in testWords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lawsonite was contained a platinum crucible and counter-weight was a plastic crucible with metal pieces'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(trainWords[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['lawsonite'], ['platinum', 'crucible'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPn1[8], trainPn2[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Non-Causal'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1003"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in train_label if i == 'Causal']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([i for i in test_label if i == 'Causal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([len(trainWords[i]) for i in range(len(train_label))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([len(testWords[i]) for i in range(len(test_label))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([len(trainWords[i]) for i in range(len(train_label)) if train_label[i] == 'Causal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([len(testWords[i]) for i in range(len(test_label)) if test_label[i] == 'Causal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 45"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23594 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokWords = trainWords.copy()\n",
    "tokWords.extend(testWords)\n",
    "tokTexts = [' '.join(i) for i in tokWords]\n",
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(tokTexts)\n",
    "word2index = tokenizer.word_index\n",
    "index2word = {i: w for w, i in word2index.items()}\n",
    "print('Found %s unique tokens.' % len(word2index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Word Embeddings with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 23595\n",
    "EMBEDDING_SIZE = 300\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Glove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_n_symbols = 1917495\n",
    "glove_index_dict = {}\n",
    "glove_embedding_weights = np.empty((glove_n_symbols, EMBEDDING_SIZE))\n",
    "globale_scale = 0.1\n",
    "with open('/Users/lizhn7/Downloads/DATA/Glove/glove.42B.300d.txt', 'r') as fp:\n",
    "    index = 0\n",
    "    for l in fp:\n",
    "        l = l.strip().split()\n",
    "        word = l[0]\n",
    "        glove_index_dict[word] = index\n",
    "        glove_embedding_weights[index, :] = [float(n) for n in l[1:]]\n",
    "        index += 1\n",
    "glove_embedding_weights *= globale_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Glove to Initialize Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import WordNetLemmatizer, PorterStemmer, LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate random embedding with same scale as glove\n",
    "np.random.seed(SEED)\n",
    "shape = (VOCAB_SIZE, EMBEDDING_SIZE)\n",
    "scale = glove_embedding_weights.std() * np.sqrt(12) / 2 \n",
    "embedding = np.random.uniform(low=-scale, high=scale, size=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22393-94.91% tokens in vocab found in glove and copied to embedding.\n"
     ]
    }
   ],
   "source": [
    "# Copy from glove weights of words that appear in index2word\n",
    "count = 0 \n",
    "for i in range(1, VOCAB_SIZE):\n",
    "    w = index2word[i]\n",
    "    g = glove_index_dict.get(w)\n",
    "    if g is None:\n",
    "        w = wnl.lemmatize(w)\n",
    "        g = glove_index_dict.get(w)\n",
    "        if g is None:\n",
    "            w = porter.stem(w)\n",
    "            g = glove_index_dict.get(w)\n",
    "            if g is None:\n",
    "                w = lancaster.stem(w)\n",
    "                g = glove_index_dict.get(w)\n",
    "    if g is None:\n",
    "        w = porter.stem(w)\n",
    "        g = glove_index_dict.get(w)\n",
    "    if g is None:\n",
    "        w = lancaster.stem(w)\n",
    "        g = glove_index_dict.get(w)\n",
    "    if g is not None:\n",
    "        embedding[i, :] = glove_embedding_weights[g, :]\n",
    "        count += 1\n",
    "print('{num_tokens}-{per:.2f}% tokens in vocab found in glove and copied to embedding.'.format(num_tokens=count, per=count/float(VOCAB_SIZE)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dateset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelDict = {'Non-Causal': 0, 'Causal': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_seq(ws, label):\n",
    "    \"\"\"\n",
    "    Pad words sequene to MAX_LEN and encode label to one-hot encoding\n",
    "    \"\"\"\n",
    "    sentText = [' '.join(i) for i in ws]\n",
    "    sentSeq = tokenizer.texts_to_sequences(sentText)\n",
    "    sentData = pad_sequences(sentSeq, maxlen=MAX_LEN, padding='post', truncating='post')\n",
    "    labelData = np.array([[labelDict[i]] for i in label])\n",
    "    return sentData, labelData \n",
    "\n",
    "def convert_pn(pn):\n",
    "    \"\"\"\n",
    "    Convert data to paired-nominals word vectors\n",
    "    \"\"\"\n",
    "    pn = [[word2index[i.lower()] for i in p] for p in pn]\n",
    "    pn = np.array([sum([embedding[i] for i in p]) for p in pn])\n",
    "    return pn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, yTrain = convert_seq(trainWords, train_label)\n",
    "xTest, yTest = convert_seq(testWords, test_label)\n",
    "pn1_xTrain = convert_pn(trainPn1)\n",
    "pn2_xTrain = convert_pn(trainPn2)\n",
    "pn1_xTest = convert_pn(testPn1)\n",
    "pn2_xTest = convert_pn(testPn2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xTrain, _, yTrain, _ = train_test_split(xTrain, yTrain, test_size=0., random_state=SEED)\n",
    "xTest, _, yTest, _ = train_test_split(xTest, yTest, test_size=0., random_state=SEED)\n",
    "pn1_xTrain, _, pn2_xTrain, _ = train_test_split(pn1_xTrain, pn2_xTrain, test_size=0., random_state=SEED)\n",
    "pn1_xTest, _, pn2_xTest, _ = train_test_split(pn1_xTest, pn2_xTest, test_size=0., random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fh = h5py.File('/Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验_1/allData.h5', 'w')\n",
    "fh['xTrain'] = xTrain\n",
    "fh['yTrain'] = yTrain\n",
    "fh['xTest'] = xTest\n",
    "fh['yTest'] = yTest\n",
    "fh['pn1_xTrain'] = pn1_xTrain\n",
    "fh['pn2_xTrain'] = pn2_xTrain\n",
    "fh['pn1_xTest'] = pn1_xTest\n",
    "fh['pn2_xTest'] = pn2_xTest\n",
    "fh['embedding'] = embedding\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('/Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验_1/allData.h5', 'r') as fh:\n",
    "    xTrain = fh['xTrain'][:]\n",
    "    yTrain = fh['yTrain'][:]\n",
    "    xTest = fh['xTest'][:]\n",
    "    yTest = fh['yTest'][:]\n",
    "    pn1_xTrain = fh['pn1_xTrain'][:]\n",
    "    pn2_xTrain = fh['pn2_xTrain'][:]\n",
    "    pn1_xTest = fh['pn1_xTest'][:]\n",
    "    pn2_xTest = fh['pn2_xTest'][:]\n",
    "    embedding = fh['embedding'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 45\n",
    "VOCAB_SIZE = 23595\n",
    "EMBEDDING_SIZE = 300\n",
    "RNN_SIZE = 150\n",
    "DROPOUT_RATE = 0.5\n",
    "RNN_DROPOUT_RATE = 0.5\n",
    "CNN_SIZE = 128\n",
    "WINDOW_SIZE = 3\n",
    "NUM_EPOCHS = 64\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Dropout, Bidirectional, LSTM, Reshape, concatenate, Conv1D, BatchNormalization, GlobalMaxPooling1D, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import*\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "seq = Input(shape=(MAX_LEN,), name='INPUT') \n",
    "emb_seq = Embedding(VOCAB_SIZE, EMBEDDING_SIZE, weights=[embedding], mask_zero=False, input_length=MAX_LEN, trainable=False, name='EMBEDDING')(seq)\n",
    "blstm = Bidirectional(LSTM(RNN_SIZE, return_sequences=True, implementation=0, dropout=RNN_DROPOUT_RATE, recurrent_dropout=RNN_DROPOUT_RATE), merge_mode='concat', name='BiLSTM')(emb_seq)\n",
    "blstm = Dropout(DROPOUT_RATE, name='DROPOUT_1')(blstm)\n",
    "#blstm = BatchNormalization(axis=-1, name='BN_1')(blstm)\n",
    "pn1 = Input(shape=(EMBEDDING_SIZE,), name='PN1_INPUT')\n",
    "rpn1 = Reshape((1, EMBEDDING_SIZE))(pn1)\n",
    "pn2 = Input(shape=(EMBEDDING_SIZE,), name='PN2_INPUT')\n",
    "rpn2 = Reshape((1, EMBEDDING_SIZE))(pn2)\n",
    "context = concatenate([rpn1, blstm, rpn2], axis=-2, name='CONTEXT')\n",
    "conv = Conv1D(CNN_SIZE, WINDOW_SIZE, padding='same', activation='elu', name='CONV')(context)\n",
    "conv = Dropout(DROPOUT_RATE, name='DROPOUT_2')(conv)\n",
    "#conv = BatchNormalization(axis=-1, name='BN_2')(conv)\n",
    "pool = GlobalMaxPooling1D(name='MAXPOOLING')(conv)\n",
    "pool = Dropout(DROPOUT_RATE, name='DROPOUT_3')(pool)\n",
    "output = Dense(1, activation='sigmoid', name='OUTPUT')(pool)\n",
    "model = Model(inputs=[seq, pn1, pn2], outputs=output)\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.{epoch:03d}-{val_loss:.6f}.hdf5'\n",
    "#log_string = '/Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验_1/tb_logs/1'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "#tensorboard = TensorBoard(log_dir=log_string) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2717 samples\n",
      "Epoch 1/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.2678Epoch 00000: val_loss improved from inf to 0.29542, saving model to /Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.000-0.295421.hdf5\n",
      "8000/8000 [==============================] - 86s - loss: 0.2681 - val_loss: 0.2954\n",
      "Epoch 2/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1856Epoch 00001: val_loss improved from 0.29542 to 0.19145, saving model to /Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.001-0.191454.hdf5\n",
      "8000/8000 [==============================] - 80s - loss: 0.1861 - val_loss: 0.1915\n",
      "Epoch 3/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1714Epoch 00002: val_loss improved from 0.19145 to 0.19131, saving model to /Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.002-0.191312.hdf5\n",
      "8000/8000 [==============================] - 82s - loss: 0.1709 - val_loss: 0.1913\n",
      "Epoch 4/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1613Epoch 00003: val_loss improved from 0.19131 to 0.14295, saving model to /Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.003-0.142949.hdf5\n",
      "8000/8000 [==============================] - 83s - loss: 0.1611 - val_loss: 0.1429\n",
      "Epoch 5/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1521Epoch 00004: val_loss did not improve\n",
      "8000/8000 [==============================] - 83s - loss: 0.1520 - val_loss: 0.1680\n",
      "Epoch 6/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1535Epoch 00005: val_loss did not improve\n",
      "8000/8000 [==============================] - 83s - loss: 0.1531 - val_loss: 0.1668\n",
      "Epoch 7/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1378Epoch 00006: val_loss did not improve\n",
      "8000/8000 [==============================] - 82s - loss: 0.1376 - val_loss: 0.1859\n",
      "Epoch 8/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1412Epoch 00007: val_loss improved from 0.14295 to 0.13911, saving model to /Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.007-0.139111.hdf5\n",
      "8000/8000 [==============================] - 84s - loss: 0.1407 - val_loss: 0.1391\n",
      "Epoch 9/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1372Epoch 00008: val_loss did not improve\n",
      "8000/8000 [==============================] - 84s - loss: 0.1373 - val_loss: 0.1498\n",
      "Epoch 10/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1314Epoch 00009: val_loss improved from 0.13911 to 0.12375, saving model to /Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.009-0.123750.hdf5\n",
      "8000/8000 [==============================] - 87s - loss: 0.1310 - val_loss: 0.1237\n",
      "Epoch 11/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1272Epoch 00010: val_loss did not improve\n",
      "8000/8000 [==============================] - 84s - loss: 0.1269 - val_loss: 0.1319\n",
      "Epoch 12/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1210Epoch 00011: val_loss improved from 0.12375 to 0.10931, saving model to /Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.011-0.109312.hdf5\n",
      "8000/8000 [==============================] - 83s - loss: 0.1207 - val_loss: 0.1093\n",
      "Epoch 13/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1185Epoch 00012: val_loss did not improve\n",
      "8000/8000 [==============================] - 82s - loss: 0.1185 - val_loss: 0.1097\n",
      "Epoch 14/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1153Epoch 00013: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.1151 - val_loss: 0.1252\n",
      "Epoch 15/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1139Epoch 00014: val_loss improved from 0.10931 to 0.10219, saving model to /Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.014-0.102192.hdf5\n",
      "8000/8000 [==============================] - 81s - loss: 0.1145 - val_loss: 0.1022\n",
      "Epoch 16/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1101Epoch 00015: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.1100 - val_loss: 0.1029\n",
      "Epoch 17/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1099Epoch 00016: val_loss improved from 0.10219 to 0.09993, saving model to /Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.016-0.099932.hdf5\n",
      "8000/8000 [==============================] - 82s - loss: 0.1096 - val_loss: 0.0999\n",
      "Epoch 18/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1079Epoch 00017: val_loss did not improve\n",
      "8000/8000 [==============================] - 82s - loss: 0.1082 - val_loss: 0.1040\n",
      "Epoch 19/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1045Epoch 00018: val_loss improved from 0.09993 to 0.09858, saving model to /Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.018-0.098577.hdf5\n",
      "8000/8000 [==============================] - 81s - loss: 0.1048 - val_loss: 0.0986\n",
      "Epoch 20/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1023Epoch 00019: val_loss improved from 0.09858 to 0.09406, saving model to /Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.019-0.094063.hdf5\n",
      "8000/8000 [==============================] - 81s - loss: 0.1019 - val_loss: 0.0941\n",
      "Epoch 21/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.1010Epoch 00020: val_loss improved from 0.09406 to 0.09312, saving model to /Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.020-0.093119.hdf5\n",
      "8000/8000 [==============================] - 82s - loss: 0.1007 - val_loss: 0.0931\n",
      "Epoch 22/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0982Epoch 00021: val_loss improved from 0.09312 to 0.08886, saving model to /Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.021-0.088857.hdf5\n",
      "8000/8000 [==============================] - 81s - loss: 0.0983 - val_loss: 0.0889\n",
      "Epoch 23/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0958Epoch 00022: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0956 - val_loss: 0.0912\n",
      "Epoch 24/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0962Epoch 00023: val_loss improved from 0.08886 to 0.08535, saving model to /Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.023-0.085347.hdf5\n",
      "8000/8000 [==============================] - 81s - loss: 0.0962 - val_loss: 0.0853\n",
      "Epoch 25/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0894Epoch 00024: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0893 - val_loss: 0.0861\n",
      "Epoch 26/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0906Epoch 00025: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0909 - val_loss: 0.0884\n",
      "Epoch 27/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0848Epoch 00026: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0846 - val_loss: 0.1016\n",
      "Epoch 28/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0901Epoch 00027: val_loss improved from 0.08535 to 0.08446, saving model to /Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.027-0.084461.hdf5\n",
      "8000/8000 [==============================] - 81s - loss: 0.0898 - val_loss: 0.0845\n",
      "Epoch 29/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0861Epoch 00028: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0862 - val_loss: 0.0849\n",
      "Epoch 30/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0848Epoch 00029: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0846 - val_loss: 0.0938\n",
      "Epoch 31/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0827Epoch 00030: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 81s - loss: 0.0824 - val_loss: 0.0939\n",
      "Epoch 32/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0842Epoch 00031: val_loss did not improve\n",
      "8000/8000 [==============================] - 80s - loss: 0.0839 - val_loss: 0.0864\n",
      "Epoch 33/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0836Epoch 00032: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0833 - val_loss: 0.0865\n",
      "Epoch 34/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0797Epoch 00033: val_loss did not improve\n",
      "8000/8000 [==============================] - 80s - loss: 0.0794 - val_loss: 0.0852\n",
      "Epoch 35/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0807Epoch 00034: val_loss did not improve\n",
      "8000/8000 [==============================] - 80s - loss: 0.0805 - val_loss: 0.0857\n",
      "Epoch 36/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0806Epoch 00035: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0814 - val_loss: 0.0872\n",
      "Epoch 37/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0758Epoch 00036: val_loss did not improve\n",
      "8000/8000 [==============================] - 82s - loss: 0.0763 - val_loss: 0.0871\n",
      "Epoch 38/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0737Epoch 00037: val_loss did not improve\n",
      "8000/8000 [==============================] - 80s - loss: 0.0738 - val_loss: 0.0950\n",
      "Epoch 39/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0702Epoch 00038: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0701 - val_loss: 0.0943\n",
      "Epoch 40/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0725Epoch 00039: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0733 - val_loss: 0.0893\n",
      "Epoch 41/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0738Epoch 00040: val_loss did not improve\n",
      "8000/8000 [==============================] - 80s - loss: 0.0740 - val_loss: 0.0896\n",
      "Epoch 42/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0696Epoch 00041: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0695 - val_loss: 0.0950\n",
      "Epoch 43/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0682Epoch 00042: val_loss did not improve\n",
      "8000/8000 [==============================] - 82s - loss: 0.0681 - val_loss: 0.0925\n",
      "Epoch 44/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0679Epoch 00043: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0677 - val_loss: 0.0926\n",
      "Epoch 45/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0653Epoch 00044: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0654 - val_loss: 0.0954\n",
      "Epoch 46/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0627Epoch 00045: val_loss did not improve\n",
      "8000/8000 [==============================] - 85s - loss: 0.0633 - val_loss: 0.0999\n",
      "Epoch 47/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0679Epoch 00046: val_loss did not improve\n",
      "8000/8000 [==============================] - 82s - loss: 0.0684 - val_loss: 0.0925\n",
      "Epoch 48/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0619Epoch 00047: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0623 - val_loss: 0.1104\n",
      "Epoch 49/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0644Epoch 00048: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0642 - val_loss: 0.0954\n",
      "Epoch 50/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0615Epoch 00049: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0613 - val_loss: 0.0961\n",
      "Epoch 51/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0663Epoch 00050: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0670 - val_loss: 0.0948\n",
      "Epoch 52/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0577Epoch 00051: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0578 - val_loss: 0.0957\n",
      "Epoch 53/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0589Epoch 00052: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0589 - val_loss: 0.0957\n",
      "Epoch 54/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0529Epoch 00053: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0532 - val_loss: 0.1025\n",
      "Epoch 55/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0597Epoch 00054: val_loss did not improve\n",
      "8000/8000 [==============================] - 82s - loss: 0.0595 - val_loss: 0.0990\n",
      "Epoch 56/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0598Epoch 00055: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0598 - val_loss: 0.1047\n",
      "Epoch 57/64\n",
      "7968/8000 [============================>.] - ETA: 0s - loss: 0.0593Epoch 00056: val_loss did not improve\n",
      "8000/8000 [==============================] - 81s - loss: 0.0591 - val_loss: 0.1007\n",
      "Epoch 58/64\n",
      "4384/8000 [===============>..............] - ETA: 34s - loss: 0.0595"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-282-f3b7fabbddec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpn1_xTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpn2_xTest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                     shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit([xTrain, pn1_xTrain, pn2_xTrain],\n",
    "                    yTrain,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS, \n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpoint],\n",
    "                    validation_data=([xTest, pn1_xTest, pn2_xTest], yTest), \n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(xTrain,\n",
    "                    yTrain,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS, \n",
    "                    verbose=1,\n",
    "                    callbacks=[checkpoint],\n",
    "                    validation_data=(xTest, yTest), \n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#threshold = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "threshold = [i/10 for i in range(1, 9, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(pred, actu, THRESHOLD):\n",
    "    \"\"\"\n",
    "    Calculate Precision Recall F1-score\n",
    "    \"\"\"\n",
    "    pred = [1 if i >= THRESHOLD else 0 for i in pred]\n",
    "    actu = sum([list(i) for i in actu], [])\n",
    "    CTP = sum([1 for i in range(len(pred)) if pred[i] == 1 and actu[i] == 1])\n",
    "    CFN = sum([1 for i in range(len(pred)) if pred[i] == 0 and actu[i] == 1])\n",
    "    CFP = sum([1 for i in range(len(pred)) if pred[i] == 1 and actu[i] == 0])\n",
    "    CTN = sum([1 for i in range(len(pred)) if pred[i] == 0 and actu[i] == 0])\n",
    "    NCTP = CTN\n",
    "    NCFN = CFP\n",
    "    NCFP = CFN\n",
    "    NCTN = CTP\n",
    "    CP = CTP/(CTP+CFP)\n",
    "    CR = CTP/(CTP+CFN)\n",
    "    CF1 = 2*CP*CR/(CP+CR)\n",
    "    NCP = NCTP/(NCTP+NCFP)\n",
    "    NCR = NCTP/(NCTP+NCFN)\n",
    "    NCF1 = 2*NCP*NCR/(NCP+NCR)\n",
    "    ACC = (CTP+CTN)/(CTP+CFP+CFN+CTN)\n",
    "    print('Threshold: \\t%.3f' % (THRESHOLD))\n",
    "    print('Causal: \\tPreciion %.3f \\tRecall %.3f \\tF1-score %.3f' % (CP, CR, CF1))\n",
    "    print('Non-Causal: \\tPreciion %.3f \\tRecall %.3f \\tF1-score %.3f' % (NCP, NCR, NCF1))\n",
    "    print('Accuracy: \\t%.3f' % (ACC))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2717/2717 [==============================] - 8s     \n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "INPUT (InputLayer)               (None, 45)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "EMBEDDING (Embedding)            (None, 45, 300)       7078500     INPUT[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "PN1_INPUT (InputLayer)           (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "BiLSTM (Bidirectional)           (None, 45, 300)       541200      EMBEDDING[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "PN2_INPUT (InputLayer)           (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 1, 300)        0           PN1_INPUT[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "DROPOUT (Dropout)                (None, 45, 300)       0           BiLSTM[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)              (None, 1, 300)        0           PN2_INPUT[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "CONTEXT (Concatenate)            (None, 47, 300)       0           reshape_1[0][0]                  \n",
      "                                                                   DROPOUT[0][0]                    \n",
      "                                                                   reshape_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "CONV (Conv1D)                    (None, 47, 128)       115328      CONTEXT[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "MAXPOOLING (GlobalMaxPooling1D)  (None, 128)           0           CONV[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "OUTPUT (Dense)                   (None, 1)             129         MAXPOOLING[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 7,735,157\n",
      "Trainable params: 656,657\n",
      "Non-trainable params: 7,078,500\n",
      "____________________________________________________________________________________________________\n",
      "Threshold: \t0.100\n",
      "Causal: \tPreciion 0.736 \tRecall 0.927 \tF1-score 0.821\n",
      "Non-Causal: \tPreciion 0.990 \tRecall 0.954 \tF1-score 0.972\n",
      "Accuracy: \t0.951\n",
      "————————————————————————\n",
      "Threshold: \t0.200\n",
      "Causal: \tPreciion 0.827 \tRecall 0.918 \tF1-score 0.870\n",
      "Non-Causal: \tPreciion 0.989 \tRecall 0.974 \tF1-score 0.981\n",
      "Accuracy: \t0.967\n",
      "————————————————————————\n",
      "Threshold: \t0.300\n",
      "Causal: \tPreciion 0.864 \tRecall 0.912 \tF1-score 0.887\n",
      "Non-Causal: \tPreciion 0.988 \tRecall 0.980 \tF1-score 0.984\n",
      "Accuracy: \t0.972\n",
      "————————————————————————\n",
      "Threshold: \t0.400\n",
      "Causal: \tPreciion 0.899 \tRecall 0.896 \tF1-score 0.898\n",
      "Non-Causal: \tPreciion 0.986 \tRecall 0.986 \tF1-score 0.986\n",
      "Accuracy: \t0.975\n",
      "————————————————————————\n",
      "Threshold: \t0.500\n",
      "Causal: \tPreciion 0.933 \tRecall 0.893 \tF1-score 0.913\n",
      "Non-Causal: \tPreciion 0.985 \tRecall 0.991 \tF1-score 0.988\n",
      "Accuracy: \t0.979\n",
      "————————————————————————\n",
      "Threshold: \t0.600\n",
      "Causal: \tPreciion 0.947 \tRecall 0.869 \tF1-score 0.906\n",
      "Non-Causal: \tPreciion 0.982 \tRecall 0.993 \tF1-score 0.988\n",
      "Accuracy: \t0.978\n",
      "————————————————————————\n",
      "Threshold: \t0.700\n",
      "Causal: \tPreciion 0.955 \tRecall 0.848 \tF1-score 0.898\n",
      "Non-Causal: \tPreciion 0.979 \tRecall 0.995 \tF1-score 0.987\n",
      "Accuracy: \t0.977\n",
      "————————————————————————\n",
      "Threshold: \t0.800\n",
      "Causal: \tPreciion 0.960 \tRecall 0.805 \tF1-score 0.876\n",
      "Non-Causal: \tPreciion 0.974 \tRecall 0.995 \tF1-score 0.984\n",
      "Accuracy: \t0.972\n",
      "————————————————————————\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"556pt\" viewBox=\"0.00 0.00 601.58 556.00\" width=\"602pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 552)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-552 597.5757,-552 597.5757,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 10326763168 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>10326763168</title>\n",
       "<polygon fill=\"none\" points=\"57.521,-511.5 57.521,-547.5 183.6274,-547.5 183.6274,-511.5 57.521,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5742\" y=\"-525.3\">INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 9922364752 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>9922364752</title>\n",
       "<polygon fill=\"none\" points=\"34.6104,-438.5 34.6104,-474.5 206.5381,-474.5 206.5381,-438.5 34.6104,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5742\" y=\"-452.3\">EMBEDDING: Embedding</text>\n",
       "</g>\n",
       "<!-- 10326763168&#45;&gt;9922364752 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>10326763168-&gt;9922364752</title>\n",
       "<path d=\"M120.5742,-511.4551C120.5742,-503.3828 120.5742,-493.6764 120.5742,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"124.0743,-484.5903 120.5742,-474.5904 117.0743,-484.5904 124.0743,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 9922353864 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>9922353864</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 241.1484,-401.5 241.1484,-365.5 0,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5742\" y=\"-379.3\">BiLSTM(lstm_1): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 9922364752&#45;&gt;9922353864 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>9922364752-&gt;9922353864</title>\n",
       "<path d=\"M120.5742,-438.4551C120.5742,-430.3828 120.5742,-420.6764 120.5742,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"124.0743,-411.5903 120.5742,-401.5904 117.0743,-411.5904 124.0743,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 9922227560 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>9922227560</title>\n",
       "<polygon fill=\"none\" points=\"259.5728,-365.5 259.5728,-401.5 417.5757,-401.5 417.5757,-365.5 259.5728,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338.5742\" y=\"-379.3\">PN1_INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 9922227224 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>9922227224</title>\n",
       "<polygon fill=\"none\" points=\"274.7896,-292.5 274.7896,-328.5 402.3589,-328.5 402.3589,-292.5 274.7896,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338.5742\" y=\"-306.3\">reshape_1: Reshape</text>\n",
       "</g>\n",
       "<!-- 9922227560&#45;&gt;9922227224 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>9922227560-&gt;9922227224</title>\n",
       "<path d=\"M338.5742,-365.4551C338.5742,-357.3828 338.5742,-347.6764 338.5742,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"342.0743,-338.5903 338.5742,-328.5904 335.0743,-338.5904 342.0743,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 9932741600 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>9932741600</title>\n",
       "<polygon fill=\"none\" points=\"86.8384,-292.5 86.8384,-328.5 222.3101,-328.5 222.3101,-292.5 86.8384,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"154.5742\" y=\"-306.3\">DROPOUT: Dropout</text>\n",
       "</g>\n",
       "<!-- 9922353864&#45;&gt;9932741600 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>9922353864-&gt;9932741600</title>\n",
       "<path d=\"M128.9787,-365.4551C132.861,-357.1196 137.5548,-347.0416 141.8572,-337.8042\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"145.0992,-339.1331 146.1486,-328.5904 138.7537,-336.1776 145.0992,-339.1331\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 9922228008 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>9922228008</title>\n",
       "<polygon fill=\"none\" points=\"435.5728,-365.5 435.5728,-401.5 593.5757,-401.5 593.5757,-365.5 435.5728,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"514.5742\" y=\"-379.3\">PN2_INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 10029222824 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>10029222824</title>\n",
       "<polygon fill=\"none\" points=\"435.7896,-292.5 435.7896,-328.5 563.3589,-328.5 563.3589,-292.5 435.7896,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"499.5742\" y=\"-306.3\">reshape_2: Reshape</text>\n",
       "</g>\n",
       "<!-- 9922228008&#45;&gt;10029222824 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>9922228008-&gt;10029222824</title>\n",
       "<path d=\"M510.8664,-365.4551C509.1896,-357.2951 507.1698,-347.4652 505.3048,-338.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"508.7326,-337.6812 503.2914,-328.5904 501.8759,-339.0902 508.7326,-337.6812\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10343098520 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>10343098520</title>\n",
       "<polygon fill=\"none\" points=\"259.9727,-219.5 259.9727,-255.5 417.1758,-255.5 417.1758,-219.5 259.9727,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338.5742\" y=\"-233.3\">CONTEXT: Concatenate</text>\n",
       "</g>\n",
       "<!-- 9922227224&#45;&gt;10343098520 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>9922227224-&gt;10343098520</title>\n",
       "<path d=\"M338.5742,-292.4551C338.5742,-284.3828 338.5742,-274.6764 338.5742,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"342.0743,-265.5903 338.5742,-255.5904 335.0743,-265.5904 342.0743,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 9932741600&#45;&gt;10343098520 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>9932741600-&gt;10343098520</title>\n",
       "<path d=\"M200.0574,-292.4551C225.2692,-282.4525 256.8059,-269.9407 283.4164,-259.3833\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"284.9721,-262.5315 292.9766,-255.5904 282.3907,-256.0249 284.9721,-262.5315\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10029222824&#45;&gt;10343098520 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>10029222824-&gt;10343098520</title>\n",
       "<path d=\"M459.7765,-292.4551C438.0064,-282.5841 410.8467,-270.2695 387.7586,-259.801\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"389.025,-256.5323 378.4721,-255.5904 386.1343,-262.9076 389.025,-256.5323\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 9922227504 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>9922227504</title>\n",
       "<polygon fill=\"none\" points=\"283.8369,-146.5 283.8369,-182.5 393.3115,-182.5 393.3115,-146.5 283.8369,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338.5742\" y=\"-160.3\">CONV: Conv1D</text>\n",
       "</g>\n",
       "<!-- 10343098520&#45;&gt;9922227504 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>10343098520-&gt;9922227504</title>\n",
       "<path d=\"M338.5742,-219.4551C338.5742,-211.3828 338.5742,-201.6764 338.5742,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"342.0743,-192.5903 338.5742,-182.5904 335.0743,-192.5904 342.0743,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10363070784 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>10363070784</title>\n",
       "<polygon fill=\"none\" points=\"217.6035,-73.5 217.6035,-109.5 459.5449,-109.5 459.5449,-73.5 217.6035,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338.5742\" y=\"-87.3\">MAXPOOLING: GlobalMaxPooling1D</text>\n",
       "</g>\n",
       "<!-- 9922227504&#45;&gt;10363070784 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>9922227504-&gt;10363070784</title>\n",
       "<path d=\"M338.5742,-146.4551C338.5742,-138.3828 338.5742,-128.6764 338.5742,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"342.0743,-119.5903 338.5742,-109.5904 335.0743,-119.5904 342.0743,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10343501216 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>10343501216</title>\n",
       "<polygon fill=\"none\" points=\"282.1245,-.5 282.1245,-36.5 395.0239,-36.5 395.0239,-.5 282.1245,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338.5742\" y=\"-14.3\">OUTPUT: Dense</text>\n",
       "</g>\n",
       "<!-- 10363070784&#45;&gt;10343501216 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>10363070784-&gt;10343501216</title>\n",
       "<path d=\"M338.5742,-73.4551C338.5742,-65.3828 338.5742,-55.6764 338.5742,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"342.0743,-46.5903 338.5742,-36.5904 335.0743,-46.5904 342.0743,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/1/weights.012-0.080162.hdf5'\n",
    "model.load_weights(filename)\n",
    "result = model.predict([xTest, pn1_xTest, pn2_xTest], batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "for THRESHOLD in threshold:\n",
    "    calculate(result, yTest, THRESHOLD)\n",
    "    print('————————————————————————')\n",
    "    \n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2717/2717 [==============================] - 9s     \n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "INPUT (InputLayer)           (None, 45)                0         \n",
      "_________________________________________________________________\n",
      "EMBEDDING (Embedding)        (None, 45, 300)           7078500   \n",
      "_________________________________________________________________\n",
      "BiLSTM (Bidirectional)       (None, 45, 300)           541200    \n",
      "_________________________________________________________________\n",
      "DROPOUT (Dropout)            (None, 45, 300)           0         \n",
      "_________________________________________________________________\n",
      "CONV (Conv1D)                (None, 45, 128)           115328    \n",
      "_________________________________________________________________\n",
      "MAXPOOLING (GlobalMaxPooling (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "OUTPUT (Dense)               (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 7,735,157\n",
      "Trainable params: 656,657\n",
      "Non-trainable params: 7,078,500\n",
      "_________________________________________________________________\n",
      "Threshold: \t0.100\n",
      "Causal: \tPreciion 0.729 \tRecall 0.918 \tF1-score 0.812\n",
      "Non-Causal: \tPreciion 0.988 \tRecall 0.953 \tF1-score 0.970\n",
      "Accuracy: \t0.949\n",
      "————————————————————————\n",
      "Threshold: \t0.200\n",
      "Causal: \tPreciion 0.817 \tRecall 0.884 \tF1-score 0.849\n",
      "Non-Causal: \tPreciion 0.984 \tRecall 0.973 \tF1-score 0.978\n",
      "Accuracy: \t0.962\n",
      "————————————————————————\n",
      "Threshold: \t0.300\n",
      "Causal: \tPreciion 0.865 \tRecall 0.860 \tF1-score 0.862\n",
      "Non-Causal: \tPreciion 0.981 \tRecall 0.982 \tF1-score 0.981\n",
      "Accuracy: \t0.967\n",
      "————————————————————————\n",
      "Threshold: \t0.400\n",
      "Causal: \tPreciion 0.885 \tRecall 0.845 \tF1-score 0.864\n",
      "Non-Causal: \tPreciion 0.979 \tRecall 0.985 \tF1-score 0.982\n",
      "Accuracy: \t0.968\n",
      "————————————————————————\n",
      "Threshold: \t0.500\n",
      "Causal: \tPreciion 0.909 \tRecall 0.820 \tF1-score 0.862\n",
      "Non-Causal: \tPreciion 0.976 \tRecall 0.989 \tF1-score 0.982\n",
      "Accuracy: \t0.968\n",
      "————————————————————————\n",
      "Threshold: \t0.600\n",
      "Causal: \tPreciion 0.928 \tRecall 0.790 \tF1-score 0.853\n",
      "Non-Causal: \tPreciion 0.972 \tRecall 0.992 \tF1-score 0.982\n",
      "Accuracy: \t0.967\n",
      "————————————————————————\n",
      "Threshold: \t0.700\n",
      "Causal: \tPreciion 0.932 \tRecall 0.750 \tF1-score 0.831\n",
      "Non-Causal: \tPreciion 0.967 \tRecall 0.992 \tF1-score 0.979\n",
      "Accuracy: \t0.963\n",
      "————————————————————————\n",
      "Threshold: \t0.800\n",
      "Causal: \tPreciion 0.942 \tRecall 0.695 \tF1-score 0.800\n",
      "Non-Causal: \tPreciion 0.960 \tRecall 0.994 \tF1-score 0.977\n",
      "Accuracy: \t0.958\n",
      "————————————————————————\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"483pt\" viewBox=\"0.00 0.00 249.94 483.00\" width=\"250pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 479)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-479 245.9414,-479 245.9414,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 10328243896 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>10328243896</title>\n",
       "<polygon fill=\"none\" points=\"57.9175,-438.5 57.9175,-474.5 184.0239,-474.5 184.0239,-438.5 57.9175,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.9707\" y=\"-452.3\">INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 10247107696 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>10247107696</title>\n",
       "<polygon fill=\"none\" points=\"35.0068,-365.5 35.0068,-401.5 206.9346,-401.5 206.9346,-365.5 35.0068,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.9707\" y=\"-379.3\">EMBEDDING: Embedding</text>\n",
       "</g>\n",
       "<!-- 10328243896&#45;&gt;10247107696 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>10328243896-&gt;10247107696</title>\n",
       "<path d=\"M120.9707,-438.4551C120.9707,-430.3828 120.9707,-420.6764 120.9707,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"124.4708,-411.5903 120.9707,-401.5904 117.4708,-411.5904 124.4708,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10328225160 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>10328225160</title>\n",
       "<polygon fill=\"none\" points=\".3965,-292.5 .3965,-328.5 241.5449,-328.5 241.5449,-292.5 .3965,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.9707\" y=\"-306.3\">BiLSTM(lstm_1): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 10247107696&#45;&gt;10328225160 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>10247107696-&gt;10328225160</title>\n",
       "<path d=\"M120.9707,-365.4551C120.9707,-357.3828 120.9707,-347.6764 120.9707,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"124.4708,-338.5903 120.9707,-328.5904 117.4708,-338.5904 124.4708,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10332041680 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>10332041680</title>\n",
       "<polygon fill=\"none\" points=\"53.2349,-219.5 53.2349,-255.5 188.7065,-255.5 188.7065,-219.5 53.2349,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.9707\" y=\"-233.3\">DROPOUT: Dropout</text>\n",
       "</g>\n",
       "<!-- 10328225160&#45;&gt;10332041680 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>10328225160-&gt;10332041680</title>\n",
       "<path d=\"M120.9707,-292.4551C120.9707,-284.3828 120.9707,-274.6764 120.9707,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"124.4708,-265.5903 120.9707,-255.5904 117.4708,-265.5904 124.4708,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10326745888 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>10326745888</title>\n",
       "<polygon fill=\"none\" points=\"66.2334,-146.5 66.2334,-182.5 175.708,-182.5 175.708,-146.5 66.2334,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.9707\" y=\"-160.3\">CONV: Conv1D</text>\n",
       "</g>\n",
       "<!-- 10332041680&#45;&gt;10326745888 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>10332041680-&gt;10326745888</title>\n",
       "<path d=\"M120.9707,-219.4551C120.9707,-211.3828 120.9707,-201.6764 120.9707,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"124.4708,-192.5903 120.9707,-182.5904 117.4708,-192.5904 124.4708,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10326746168 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>10326746168</title>\n",
       "<polygon fill=\"none\" points=\"0,-73.5 0,-109.5 241.9414,-109.5 241.9414,-73.5 0,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.9707\" y=\"-87.3\">MAXPOOLING: GlobalMaxPooling1D</text>\n",
       "</g>\n",
       "<!-- 10326745888&#45;&gt;10326746168 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>10326745888-&gt;10326746168</title>\n",
       "<path d=\"M120.9707,-146.4551C120.9707,-138.3828 120.9707,-128.6764 120.9707,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"124.4708,-119.5903 120.9707,-109.5904 117.4708,-119.5904 124.4708,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10159476464 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>10159476464</title>\n",
       "<polygon fill=\"none\" points=\"64.521,-.5 64.521,-36.5 177.4204,-36.5 177.4204,-.5 64.521,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.9707\" y=\"-14.3\">OUTPUT: Dense</text>\n",
       "</g>\n",
       "<!-- 10326746168&#45;&gt;10159476464 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>10326746168-&gt;10159476464</title>\n",
       "<path d=\"M120.9707,-73.4551C120.9707,-65.3828 120.9707,-55.6764 120.9707,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"124.4708,-46.5903 120.9707,-36.5904 117.4708,-46.5904 124.4708,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/2/weights.008-0.099124.hdf5'\n",
    "model.load_weights(filename)\n",
    "result = model.predict(xTest, batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "model.summary()\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n",
    "\n",
    "for THRESHOLD in threshold:\n",
    "    calculate(result, yTest, THRESHOLD)\n",
    "    print('————————————————————————')\n",
    "    \n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2717/2717 [==============================] - 10s    \n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "INPUT (InputLayer)               (None, 45)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "EMBEDDING (Embedding)            (None, 45, 300)       7078500     INPUT[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "PN1_INPUT (InputLayer)           (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "BiLSTM (Bidirectional)           (None, 45, 300)       541200      EMBEDDING[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "PN2_INPUT (InputLayer)           (None, 300)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)              (None, 1, 300)        0           PN1_INPUT[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "DROPOUT (Dropout)                (None, 45, 300)       0           BiLSTM[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)              (None, 1, 300)        0           PN2_INPUT[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "CONTEXT (Concatenate)            (None, 47, 300)       0           reshape_1[0][0]                  \n",
      "                                                                   DROPOUT[0][0]                    \n",
      "                                                                   reshape_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "CONV (Conv1D)                    (None, 47, 128)       115328      CONTEXT[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "BN (BatchNormalization)          (None, 47, 128)       512         CONV[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "MAXPOOLING (GlobalMaxPooling1D)  (None, 128)           0           BN[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "OUTPUT (Dense)                   (None, 1)             129         MAXPOOLING[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 7,735,669\n",
      "Trainable params: 656,913\n",
      "Non-trainable params: 7,078,756\n",
      "____________________________________________________________________________________________________\n",
      "Threshold: \t0.100\n",
      "Causal: \tPreciion 0.740 \tRecall 0.936 \tF1-score 0.826\n",
      "Non-Causal: \tPreciion 0.991 \tRecall 0.955 \tF1-score 0.973\n",
      "Accuracy: \t0.953\n",
      "————————————————————————\n",
      "Threshold: \t0.200\n",
      "Causal: \tPreciion 0.827 \tRecall 0.921 \tF1-score 0.872\n",
      "Non-Causal: \tPreciion 0.989 \tRecall 0.974 \tF1-score 0.981\n",
      "Accuracy: \t0.967\n",
      "————————————————————————\n",
      "Threshold: \t0.300\n",
      "Causal: \tPreciion 0.869 \tRecall 0.909 \tF1-score 0.888\n",
      "Non-Causal: \tPreciion 0.987 \tRecall 0.981 \tF1-score 0.984\n",
      "Accuracy: \t0.972\n",
      "————————————————————————\n",
      "Threshold: \t0.400\n",
      "Causal: \tPreciion 0.902 \tRecall 0.902 \tF1-score 0.902\n",
      "Non-Causal: \tPreciion 0.987 \tRecall 0.987 \tF1-score 0.987\n",
      "Accuracy: \t0.976\n",
      "————————————————————————\n",
      "Threshold: \t0.500\n",
      "Causal: \tPreciion 0.917 \tRecall 0.881 \tF1-score 0.899\n",
      "Non-Causal: \tPreciion 0.984 \tRecall 0.989 \tF1-score 0.986\n",
      "Accuracy: \t0.976\n",
      "————————————————————————\n",
      "Threshold: \t0.600\n",
      "Causal: \tPreciion 0.929 \tRecall 0.872 \tF1-score 0.899\n",
      "Non-Causal: \tPreciion 0.983 \tRecall 0.991 \tF1-score 0.987\n",
      "Accuracy: \t0.976\n",
      "————————————————————————\n",
      "Threshold: \t0.700\n",
      "Causal: \tPreciion 0.939 \tRecall 0.851 \tF1-score 0.893\n",
      "Non-Causal: \tPreciion 0.980 \tRecall 0.992 \tF1-score 0.986\n",
      "Accuracy: \t0.975\n",
      "————————————————————————\n",
      "Threshold: \t0.800\n",
      "Causal: \tPreciion 0.958 \tRecall 0.826 \tF1-score 0.887\n",
      "Non-Causal: \tPreciion 0.977 \tRecall 0.995 \tF1-score 0.986\n",
      "Accuracy: \t0.975\n",
      "————————————————————————\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"629pt\" viewBox=\"0.00 0.00 601.58 629.00\" width=\"602pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 625)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-625 597.5757,-625 597.5757,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 10052520088 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>10052520088</title>\n",
       "<polygon fill=\"none\" points=\"57.521,-584.5 57.521,-620.5 183.6274,-620.5 183.6274,-584.5 57.521,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5742\" y=\"-598.3\">INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 10198726528 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>10198726528</title>\n",
       "<polygon fill=\"none\" points=\"34.6104,-511.5 34.6104,-547.5 206.5381,-547.5 206.5381,-511.5 34.6104,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5742\" y=\"-525.3\">EMBEDDING: Embedding</text>\n",
       "</g>\n",
       "<!-- 10052520088&#45;&gt;10198726528 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>10052520088-&gt;10198726528</title>\n",
       "<path d=\"M120.5742,-584.4551C120.5742,-576.3828 120.5742,-566.6764 120.5742,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"124.0743,-557.5903 120.5742,-547.5904 117.0743,-557.5904 124.0743,-557.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10198726808 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>10198726808</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 241.1484,-474.5 241.1484,-438.5 0,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.5742\" y=\"-452.3\">BiLSTM(lstm_1): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 10198726528&#45;&gt;10198726808 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>10198726528-&gt;10198726808</title>\n",
       "<path d=\"M120.5742,-511.4551C120.5742,-503.3828 120.5742,-493.6764 120.5742,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"124.0743,-484.5903 120.5742,-474.5904 117.0743,-484.5904 124.0743,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10046847576 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>10046847576</title>\n",
       "<polygon fill=\"none\" points=\"259.5728,-438.5 259.5728,-474.5 417.5757,-474.5 417.5757,-438.5 259.5728,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338.5742\" y=\"-452.3\">PN1_INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 10046845840 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>10046845840</title>\n",
       "<polygon fill=\"none\" points=\"274.7896,-365.5 274.7896,-401.5 402.3589,-401.5 402.3589,-365.5 274.7896,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338.5742\" y=\"-379.3\">reshape_1: Reshape</text>\n",
       "</g>\n",
       "<!-- 10046847576&#45;&gt;10046845840 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>10046847576-&gt;10046845840</title>\n",
       "<path d=\"M338.5742,-438.4551C338.5742,-430.3828 338.5742,-420.6764 338.5742,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"342.0743,-411.5903 338.5742,-401.5904 335.0743,-411.5904 342.0743,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10335806688 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>10335806688</title>\n",
       "<polygon fill=\"none\" points=\"86.8384,-365.5 86.8384,-401.5 222.3101,-401.5 222.3101,-365.5 86.8384,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"154.5742\" y=\"-379.3\">DROPOUT: Dropout</text>\n",
       "</g>\n",
       "<!-- 10198726808&#45;&gt;10335806688 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>10198726808-&gt;10335806688</title>\n",
       "<path d=\"M128.9787,-438.4551C132.861,-430.1196 137.5548,-420.0416 141.8572,-410.8042\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"145.0992,-412.1331 146.1486,-401.5904 138.7537,-409.1776 145.0992,-412.1331\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10046848024 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>10046848024</title>\n",
       "<polygon fill=\"none\" points=\"435.5728,-438.5 435.5728,-474.5 593.5757,-474.5 593.5757,-438.5 435.5728,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"514.5742\" y=\"-452.3\">PN2_INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 10052273880 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>10052273880</title>\n",
       "<polygon fill=\"none\" points=\"435.7896,-365.5 435.7896,-401.5 563.3589,-401.5 563.3589,-365.5 435.7896,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"499.5742\" y=\"-379.3\">reshape_2: Reshape</text>\n",
       "</g>\n",
       "<!-- 10046848024&#45;&gt;10052273880 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>10046848024-&gt;10052273880</title>\n",
       "<path d=\"M510.8664,-438.4551C509.1896,-430.2951 507.1698,-420.4652 505.3048,-411.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"508.7326,-410.6812 503.2914,-401.5904 501.8759,-412.0902 508.7326,-410.6812\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10238960864 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>10238960864</title>\n",
       "<polygon fill=\"none\" points=\"259.9727,-292.5 259.9727,-328.5 417.1758,-328.5 417.1758,-292.5 259.9727,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338.5742\" y=\"-306.3\">CONTEXT: Concatenate</text>\n",
       "</g>\n",
       "<!-- 10046845840&#45;&gt;10238960864 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>10046845840-&gt;10238960864</title>\n",
       "<path d=\"M338.5742,-365.4551C338.5742,-357.3828 338.5742,-347.6764 338.5742,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"342.0743,-338.5903 338.5742,-328.5904 335.0743,-338.5904 342.0743,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10335806688&#45;&gt;10238960864 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>10335806688-&gt;10238960864</title>\n",
       "<path d=\"M200.0574,-365.4551C225.2692,-355.4525 256.8059,-342.9407 283.4164,-332.3833\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"284.9721,-335.5315 292.9766,-328.5904 282.3907,-329.0249 284.9721,-335.5315\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10052273880&#45;&gt;10238960864 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>10052273880-&gt;10238960864</title>\n",
       "<path d=\"M459.7765,-365.4551C438.0064,-355.5841 410.8467,-343.2695 387.7586,-332.801\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"389.025,-329.5323 378.4721,-328.5904 386.1343,-335.9076 389.025,-329.5323\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10046848360 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>10046848360</title>\n",
       "<polygon fill=\"none\" points=\"283.8369,-219.5 283.8369,-255.5 393.3115,-255.5 393.3115,-219.5 283.8369,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338.5742\" y=\"-233.3\">CONV: Conv1D</text>\n",
       "</g>\n",
       "<!-- 10238960864&#45;&gt;10046848360 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>10238960864-&gt;10046848360</title>\n",
       "<path d=\"M338.5742,-292.4551C338.5742,-284.3828 338.5742,-274.6764 338.5742,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"342.0743,-265.5903 338.5742,-255.5904 335.0743,-265.5904 342.0743,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10247108256 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>10247108256</title>\n",
       "<polygon fill=\"none\" points=\"260.3965,-146.5 260.3965,-182.5 416.752,-182.5 416.752,-146.5 260.3965,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338.5742\" y=\"-160.3\">BN: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 10046848360&#45;&gt;10247108256 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>10046848360-&gt;10247108256</title>\n",
       "<path d=\"M338.5742,-219.4551C338.5742,-211.3828 338.5742,-201.6764 338.5742,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"342.0743,-192.5903 338.5742,-182.5904 335.0743,-192.5904 342.0743,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10364284712 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>10364284712</title>\n",
       "<polygon fill=\"none\" points=\"217.6035,-73.5 217.6035,-109.5 459.5449,-109.5 459.5449,-73.5 217.6035,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338.5742\" y=\"-87.3\">MAXPOOLING: GlobalMaxPooling1D</text>\n",
       "</g>\n",
       "<!-- 10247108256&#45;&gt;10364284712 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>10247108256-&gt;10364284712</title>\n",
       "<path d=\"M338.5742,-146.4551C338.5742,-138.3828 338.5742,-128.6764 338.5742,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"342.0743,-119.5903 338.5742,-109.5904 335.0743,-119.5904 342.0743,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10364268328 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>10364268328</title>\n",
       "<polygon fill=\"none\" points=\"282.1245,-.5 282.1245,-36.5 395.0239,-36.5 395.0239,-.5 282.1245,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338.5742\" y=\"-14.3\">OUTPUT: Dense</text>\n",
       "</g>\n",
       "<!-- 10364284712&#45;&gt;10364268328 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>10364284712-&gt;10364268328</title>\n",
       "<path d=\"M338.5742,-73.4551C338.5742,-65.3828 338.5742,-55.6764 338.5742,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"342.0743,-46.5903 338.5742,-36.5904 335.0743,-46.5904 342.0743,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '/Users/lizhn7/Downloads/DATA/semeval2010_task8_all_data/因果关系检测实验/cp_logs/3/weights.006-0.080508.hdf5'\n",
    "model.load_weights(filename)\n",
    "result = model.predict([xTest, pn1_xTest, pn2_xTest], batch_size=BATCH_SIZE, verbose=1)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "for THRESHOLD in threshold:\n",
    "    calculate(result, yTest, THRESHOLD)\n",
    "    print('————————————————————————')\n",
    "    \n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "192px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
