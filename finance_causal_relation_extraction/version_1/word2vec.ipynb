{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gensim\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load date from file\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file) as f:\n",
    "        lines = f.readlines()\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class data_for_word2vec:\n",
    "    \"\"\"\n",
    "    Generate trianing data for word2vec\n",
    "    \"\"\"\n",
    "    def __iter__(self):\n",
    "        for c in content:\n",
    "            item = json.loads(c)\n",
    "            yield item['contWords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_1 = load_data('/Users/lizhn7/Downloads/EXPERIMENT/finance_causal_relation_extraction/corpus/version_1/content_1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"contWords\": [\"南\", \"都\", \"讯\", \"记者\", \"刘\", \"凡\", \"周\", \"昌\", \"和\", \"任\", \"笑\", \"一\", \"继\", \"推出\", \"日\", \"票\", \"后\", \"深圳\", \"今后\", \"将\", \"设\", \"地铁\", \"头等\", \"车厢\", \"设\", \"坐票\", \"制\", \"昨日\", \"《\", \"南都     \", \"》\", \"创刊\", \"仪式\", \"暨\", \"年\", \"深港\", \"地铁\", \"圈\", \"高峰论坛\", \"上\", \"透露\", \"在\", \"未来\", \"的\", \"号\", \"线\", \"上将\", \"增加\", \"特色\", \"服务\", \"满足\", \"不同\", \"消费\", \"层次\", \"的\", \"乘客\", \"的\", \"不同\", \"需求\", \"如\", \"特设\", \"行李架\", \"的\", \"车厢\", \"和\", \"买\", \"双倍\", \"票\", \"可\", \"有\", \"座位\", \"坐\", \"的\", \"车厢\", \"等\", \"论坛\", \"上\", \"深圳市政府\", \"副\", \"秘书长\", \"轨道交通\", \"建设\", \"办公室\", \"主任\", \"赵\", \"鹏\", \"林\", \"透露\", \"地铁\", \"未来\", \"的\", \"方向\", \"将\", \"分等级\", \"满足\", \"不同\", \"层次\", \"的\", \"人\", \"的\", \"需求\", \"提供\", \"不同\", \"层次\", \"的\", \"有\", \"针对\", \"的\", \"服务\", \"其中\", \"包括\", \"一些\", \"档次\", \"稍微\", \"高\", \"一些\", \"的\", \"服务\", \"“\", \"我们\", \"要\", \"让\", \"公共交通\", \"也\", \"能\", \"满足\", \"档次\", \"稍\", \"高\", \"一些\", \"的\", \"服务\", \"”\", \"比如\", \"尝试\", \"有\", \"座位\", \"的\", \"地铁票\", \"服务\", \"尤其\", \"是\", \"一些\", \"远道而来\", \"的\", \"乘客\", \"通过\", \"提供\", \"坐票\", \"服务\", \"让\", \"乘坐\", \"地铁\", \"也\", \"能\", \"享受\", \"到\", \"非常\", \"舒适\", \"的\", \"体验\", \"他\", \"说\", \"这种\", \"坐票\", \"的\", \"服务\", \"有望\", \"在\", \"地铁\", \"期\", \"上\", \"实行\", \"将\", \"加挂\", \"节车厢\", \"以\", \"实施\", \"花钱\", \"可\", \"买\", \"座位\", \"的\", \"服务\", \"“\", \"我们\", \"希望\", \"轨道交通\", \"和\", \"家里\", \"开\", \"的\", \"车\", \"一样\", \"分\", \"很\", \"多种\", \"”\", \"赵\", \"鹏\", \"林\", \"说\", \"比如\", \"有些\", \"地铁\", \"是\", \"“\", \"观光线\", \"”\", \"不仅\", \"沿途\", \"的\", \"风光\", \"非常\", \"好\", \"还\", \"能\", \"凭\", \"一张\", \"票\", \"无数次\", \"上下\", \"如同\", \"旅游\", \"时\", \"提供\", \"的\", \"“\", \"通票服务\", \"”\", \"再\", \"比如\", \"设立\", \"可以\", \"放\", \"大件\", \"行李\", \"的\", \"车厢\", \"今后\", \"通过\", \"设\", \"专门\", \"可\", \"放\", \"大件\", \"行李\", \"的\", \"座位\", \"避免\", \"像\", \"现在\", \"放\", \"行李\", \"不\", \"太\", \"方便\", \"的\", \"现象\", \"“\", \"未来\", \"地铁\", \"初步\", \"不仅\", \"在\", \"干线\", \"上\", \"铺设\", \"还\", \"会\", \"在\", \"支线\", \"城际\", \"线\", \"上去\", \"建设\", \"”\", \"“\", \"觉得\", \"如果\", \"车费\", \"不\", \"太贵\", \"的话\", \"还是\", \"愿意\", \"考虑\", \"的\", \"”\", \"昨日\", \"市民\", \"黄\", \"小姐\", \"表示\", \"尤其\", \"是从\", \"老街\", \"到\", \"机场\", \"这\", \"一段\", \"老街\", \"站\", \"每次\", \"上下\", \"客\", \"都\", \"很多\", \"人\", \"而\", \"如果\", \"赶上\", \"上下班\", \"高峰期\", \"特别\", \"拥挤\", \"要\", \"一路\", \"从\", \"老街\", \"站\", \"站\", \"到\", \"机场\", \"分钟\", \"还是\", \"挺\", \"吃力\", \"的\", \"宁愿\", \"多\", \"花\", \"点\", \"钱\", \"也\", \"能\", \"稍微\", \"舒适\", \"一点\", \"但是\", \"白领\", \"林先生\", \"则\", \"表示\", \"自己\", \"每天\", \"上下班\", \"都\", \"要\", \"坐地铁\", \"出\", \"双倍\", \"车资\", \"买\", \"坐票\", \"费用\", \"有点\", \"高\"]}\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_1 = load_data('/Users/lizhn7/Downloads/DATA/chinese_news/word2vec/content_1.json')\n",
    "content_2 = load_data('/Users/lizhn7/Downloads/DATA/chinese_news/word2vec/content_1.json')\n",
    "content_3 = load_data('/Users/lizhn7/Downloads/DATA/chinese_news/word2vec/content_1.json')\n",
    "\n",
    "content = []\n",
    "content.extend(content_1)\n",
    "content.extend(content_2)\n",
    "content.extend(content_3)\n",
    "\n",
    "trainWords, _, _, _ = train_test_split(content, content, test_size=0., random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WORD_SIZE = 256\n",
    "SEED = 42\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', \n",
    "                    level=logging.INFO)\n",
    "word2vec = gensim.models.Word2Vec(data_for_word2vec(),\n",
    "                                  min_count=8,\n",
    "                                  size=WORD_SIZE,\n",
    "                                  workers=25,\n",
    "                                  iter=10,\n",
    "                                  window=10,\n",
    "                                  sg=1,\n",
    "                                  hs=1)\n",
    "\n",
    "word2vec.save('word2vec')\n",
    "word2vec.init_sims(replace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "48px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
