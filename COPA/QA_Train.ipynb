{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('embedding.h5', 'r') as fh:\n",
    "    embedding = fh['embedding'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('train.h5', 'r') as fh:\n",
    "    xpTrain = fh['xpTrain'][:]\n",
    "    xaTrain = fh['xaTrain'][:]\n",
    "    xVal = fh['xVal'][:]\n",
    "    yTrain = fh['yTrain'][:]\n",
    "    yVal = fh['yVal'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('test.h5', 'r') as fh:\n",
    "    xpTest = fh['xpTest'][:]\n",
    "    xa1Test = fh['xa1Test'][:]\n",
    "    xa2Test = fh['xa2Test'][:]\n",
    "    yTest = fh['yTest'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xpVal = np.vstack((xpTest, xpTest))\n",
    "xaVal = xVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "DELTA = 0.009\n",
    "MAX_P_LEN = 13\n",
    "MAX_A_LEN = 11\n",
    "VOCAB_SIZE = 3371\n",
    "SEED = 42\n",
    "EMBEDDING_DIM = 300\n",
    "TUNE = False\n",
    "BATCH_SIZE = 200\n",
    "NUM_EPOCHS = 1024\n",
    "CNN_SIZE = 64\n",
    "WINDOW_SIZE = 3\n",
    "L2_NORM = 1e-4\n",
    "WEIGHT_CONSTRAINT = 3.\n",
    "DROPOUT_RATE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D\n",
    "from keras.layers import Dense, Dropout, Activation, Lambda, dot\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import*\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Define hinge loss function\n",
    "    \"\"\"\n",
    "    return K.mean(K.maximum(DELTA - y_true * y_pred, 0.), axis=-1)\n",
    "\n",
    "def build():\n",
    "    \"\"\"\n",
    "    Build model\n",
    "    \"\"\"\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(None,))\n",
    "    emb_seq = Embedding(VOCAB_SIZE, \n",
    "                        EMBEDDING_DIM, \n",
    "                        weights=[embedding], \n",
    "                        mask_zero=False, \n",
    "                        trainable=TUNE)(inputs)\n",
    "    conv = Conv1D(CNN_SIZE, \n",
    "                  WINDOW_SIZE, \n",
    "                  padding='same', \n",
    "                  activation=None,\n",
    "                  kernel_regularizer=l2(L2_NORM),\n",
    "                  kernel_constraint=maxnorm(WEIGHT_CONSTRAINT))(emb_seq)\n",
    "    conv = BatchNormalization()(conv)\n",
    "    conv = Activation('relu')(conv)\n",
    "    pool = GlobalMaxPooling1D()(conv)\n",
    "    pool = Dropout(DROPOUT_RATE)(pool)\n",
    "    outputs = Activation('tanh')(pool)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model\n",
    "\n",
    "model = build()\n",
    "p_seq, a_seq = Input(shape=(MAX_P_LEN,)), Input(shape=(MAX_A_LEN,))\n",
    "p_out, a_out = model(p_seq), model(a_seq)\n",
    "similarity = dot([p_out, a_out], axes=-1, normalize=True)\n",
    "qa = Model(inputs=[p_seq, a_seq], outputs=[similarity])\n",
    "sgd = optimizers.SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "qa.compile(loss=hinge, optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 300)         1011300   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 64)          57664     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, None, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, None, 64)          0         \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "=================================================================\n",
      "Total params: 1,069,220\n",
      "Trainable params: 57,792\n",
      "Non-trainable params: 1,011,428\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 13)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 11)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 64)            1069220     input_2[0][0]                    \n",
      "                                                                   input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dot_1 (Dot)                      (None, 1)             0           model_1[1][0]                    \n",
      "                                                                   model_1[2][0]                    \n",
      "====================================================================================================\n",
      "Total params: 1,069,220\n",
      "Trainable params: 57,792\n",
      "Non-trainable params: 1,011,428\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "qa.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(p, a1, a2, actu, show=True):\n",
    "    \"\"\"\n",
    "    Calculate Accuracy\n",
    "    \"\"\"\n",
    "    A1 = qa.predict([p, a1])\n",
    "    A2 = qa.predict([p, a2])\n",
    "    pred = []\n",
    "    for i in range(len(p)):\n",
    "        if A1[i] > A2[i]:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(2)\n",
    "    S = sum([1 for i in range(len(pred)) if pred[i] == actu[i]])\n",
    "    ACC = S / len(actu)\n",
    "    if show:\n",
    "        print('Accuracy: \\t%.3f' % (ACC))\n",
    "    return np.array([ACC])\n",
    "\n",
    "def plot_acc(acc, num_epochs):\n",
    "    \"\"\"\n",
    "    Plot Accuracy\n",
    "    \"\"\"\n",
    "    print('MAX Accuracy: \\t%.3f' % (max(acc)))\n",
    "    epochs = list(range(1, num_epochs+1))\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(epochs, acc, label=\"Accuracy\", color=\"red\", linewidth=1)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xticks([i for i in range(1, len(acc), len(acc)//10)])\n",
    "    plt.grid(True)  \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(log):\n",
    "    \"\"\"\n",
    "    Plot Loss\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    loss = log['loss']\n",
    "    if 'val_loss' in log:\n",
    "        val_loss = log['val_loss']\n",
    "        plt.plot(val_loss, color=\"r\", label=\"Val Loss\")\n",
    "    plt.plot(loss, color=\"g\", label=\"Train Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    \n",
    "def train(model, num_epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, verbose=1, show=True, plot=True):\n",
    "    \"\"\"\n",
    "    Train\n",
    "    \"\"\"\n",
    "    ACC = []\n",
    "    history = {}\n",
    "    for e in range(num_epochs):\n",
    "        print('EPOCHS', e+1)\n",
    "        t = model.fit([xpTrain, xaTrain],\n",
    "                      yTrain,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=1,\n",
    "                      shuffle=True,\n",
    "                      validation_data=([xpVal, xaVal], yVal),\n",
    "                      verbose=verbose)\n",
    "        for i, j in t.history.items():\n",
    "            history[i] = history.get(i, []) + j\n",
    "        ACC.append(accuracy(xpTest, xa1Test, xa2Test, yTest, show=show))\n",
    "    if plot:\n",
    "        plot_acc(ACC, num_epochs)\n",
    "        plot_loss(history)\n",
    "    ACC = sum([list(i) for i in ACC], [])\n",
    "    K.clear_session()\n",
    "    return max(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS 1\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 1s - loss: 0.3432 - val_loss: 0.4415\n",
      "Accuracy: \t0.486\n",
      "EPOCHS 2\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.3229 - val_loss: 0.3977\n",
      "Accuracy: \t0.478\n",
      "EPOCHS 3\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.3071 - val_loss: 0.3314\n",
      "Accuracy: \t0.502\n",
      "EPOCHS 4\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.2907 - val_loss: 0.2630\n",
      "Accuracy: \t0.458\n",
      "EPOCHS 5\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.2751 - val_loss: 0.1914\n",
      "Accuracy: \t0.476\n",
      "EPOCHS 6\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.2638 - val_loss: 0.2313\n",
      "Accuracy: \t0.472\n",
      "EPOCHS 7\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.2574 - val_loss: 0.1565\n",
      "Accuracy: \t0.466\n",
      "EPOCHS 8\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.2432 - val_loss: 0.1315\n",
      "Accuracy: \t0.496\n",
      "EPOCHS 9\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.2338 - val_loss: 0.1279\n",
      "Accuracy: \t0.492\n",
      "EPOCHS 10\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.2275 - val_loss: 0.1315\n",
      "Accuracy: \t0.486\n",
      "EPOCHS 11\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.2201 - val_loss: 0.1209\n",
      "Accuracy: \t0.474\n",
      "EPOCHS 12\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.2161 - val_loss: 0.1052\n",
      "Accuracy: \t0.498\n",
      "EPOCHS 13\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.2012 - val_loss: 0.1093\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 14\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1971 - val_loss: 0.1092\n",
      "Accuracy: \t0.482\n",
      "EPOCHS 15\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1970 - val_loss: 0.0879\n",
      "Accuracy: \t0.492\n",
      "EPOCHS 16\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1860 - val_loss: 0.1015\n",
      "Accuracy: \t0.498\n",
      "EPOCHS 17\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1751 - val_loss: 0.0927\n",
      "Accuracy: \t0.478\n",
      "EPOCHS 18\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1785 - val_loss: 0.0984\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 19\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1651 - val_loss: 0.0921\n",
      "Accuracy: \t0.498\n",
      "EPOCHS 20\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1634 - val_loss: 0.0989\n",
      "Accuracy: \t0.488\n",
      "EPOCHS 21\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1611 - val_loss: 0.0903\n",
      "Accuracy: \t0.490\n",
      "EPOCHS 22\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1548 - val_loss: 0.1015\n",
      "Accuracy: \t0.494\n",
      "EPOCHS 23\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1487 - val_loss: 0.0906\n",
      "Accuracy: \t0.502\n",
      "EPOCHS 24\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1494 - val_loss: 0.1011\n",
      "Accuracy: \t0.486\n",
      "EPOCHS 25\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1442 - val_loss: 0.0905\n",
      "Accuracy: \t0.498\n",
      "EPOCHS 26\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1370 - val_loss: 0.0815\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 27\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1289 - val_loss: 0.0919\n",
      "Accuracy: \t0.490\n",
      "EPOCHS 28\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1251 - val_loss: 0.0912\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 29\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1331 - val_loss: 0.0858\n",
      "Accuracy: \t0.488\n",
      "EPOCHS 30\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1231 - val_loss: 0.0931\n",
      "Accuracy: \t0.504\n",
      "EPOCHS 31\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1176 - val_loss: 0.0942\n",
      "Accuracy: \t0.472\n",
      "EPOCHS 32\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1258 - val_loss: 0.0919\n",
      "Accuracy: \t0.498\n",
      "EPOCHS 33\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1145 - val_loss: 0.0881\n",
      "Accuracy: \t0.496\n",
      "EPOCHS 34\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1057 - val_loss: 0.0829\n",
      "Accuracy: \t0.494\n",
      "EPOCHS 35\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1078 - val_loss: 0.0807\n",
      "Accuracy: \t0.500\n",
      "EPOCHS 36\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1121 - val_loss: 0.0798\n",
      "Accuracy: \t0.496\n",
      "EPOCHS 37\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1012 - val_loss: 0.0725\n",
      "Accuracy: \t0.482\n",
      "EPOCHS 38\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1000 - val_loss: 0.0838\n",
      "Accuracy: \t0.492\n",
      "EPOCHS 39\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.1071 - val_loss: 0.0806\n",
      "Accuracy: \t0.496\n",
      "EPOCHS 40\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0968 - val_loss: 0.0687\n",
      "Accuracy: \t0.490\n",
      "EPOCHS 41\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0888 - val_loss: 0.0590\n",
      "Accuracy: \t0.476\n",
      "EPOCHS 42\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0868 - val_loss: 0.0849\n",
      "Accuracy: \t0.474\n",
      "EPOCHS 43\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0867 - val_loss: 0.0591\n",
      "Accuracy: \t0.488\n",
      "EPOCHS 44\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0958 - val_loss: 0.0658\n",
      "Accuracy: \t0.494\n",
      "EPOCHS 45\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0849 - val_loss: 0.0852\n",
      "Accuracy: \t0.448\n",
      "EPOCHS 46\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0920 - val_loss: 0.0631\n",
      "Accuracy: \t0.488\n",
      "EPOCHS 47\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0878 - val_loss: 0.0634\n",
      "Accuracy: \t0.494\n",
      "EPOCHS 48\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0745 - val_loss: 0.0811\n",
      "Accuracy: \t0.486\n",
      "EPOCHS 49\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0880 - val_loss: 0.0800\n",
      "Accuracy: \t0.470\n",
      "EPOCHS 50\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0795 - val_loss: 0.0692\n",
      "Accuracy: \t0.498\n",
      "EPOCHS 51\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0711 - val_loss: 0.0741\n",
      "Accuracy: \t0.492\n",
      "EPOCHS 52\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0710 - val_loss: 0.1188\n",
      "Accuracy: \t0.470\n",
      "EPOCHS 53\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0795 - val_loss: 0.0739\n",
      "Accuracy: \t0.464\n",
      "EPOCHS 54\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0673 - val_loss: 0.0738\n",
      "Accuracy: \t0.474\n",
      "EPOCHS 55\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0761 - val_loss: 0.0730\n",
      "Accuracy: \t0.496\n",
      "EPOCHS 56\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0631 - val_loss: 0.0915\n",
      "Accuracy: \t0.472\n",
      "EPOCHS 57\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0711 - val_loss: 0.1074\n",
      "Accuracy: \t0.462\n",
      "EPOCHS 58\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0709 - val_loss: 0.0830\n",
      "Accuracy: \t0.474\n",
      "EPOCHS 59\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0660 - val_loss: 0.0870\n",
      "Accuracy: \t0.500\n",
      "EPOCHS 60\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0602 - val_loss: 0.0819\n",
      "Accuracy: \t0.486\n",
      "EPOCHS 61\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0558 - val_loss: 0.1203\n",
      "Accuracy: \t0.468\n",
      "EPOCHS 62\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0583 - val_loss: 0.1142\n",
      "Accuracy: \t0.488\n",
      "EPOCHS 63\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0663 - val_loss: 0.0996\n",
      "Accuracy: \t0.488\n",
      "EPOCHS 64\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0625 - val_loss: 0.1226\n",
      "Accuracy: \t0.482\n",
      "EPOCHS 65\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0622 - val_loss: 0.0992\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 66\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0546 - val_loss: 0.0894\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 67\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0506 - val_loss: 0.1222\n",
      "Accuracy: \t0.476\n",
      "EPOCHS 68\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0633 - val_loss: 0.0938\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 69\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0527 - val_loss: 0.1327\n",
      "Accuracy: \t0.492\n",
      "EPOCHS 70\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0555 - val_loss: 0.1329\n",
      "Accuracy: \t0.488\n",
      "EPOCHS 71\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0481 - val_loss: 0.0874\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 72\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0399 - val_loss: 0.1019\n",
      "Accuracy: \t0.482\n",
      "EPOCHS 73\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0493 - val_loss: 0.0998\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 74\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0546 - val_loss: 0.0933\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 75\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0489 - val_loss: 0.0979\n",
      "Accuracy: \t0.500\n",
      "EPOCHS 76\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0538 - val_loss: 0.1392\n",
      "Accuracy: \t0.474\n",
      "EPOCHS 77\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0633 - val_loss: 0.1107\n",
      "Accuracy: \t0.498\n",
      "EPOCHS 78\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0514 - val_loss: 0.1060\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 79\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0434 - val_loss: 0.1169\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 80\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0503 - val_loss: 0.1024\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 81\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0369 - val_loss: 0.1168\n",
      "Accuracy: \t0.504\n",
      "EPOCHS 82\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0584 - val_loss: 0.1622\n",
      "Accuracy: \t0.486\n",
      "EPOCHS 83\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0513 - val_loss: 0.1659\n",
      "Accuracy: \t0.502\n",
      "EPOCHS 84\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0522 - val_loss: 0.1580\n",
      "Accuracy: \t0.498\n",
      "EPOCHS 85\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0404 - val_loss: 0.1154\n",
      "Accuracy: \t0.504\n",
      "EPOCHS 86\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0553 - val_loss: 0.1146\n",
      "Accuracy: \t0.494\n",
      "EPOCHS 87\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0429 - val_loss: 0.1381\n",
      "Accuracy: \t0.488\n",
      "EPOCHS 88\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0500 - val_loss: 0.1133\n",
      "Accuracy: \t0.488\n",
      "EPOCHS 89\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0449 - val_loss: 0.1136\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 90\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0507 - val_loss: 0.1317\n",
      "Accuracy: \t0.500\n",
      "EPOCHS 91\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0515 - val_loss: 0.1439\n",
      "Accuracy: \t0.486\n",
      "EPOCHS 92\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0422 - val_loss: 0.1137\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 93\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0498 - val_loss: 0.1258\n",
      "Accuracy: \t0.498\n",
      "EPOCHS 94\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0495 - val_loss: 0.1177\n",
      "Accuracy: \t0.504\n",
      "EPOCHS 95\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0307 - val_loss: 0.1454\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 96\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0568 - val_loss: 0.1133\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 97\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0345 - val_loss: 0.1212\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 98\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0404 - val_loss: 0.1264\n",
      "Accuracy: \t0.502\n",
      "EPOCHS 99\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0449 - val_loss: 0.1262\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 100\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0396 - val_loss: 0.1066\n",
      "Accuracy: \t0.504\n",
      "EPOCHS 101\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0270 - val_loss: 0.1116\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 102\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0337 - val_loss: 0.1231\n",
      "Accuracy: \t0.532\n",
      "EPOCHS 103\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0441 - val_loss: 0.1144\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 104\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0378 - val_loss: 0.1330\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 105\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0467 - val_loss: 0.1193\n",
      "Accuracy: \t0.494\n",
      "EPOCHS 106\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0385 - val_loss: 0.1106\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 107\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0277 - val_loss: 0.1123\n",
      "Accuracy: \t0.504\n",
      "EPOCHS 108\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0396 - val_loss: 0.1267\n",
      "Accuracy: \t0.484\n",
      "EPOCHS 109\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0310 - val_loss: 0.1080\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 110\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0236 - val_loss: 0.1091\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 111\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0333 - val_loss: 0.1159\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 112\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0382 - val_loss: 0.1244\n",
      "Accuracy: \t0.502\n",
      "EPOCHS 113\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0261 - val_loss: 0.1094\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 114\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0253 - val_loss: 0.1222\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 115\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0393 - val_loss: 0.1081\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 116\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0320 - val_loss: 0.1179\n",
      "Accuracy: \t0.502\n",
      "EPOCHS 117\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0302 - val_loss: 0.1195\n",
      "Accuracy: \t0.532\n",
      "EPOCHS 118\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0464 - val_loss: 0.1336\n",
      "Accuracy: \t0.492\n",
      "EPOCHS 119\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0358 - val_loss: 0.1051\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 120\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0240 - val_loss: 0.1042\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 121\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0237 - val_loss: 0.1146\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 122\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0343 - val_loss: 0.1157\n",
      "Accuracy: \t0.502\n",
      "EPOCHS 123\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0361 - val_loss: 0.1360\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 124\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0339 - val_loss: 0.1112\n",
      "Accuracy: \t0.504\n",
      "EPOCHS 125\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0370 - val_loss: 0.1142\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 126\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0277 - val_loss: 0.1239\n",
      "Accuracy: \t0.492\n",
      "EPOCHS 127\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0339 - val_loss: 0.1195\n",
      "Accuracy: \t0.498\n",
      "EPOCHS 128\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0224 - val_loss: 0.1023\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 129\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0208 - val_loss: 0.1074\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 130\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0333 - val_loss: 0.1127\n",
      "Accuracy: \t0.504\n",
      "EPOCHS 131\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0422 - val_loss: 0.1401\n",
      "Accuracy: \t0.490\n",
      "EPOCHS 132\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0411 - val_loss: 0.1110\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 133\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0390 - val_loss: 0.1074\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 134\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0225 - val_loss: 0.1030\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 135\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0202 - val_loss: 0.1060\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 136\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0250 - val_loss: 0.1504\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 137\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0387 - val_loss: 0.1088\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 138\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0230 - val_loss: 0.1743\n",
      "Accuracy: \t0.498\n",
      "EPOCHS 139\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0277 - val_loss: 0.1106\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 140\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0261 - val_loss: 0.1078\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 141\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0207 - val_loss: 0.1133\n",
      "Accuracy: \t0.500\n",
      "EPOCHS 142\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0225 - val_loss: 0.1060\n",
      "Accuracy: \t0.532\n",
      "EPOCHS 143\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0204 - val_loss: 0.1057\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 144\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0224 - val_loss: 0.1511\n",
      "Accuracy: \t0.486\n",
      "EPOCHS 145\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0313 - val_loss: 0.2204\n",
      "Accuracy: \t0.476\n",
      "EPOCHS 146\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0392 - val_loss: 0.1427\n",
      "Accuracy: \t0.498\n",
      "EPOCHS 147\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0344 - val_loss: 0.1469\n",
      "Accuracy: \t0.490\n",
      "EPOCHS 148\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0366 - val_loss: 0.1110\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 149\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0216 - val_loss: 0.1370\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 150\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0288 - val_loss: 0.1087\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 151\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0224 - val_loss: 0.1165\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 152\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0218 - val_loss: 0.1152\n",
      "Accuracy: \t0.530\n",
      "EPOCHS 153\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0176 - val_loss: 0.1128\n",
      "Accuracy: \t0.532\n",
      "EPOCHS 154\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0194 - val_loss: 0.1452\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 155\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0365 - val_loss: 0.1115\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 156\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0201 - val_loss: 0.1054\n",
      "Accuracy: \t0.536\n",
      "EPOCHS 157\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0191 - val_loss: 0.1028\n",
      "Accuracy: \t0.540\n",
      "EPOCHS 158\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0186 - val_loss: 0.1052\n",
      "Accuracy: \t0.536\n",
      "EPOCHS 159\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0176 - val_loss: 0.1039\n",
      "Accuracy: \t0.530\n",
      "EPOCHS 160\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0173 - val_loss: 0.1074\n",
      "Accuracy: \t0.532\n",
      "EPOCHS 161\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0236 - val_loss: 0.1093\n",
      "Accuracy: \t0.532\n",
      "EPOCHS 162\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0188 - val_loss: 0.1050\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 163\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0169 - val_loss: 0.1032\n",
      "Accuracy: \t0.532\n",
      "EPOCHS 164\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0175 - val_loss: 0.1027\n",
      "Accuracy: \t0.532\n",
      "EPOCHS 165\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0231 - val_loss: 0.1485\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 166\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0224 - val_loss: 0.1091\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 167\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0258 - val_loss: 0.1432\n",
      "Accuracy: \t0.490\n",
      "EPOCHS 168\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0332 - val_loss: 0.1080\n",
      "Accuracy: \t0.530\n",
      "EPOCHS 169\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0184 - val_loss: 0.1051\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 170\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0178 - val_loss: 0.1059\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 171\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0174 - val_loss: 0.1076\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 172\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0277 - val_loss: 0.1032\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 173\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0235 - val_loss: 0.1471\n",
      "Accuracy: \t0.488\n",
      "EPOCHS 174\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0271 - val_loss: 0.1141\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 175\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0362 - val_loss: 0.1312\n",
      "Accuracy: \t0.484\n",
      "EPOCHS 176\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0190 - val_loss: 0.1095\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 177\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0260 - val_loss: 0.1245\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 178\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0181 - val_loss: 0.1224\n",
      "Accuracy: \t0.534\n",
      "EPOCHS 179\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0373 - val_loss: 0.1169\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 180\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0181 - val_loss: 0.1153\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 181\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0344 - val_loss: 0.1276\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 182\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0185 - val_loss: 0.1090\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 183\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0154 - val_loss: 0.1058\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 184\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0178 - val_loss: 0.1078\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 185\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0147 - val_loss: 0.1049\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 186\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0148 - val_loss: 0.1047\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 187\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0129 - val_loss: 0.1038\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 188\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0141 - val_loss: 0.1064\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 189\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0152 - val_loss: 0.1084\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 190\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0195 - val_loss: 0.1056\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 191\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0145 - val_loss: 0.1043\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 192\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0143 - val_loss: 0.1074\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 193\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0273 - val_loss: 0.1088\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 194\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0260 - val_loss: 0.1249\n",
      "Accuracy: \t0.490\n",
      "EPOCHS 195\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0337 - val_loss: 0.1103\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 196\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0186 - val_loss: 0.1131\n",
      "Accuracy: \t0.492\n",
      "EPOCHS 197\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0221 - val_loss: 0.1119\n",
      "Accuracy: \t0.502\n",
      "EPOCHS 198\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0128 - val_loss: 0.1185\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 199\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0302 - val_loss: 0.1191\n",
      "Accuracy: \t0.498\n",
      "EPOCHS 200\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0275 - val_loss: 0.1133\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 201\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0134 - val_loss: 0.1084\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 202\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0360 - val_loss: 0.1133\n",
      "Accuracy: \t0.500\n",
      "EPOCHS 203\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0306 - val_loss: 0.1275\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 204\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0279 - val_loss: 0.1367\n",
      "Accuracy: \t0.476\n",
      "EPOCHS 205\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0329 - val_loss: 0.1133\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 206\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0128 - val_loss: 0.1192\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 207\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0286 - val_loss: 0.1220\n",
      "Accuracy: \t0.502\n",
      "EPOCHS 208\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0214 - val_loss: 0.1161\n",
      "Accuracy: \t0.504\n",
      "EPOCHS 209\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0109 - val_loss: 0.1059\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 210\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0107 - val_loss: 0.1103\n",
      "Accuracy: \t0.504\n",
      "EPOCHS 211\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0258 - val_loss: 0.1587\n",
      "Accuracy: \t0.472\n",
      "EPOCHS 212\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0219 - val_loss: 0.1339\n",
      "Accuracy: \t0.480\n",
      "EPOCHS 213\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0263 - val_loss: 0.1149\n",
      "Accuracy: \t0.484\n",
      "EPOCHS 214\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0105 - val_loss: 0.1248\n",
      "Accuracy: \t0.486\n",
      "EPOCHS 215\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0222 - val_loss: 0.1148\n",
      "Accuracy: \t0.498\n",
      "EPOCHS 216\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0189 - val_loss: 0.1276\n",
      "Accuracy: \t0.488\n",
      "EPOCHS 217\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0273 - val_loss: 0.1148\n",
      "Accuracy: \t0.500\n",
      "EPOCHS 218\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0253 - val_loss: 0.1216\n",
      "Accuracy: \t0.492\n",
      "EPOCHS 219\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0204 - val_loss: 0.1067\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 220\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0085 - val_loss: 0.1079\n",
      "Accuracy: \t0.502\n",
      "EPOCHS 221\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0271 - val_loss: 0.1103\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 222\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0118 - val_loss: 0.1070\n",
      "Accuracy: \t0.504\n",
      "EPOCHS 223\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0113 - val_loss: 0.1335\n",
      "Accuracy: \t0.486\n",
      "EPOCHS 224\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0256 - val_loss: 0.1065\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 225\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0115 - val_loss: 0.1330\n",
      "Accuracy: \t0.496\n",
      "EPOCHS 226\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0304 - val_loss: 0.1092\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 227\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0141 - val_loss: 0.1357\n",
      "Accuracy: \t0.474\n",
      "EPOCHS 228\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0209 - val_loss: 0.1074\n",
      "Accuracy: \t0.500\n",
      "EPOCHS 229\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0070 - val_loss: 0.1073\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 230\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0069 - val_loss: 0.1059\n",
      "Accuracy: \t0.504\n",
      "EPOCHS 231\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0107 - val_loss: 0.1133\n",
      "Accuracy: \t0.502\n",
      "EPOCHS 232\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0072 - val_loss: 0.1064\n",
      "Accuracy: \t0.496\n",
      "EPOCHS 233\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0058 - val_loss: 0.1057\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 234\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0106 - val_loss: 0.1752\n",
      "Accuracy: \t0.472\n",
      "EPOCHS 235\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0292 - val_loss: 0.1150\n",
      "Accuracy: \t0.496\n",
      "EPOCHS 236\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0074 - val_loss: 0.1088\n",
      "Accuracy: \t0.502\n",
      "EPOCHS 237\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0057 - val_loss: 0.1074\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 238\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0115 - val_loss: 0.1376\n",
      "Accuracy: \t0.494\n",
      "EPOCHS 239\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0273 - val_loss: 0.1211\n",
      "Accuracy: \t0.494\n",
      "EPOCHS 240\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0152 - val_loss: 0.1125\n",
      "Accuracy: \t0.498\n",
      "EPOCHS 241\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0105 - val_loss: 0.1733\n",
      "Accuracy: \t0.470\n",
      "EPOCHS 242\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0381 - val_loss: 0.1159\n",
      "Accuracy: \t0.498\n",
      "EPOCHS 243\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0210 - val_loss: 0.1360\n",
      "Accuracy: \t0.482\n",
      "EPOCHS 244\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0183 - val_loss: 0.1815\n",
      "Accuracy: \t0.476\n",
      "EPOCHS 245\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0263 - val_loss: 0.1445\n",
      "Accuracy: \t0.500\n",
      "EPOCHS 246\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0324 - val_loss: 0.1683\n",
      "Accuracy: \t0.476\n",
      "EPOCHS 247\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0259 - val_loss: 0.1070\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 248\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0069 - val_loss: 0.1028\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 249\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0053 - val_loss: 0.1026\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 250\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0052 - val_loss: 0.1040\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 251\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0169 - val_loss: 0.1473\n",
      "Accuracy: \t0.490\n",
      "EPOCHS 252\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0148 - val_loss: 0.1217\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 253\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0123 - val_loss: 0.1054\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 254\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0062 - val_loss: 0.1056\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 255\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0051 - val_loss: 0.1047\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 256\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0052 - val_loss: 0.1048\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 257\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0050 - val_loss: 0.1048\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 258\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0049 - val_loss: 0.1045\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 259\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0050 - val_loss: 0.1034\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 260\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0051 - val_loss: 0.1086\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 261\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0141 - val_loss: 0.1520\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 262\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0191 - val_loss: 0.1791\n",
      "Accuracy: \t0.486\n",
      "EPOCHS 263\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0143 - val_loss: 0.1066\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 264\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0102 - val_loss: 0.1423\n",
      "Accuracy: \t0.492\n",
      "EPOCHS 265\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0226 - val_loss: 0.1108\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 266\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0089 - val_loss: 0.1173\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 267\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0072 - val_loss: 0.1056\n",
      "Accuracy: \t0.504\n",
      "EPOCHS 268\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0051 - val_loss: 0.1051\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 269\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0049 - val_loss: 0.1131\n",
      "Accuracy: \t0.500\n",
      "EPOCHS 270\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0083 - val_loss: 0.1063\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 271\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0049 - val_loss: 0.1054\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 272\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0049 - val_loss: 0.1053\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 273\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0051 - val_loss: 0.1068\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 274\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1057\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 275\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1055\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 276\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1057\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 277\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1050\n",
      "Accuracy: \t0.530\n",
      "EPOCHS 278\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0049 - val_loss: 0.1065\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 279\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0049 - val_loss: 0.1064\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 280\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1064\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 281\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1060\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 282\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1059\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 283\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1053\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 284\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1053\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 285\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0049 - val_loss: 0.1054\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 286\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1051\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 287\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1054\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 288\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1057\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 289\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0051 - val_loss: 0.1177\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 290\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0084 - val_loss: 0.1182\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 291\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0195 - val_loss: 0.1204\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 292\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0164 - val_loss: 0.1075\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 293\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0056 - val_loss: 0.1064\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 294\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0049 - val_loss: 0.1075\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 295\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0222 - val_loss: 0.1155\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 296\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0106 - val_loss: 0.1078\n",
      "Accuracy: \t0.500\n",
      "EPOCHS 297\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0049 - val_loss: 0.1067\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 298\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1070\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 299\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1056\n",
      "Accuracy: \t0.502\n",
      "EPOCHS 300\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1055\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 301\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0049 - val_loss: 0.1055\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 302\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1053\n",
      "Accuracy: \t0.502\n",
      "EPOCHS 303\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1055\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 304\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1053\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 305\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1052\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 306\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1052\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 307\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1058\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 308\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1055\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 309\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1049\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 310\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0076 - val_loss: 0.1461\n",
      "Accuracy: \t0.488\n",
      "EPOCHS 311\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0215 - val_loss: 0.1152\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 312\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0063 - val_loss: 0.1077\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 313\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0150 - val_loss: 0.1141\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 314\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0089 - val_loss: 0.1069\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 315\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0049 - val_loss: 0.1062\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 316\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1061\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 317\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1058\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 318\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1057\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 319\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1058\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 320\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 321\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1056\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 322\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1054\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 323\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1053\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 324\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1053\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 325\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1055\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 326\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1056\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 327\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1056\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 328\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1056\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 329\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0069 - val_loss: 0.1137\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 330\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0061 - val_loss: 0.1067\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 331\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1062\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 332\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 333\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1059\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 334\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1058\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 335\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 336\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 337\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1058\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 338\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 339\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1060\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 340\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1058\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 341\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 342\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 343\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 344\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 345\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1056\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 346\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.005 - 0s - loss: 0.0047 - val_loss: 0.1054\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 347\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1053\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 348\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1053\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 349\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1052\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 350\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1054\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 351\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1052\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 352\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1052\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 353\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1051\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 354\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1051\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 355\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1051\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 356\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1052\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 357\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1052\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 358\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1051\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 359\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1051\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 360\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 361\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 362\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 363\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 364\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 365\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 366\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1059\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 367\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 368\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 369\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 370\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 371\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1058\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 372\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 373\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1058\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 374\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 375\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1054\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 376\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1052\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 377\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1052\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 378\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1049\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 379\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1054\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 380\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1053\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 381\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1054\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 382\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 383\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1057\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 384\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1055\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 385\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1054\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 386\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1055\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 387\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 388\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1057\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 389\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1054\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 390\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1055\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 391\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1054\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 392\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1055\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 393\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 394\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 395\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 396\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 397\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 398\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1060\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 399\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 400\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 401\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 402\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 403\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 404\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 405\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1057\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 406\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 407\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 408\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 409\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 410\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1061\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 411\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1062\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 412\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1062\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 413\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1061\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 414\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1061\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 415\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1060\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 416\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 417\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 418\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 419\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 420\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 421\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 422\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1061\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 423\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1060\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 424\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 425\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 426\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1060\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 427\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1061\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 428\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1062\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 429\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1060\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 430\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1061\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 431\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1060\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 432\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 433\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 434\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 435\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 436\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1057\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 437\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 438\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 439\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 440\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 441\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 442\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1061\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 443\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1061\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 444\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1061\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 445\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1061\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 446\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 447\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1060\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 448\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1062\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 449\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1061\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 450\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1060\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 451\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1061\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 452\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1061\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 453\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1061\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 454\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1061\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 455\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1060\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 456\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 457\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 458\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1060\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 459\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 460\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 461\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 462\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 463\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 464\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 465\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 466\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 467\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 468\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 469\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 470\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 471\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 472\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 473\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 474\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 475\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 476\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 477\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 478\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 479\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 480\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 481\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 482\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 483\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 484\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 485\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 486\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 487\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 488\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 489\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 490\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 491\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1057\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 492\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 493\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 494\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 495\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 496\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 497\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 498\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 499\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 500\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 501\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1062\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 502\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 503\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 504\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 505\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 506\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 507\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 508\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 509\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 510\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1055\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 511\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 512\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1055\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 513\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1054\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 514\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1053\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 515\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1054\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 516\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 517\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1055\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 518\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 519\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 520\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 521\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 522\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 523\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 524\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 525\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 526\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1060\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 527\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 528\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 529\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 530\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 531\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 532\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1055\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 533\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1055\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 534\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 535\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 536\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 537\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1059\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 538\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1058\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 539\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 540\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 541\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 542\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 543\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 544\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 545\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 546\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1055\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 547\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1052\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 548\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1053\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 549\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1052\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 550\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1052\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 551\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1053\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 552\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1053\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 553\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1058\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 554\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1055\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 555\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1054\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 556\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1054\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 557\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1054\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 558\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1054\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 559\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1054\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 560\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1056\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 561\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1057\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 562\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0224 - val_loss: 0.1153\n",
      "Accuracy: \t0.500\n",
      "EPOCHS 563\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0235 - val_loss: 0.1113\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 564\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0196 - val_loss: 0.1204\n",
      "Accuracy: \t0.508\n",
      "EPOCHS 565\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0058 - val_loss: 0.1073\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 566\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1069\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 567\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1066\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 568\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1071\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 569\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 570\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 571\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 572\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 573\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1068\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 574\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 575\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1065\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 576\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 577\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1067\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 578\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1067\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 579\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1067\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 580\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 581\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 582\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 583\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1067\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 584\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 585\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1065\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 586\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1064\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 587\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1065\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 588\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 589\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1065\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 590\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 591\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 592\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 593\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 594\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 595\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 596\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 597\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 598\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 599\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1067\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 600\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 601\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 602\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 603\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 604\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 605\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 606\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 607\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 608\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0052 - val_loss: 0.1140\n",
      "Accuracy: \t0.502\n",
      "EPOCHS 609\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0228 - val_loss: 0.1167\n",
      "Accuracy: \t0.500\n",
      "EPOCHS 610\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0078 - val_loss: 0.1083\n",
      "Accuracy: \t0.506\n",
      "EPOCHS 611\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1069\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 612\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1064\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 613\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1064\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 614\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1064\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 615\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1064\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 616\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1064\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 617\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 618\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1067\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 619\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 620\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1067\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 621\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 622\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 623\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 624\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 625\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 626\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 627\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 628\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 629\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 630\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 631\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 632\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0048 - val_loss: 0.1074\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 633\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 634\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 635\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 636\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 637\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1070\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 638\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 639\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 640\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 641\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 642\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 643\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 644\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 645\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 646\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.530\n",
      "EPOCHS 647\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 648\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 649\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 650\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 651\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 652\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 653\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 654\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 655\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 656\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 657\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1078\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 658\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1077\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 659\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1078\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 660\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 661\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 662\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 663\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 664\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 665\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 666\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 667\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 668\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 669\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 670\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 671\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 672\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 673\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 674\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 675\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 676\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 0.004 - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 677\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 678\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 679\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 680\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 681\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 682\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 683\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 684\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 685\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 686\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 687\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 688\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 689\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 690\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 691\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 692\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 693\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 694\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1073\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 695\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 696\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 697\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 698\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 699\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 700\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 701\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 702\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 703\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 704\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 705\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 706\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 707\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 708\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 709\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 710\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 711\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 712\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 713\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 714\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 715\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 716\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 717\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 718\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 719\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 720\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 721\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1079\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 722\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1080\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 723\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1079\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 724\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1079\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 725\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1079\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 726\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1079\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 727\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1081\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 728\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1081\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 729\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1079\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 730\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1079\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 731\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1079\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 732\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1077\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 733\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 734\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 735\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1077\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 736\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 737\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 738\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 739\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 740\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 741\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1075\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 742\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 743\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1078\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 744\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1077\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 745\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1077\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 746\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1078\n",
      "Accuracy: \t0.530\n",
      "EPOCHS 747\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1077\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 748\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 749\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1077\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 750\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 751\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 752\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 753\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 754\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 755\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 756\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1073\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 757\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 758\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 759\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 760\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 761\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 762\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1078\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 763\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1077\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 764\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1078\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 765\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 766\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 767\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1078\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 768\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 769\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 770\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1077\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 771\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 772\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 773\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 774\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1077\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 775\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1077\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 776\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1079\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 777\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1078\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 778\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1078\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 779\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 780\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 781\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 782\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 783\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 784\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 785\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 786\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1078\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 787\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.528\n",
      "EPOCHS 788\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.526\n",
      "EPOCHS 789\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 790\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 791\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 792\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 793\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 794\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 795\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 796\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 797\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 798\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 799\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 800\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 801\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 802\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 803\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 804\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 805\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 806\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 807\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 808\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 809\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 810\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 811\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 812\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 813\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 814\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 815\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 816\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 817\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1073\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 818\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 819\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 820\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 821\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 822\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 823\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 824\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 825\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 826\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 827\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 828\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 829\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 830\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 831\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 832\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 833\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 834\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 835\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 836\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 837\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 838\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 839\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 840\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 841\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 842\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 843\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 844\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 845\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 846\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 847\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 848\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 849\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 850\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 851\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 852\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1073\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 853\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 854\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 855\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 856\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 857\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1071\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 858\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 859\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 860\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 861\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 862\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 863\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 864\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 865\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 866\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 867\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 868\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 869\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 870\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1069\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 871\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 872\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 873\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 874\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 875\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 876\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 877\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 878\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 879\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 880\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 881\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 882\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 883\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 884\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 885\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 886\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 887\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 888\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1073\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 889\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 890\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 891\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 892\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 893\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 894\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.510\n",
      "EPOCHS 895\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 896\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 897\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 898\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 899\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 900\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 901\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 902\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1074\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 903\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 904\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 905\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 906\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.512\n",
      "EPOCHS 907\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 908\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 909\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1074\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 910\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 911\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1073\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 912\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 913\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 914\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 915\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 916\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 917\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 918\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 919\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 920\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 921\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 922\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 923\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 924\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 925\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1077\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 926\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 927\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 928\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 929\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 930\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 931\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 932\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 933\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 934\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 935\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 936\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 937\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 938\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 939\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 940\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1071\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 941\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 942\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 943\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 944\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1072\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 945\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 946\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 947\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 948\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 949\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 950\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 951\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.514\n",
      "EPOCHS 952\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 953\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 954\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 955\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 956\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 957\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 958\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1072\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 959\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 960\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 961\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 962\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1071\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 963\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1073\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 964\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 965\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1074\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 966\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1075\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 967\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1076\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 968\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1069\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 969\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 970\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 971\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 972\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1070\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 973\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1068\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 974\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 975\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1070\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 976\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1068\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 977\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 978\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 979\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1068\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 980\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 981\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1067\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 982\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 983\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 984\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1067\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 985\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1067\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 986\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1068\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 987\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1069\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 988\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1069\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 989\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1067\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 990\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1067\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 991\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 992\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1067\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 993\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 994\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1067\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 995\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 996\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1067\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 997\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1068\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 998\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1064\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 999\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1064\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 1000\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1063\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 1001\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1063\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 1002\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1063\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 1003\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1064\n",
      "Accuracy: \t0.524\n",
      "EPOCHS 1004\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1064\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 1005\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1064\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 1006\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1062\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 1007\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1065\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 1008\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1065\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 1009\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1065\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 1010\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1065\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 1011\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1064\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 1012\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1065\n",
      "Accuracy: \t0.516\n",
      "EPOCHS 1013\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1065\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 1014\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1065\n",
      "Accuracy: \t0.518\n",
      "EPOCHS 1015\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 1016\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0046 - val_loss: 0.1067\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 1017\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1067\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 1018\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 1019\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 1020\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 1021\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.522\n",
      "EPOCHS 1022\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 1023\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.520\n",
      "EPOCHS 1024\n",
      "Train on 1000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 0s - loss: 0.0047 - val_loss: 0.1066\n",
      "Accuracy: \t0.522\n",
      "MAX Accuracy: \t0.540\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABNIAAAPCCAYAAAC9fvXGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYIT/D6reLacy4eYHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9d1908f8d0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 481,
       "width": 617
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABMUAAAPCCAYAAAB4DG9XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9d19032be0>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 481,
       "width": 610
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.54000000000000004"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(qa)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
