{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load Data</a></div><div class=\"lev1 toc-item\"><a href=\"#Word-Segmentation\" data-toc-modified-id=\"Word-Segmentation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Word Segmentation</a></div><div class=\"lev1 toc-item\"><a href=\"#Embedding\" data-toc-modified-id=\"Embedding-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Embedding</a></div><div class=\"lev1 toc-item\"><a href=\"#Compute\" data-toc-modified-id=\"Compute-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Compute</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path, name):\n",
    "    \"\"\"\n",
    "    Load date from file\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file) as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        item = json.loads(line)\n",
    "        data.append(item[name])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/Users/lizhn7/Downloads/EXPERIMENT/COPA/LM/data/copa-test.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "premise = load_data(DATA_DIR, 'premise')\n",
    "alternative1 = load_data(DATA_DIR, 'alternative1')\n",
    "alternative2 = load_data(DATA_DIR, 'alternative2')\n",
    "label = [int(l) for l in load_data(DATA_DIR, 'most-plausible-alternative')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replDict = {\"woman's\": 'woman', \"man's\": 'man', \"patient's\": 'patient', \"student's\": 'student', \"boy's\": 'boy', \n",
    "            \"friend's\": 'friend', \"enemy's\": 'enemy', \"parent's\": 'parent', \"humanitarian's\": 'humanitarian', \n",
    "            \"child's\": 'child', \"professor's\": 'professor', \"daughter's\": 'daughter', \"mother's\": 'mother', \n",
    "            \"children's\": 'children', \"teller's\": 'teller', \"company's\": 'company', \"group's\": 'group', \n",
    "            \"laptop's\": 'laptop', \"girl's\": 'girl', \"salesman's\": 'salesman', \"cook's\": 'cook', \"car's\": 'car', \n",
    "            \"offender's\": 'offender', \"detective's\": 'detective', \"librarian's\": 'librarian', \"caller's\": 'caller', \n",
    "            \"victim's\": 'victim', \"interviewer's\": 'interviewer', \"ship's\": 'ship', \"site's\": 'site', \n",
    "            \"chandelier's\": 'chandelier', \"bully's\": 'bully', \"river's\": 'river', \"puppy's\": 'puppy', \n",
    "            \"pilot's\": 'pilot', \"girlfriend's\": 'girlfriend', \"politician's\": 'politician', \"couple's\": 'couple', \n",
    "            \"son's\": 'son', \"actor's\": 'actor', \"neighbor's\": 'neighbor', \"nation's\": 'nation', \n",
    "            \"classmate's\": 'classmate', \"businessman's\": 'businessman', \"architect's\": 'architect', \n",
    "            \"imposter's\": 'imposter', \"kidnapper's\": 'kidnapper', \"colleague's\": 'colleague', \"flower's\": 'flower',\n",
    "            \"bull's\": 'bull', \"employee's\": 'employee', \"team's\": 'team', \"other's\": 'other', \n",
    "            \"writer's\": 'writer', \"baby's\": 'baby', \"attacker's\": 'attacker', \"uncle's\": 'uncle', \"driver's\": 'driver'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut(s):\n",
    "    \"\"\"\n",
    "    Word segmentation\n",
    "    \"\"\"\n",
    "    pattern = r'''\n",
    "              (?x)                   # set flag to allow verbose regexps \n",
    "              (?:[A-Z]\\.)+           # abbreviations, e.g. U.S.A. \n",
    "              |\\w+(?:[-&']\\w+)*      # words w/ optional internal hyphens/apostrophe  \n",
    "            '''  \n",
    "    return regexp_tokenize(s, pattern=pattern)\n",
    "\n",
    "def clean(s):\n",
    "    \"\"\"\n",
    "    Clean data \n",
    "    \"\"\"\n",
    "    for i in range(len(s)):\n",
    "        if s[i] == \"couldn't\":\n",
    "            s[i] = 'could'\n",
    "            s.insert(i+1, 'not')\n",
    "        if s[i] == \"wouldn't\":\n",
    "            s[i] = 'would'\n",
    "            s.insert(i+1, 'not')\n",
    "    s = [i for i in s if i != '']\n",
    "    return [replDict.get(i.lower(), i.lower()) for i in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pWords = [clean(cut(s)) for s in premise]\n",
    "a1Words = [clean(cut(s)) for s in alternative1]\n",
    "a2Words = [clean(cut(s)) for s in alternative2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/lizhn7/Downloads/EXPERIMENT/COPA/Sentence_Classification_Glove/data/index.pkl', 'rb') as fp:\n",
    "    word2index = pickle.load(fp)\n",
    "    \n",
    "with h5py.File('/Users/lizhn7/Downloads/EXPERIMENT/COPA/RN/data/embedding.h5', 'r') as fh:\n",
    "    embedding = fh['embedding'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pSeq = [[word2index[w] for w in s] for s in pWords]\n",
    "a1Seq = [[word2index[w] for w in s] for s in a1Words]\n",
    "a2Seq = [[word2index[w] for w in s] for s in a2Words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pEmb = np.array([[embedding[w] for w in s] for s in pSeq])\n",
    "a1Emb = np.array([[embedding[w] for w in s] for s in a1Seq])\n",
    "a2Emb = np.array([[embedding[w] for w in s] for s in a2Seq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pEmb = [sum(s)/len(s) for s in pEmb]\n",
    "a1Emb = [sum(s)/len(s) for s in a1Emb]\n",
    "a2Emb = [sum(s)/len(s) for s in a2Emb]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    \"\"\"\n",
    "    Compute_cosine_similarity\n",
    "    \"\"\"\n",
    "    return np.dot(x, y) / (np.linalg.norm(x, 2) * np.linalg.norm(y, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pEmb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(p, a1, a2, actu, show=True):\n",
    "    \"\"\"\n",
    "    Calculate Accuracy\n",
    "    \"\"\"\n",
    "    p1 = []\n",
    "    p2 = []\n",
    "    for i in range(len(a1)):\n",
    "        p1.append(cosine_similarity(p[i], a1[i]))\n",
    "        p2.append(cosine_similarity(p[i], a2[i]))\n",
    "    pred = []\n",
    "    for i in range(len(p1)):\n",
    "        if p1[i] <= p2[i]:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(2)\n",
    "    S = sum([1 for i in range(len(pred)) if pred[i] == actu[i]])\n",
    "    ACC = S / len(actu)\n",
    "    if show:\n",
    "        print('Accuracy: \\t%.3f' % (ACC))\n",
    "    return ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: \t0.510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.51"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(pEmb, a1Emb, a2Emb, label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
