{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Checkpoint\" data-toc-modified-id=\"Checkpoint-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Checkpoint</a></div><div class=\"lev1 toc-item\"><a href=\"#Build-Model\" data-toc-modified-id=\"Build-Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Build Model</a></div><div class=\"lev2 toc-item\"><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Import Libraries</a></div><div class=\"lev2 toc-item\"><a href=\"#Set-Hyperparameters\" data-toc-modified-id=\"Set-Hyperparameters-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Set Hyperparameters</a></div><div class=\"lev2 toc-item\"><a href=\"#Build-Graph\" data-toc-modified-id=\"Build-Graph-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Build Graph</a></div><div class=\"lev1 toc-item\"><a href=\"#Model-Visualization\" data-toc-modified-id=\"Model-Visualization-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model Visualization</a></div><div class=\"lev1 toc-item\"><a href=\"#Train\" data-toc-modified-id=\"Train-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Train</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('/Users/lizhn7/Downloads/EXPERIMENT/COPA/Sentence_Classification_Glove/data/embedding.h5', 'r') as fh:\n",
    "    embedding = fh['embedding'][:]\n",
    "    \n",
    "with h5py.File('/Users/lizhn7/Downloads/EXPERIMENT/COPA/Sentence_Classification_Glove/data/train_2000_2.h5', 'r') as fh:\n",
    "    xTrain = fh['xTrain'][:]\n",
    "    yTrain = fh['yTrain'][:]\n",
    "    \n",
    "with h5py.File('/Users/lizhn7/Downloads/EXPERIMENT/COPA/Sentence_Classification_Glove/data/test.h5', 'r') as fh:\n",
    "    x1Test = fh['x1Test'][:]\n",
    "    x2Test = fh['x2Test'][:]\n",
    "    yTest = fh['yTest'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xVal = np.vstack((x1Test, x2Test))\n",
    "\n",
    "l = [0] * 1000\n",
    "for i in range(len(yTest)):\n",
    "    if yTest[i] == 1:\n",
    "        l[i] = 1\n",
    "        l[i+len(yTest)] = -1\n",
    "    if yTest[i] == 2:\n",
    "        l[i] = -1\n",
    "        l[i+len(yTest)] = 1\n",
    "\n",
    "yVal = np.array(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda, Input, Embedding, Dropout, GRU, RepeatVector, Concatenate, concatenate, TimeDistributed, Dense, BatchNormalization, Activation\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import maxnorm\n",
    "from keras.callbacks import*\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 22\n",
    "VOCAB_SIZE = 3371\n",
    "EMBEDDING_SIZE = 300\n",
    "GRU_SIZE = 300\n",
    "DROPOUT_RATE = 0.2\n",
    "L2_NORM = 1e-4\n",
    "HIDDEN_SIZE = 600\n",
    "WEIGHT_CONSTRAINT = 2.\n",
    "DELTA = 1.\n",
    "BATCH_SIZE = 200\n",
    "NUM_EPOCHS = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hinge(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Define hinge loss function\n",
    "    \"\"\"\n",
    "    return K.mean(K.maximum(DELTA - y_true * y_pred, 0.), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_map():\n",
    "    \"\"\"\n",
    "    Build Attention GRU feature maps\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(MAX_LEN,), name='INPUT')\n",
    "    emb_seq = Embedding(VOCAB_SIZE, \n",
    "                        EMBEDDING_SIZE, \n",
    "                        weights=[embedding], \n",
    "                        mask_zero=True, \n",
    "                        trainable=False, \n",
    "                        name='EMBEDDING')(inputs)\n",
    "    gru = GRU(GRU_SIZE, \n",
    "              return_sequences=True, \n",
    "              implementation=0, \n",
    "              dropout=DROPOUT_RATE, \n",
    "              recurrent_dropout=DROPOUT_RATE,\n",
    "              kernel_regularizer=l2(L2_NORM),\n",
    "              recurrent_regularizer=l2(L2_NORM),\n",
    "              name='GRU')(emb_seq)\n",
    "    gru = Dropout(DROPOUT_RATE, name='DROPOUT')(gru)\n",
    "    model = Model(inputs=[inputs], outputs=[gru])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "INPUT (InputLayer)           (None, 22)                0         \n",
      "_________________________________________________________________\n",
      "EMBEDDING (Embedding)        (None, 22, 300)           1011300   \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    (None, 22, 300)           540900    \n",
      "_________________________________________________________________\n",
      "DROPOUT (Dropout)            (None, 22, 300)           0         \n",
      "=================================================================\n",
      "Total params: 1,552,200\n",
      "Trainable params: 540,900\n",
      "Non-trainable params: 1,011,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = feature_map()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relation_networks():\n",
    "    \"\"\"\n",
    "    Build relation networks\n",
    "    \"\"\"\n",
    "    GRU = feature_map()\n",
    "    inputs = Input(shape=(MAX_LEN,), name='INPUT')\n",
    "    feaMap = GRU(inputs)\n",
    "    mlp = TimeDistributed(Dense(HIDDEN_SIZE,\n",
    "                                activation=None,\n",
    "                                kernel_regularizer=l2(L2_NORM),\n",
    "                                kernel_constraint=maxnorm(WEIGHT_CONSTRAINT)),\n",
    "                          name='MLP_1')(feaMap)\n",
    "    mlp = BatchNormalization(name='BN_1')(mlp)\n",
    "    mlp = Activation('elu', name='ELU_1')(mlp)\n",
    "    mlp = Dropout(DROPOUT_RATE, name='DROPOUT_1')(mlp)\n",
    "    ewSum = Lambda(lambda x: K.sum(x, axis=1), name='ELEMENT-WISE_SUM')(mlp)\n",
    "    mlp2 = Dense(HIDDEN_SIZE, \n",
    "                 activation=None,\n",
    "                 kernel_regularizer=l2(L2_NORM),\n",
    "                 kernel_constraint=maxnorm(WEIGHT_CONSTRAINT),\n",
    "                 name='MLP_2')(ewSum)\n",
    "    mlp2 = BatchNormalization(name='BN_2')(mlp2)\n",
    "    mlp2 = Activation('elu', name='ELU_2')(mlp2)\n",
    "    mlp2 = Dropout(DROPOUT_RATE, name='DROPOUT_2')(mlp2)\n",
    "    outputs = Dense(1, \n",
    "                    activation='tanh', \n",
    "                    kernel_regularizer=l2(L2_NORM),\n",
    "                    kernel_constraint=maxnorm(WEIGHT_CONSTRAINT),\n",
    "                    name='OUTPUT')(mlp2)\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(loss=hinge, optimizer='rmsprop')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "INPUT (InputLayer)           (None, 22)                0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 22, 300)           1552200   \n",
      "_________________________________________________________________\n",
      "MLP_1 (TimeDistributed)      (None, 22, 600)           180600    \n",
      "_________________________________________________________________\n",
      "BN_1 (BatchNormalization)    (None, 22, 600)           2400      \n",
      "_________________________________________________________________\n",
      "ELU_1 (Activation)           (None, 22, 600)           0         \n",
      "_________________________________________________________________\n",
      "DROPOUT_1 (Dropout)          (None, 22, 600)           0         \n",
      "_________________________________________________________________\n",
      "ELEMENT-WISE_SUM (Lambda)    (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "MLP_2 (Dense)                (None, 600)               360600    \n",
      "_________________________________________________________________\n",
      "BN_2 (BatchNormalization)    (None, 600)               2400      \n",
      "_________________________________________________________________\n",
      "ELU_2 (Activation)           (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "DROPOUT_2 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "OUTPUT (Dense)               (None, 1)                 601       \n",
      "=================================================================\n",
      "Total params: 2,098,801\n",
      "Trainable params: 1,085,101\n",
      "Non-trainable params: 1,013,700\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"848pt\" viewBox=\"0.00 0.00 265.49 848.00\" width=\"265pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 844)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-844 261.4932,-844 261.4932,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 112784711520 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>112784711520</title>\n",
       "<polygon fill=\"none\" points=\"65.6934,-803.5 65.6934,-839.5 191.7998,-839.5 191.7998,-803.5 65.6934,-803.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128.7466\" y=\"-817.3\">INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 112811802240 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>112811802240</title>\n",
       "<polygon fill=\"none\" points=\"74.2793,-730.5 74.2793,-766.5 183.2139,-766.5 183.2139,-730.5 74.2793,-730.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128.7466\" y=\"-744.3\">model_1: Model</text>\n",
       "</g>\n",
       "<!-- 112784711520&#45;&gt;112811802240 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>112784711520-&gt;112811802240</title>\n",
       "<path d=\"M128.7466,-803.4551C128.7466,-795.3828 128.7466,-785.6764 128.7466,-776.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"132.2467,-776.5903 128.7466,-766.5904 125.2467,-776.5904 132.2467,-776.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112835739152 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>112835739152</title>\n",
       "<polygon fill=\"none\" points=\"0,-657.5 0,-693.5 257.4932,-693.5 257.4932,-657.5 0,-657.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128.7466\" y=\"-671.3\">MLP_1(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 112811802240&#45;&gt;112835739152 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>112811802240-&gt;112835739152</title>\n",
       "<path d=\"M128.7466,-730.4551C128.7466,-722.3828 128.7466,-712.6764 128.7466,-703.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"132.2467,-703.5903 128.7466,-693.5904 125.2467,-703.5904 132.2467,-703.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112838929320 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>112838929320</title>\n",
       "<polygon fill=\"none\" points=\"43.5688,-584.5 43.5688,-620.5 213.9243,-620.5 213.9243,-584.5 43.5688,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128.7466\" y=\"-598.3\">BN_1: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 112835739152&#45;&gt;112838929320 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>112835739152-&gt;112838929320</title>\n",
       "<path d=\"M128.7466,-657.4551C128.7466,-649.3828 128.7466,-639.6764 128.7466,-630.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"132.2467,-630.5903 128.7466,-620.5904 125.2467,-630.5904 132.2467,-630.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112835899232 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>112835899232</title>\n",
       "<polygon fill=\"none\" points=\"67.2793,-511.5 67.2793,-547.5 190.2139,-547.5 190.2139,-511.5 67.2793,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128.7466\" y=\"-525.3\">ELU_1: Activation</text>\n",
       "</g>\n",
       "<!-- 112838929320&#45;&gt;112835899232 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>112838929320-&gt;112835899232</title>\n",
       "<path d=\"M128.7466,-584.4551C128.7466,-576.3828 128.7466,-566.6764 128.7466,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"132.2467,-557.5903 128.7466,-547.5904 125.2467,-557.5904 132.2467,-557.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112839357832 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>112839357832</title>\n",
       "<polygon fill=\"none\" points=\"53.6621,-438.5 53.6621,-474.5 203.8311,-474.5 203.8311,-438.5 53.6621,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128.7466\" y=\"-452.3\">DROPOUT_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 112835899232&#45;&gt;112839357832 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>112835899232-&gt;112839357832</title>\n",
       "<path d=\"M128.7466,-511.4551C128.7466,-503.3828 128.7466,-493.6764 128.7466,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"132.2467,-484.5903 128.7466,-474.5904 125.2467,-484.5904 132.2467,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112836513408 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>112836513408</title>\n",
       "<polygon fill=\"none\" points=\"23.9907,-365.5 23.9907,-401.5 233.5024,-401.5 233.5024,-365.5 23.9907,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128.7466\" y=\"-379.3\">ELEMENT-WISE_SUM: Lambda</text>\n",
       "</g>\n",
       "<!-- 112839357832&#45;&gt;112836513408 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>112839357832-&gt;112836513408</title>\n",
       "<path d=\"M128.7466,-438.4551C128.7466,-430.3828 128.7466,-420.6764 128.7466,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"132.2467,-411.5903 128.7466,-401.5904 125.2467,-411.5904 132.2467,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112841731096 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>112841731096</title>\n",
       "<polygon fill=\"none\" points=\"78.1655,-292.5 78.1655,-328.5 179.3276,-328.5 179.3276,-292.5 78.1655,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128.7466\" y=\"-306.3\">MLP_2: Dense</text>\n",
       "</g>\n",
       "<!-- 112836513408&#45;&gt;112841731096 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>112836513408-&gt;112841731096</title>\n",
       "<path d=\"M128.7466,-365.4551C128.7466,-357.3828 128.7466,-347.6764 128.7466,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"132.2467,-338.5903 128.7466,-328.5904 125.2467,-338.5904 132.2467,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112842108320 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>112842108320</title>\n",
       "<polygon fill=\"none\" points=\"43.5688,-219.5 43.5688,-255.5 213.9243,-255.5 213.9243,-219.5 43.5688,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128.7466\" y=\"-233.3\">BN_2: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 112841731096&#45;&gt;112842108320 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>112841731096-&gt;112842108320</title>\n",
       "<path d=\"M128.7466,-292.4551C128.7466,-284.3828 128.7466,-274.6764 128.7466,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"132.2467,-265.5903 128.7466,-255.5904 125.2467,-265.5904 132.2467,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112842292696 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>112842292696</title>\n",
       "<polygon fill=\"none\" points=\"67.2793,-146.5 67.2793,-182.5 190.2139,-182.5 190.2139,-146.5 67.2793,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128.7466\" y=\"-160.3\">ELU_2: Activation</text>\n",
       "</g>\n",
       "<!-- 112842108320&#45;&gt;112842292696 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>112842108320-&gt;112842292696</title>\n",
       "<path d=\"M128.7466,-219.4551C128.7466,-211.3828 128.7466,-201.6764 128.7466,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"132.2467,-192.5903 128.7466,-182.5904 125.2467,-192.5904 132.2467,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112842501984 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>112842501984</title>\n",
       "<polygon fill=\"none\" points=\"53.6621,-73.5 53.6621,-109.5 203.8311,-109.5 203.8311,-73.5 53.6621,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128.7466\" y=\"-87.3\">DROPOUT_2: Dropout</text>\n",
       "</g>\n",
       "<!-- 112842292696&#45;&gt;112842501984 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>112842292696-&gt;112842501984</title>\n",
       "<path d=\"M128.7466,-146.4551C128.7466,-138.3828 128.7466,-128.6764 128.7466,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"132.2467,-119.5903 128.7466,-109.5904 125.2467,-119.5904 132.2467,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112842349256 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>112842349256</title>\n",
       "<polygon fill=\"none\" points=\"72.2969,-.5 72.2969,-36.5 185.1963,-36.5 185.1963,-.5 72.2969,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"128.7466\" y=\"-14.3\">OUTPUT: Dense</text>\n",
       "</g>\n",
       "<!-- 112842501984&#45;&gt;112842349256 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>112842501984-&gt;112842349256</title>\n",
       "<path d=\"M128.7466,-73.4551C128.7466,-65.3828 128.7466,-55.6764 128.7466,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"132.2467,-46.5903 128.7466,-36.5904 125.2467,-46.5904 132.2467,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = relation_networks()\n",
    "model.summary()\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(a1, a2, actu, show=True):\n",
    "    \"\"\"\n",
    "    Calculate Accuracy\n",
    "    \"\"\"\n",
    "    A1 = model.predict(a1)\n",
    "    A2 = model.predict(a2)\n",
    "    pred = []\n",
    "    for i in range(len(A1)):\n",
    "        if A1[i] > A2[i]:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(2)\n",
    "    S = sum([1 for i in range(len(pred)) if pred[i] == actu[i]])\n",
    "    ACC = S / len(actu)\n",
    "    if show:\n",
    "        print('Accuracy: \\t%.9f' % (ACC))\n",
    "    return np.array([ACC])\n",
    "\n",
    "def plot_acc(acc, num_epochs):\n",
    "    \"\"\"\n",
    "    Plot Accuracy\n",
    "    \"\"\"\n",
    "    print('MAX Accuracy: \\t%.3f' % (max(acc)))\n",
    "    epochs = list(range(1, num_epochs+1))\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(epochs, acc, label=\"Accuracy\", color=\"red\", linewidth=1)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xticks([i for i in range(1, len(acc), len(acc)//10)])\n",
    "    plt.grid(True)  \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(log):\n",
    "    \"\"\"\n",
    "    Plot Loss\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    loss = log['loss']\n",
    "    if 'val_loss' in log:\n",
    "        val_loss = log['val_loss']\n",
    "        plt.plot(val_loss, color=\"r\", label=\"Val Loss\")\n",
    "    plt.plot(loss, color=\"g\", label=\"Train Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, verbose=1, show=True, plot=True):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :                  training model          \n",
    "    num_epochs 128:          training epochs   \n",
    "    batch_size 200:          size of batch \n",
    "    verbose :                1\n",
    "    show True:               show accuracy every epoch\n",
    "    plot True:               plot accuracy and loss or not\n",
    "    Returns\n",
    "    ----------\n",
    "    The training results\n",
    "    \"\"\"\n",
    "    ACC = []\n",
    "    history = {}\n",
    "    for e in range(num_epochs):\n",
    "        print('EPOCHS', e+1)\n",
    "        t = model.fit(xTrain, \n",
    "                      yTrain,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=1,\n",
    "                      shuffle=True,\n",
    "                      validation_data=(xVal, yVal),\n",
    "                      verbose=verbose)\n",
    "        for i, j in t.history.items():\n",
    "            history[i] = history.get(i, []) + j\n",
    "        ACC.append(accuracy(x1Test, x2Test, yTest, show=show))\n",
    "    if plot:\n",
    "        plot_acc(ACC, num_epochs)\n",
    "        plot_loss(history)\n",
    "    ACC = sum([list(i) for i in ACC], [])\n",
    "    return max(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS 1\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.1582 - val_loss: 1.1734\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 2\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.1555 - val_loss: 1.1564\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 3\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.1848 - val_loss: 1.1487\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 4\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.1377 - val_loss: 1.1472\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 5\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.1112 - val_loss: 1.1424\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 6\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.1046 - val_loss: 1.1362\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 7\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.1287 - val_loss: 1.1349\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 8\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0868 - val_loss: 1.1356\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 9\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.1034 - val_loss: 1.1226\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 10\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.1082 - val_loss: 1.0963\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 11\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0735 - val_loss: 1.1204\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 12\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0664 - val_loss: 1.1121\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 13\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0652 - val_loss: 1.1028\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 14\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0717 - val_loss: 1.0902\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 15\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0844 - val_loss: 1.1146\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 16\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0628 - val_loss: 1.1052\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 17\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0692 - val_loss: 1.1059\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 18\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0641 - val_loss: 1.0993\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 19\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0699 - val_loss: 1.1058\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 20\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0301 - val_loss: 1.1012\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 21\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0398 - val_loss: 1.0892\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 22\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0406 - val_loss: 1.1004\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 23\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0668 - val_loss: 1.0846\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 24\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0637 - val_loss: 1.0948\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 25\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0430 - val_loss: 1.0911\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 26\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0781 - val_loss: 1.0809\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 27\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 10s - loss: 1.0443 - val_loss: 1.0864\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 28\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0486 - val_loss: 1.0882\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 29\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0758 - val_loss: 1.0831\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 30\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.1049 - val_loss: 1.0874\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 31\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0899 - val_loss: 1.0859\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 32\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0877 - val_loss: 1.0847\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 33\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0859 - val_loss: 1.0832\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 34\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0566 - val_loss: 1.0819\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 35\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0641 - val_loss: 1.0792\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 36\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0663 - val_loss: 1.0757\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 37\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0480 - val_loss: 1.0810\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 38\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 10s - loss: 1.0289 - val_loss: 1.0801\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 39\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0733 - val_loss: 1.0775\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 40\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0668 - val_loss: 1.0781\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 41\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0680 - val_loss: 1.0628\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 42\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0430 - val_loss: 1.0719\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 43\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 10s - loss: 1.0484 - val_loss: 1.0717\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 44\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 10s - loss: 1.0414 - val_loss: 1.0671\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 45\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0720 - val_loss: 1.0708\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 46\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0551 - val_loss: 1.0745\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 47\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0481 - val_loss: 1.0601\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 48\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 9s - loss: 1.0461 - val_loss: 1.0727\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 49\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0286 - val_loss: 1.0678\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 50\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0599 - val_loss: 1.0686\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 51\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0626 - val_loss: 1.0397\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 52\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0557 - val_loss: 1.0403\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 53\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0262 - val_loss: 1.0418\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 54\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0391 - val_loss: 1.0440\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 55\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0275 - val_loss: 1.0661\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 56\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0138 - val_loss: 1.0621\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 57\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0478 - val_loss: 1.0617\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 58\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0339 - val_loss: 1.0621\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 59\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0797 - val_loss: 1.0621\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 60\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0458 - val_loss: 1.0621\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 61\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0088 - val_loss: 1.0619\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 62\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0051 - val_loss: 1.0616\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 63\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0116 - val_loss: 1.0615\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 64\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0095 - val_loss: 1.0610\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 65\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0086 - val_loss: 1.0575\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 66\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0519 - val_loss: 1.0642\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 67\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0185 - val_loss: 1.0607\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 68\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0046 - val_loss: 1.0548\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 69\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0203 - val_loss: 1.0454\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 70\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 0.9779 - val_loss: 1.0429\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 71\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0339 - val_loss: 1.0703\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 72\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0241 - val_loss: 1.0470\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 73\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0658 - val_loss: 1.0700\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 74\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0716 - val_loss: 1.0430\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 75\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0379 - val_loss: 1.0276\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 76\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0952 - val_loss: 1.0702\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 77\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0539 - val_loss: 1.0654\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 78\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0504 - val_loss: 1.0473\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 79\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0284 - val_loss: 1.0406\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 80\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0365 - val_loss: 1.0325\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 81\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0521 - val_loss: 1.0439\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 82\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 8s - loss: 1.0437 - val_loss: 1.0277\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 83\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0218 - val_loss: 1.0448\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 84\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0193 - val_loss: 1.0705\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 85\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 9s - loss: 1.0536 - val_loss: 1.0748\n",
      "Accuracy: \t0.518000000\n",
      "EPOCHS 86\n",
      "Train on 2000 samples, validate on 1000 samples\n",
      "Epoch 1/1\n",
      "1600/2000 [=======================>......] - ETA: 1s - loss: 1.0726"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-05be02ee6d26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelation_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-129-0dac1d3ef622>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, num_epochs, batch_size, verbose, show, plot)\u001b[0m\n\u001b[1;32m     23\u001b[0m                       \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                       \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myVal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                       verbose=verbose)\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(relation_networks(), num_epochs=NUM_EPOCHS//4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model.predict(xVal[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.24379191],\n",
       "       [ 0.08418044],\n",
       "       [ 0.22674717],\n",
       "       [-0.15308015],\n",
       "       [ 0.40756169],\n",
       "       [ 0.05775225],\n",
       "       [-0.08575277],\n",
       "       [-0.27144909],\n",
       "       [ 0.15838641],\n",
       "       [-0.2968986 ],\n",
       "       [-0.25853518],\n",
       "       [ 0.07909727],\n",
       "       [ 0.17884338],\n",
       "       [-0.27796826],\n",
       "       [ 0.02813196],\n",
       "       [ 0.20843229],\n",
       "       [-0.01775522],\n",
       "       [-0.22357695],\n",
       "       [ 0.12967746],\n",
       "       [ 0.04855088],\n",
       "       [-0.21450867],\n",
       "       [-0.2720491 ],\n",
       "       [-0.06026888],\n",
       "       [-0.19318107],\n",
       "       [ 0.41353109],\n",
       "       [-0.29551032],\n",
       "       [-0.20800786],\n",
       "       [-0.03044415],\n",
       "       [-0.28120646],\n",
       "       [ 0.16107464],\n",
       "       [-0.27719367],\n",
       "       [ 0.22158483],\n",
       "       [-0.11473616],\n",
       "       [ 0.0407241 ],\n",
       "       [-0.20183262],\n",
       "       [-0.15411952],\n",
       "       [-0.54120332],\n",
       "       [-0.01891542],\n",
       "       [ 0.02868381],\n",
       "       [-0.23319156],\n",
       "       [-0.26603058],\n",
       "       [ 0.18231602],\n",
       "       [-0.00419778],\n",
       "       [ 0.43494475],\n",
       "       [-0.17411925],\n",
       "       [ 0.18865183],\n",
       "       [-0.27656582],\n",
       "       [-0.38953459],\n",
       "       [ 0.2262727 ],\n",
       "       [ 0.01464861],\n",
       "       [-0.35065255],\n",
       "       [ 0.31319407],\n",
       "       [ 0.15136622],\n",
       "       [-0.23493232],\n",
       "       [-0.33556533],\n",
       "       [-0.25164932],\n",
       "       [-0.01009487],\n",
       "       [ 0.11158658],\n",
       "       [ 0.16182123],\n",
       "       [ 0.06350598],\n",
       "       [ 0.03385552],\n",
       "       [ 0.13279018],\n",
       "       [ 0.39533302],\n",
       "       [ 0.10453127],\n",
       "       [ 0.39417985],\n",
       "       [ 0.18625429],\n",
       "       [-0.12350887],\n",
       "       [-0.16058078],\n",
       "       [ 0.23984635],\n",
       "       [-0.42616969],\n",
       "       [ 0.23709899],\n",
       "       [ 0.12908217],\n",
       "       [-0.01370249],\n",
       "       [-0.17606609],\n",
       "       [-0.00186234],\n",
       "       [ 0.24970862],\n",
       "       [-0.2731145 ],\n",
       "       [-0.05631717],\n",
       "       [-0.02580773],\n",
       "       [-0.03950172],\n",
       "       [-0.0639469 ],\n",
       "       [ 0.11570872],\n",
       "       [-0.03652252],\n",
       "       [-0.4195967 ],\n",
       "       [ 0.17061655],\n",
       "       [-0.2394678 ],\n",
       "       [-0.1527143 ],\n",
       "       [ 0.18467897],\n",
       "       [-0.29733735],\n",
       "       [ 0.03644901],\n",
       "       [-0.49753773],\n",
       "       [-0.17400846],\n",
       "       [-0.04347532],\n",
       "       [ 0.24069768],\n",
       "       [-0.11365107],\n",
       "       [ 0.0327094 ],\n",
       "       [-0.03857214],\n",
       "       [ 0.11788617],\n",
       "       [ 0.00102007],\n",
       "       [-0.3965486 ],\n",
       "       [-0.02680884],\n",
       "       [ 0.02416962],\n",
       "       [ 0.09734084],\n",
       "       [-0.07416348],\n",
       "       [ 0.4101547 ],\n",
       "       [ 0.49614656],\n",
       "       [-0.04521598],\n",
       "       [ 0.04590225],\n",
       "       [ 0.1048481 ],\n",
       "       [ 0.17503917],\n",
       "       [-0.27022865],\n",
       "       [ 0.24440093],\n",
       "       [ 0.02886855],\n",
       "       [-0.10835165],\n",
       "       [-0.34503773],\n",
       "       [-0.16386788],\n",
       "       [-0.31884524],\n",
       "       [-0.00996035],\n",
       "       [ 0.15554743],\n",
       "       [-0.32132354],\n",
       "       [-0.03931134],\n",
       "       [-0.02059556],\n",
       "       [-0.23912515],\n",
       "       [ 0.1406779 ],\n",
       "       [ 0.0152001 ],\n",
       "       [ 0.38911811],\n",
       "       [ 0.15577464],\n",
       "       [-0.45035103],\n",
       "       [ 0.05385809],\n",
       "       [-0.14811049],\n",
       "       [-0.04063909],\n",
       "       [-0.11818801],\n",
       "       [ 0.02348399],\n",
       "       [-0.23524663],\n",
       "       [ 0.1751233 ],\n",
       "       [-0.41536057],\n",
       "       [ 0.09473708],\n",
       "       [-0.37127393],\n",
       "       [-0.15987945],\n",
       "       [ 0.20796736],\n",
       "       [ 0.38886631],\n",
       "       [ 0.02383075],\n",
       "       [ 0.0833457 ],\n",
       "       [ 0.15817218],\n",
       "       [-0.29133776],\n",
       "       [-0.15372202],\n",
       "       [ 0.05518902],\n",
       "       [-0.16942233],\n",
       "       [-0.2289224 ],\n",
       "       [ 0.02236662],\n",
       "       [-0.04374273],\n",
       "       [ 0.27712351],\n",
       "       [ 0.10515627],\n",
       "       [ 0.00903707],\n",
       "       [-0.22629903],\n",
       "       [-0.19444788],\n",
       "       [-0.22544967],\n",
       "       [-0.12098448],\n",
       "       [-0.0638134 ],\n",
       "       [-0.13863049],\n",
       "       [-0.34282327],\n",
       "       [-0.37858498],\n",
       "       [-0.17733128],\n",
       "       [-0.07218811],\n",
       "       [ 0.17412329],\n",
       "       [-0.07164484],\n",
       "       [ 0.13820724],\n",
       "       [ 0.18672514],\n",
       "       [ 0.39246985],\n",
       "       [-0.22350977],\n",
       "       [ 0.05790775],\n",
       "       [-0.34119049],\n",
       "       [-0.36907512],\n",
       "       [ 0.47380787],\n",
       "       [ 0.42124242],\n",
       "       [-0.08824337],\n",
       "       [-0.12600027],\n",
       "       [ 0.32970339],\n",
       "       [ 0.07076642],\n",
       "       [ 0.19496958],\n",
       "       [-0.33033529],\n",
       "       [-0.18943815],\n",
       "       [-0.15732746],\n",
       "       [ 0.25441986],\n",
       "       [ 0.20835496],\n",
       "       [-0.08080098],\n",
       "       [-0.20974518],\n",
       "       [-0.16505013],\n",
       "       [-0.05838074],\n",
       "       [ 0.22757058],\n",
       "       [-0.12382875],\n",
       "       [-0.16698746],\n",
       "       [-0.05551118],\n",
       "       [ 0.15348761],\n",
       "       [-0.30758068],\n",
       "       [-0.08030124],\n",
       "       [ 0.04100674],\n",
       "       [ 0.04031206],\n",
       "       [-0.03937713],\n",
       "       [ 0.18349825],\n",
       "       [ 0.31055149],\n",
       "       [-0.07491663],\n",
       "       [-0.03844088],\n",
       "       [ 0.0812773 ],\n",
       "       [-0.16926692],\n",
       "       [-0.07723042],\n",
       "       [ 0.12335008],\n",
       "       [ 0.19958648],\n",
       "       [ 0.06945942],\n",
       "       [-0.07001599],\n",
       "       [-0.18825564],\n",
       "       [ 0.08438089],\n",
       "       [-0.25155941],\n",
       "       [-0.18790253],\n",
       "       [-0.30182239],\n",
       "       [-0.1721551 ],\n",
       "       [-0.48140219],\n",
       "       [ 0.08903225],\n",
       "       [-0.52636802],\n",
       "       [-0.04373135],\n",
       "       [-0.0239104 ],\n",
       "       [-0.44561765],\n",
       "       [-0.06387768],\n",
       "       [-0.14955053],\n",
       "       [ 0.05267698],\n",
       "       [-0.02773932],\n",
       "       [-0.14906192],\n",
       "       [ 0.00614963],\n",
       "       [-0.01496966],\n",
       "       [-0.11295135],\n",
       "       [-0.20194927],\n",
       "       [-0.35826179],\n",
       "       [ 0.12397822],\n",
       "       [ 0.0860139 ],\n",
       "       [-0.28428736],\n",
       "       [ 0.13721572],\n",
       "       [-0.16577749],\n",
       "       [-0.15648249],\n",
       "       [ 0.00756298],\n",
       "       [-0.0327225 ],\n",
       "       [-0.02991862],\n",
       "       [-0.52398831],\n",
       "       [-0.08628852],\n",
       "       [-0.03491636],\n",
       "       [-0.07963537],\n",
       "       [ 0.10865494],\n",
       "       [-0.29607853],\n",
       "       [-0.11681358],\n",
       "       [-0.0611312 ],\n",
       "       [-0.03175028],\n",
       "       [-0.1400097 ],\n",
       "       [-0.04522817],\n",
       "       [-0.12067184],\n",
       "       [ 0.21010467],\n",
       "       [-0.17577638],\n",
       "       [ 0.13684091],\n",
       "       [ 0.06995355],\n",
       "       [ 0.12620655],\n",
       "       [ 0.05065477],\n",
       "       [ 0.05937849],\n",
       "       [ 0.26825991],\n",
       "       [-0.09834475],\n",
       "       [ 0.07045716],\n",
       "       [-0.10643161],\n",
       "       [ 0.11991833],\n",
       "       [-0.01580119],\n",
       "       [ 0.06975112],\n",
       "       [ 0.01112554],\n",
       "       [ 0.16261756],\n",
       "       [-0.24047074],\n",
       "       [-0.07276881],\n",
       "       [ 0.24467702],\n",
       "       [ 0.08245742],\n",
       "       [-0.1250641 ],\n",
       "       [-0.17851312],\n",
       "       [ 0.0227189 ],\n",
       "       [ 0.14796753],\n",
       "       [-0.01353667],\n",
       "       [ 0.10717531],\n",
       "       [-0.42231283],\n",
       "       [ 0.24787681],\n",
       "       [ 0.0987828 ],\n",
       "       [-0.06561141],\n",
       "       [ 0.26464674],\n",
       "       [ 0.17863636],\n",
       "       [ 0.27962255],\n",
       "       [-0.10892785],\n",
       "       [-0.06748901],\n",
       "       [-0.03262631],\n",
       "       [ 0.2620905 ],\n",
       "       [ 0.12773061],\n",
       "       [ 0.00429258],\n",
       "       [ 0.25154495],\n",
       "       [-0.02574235],\n",
       "       [-0.38318092],\n",
       "       [ 0.28451163],\n",
       "       [-0.06207595],\n",
       "       [-0.17073607],\n",
       "       [ 0.50963539],\n",
       "       [-0.20658647],\n",
       "       [-0.2279828 ],\n",
       "       [-0.27247372],\n",
       "       [-0.1335431 ],\n",
       "       [-0.29709676],\n",
       "       [-0.18169707],\n",
       "       [-0.06448018],\n",
       "       [-0.31158677],\n",
       "       [-0.07510013],\n",
       "       [-0.30802172],\n",
       "       [-0.3626653 ],\n",
       "       [-0.12123897],\n",
       "       [ 0.01575786],\n",
       "       [-0.39029232],\n",
       "       [-0.30775836],\n",
       "       [-0.32230097],\n",
       "       [ 0.11182837],\n",
       "       [ 0.01606028],\n",
       "       [-0.67611873],\n",
       "       [ 0.36503568],\n",
       "       [-0.10622413],\n",
       "       [ 0.29150701],\n",
       "       [-0.17496492],\n",
       "       [-0.11396059],\n",
       "       [ 0.39853543],\n",
       "       [-0.3194598 ],\n",
       "       [-0.14839473],\n",
       "       [-0.23204231],\n",
       "       [-0.27587244],\n",
       "       [-0.05337977],\n",
       "       [-0.12527452],\n",
       "       [ 0.21635081],\n",
       "       [-0.04642968],\n",
       "       [ 0.34459874],\n",
       "       [ 0.11218397],\n",
       "       [ 0.32257801],\n",
       "       [ 0.33294484],\n",
       "       [-0.21909736],\n",
       "       [-0.27071413],\n",
       "       [ 0.17333806],\n",
       "       [ 0.45254511],\n",
       "       [-0.087502  ],\n",
       "       [-0.23955543],\n",
       "       [-0.04888776],\n",
       "       [-0.14362679],\n",
       "       [-0.2524623 ],\n",
       "       [-0.2079943 ],\n",
       "       [ 0.31724343],\n",
       "       [ 0.20742242],\n",
       "       [ 0.00193393],\n",
       "       [-0.12849715],\n",
       "       [-0.20340157],\n",
       "       [-0.1184402 ],\n",
       "       [-0.07240462],\n",
       "       [-0.49263915],\n",
       "       [-0.25570291],\n",
       "       [ 0.11480627],\n",
       "       [ 0.15853654],\n",
       "       [-0.20191695],\n",
       "       [ 0.13023235],\n",
       "       [-0.22702296],\n",
       "       [ 0.07030421],\n",
       "       [ 0.11113277],\n",
       "       [-0.0321561 ],\n",
       "       [-0.2357803 ],\n",
       "       [ 0.04160064],\n",
       "       [ 0.24074471],\n",
       "       [-0.17472881],\n",
       "       [-0.14687623],\n",
       "       [ 0.25905928],\n",
       "       [ 0.03426741],\n",
       "       [ 0.08831635],\n",
       "       [-0.09529686],\n",
       "       [ 0.05113796],\n",
       "       [ 0.17468181],\n",
       "       [ 0.05038443],\n",
       "       [-0.45452794],\n",
       "       [ 0.04573856],\n",
       "       [ 0.21204691],\n",
       "       [-0.02491599],\n",
       "       [ 0.06315827],\n",
       "       [ 0.25437507],\n",
       "       [-0.0527668 ],\n",
       "       [-0.11081252],\n",
       "       [ 0.09192778],\n",
       "       [-0.24945994],\n",
       "       [ 0.10182002],\n",
       "       [-0.16009602],\n",
       "       [ 0.15559396],\n",
       "       [-0.15234444],\n",
       "       [-0.34944126],\n",
       "       [ 0.01494648],\n",
       "       [-0.12817676],\n",
       "       [ 0.06248865],\n",
       "       [ 0.27704135],\n",
       "       [-0.19872235],\n",
       "       [-0.12166893],\n",
       "       [-0.29491252],\n",
       "       [ 0.23266499],\n",
       "       [-0.3429189 ],\n",
       "       [-0.01866583],\n",
       "       [-0.26048943],\n",
       "       [-0.18444148],\n",
       "       [-0.05288336],\n",
       "       [-0.02422097],\n",
       "       [-0.02204442],\n",
       "       [ 0.21221453],\n",
       "       [-0.04244007],\n",
       "       [-0.4839921 ],\n",
       "       [-0.10781281],\n",
       "       [-0.11997491],\n",
       "       [-0.15539621],\n",
       "       [ 0.09978397],\n",
       "       [-0.08382373],\n",
       "       [ 0.09606326],\n",
       "       [-0.28536952],\n",
       "       [-0.12085798],\n",
       "       [ 0.15351164],\n",
       "       [-0.19245043],\n",
       "       [ 0.28299409],\n",
       "       [-0.16932115],\n",
       "       [ 0.23070404],\n",
       "       [ 0.07438327],\n",
       "       [ 0.09315333],\n",
       "       [ 0.00950308],\n",
       "       [-0.38216895],\n",
       "       [ 0.27966279],\n",
       "       [ 0.01702782],\n",
       "       [ 0.0367275 ],\n",
       "       [ 0.00233219],\n",
       "       [-0.27433252],\n",
       "       [-0.12916996],\n",
       "       [ 0.10422755],\n",
       "       [-0.22001326],\n",
       "       [-0.38255942],\n",
       "       [ 0.053995  ],\n",
       "       [ 0.13035743],\n",
       "       [-0.07411896],\n",
       "       [ 0.10841688],\n",
       "       [-0.02202792],\n",
       "       [ 0.15517409],\n",
       "       [-0.01949465],\n",
       "       [-0.30266112],\n",
       "       [-0.25887236],\n",
       "       [ 0.12871188],\n",
       "       [-0.34368739],\n",
       "       [-0.00846598],\n",
       "       [ 0.42563727],\n",
       "       [-0.25969636],\n",
       "       [-0.35296482],\n",
       "       [-0.35832873],\n",
       "       [-0.21148981],\n",
       "       [ 0.37453267],\n",
       "       [ 0.04648887],\n",
       "       [-0.19655316],\n",
       "       [-0.07142249],\n",
       "       [-0.17953017],\n",
       "       [-0.44230074],\n",
       "       [ 0.42344445],\n",
       "       [ 0.07789919],\n",
       "       [ 0.30857205],\n",
       "       [-0.06340171],\n",
       "       [-0.37625831],\n",
       "       [ 0.1362067 ],\n",
       "       [ 0.27502337],\n",
       "       [-0.34589654],\n",
       "       [-0.2095568 ],\n",
       "       [-0.23220454],\n",
       "       [ 0.13847288],\n",
       "       [ 0.11562283],\n",
       "       [-0.10980489],\n",
       "       [-0.21222161],\n",
       "       [-0.10544513],\n",
       "       [-0.07835286],\n",
       "       [ 0.18188742],\n",
       "       [-0.08971971],\n",
       "       [-0.15730701],\n",
       "       [-0.00724121],\n",
       "       [ 0.29163402],\n",
       "       [-0.33205113],\n",
       "       [ 0.18071268],\n",
       "       [-0.18635219],\n",
       "       [-0.35429773],\n",
       "       [-0.23442879],\n",
       "       [-0.16560857],\n",
       "       [-0.1730139 ],\n",
       "       [ 0.16084075],\n",
       "       [ 0.14818871],\n",
       "       [-0.52536756],\n",
       "       [ 0.22912246],\n",
       "       [ 0.01805961],\n",
       "       [-0.09299988],\n",
       "       [ 0.24777851],\n",
       "       [-0.28097489],\n",
       "       [-0.03365407],\n",
       "       [-0.18415818],\n",
       "       [ 0.00449705],\n",
       "       [-0.34976083],\n",
       "       [ 0.13663076],\n",
       "       [-0.11858849],\n",
       "       [ 0.21046221]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = model.predict(xVal[500:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.32238904e-01],\n",
       "       [ -8.83640498e-02],\n",
       "       [  3.16985697e-02],\n",
       "       [ -4.50829357e-01],\n",
       "       [  4.18731987e-01],\n",
       "       [  5.60927689e-02],\n",
       "       [ -1.23054653e-01],\n",
       "       [ -1.94750831e-01],\n",
       "       [  1.27786338e-01],\n",
       "       [ -3.83240789e-01],\n",
       "       [ -2.13257253e-01],\n",
       "       [ -2.33909234e-01],\n",
       "       [  2.63439529e-02],\n",
       "       [ -1.02819353e-01],\n",
       "       [  1.81481957e-01],\n",
       "       [  1.19013235e-01],\n",
       "       [ -1.17485352e-01],\n",
       "       [ -9.08195525e-02],\n",
       "       [ -1.30913511e-01],\n",
       "       [ -1.07863816e-02],\n",
       "       [ -1.78052157e-01],\n",
       "       [ -2.58877268e-03],\n",
       "       [ -4.75778524e-03],\n",
       "       [ -1.81224003e-01],\n",
       "       [  3.66369814e-01],\n",
       "       [ -1.54159889e-01],\n",
       "       [ -1.90849200e-01],\n",
       "       [ -1.03060357e-01],\n",
       "       [ -2.52420366e-01],\n",
       "       [  1.73553959e-01],\n",
       "       [ -3.01830262e-01],\n",
       "       [  2.47940689e-01],\n",
       "       [ -1.51643515e-01],\n",
       "       [ -2.03894246e-02],\n",
       "       [ -1.26680881e-01],\n",
       "       [ -1.58673003e-01],\n",
       "       [ -4.10824627e-01],\n",
       "       [ -3.21620941e-01],\n",
       "       [ -1.13715390e-02],\n",
       "       [ -1.62363604e-01],\n",
       "       [  1.10306516e-01],\n",
       "       [ -2.34092206e-01],\n",
       "       [  2.22408376e-03],\n",
       "       [  5.37568510e-01],\n",
       "       [ -1.08972706e-01],\n",
       "       [  2.02595100e-01],\n",
       "       [ -2.87295878e-01],\n",
       "       [  2.99934428e-02],\n",
       "       [  1.30958661e-01],\n",
       "       [ -3.21549699e-02],\n",
       "       [ -2.66574413e-01],\n",
       "       [  2.94559270e-01],\n",
       "       [ -2.78111473e-02],\n",
       "       [ -3.32996994e-01],\n",
       "       [ -1.27531826e-01],\n",
       "       [ -2.98210412e-01],\n",
       "       [ -1.30306885e-01],\n",
       "       [ -2.14340970e-01],\n",
       "       [  8.19059610e-02],\n",
       "       [  2.14498907e-01],\n",
       "       [  1.66595951e-01],\n",
       "       [ -2.36400440e-01],\n",
       "       [  2.60440558e-01],\n",
       "       [  5.10464832e-02],\n",
       "       [  3.76231849e-01],\n",
       "       [  2.64354646e-01],\n",
       "       [ -1.23271808e-01],\n",
       "       [ -5.94375543e-02],\n",
       "       [  1.11042038e-01],\n",
       "       [ -4.51215863e-01],\n",
       "       [  1.44978568e-01],\n",
       "       [  7.70485327e-02],\n",
       "       [ -3.22225094e-02],\n",
       "       [ -3.48866284e-01],\n",
       "       [ -2.38376968e-02],\n",
       "       [  1.05638966e-01],\n",
       "       [ -3.24651718e-01],\n",
       "       [  5.45975529e-02],\n",
       "       [ -1.55456707e-01],\n",
       "       [ -1.42798901e-01],\n",
       "       [ -8.22370593e-03],\n",
       "       [  7.39205182e-02],\n",
       "       [  1.93852037e-01],\n",
       "       [ -4.19076592e-01],\n",
       "       [  5.02247214e-02],\n",
       "       [ -1.84064627e-01],\n",
       "       [ -3.30787122e-01],\n",
       "       [  2.32409701e-01],\n",
       "       [  1.13816954e-01],\n",
       "       [ -2.78767556e-01],\n",
       "       [ -4.91064221e-01],\n",
       "       [ -1.39219314e-01],\n",
       "       [ -1.16508253e-01],\n",
       "       [  2.71360636e-01],\n",
       "       [ -1.49965510e-01],\n",
       "       [ -1.13199703e-01],\n",
       "       [  2.33725496e-02],\n",
       "       [  2.74317831e-01],\n",
       "       [ -6.92365989e-02],\n",
       "       [ -3.67384553e-01],\n",
       "       [  3.25992525e-01],\n",
       "       [  6.51561841e-03],\n",
       "       [  4.52689491e-02],\n",
       "       [ -5.48531897e-02],\n",
       "       [  3.93002719e-01],\n",
       "       [  4.28946644e-01],\n",
       "       [ -3.87786627e-02],\n",
       "       [  1.35147601e-01],\n",
       "       [  1.37745738e-01],\n",
       "       [  1.58902168e-01],\n",
       "       [ -2.77833909e-01],\n",
       "       [  2.42676273e-01],\n",
       "       [  6.86798524e-03],\n",
       "       [ -1.57704651e-01],\n",
       "       [ -3.63351673e-01],\n",
       "       [ -1.97601080e-01],\n",
       "       [ -2.75251478e-01],\n",
       "       [  2.43429378e-01],\n",
       "       [ -2.55111903e-01],\n",
       "       [ -3.23968142e-01],\n",
       "       [ -5.62125891e-02],\n",
       "       [ -2.26687361e-02],\n",
       "       [ -3.17231596e-01],\n",
       "       [  7.60725737e-02],\n",
       "       [  7.52720935e-03],\n",
       "       [ -1.09509133e-01],\n",
       "       [  1.80444390e-01],\n",
       "       [ -1.97093189e-01],\n",
       "       [  5.66930696e-02],\n",
       "       [ -1.04953900e-01],\n",
       "       [ -7.51749575e-02],\n",
       "       [ -1.90606594e-01],\n",
       "       [  3.33525129e-02],\n",
       "       [ -3.62224460e-01],\n",
       "       [  3.77952904e-02],\n",
       "       [ -4.08548415e-01],\n",
       "       [ -3.20884772e-02],\n",
       "       [ -5.52335143e-01],\n",
       "       [ -7.47194663e-02],\n",
       "       [  2.63644487e-01],\n",
       "       [  3.81797254e-01],\n",
       "       [  2.07818002e-02],\n",
       "       [ -1.29841983e-01],\n",
       "       [  3.41828428e-02],\n",
       "       [ -2.26783976e-01],\n",
       "       [ -2.12029040e-01],\n",
       "       [  1.34164970e-02],\n",
       "       [ -1.84837788e-01],\n",
       "       [ -3.04674476e-01],\n",
       "       [ -2.19268799e-02],\n",
       "       [  2.99488544e-03],\n",
       "       [  1.99366137e-01],\n",
       "       [ -1.61320701e-01],\n",
       "       [ -8.96265917e-03],\n",
       "       [ -1.16614006e-01],\n",
       "       [ -1.18036248e-01],\n",
       "       [ -5.92209063e-02],\n",
       "       [  4.05426845e-02],\n",
       "       [ -4.59834039e-02],\n",
       "       [ -2.33561829e-01],\n",
       "       [ -2.24353537e-01],\n",
       "       [ -4.06889886e-01],\n",
       "       [ -9.65298340e-02],\n",
       "       [ -6.32770881e-02],\n",
       "       [  1.90538600e-01],\n",
       "       [ -1.26689866e-01],\n",
       "       [  1.66614056e-01],\n",
       "       [  1.25427455e-01],\n",
       "       [  4.15319622e-01],\n",
       "       [  2.21780851e-01],\n",
       "       [  1.77876860e-01],\n",
       "       [ -2.97270715e-01],\n",
       "       [ -3.98349375e-01],\n",
       "       [  1.33672431e-01],\n",
       "       [  1.25048548e-01],\n",
       "       [  3.96979861e-02],\n",
       "       [  5.80527773e-03],\n",
       "       [  2.71327198e-01],\n",
       "       [  3.99603695e-02],\n",
       "       [  6.63535073e-02],\n",
       "       [  8.94951746e-02],\n",
       "       [ -2.22690716e-01],\n",
       "       [  3.34148780e-02],\n",
       "       [ -1.11390993e-01],\n",
       "       [  9.87045392e-02],\n",
       "       [ -2.83930544e-02],\n",
       "       [ -2.82781005e-01],\n",
       "       [ -1.67327732e-01],\n",
       "       [ -1.03433773e-01],\n",
       "       [  1.26832321e-01],\n",
       "       [ -1.10717766e-01],\n",
       "       [  5.23972251e-02],\n",
       "       [ -6.27884865e-02],\n",
       "       [ -2.10148152e-02],\n",
       "       [ -2.44448274e-01],\n",
       "       [ -1.28024906e-01],\n",
       "       [  2.26851508e-01],\n",
       "       [ -4.30082120e-02],\n",
       "       [  6.30846322e-02],\n",
       "       [  2.46517017e-01],\n",
       "       [  1.72932118e-01],\n",
       "       [ -1.00859543e-02],\n",
       "       [  4.32154816e-03],\n",
       "       [  1.58767655e-01],\n",
       "       [ -1.27162337e-01],\n",
       "       [ -1.74311325e-02],\n",
       "       [ -9.00861062e-03],\n",
       "       [  2.49088630e-01],\n",
       "       [ -1.77830443e-04],\n",
       "       [ -9.11513716e-02],\n",
       "       [ -8.06647837e-02],\n",
       "       [  1.18247636e-01],\n",
       "       [ -2.52282053e-01],\n",
       "       [ -1.89166337e-01],\n",
       "       [ -6.05881177e-02],\n",
       "       [ -9.99893099e-02],\n",
       "       [ -3.67355198e-01],\n",
       "       [  1.16812304e-01],\n",
       "       [ -4.92879659e-01],\n",
       "       [ -1.63283244e-01],\n",
       "       [ -3.38685811e-02],\n",
       "       [ -3.06190491e-01],\n",
       "       [ -1.65226668e-01],\n",
       "       [ -2.05450967e-01],\n",
       "       [  4.27233204e-02],\n",
       "       [ -6.89647943e-02],\n",
       "       [ -1.42480731e-01],\n",
       "       [  8.84199794e-03],\n",
       "       [ -1.33654371e-01],\n",
       "       [  6.05785809e-02],\n",
       "       [ -2.22258538e-01],\n",
       "       [ -3.46161544e-01],\n",
       "       [  2.03651696e-01],\n",
       "       [  2.56709218e-01],\n",
       "       [ -2.16877684e-01],\n",
       "       [  7.07804710e-02],\n",
       "       [  1.28309224e-02],\n",
       "       [  6.02899641e-02],\n",
       "       [  3.51022989e-01],\n",
       "       [  9.19928774e-02],\n",
       "       [ -1.09408293e-02],\n",
       "       [ -4.64086682e-01],\n",
       "       [ -7.42975101e-02],\n",
       "       [ -6.92511648e-02],\n",
       "       [ -1.25533462e-01],\n",
       "       [  2.95801815e-02],\n",
       "       [ -2.88088799e-01],\n",
       "       [ -1.12478301e-01],\n",
       "       [ -2.57237881e-01],\n",
       "       [ -6.16850704e-02],\n",
       "       [ -9.52956378e-02],\n",
       "       [  1.19770378e-01],\n",
       "       [ -2.14374155e-01],\n",
       "       [ -3.57827432e-02],\n",
       "       [ -2.18632460e-01],\n",
       "       [  1.11391783e-01],\n",
       "       [ -1.22763783e-01],\n",
       "       [  2.47819275e-01],\n",
       "       [  6.45921454e-02],\n",
       "       [  3.33886258e-02],\n",
       "       [  4.84437495e-02],\n",
       "       [ -2.80777551e-02],\n",
       "       [ -1.37949765e-01],\n",
       "       [ -1.35914922e-01],\n",
       "       [  1.90046504e-01],\n",
       "       [ -4.05478030e-02],\n",
       "       [ -4.34444875e-01],\n",
       "       [  2.97223069e-02],\n",
       "       [  4.49717119e-02],\n",
       "       [ -2.68105477e-01],\n",
       "       [  5.52663486e-03],\n",
       "       [  7.63084367e-02],\n",
       "       [  1.60604883e-02],\n",
       "       [ -2.00629428e-01],\n",
       "       [ -1.43257067e-01],\n",
       "       [  1.86318040e-01],\n",
       "       [  2.47318774e-01],\n",
       "       [ -1.26372688e-02],\n",
       "       [ -7.86468536e-02],\n",
       "       [ -6.84337199e-01],\n",
       "       [  2.00039029e-01],\n",
       "       [  3.25807594e-02],\n",
       "       [  2.99499128e-02],\n",
       "       [  3.09208989e-01],\n",
       "       [ -9.13323089e-02],\n",
       "       [  3.58030856e-01],\n",
       "       [ -1.39041217e-02],\n",
       "       [ -1.55611569e-02],\n",
       "       [ -6.74286634e-02],\n",
       "       [  1.63342163e-01],\n",
       "       [  1.70316473e-01],\n",
       "       [  6.19252846e-02],\n",
       "       [  2.41739824e-01],\n",
       "       [ -5.34188710e-02],\n",
       "       [ -3.57679695e-01],\n",
       "       [  3.76577526e-01],\n",
       "       [ -3.10270060e-02],\n",
       "       [ -2.27571696e-01],\n",
       "       [  4.70305860e-01],\n",
       "       [  1.57542914e-01],\n",
       "       [ -2.45176971e-01],\n",
       "       [ -5.23346603e-01],\n",
       "       [  1.47977814e-01],\n",
       "       [ -2.75765449e-01],\n",
       "       [  1.28229260e-01],\n",
       "       [ -1.01118922e-01],\n",
       "       [ -2.74867415e-01],\n",
       "       [  2.77876500e-02],\n",
       "       [ -3.43397528e-01],\n",
       "       [ -3.51266772e-01],\n",
       "       [ -1.43579900e-01],\n",
       "       [ -8.71348828e-02],\n",
       "       [ -4.15508598e-01],\n",
       "       [ -2.51435548e-01],\n",
       "       [ -3.86087656e-01],\n",
       "       [ -2.18334445e-03],\n",
       "       [ -6.23170063e-02],\n",
       "       [ -6.80662096e-01],\n",
       "       [  3.18116456e-01],\n",
       "       [  3.00076365e-01],\n",
       "       [  1.23045616e-01],\n",
       "       [ -1.52106583e-01],\n",
       "       [ -3.44323874e-01],\n",
       "       [  4.46960539e-01],\n",
       "       [ -4.13561128e-02],\n",
       "       [ -1.54617220e-01],\n",
       "       [ -1.50180832e-01],\n",
       "       [ -2.25403070e-01],\n",
       "       [ -3.77595366e-04],\n",
       "       [  6.65694359e-04],\n",
       "       [  1.88336641e-01],\n",
       "       [ -8.42772052e-02],\n",
       "       [  3.42674434e-01],\n",
       "       [  3.93620022e-02],\n",
       "       [  2.81751633e-01],\n",
       "       [  3.24068546e-01],\n",
       "       [ -2.53914893e-01],\n",
       "       [ -5.67206368e-02],\n",
       "       [ -8.33338872e-02],\n",
       "       [  4.63102937e-01],\n",
       "       [ -6.63491860e-02],\n",
       "       [ -2.99034923e-01],\n",
       "       [ -1.55928567e-01],\n",
       "       [ -3.44632864e-01],\n",
       "       [ -2.14253500e-01],\n",
       "       [ -8.60469341e-02],\n",
       "       [  3.93410444e-01],\n",
       "       [  3.00668150e-01],\n",
       "       [ -1.42600149e-01],\n",
       "       [ -3.19099605e-01],\n",
       "       [ -1.98550165e-01],\n",
       "       [ -7.78433010e-02],\n",
       "       [  9.18982364e-03],\n",
       "       [ -5.03881872e-01],\n",
       "       [ -1.97498053e-01],\n",
       "       [  1.84271157e-01],\n",
       "       [  1.35788903e-01],\n",
       "       [ -1.71849310e-01],\n",
       "       [ -1.30001664e-01],\n",
       "       [  1.30624343e-02],\n",
       "       [  1.19594894e-01],\n",
       "       [ -2.08262026e-01],\n",
       "       [ -3.12400628e-02],\n",
       "       [ -1.24811910e-01],\n",
       "       [ -3.88323180e-02],\n",
       "       [  2.30397761e-01],\n",
       "       [  3.74993682e-01],\n",
       "       [ -1.92693517e-01],\n",
       "       [  2.82426745e-01],\n",
       "       [ -2.60059595e-01],\n",
       "       [ -5.46958596e-02],\n",
       "       [ -6.62333518e-02],\n",
       "       [  1.25171334e-01],\n",
       "       [ -3.45277250e-01],\n",
       "       [  1.15857847e-01],\n",
       "       [  5.49951829e-02],\n",
       "       [  9.69016086e-03],\n",
       "       [ -3.16073745e-02],\n",
       "       [ -2.42660940e-02],\n",
       "       [  1.25063345e-01],\n",
       "       [  9.35784057e-02],\n",
       "       [  8.30781683e-02],\n",
       "       [ -1.13708816e-01],\n",
       "       [ -7.25336671e-02],\n",
       "       [ -1.41309768e-01],\n",
       "       [  2.78984636e-01],\n",
       "       [ -1.06587395e-01],\n",
       "       [  1.64362058e-01],\n",
       "       [ -7.02008754e-02],\n",
       "       [ -3.20951730e-01],\n",
       "       [  6.54294118e-02],\n",
       "       [  4.28333879e-02],\n",
       "       [ -2.26278335e-01],\n",
       "       [  3.07258368e-01],\n",
       "       [ -1.32070586e-01],\n",
       "       [ -2.05682516e-01],\n",
       "       [ -3.14618587e-01],\n",
       "       [  1.14898637e-01],\n",
       "       [ -3.24223608e-01],\n",
       "       [ -1.55223742e-01],\n",
       "       [ -1.59578651e-01],\n",
       "       [ -3.89325768e-01],\n",
       "       [  7.67796710e-02],\n",
       "       [ -5.86011857e-02],\n",
       "       [ -1.14643313e-02],\n",
       "       [ -5.03059216e-02],\n",
       "       [ -1.08777650e-01],\n",
       "       [ -5.62598050e-01],\n",
       "       [ -1.72457621e-01],\n",
       "       [ -7.26310238e-02],\n",
       "       [ -1.41932070e-02],\n",
       "       [ -1.79763466e-01],\n",
       "       [ -8.96326974e-02],\n",
       "       [  7.89355636e-02],\n",
       "       [ -2.98099518e-01],\n",
       "       [ -1.15718767e-01],\n",
       "       [  1.42295361e-01],\n",
       "       [ -1.06390350e-01],\n",
       "       [  3.40651274e-01],\n",
       "       [ -1.85028389e-01],\n",
       "       [ -1.40800690e-02],\n",
       "       [  7.00804517e-02],\n",
       "       [  1.03648238e-01],\n",
       "       [ -6.62496462e-02],\n",
       "       [ -4.00088668e-01],\n",
       "       [  3.43243778e-01],\n",
       "       [ -5.72756045e-02],\n",
       "       [  1.60210893e-01],\n",
       "       [ -1.56145059e-02],\n",
       "       [ -2.12958649e-01],\n",
       "       [ -7.97554776e-02],\n",
       "       [ -2.63418138e-01],\n",
       "       [ -2.50344485e-01],\n",
       "       [ -3.80506724e-01],\n",
       "       [ -2.43869990e-01],\n",
       "       [ -5.12363352e-02],\n",
       "       [ -2.84744948e-02],\n",
       "       [ -2.24777281e-01],\n",
       "       [ -2.16239039e-02],\n",
       "       [ -2.46497437e-01],\n",
       "       [ -1.16400100e-01],\n",
       "       [ -5.86928070e-01],\n",
       "       [ -6.11355722e-01],\n",
       "       [ -4.79114652e-02],\n",
       "       [ -3.21982324e-01],\n",
       "       [ -5.94186261e-02],\n",
       "       [  5.36003895e-02],\n",
       "       [ -1.46009803e-01],\n",
       "       [ -3.83453518e-01],\n",
       "       [ -4.01508629e-01],\n",
       "       [ -4.04069722e-01],\n",
       "       [  3.45347345e-01],\n",
       "       [ -4.94053364e-02],\n",
       "       [ -1.54822960e-01],\n",
       "       [ -5.64563647e-02],\n",
       "       [ -8.47389847e-02],\n",
       "       [ -6.51958108e-01],\n",
       "       [  3.67080986e-01],\n",
       "       [  6.08808771e-02],\n",
       "       [  3.13178211e-01],\n",
       "       [ -2.19329428e-02],\n",
       "       [ -2.72363573e-01],\n",
       "       [ -1.84480563e-01],\n",
       "       [  3.38184834e-01],\n",
       "       [ -2.64957696e-01],\n",
       "       [ -2.31458738e-01],\n",
       "       [  1.72743022e-01],\n",
       "       [  6.91016167e-02],\n",
       "       [  7.61786699e-02],\n",
       "       [ -5.31890653e-02],\n",
       "       [ -2.37624556e-01],\n",
       "       [ -3.61873448e-01],\n",
       "       [  1.33861043e-02],\n",
       "       [  1.38198063e-01],\n",
       "       [  3.10135275e-01],\n",
       "       [ -9.83601287e-02],\n",
       "       [ -1.02093868e-01],\n",
       "       [  1.87139750e-01],\n",
       "       [  5.65608926e-02],\n",
       "       [ -7.01342151e-02],\n",
       "       [ -2.56393909e-01],\n",
       "       [ -4.20660734e-01],\n",
       "       [ -4.76481691e-02],\n",
       "       [ -1.29033968e-01],\n",
       "       [  3.08809392e-02],\n",
       "       [ -6.65904433e-02],\n",
       "       [  6.64574578e-02],\n",
       "       [ -5.62071741e-01],\n",
       "       [  3.77966255e-01],\n",
       "       [  1.84050258e-02],\n",
       "       [ -5.20795695e-02],\n",
       "       [  4.91284356e-02],\n",
       "       [ -3.46145779e-01],\n",
       "       [  4.95405719e-02],\n",
       "       [ -1.74950048e-01],\n",
       "       [ -2.37377360e-02],\n",
       "       [ -1.81010127e-01],\n",
       "       [  3.32428426e-01],\n",
       "       [ -2.29115695e-01],\n",
       "       [  6.00913949e-02]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 8s - loss: 0.6280     \n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 6s - loss: 0.6068     \n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 7s - loss: 0.5909     \n"
     ]
    }
   ],
   "source": [
    "history = model.fit(xTrain, \n",
    "                    yTrain,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=3,\n",
    "                    shuffle=True,\n",
    "                    verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
