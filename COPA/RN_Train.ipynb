{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Checkpoint\" data-toc-modified-id=\"Checkpoint-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Checkpoint</a></div><div class=\"lev1 toc-item\"><a href=\"#Build-Model\" data-toc-modified-id=\"Build-Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Build Model</a></div><div class=\"lev2 toc-item\"><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Import Libraries</a></div><div class=\"lev2 toc-item\"><a href=\"#Set-Hyperparameters\" data-toc-modified-id=\"Set-Hyperparameters-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Set Hyperparameters</a></div><div class=\"lev2 toc-item\"><a href=\"#Build-Graph\" data-toc-modified-id=\"Build-Graph-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Build Graph</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('/Users/lizhn7/Downloads/EXPERIMENT/COPA/RN/data/embedding.h5', 'r') as fh:\n",
    "    embedding = fh['embedding'][:]\n",
    "    \n",
    "with h5py.File('/Users/lizhn7/Downloads/EXPERIMENT/COPA/RN/data/train.h5', 'r') as fh:\n",
    "    xpTrain = fh['xpTrain'][:]\n",
    "    xaTrain = fh['xaTrain'][:]\n",
    "    xqTrain = fh['xaTrain'][:]\n",
    "    yceTrain = fh['yceTrain'][:]\n",
    "    yhiTrain = fh['yhiTrain'][:]\n",
    "    \n",
    "with h5py.File('/Users/lizhn7/Downloads/EXPERIMENT/COPA/RN/data/test.h5', 'r') as fh:\n",
    "    xpTest = fh['xpTest'][:]\n",
    "    xa1Test = fh['xa1Test'][:]\n",
    "    xa2Test = fh['xa2Test'][:]\n",
    "    xqTest = fh['xqTest'][:]\n",
    "    yTest = fh['yTest'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0, 2984, 2985,\n",
       "          1,  749], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xpTrain[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,   69,  748,    1, 1519,  999,  749,    0,    0,    0,    0,\n",
       "          0,    0], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xaTrain[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda, Input, Embedding, Dropout, GRU, RepeatVector, Concatenate, concatenate, TimeDistributed, Dense, BatchNormalization, Merge\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "import keras.backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import maxnorm\n",
    "from keras.callbacks import*\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 13\n",
    "MAX_Q_LEN = 6\n",
    "VOCAB_SIZE = 3371\n",
    "VOCAB_Q_SIZE = 11\n",
    "EMBEDDING_SIZE = 300\n",
    "EMBEDDING_Q_SIZE = 8\n",
    "GRU_SIZE = 192\n",
    "GRU_Q_SIZE = 16\n",
    "DROPOUT_RATE = 0.2\n",
    "L2_NORM = 1e-4\n",
    "HIDDEN_SIZE = 200\n",
    "WEIGHT_CONSTRAINT = 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 22\n",
    "VOCAB_SIZE = 3371\n",
    "SEED = 42\n",
    "EMBEDDING_DIM = 300\n",
    "TUNE = False\n",
    "BATCH_SIZE = 50\n",
    "NUM_EPOCHS = 10\n",
    "NUM_FILTER = 100\n",
    "FILTER_SIZES = (3, 4, 5)\n",
    "DROPOUT_RATE = 0.5\n",
    "DELTA = 0.009\n",
    "LAMBDA = 0.0001\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attention_context(x):\n",
    "    \"\"\"\n",
    "    Compute context with attention weight\n",
    "    \"\"\"\n",
    "    pre, alt = x[:, :MAX_LEN, :], x[:, :MAX_LEN, :]\n",
    "    attention_energies = K.batch_dot(pre, alt, axes=(2, 2))\n",
    "    attention_energies = K.reshape(attention_energies, (-1, MAX_LEN))\n",
    "    attention_weights = K.softmax(attention_energies)\n",
    "    attention_weights = K.reshape(attention_weights, (-1, MAX_LEN, MAX_LEN))\n",
    "    attention_context = K.batch_dot(attention_weights, pre, axes=(2, 1))\n",
    "    return K.concatenate((attention_context, alt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_map():\n",
    "    \"\"\"\n",
    "    Build Attention GRU feature maps\n",
    "    \"\"\"\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(MAX_LEN*2,), name='INPUT')\n",
    "    emb_seq = Embedding(VOCAB_SIZE, \n",
    "                        EMBEDDING_SIZE, \n",
    "                        weights=[embedding], \n",
    "                        mask_zero=True, \n",
    "                        trainable=False, \n",
    "                        name='EMBEDDING')(inputs)\n",
    "    gru = GRU(GRU_SIZE, \n",
    "              return_sequences=True, \n",
    "              implementation=0, \n",
    "              dropout=DROPOUT_RATE, \n",
    "              recurrent_dropout=DROPOUT_RATE,\n",
    "              kernel_regularizer=l2(L2_NORM),\n",
    "              recurrent_regularizer=l2(L2_NORM),\n",
    "              name='GRU')(emb_seq)\n",
    "    gru = Dropout(DROPOUT_RATE, name='DROPOUT_FM')(gru)\n",
    "    att_maps = Lambda(attention_context, name='ATTENTION_MAPS')(gru)\n",
    "    model = Model(inputs=[inputs], outputs=[att_maps])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def question_encoder():\n",
    "    \"\"\"\n",
    "    Build question encoder\n",
    "    \"\"\"\n",
    "    #K.clear_session()\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(VOCAB_Q_SIZE, \n",
    "                        EMBEDDING_Q_SIZE, \n",
    "                        mask_zero=True, \n",
    "                        input_length=MAX_Q_LEN, \n",
    "                        trainable=True, \n",
    "                        name='EMBEDDING_Q'))\n",
    "    model.add(GRU(GRU_Q_SIZE, \n",
    "                  return_sequences=False, \n",
    "                  implementation=0, \n",
    "                  dropout=DROPOUT_RATE, \n",
    "                  recurrent_dropout=DROPOUT_RATE,\n",
    "                  kernel_regularizer=l2(L2_NORM),\n",
    "                  recurrent_regularizer=l2(L2_NORM),\n",
    "                  name='GRU_Q'))    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "INPUT (InputLayer)           (None, 26)                0         \n",
      "_________________________________________________________________\n",
      "EMBEDDING (Embedding)        (None, 26, 300)           1011300   \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    (None, 26, 192)           283968    \n",
      "_________________________________________________________________\n",
      "DROPOUT (Dropout)            (None, 26, 192)           0         \n",
      "_________________________________________________________________\n",
      "ATTENTION_MAPS (Lambda)      (None, 13, 384)           0         \n",
      "=================================================================\n",
      "Total params: 1,295,268\n",
      "Trainable params: 283,968\n",
      "Non-trainable params: 1,011,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = feature_map()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relation_networks():\n",
    "    \"\"\"\n",
    "    Build relation networks\n",
    "    \"\"\"\n",
    "    AttGRU = feature_map()\n",
    "    QueENC = question_encoder()\n",
    "    joint = []\n",
    "    inputs_p = Input(shape=(MAX_LEN*2,), name='INPUT_P')\n",
    "    joint.append(inputs_p)\n",
    "    inputs_a = Input(shape=(MAX_LEN,), name='INPUT_A')\n",
    "    joint.append(inputs_a)\n",
    "    inputs = Concatenate(axis=1, name='INPUT')(joint)\n",
    "    inputs_q = Input(shape=(MAX_Q_LEN,), name='INPUT_Q')\n",
    "    feaMap = AttGRU(inputs)\n",
    "    queSeq = QueENC(inputs_q)\n",
    "    queSeq = RepeatVector(MAX_LEN, name='Q_ENC')(queSeq)\n",
    "    feaComb = concatenate([feaMap, queSeq], axis=-1, name='FEA_COMB')\n",
    "    mlp = TimeDistributed(Dense(HIDDEN_SIZE,\n",
    "                                activation='elu',\n",
    "                                kernel_regularizer=l2(L2_NORM),\n",
    "                                kernel_constraint=maxnorm(WEIGHT_CONSTRAINT)),\n",
    "                          name='MLP')(feaComb)\n",
    "    mlp = BatchNormalization(name='BN')(mlp)\n",
    "    mlp = Dropout(DROPOUT_RATE, name='DROPOUT_MLP')(mlp)\n",
    "    ewSum = Lambda(lambda x: K.sum(x, axis=1), name='ELEMENT-WISE_SUM')(mlp)\n",
    "    return ewSum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = relation_networks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'ELEMENT-WISE_SUM/Sum:0' shape=(?, 200) dtype=float32>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.random((100, 13, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a:\n",
    "    b.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 200)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
