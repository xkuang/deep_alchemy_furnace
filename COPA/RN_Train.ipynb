{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Checkpoint\" data-toc-modified-id=\"Checkpoint-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Checkpoint</a></div><div class=\"lev1 toc-item\"><a href=\"#Build-Model\" data-toc-modified-id=\"Build-Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Build Model</a></div><div class=\"lev2 toc-item\"><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Import Libraries</a></div><div class=\"lev2 toc-item\"><a href=\"#Set-Hyperparameters\" data-toc-modified-id=\"Set-Hyperparameters-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Set Hyperparameters</a></div><div class=\"lev2 toc-item\"><a href=\"#Build-Graph\" data-toc-modified-id=\"Build-Graph-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Build Graph</a></div><div class=\"lev1 toc-item\"><a href=\"#Model-Visualization\" data-toc-modified-id=\"Model-Visualization-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model Visualization</a></div><div class=\"lev1 toc-item\"><a href=\"#Train\" data-toc-modified-id=\"Train-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Train</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('/Users/lizhn7/Downloads/EXPERIMENT/COPA/RN/data/embedding.h5', 'r') as fh:\n",
    "    embedding = fh['embedding'][:]\n",
    "    \n",
    "with h5py.File('/Users/lizhn7/Downloads/EXPERIMENT/COPA/RN/data/train.h5', 'r') as fh:\n",
    "    xpTrain = fh['xpTrain'][:]\n",
    "    xaTrain = fh['xaTrain'][:]\n",
    "    xqTrain = fh['xqTrain'][:]\n",
    "    yceTrain = fh['yceTrain'][:]\n",
    "    yhiTrain = fh['yhiTrain'][:]\n",
    "    \n",
    "with h5py.File('/Users/lizhn7/Downloads/EXPERIMENT/COPA/RN/data/test.h5', 'r') as fh:\n",
    "    xpTest = fh['xpTest'][:]\n",
    "    xa1Test = fh['xa1Test'][:]\n",
    "    xa2Test = fh['xa2Test'][:]\n",
    "    xqTest = fh['xqTest'][:]\n",
    "    yTest = fh['yTest'][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Lambda, Input, Embedding, Dropout, GRU, RepeatVector, Concatenate, concatenate, TimeDistributed, Dense, BatchNormalization, Activation, Flatten\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.regularizers import l2\n",
    "from keras.constraints import maxnorm\n",
    "from keras.callbacks import*\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LEN = 13\n",
    "MAX_Q_LEN = 6\n",
    "VOCAB_SIZE = 3371\n",
    "VOCAB_Q_SIZE = 11\n",
    "EMBEDDING_SIZE = 300\n",
    "EMBEDDING_Q_SIZE = 4\n",
    "GRU_SIZE = 296\n",
    "GRU_Q_SIZE = 8\n",
    "DROPOUT_RATE = 0.2\n",
    "L2_NORM = 1e-4\n",
    "HIDDEN_SIZE = 100\n",
    "WEIGHT_CONSTRAINT = 2.\n",
    "DELTA = 0.009\n",
    "BATCH_SIZE = 200\n",
    "NUM_EPOCHS = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hinge(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Define hinge loss function\n",
    "    \"\"\"\n",
    "    return K.mean(K.maximum(DELTA - y_true * y_pred, 0.), axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```pyhton\n",
    "def attention_context(x):\n",
    "    \"\"\"\n",
    "    Compute context with attention weight\n",
    "    \"\"\"\n",
    "    pre, alt = x[:, :MAX_LEN, :], x[:, :MAX_LEN, :]\n",
    "    attention_energies = K.batch_dot(pre, alt, axes=(2, 2))\n",
    "    attention_energies = K.reshape(attention_energies, (-1, MAX_LEN))\n",
    "    attention_weights = K.softmax(attention_energies)\n",
    "    attention_weights = K.reshape(attention_weights, (-1, MAX_LEN, MAX_LEN))\n",
    "    attention_context = K.batch_dot(attention_weights, pre, axes=(2, 1))\n",
    "    return K.concatenate((attention_context, alt))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_context(x):\n",
    "    \"\"\"\n",
    "    Compute context with attention weight\n",
    "    \"\"\"\n",
    "    pre, alt = x[:, :MAX_LEN, :], x[:, :MAX_LEN, :]\n",
    "    attention_energies = K.batch_dot(pre, alt, axes=(2, 2))\n",
    "    attention_energies = K.reshape(attention_energies, (-1, MAX_LEN))\n",
    "    attention_weights = K.softmax(attention_energies)\n",
    "    attention_weights = K.reshape(attention_weights, (-1, MAX_LEN, MAX_LEN))\n",
    "    attention_maps1 = K.batch_dot(attention_weights, pre, axes=(2, 1))\n",
    "    attention_maps2 = K.batch_dot(attention_weights, alt, axes=(2, 1))\n",
    "    return K.concatenate((attention_maps1, attention_maps2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_map():\n",
    "    \"\"\"\n",
    "    Build Attention GRU feature maps\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(MAX_LEN*2,), name='INPUT')\n",
    "    emb_seq = Embedding(VOCAB_SIZE, \n",
    "                        EMBEDDING_SIZE, \n",
    "                        weights=[embedding], \n",
    "                        mask_zero=True, \n",
    "                        trainable=False, \n",
    "                        name='EMBEDDING')(inputs)\n",
    "    gru = GRU(GRU_SIZE, \n",
    "              return_sequences=True, \n",
    "              implementation=0, \n",
    "              dropout=DROPOUT_RATE, \n",
    "              recurrent_dropout=DROPOUT_RATE,\n",
    "              kernel_regularizer=l2(L2_NORM),\n",
    "              recurrent_regularizer=l2(L2_NORM),\n",
    "              name='GRU')(emb_seq)\n",
    "    gru = Dropout(DROPOUT_RATE, name='DROPOUT_FM')(gru)\n",
    "    att_maps = Lambda(attention_context, name='ATTENTION_MAPS')(gru)\n",
    "    model = Model(inputs=[inputs], outputs=[att_maps])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "INPUT (InputLayer)           (None, 26)                0         \n",
      "_________________________________________________________________\n",
      "EMBEDDING (Embedding)        (None, 26, 300)           1011300   \n",
      "_________________________________________________________________\n",
      "GRU (GRU)                    (None, 26, 296)           530136    \n",
      "_________________________________________________________________\n",
      "DROPOUT_FM (Dropout)         (None, 26, 296)           0         \n",
      "_________________________________________________________________\n",
      "ATTENTION_MAPS (Lambda)      (None, 13, 592)           0         \n",
      "=================================================================\n",
      "Total params: 1,541,436\n",
      "Trainable params: 530,136\n",
      "Non-trainable params: 1,011,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = feature_map()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def question_encoder():\n",
    "    \"\"\"\n",
    "    Build question encoder\n",
    "    \"\"\"\n",
    "    inputs = Input(shape=(MAX_Q_LEN,), name='INPUT')\n",
    "    emb_seq = Embedding(VOCAB_Q_SIZE, \n",
    "                        EMBEDDING_Q_SIZE, \n",
    "                        mask_zero=True, \n",
    "                        input_length=MAX_Q_LEN, \n",
    "                        trainable=True, \n",
    "                        name='EMBEDDING_Q')(inputs)\n",
    "    gru = GRU(GRU_Q_SIZE, \n",
    "              return_sequences=False, \n",
    "              implementation=0, \n",
    "              dropout=DROPOUT_RATE, \n",
    "              recurrent_dropout=DROPOUT_RATE,\n",
    "              kernel_regularizer=l2(L2_NORM),\n",
    "              recurrent_regularizer=l2(L2_NORM),\n",
    "              name='GRU_Q')(emb_seq)\n",
    "    model = Model(inputs=[inputs], outputs=[gru])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relation_networks():\n",
    "    \"\"\"\n",
    "    Build relation networks\n",
    "    \"\"\"\n",
    "    AttGRU = feature_map()\n",
    "    QueENC = question_encoder()\n",
    "    joint = []\n",
    "    inputs_p = Input(shape=(MAX_LEN,), name='INPUT_P')\n",
    "    joint.append(inputs_p)\n",
    "    inputs_a = Input(shape=(MAX_LEN,), name='INPUT_A')\n",
    "    joint.append(inputs_a)\n",
    "    inputs = Concatenate(axis=1, name='INPUT')(joint)\n",
    "    inputs_q = Input(shape=(MAX_Q_LEN,), name='INPUT_Q')\n",
    "    feaMap = AttGRU(inputs)\n",
    "    queSeq = QueENC(inputs_q)\n",
    "    queSeq = RepeatVector(MAX_LEN, name='Q_ENC')(queSeq)\n",
    "    feaComb = concatenate([feaMap, queSeq], axis=-1, name='FEA_COMB')\n",
    "    mlp = TimeDistributed(Dense(HIDDEN_SIZE,\n",
    "                                activation=None,\n",
    "                                kernel_regularizer=l2(L2_NORM),\n",
    "                                kernel_constraint=maxnorm(WEIGHT_CONSTRAINT)),\n",
    "                          name='MLP')(feaComb)\n",
    "    mlp = BatchNormalization(name='BN')(mlp)\n",
    "    mlp = Activation('relu', name='RELU')(mlp)\n",
    "    mlp = Dropout(DROPOUT_RATE, name='DROPOUT_1')(mlp)\n",
    "    #ewSum = Lambda(lambda x: K.sum(x, axis=1), name='ELEMENT-WISE_SUM')(mlp)\n",
    "    #ewSum = Dropout(DROPOUT_RATE, name='DROPOUT_2')(ewSum)\n",
    "    ewSum = Flatten()(mlp)\n",
    "    outputs = Dense(1, \n",
    "                    activation='tanh', \n",
    "                    kernel_regularizer=l2(L2_NORM),\n",
    "                    kernel_constraint=maxnorm(WEIGHT_CONSTRAINT),\n",
    "                    name='OUTPUT')(ewSum)\n",
    "    model = Model(inputs=[inputs_p, inputs_a, inputs_q], outputs=[outputs])\n",
    "    model.compile(loss=hinge, optimizer='rmsprop')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "INPUT_P (InputLayer)             (None, 13)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "INPUT_A (InputLayer)             (None, 13)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "INPUT_Q (InputLayer)             (None, 6)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "INPUT (Concatenate)              (None, 26)            0           INPUT_P[0][0]                    \n",
      "                                                                   INPUT_A[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  (None, 8)             356         INPUT_Q[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 13, 592)       1541436     INPUT[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "Q_ENC (RepeatVector)             (None, 13, 8)         0           model_2[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "FEA_COMB (Concatenate)           (None, 13, 600)       0           model_1[1][0]                    \n",
      "                                                                   Q_ENC[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "MLP (TimeDistributed)            (None, 13, 100)       60100       FEA_COMB[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "BN (BatchNormalization)          (None, 13, 100)       400         MLP[0][0]                        \n",
      "____________________________________________________________________________________________________\n",
      "RELU (Activation)                (None, 13, 100)       0           BN[0][0]                         \n",
      "____________________________________________________________________________________________________\n",
      "DROPOUT_1 (Dropout)              (None, 13, 100)       0           RELU[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1300)          0           DROPOUT_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "OUTPUT (Dense)                   (None, 1)             1301        flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1,603,593\n",
      "Trainable params: 592,093\n",
      "Non-trainable params: 1,011,500\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"702pt\" viewBox=\"0.00 0.00 473.75 702.00\" width=\"474pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 698)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-698 469.752,-698 469.752,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 112642442632 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>112642442632</title>\n",
       "<polygon fill=\"none\" points=\"0,-657.5 0,-693.5 141.5898,-693.5 141.5898,-657.5 0,-657.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"70.7949\" y=\"-671.3\">INPUT_P: InputLayer</text>\n",
       "</g>\n",
       "<!-- 112650075272 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>112650075272</title>\n",
       "<polygon fill=\"none\" points=\"165.2451,-584.5 165.2451,-620.5 298.3447,-620.5 298.3447,-584.5 165.2451,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231.7949\" y=\"-598.3\">INPUT: Concatenate</text>\n",
       "</g>\n",
       "<!-- 112642442632&#45;&gt;112650075272 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>112642442632-&gt;112650075272</title>\n",
       "<path d=\"M110.5927,-657.4551C132.3628,-647.5841 159.5224,-635.2695 182.6105,-624.801\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"184.2348,-627.9076 191.897,-620.5904 181.3441,-621.5323 184.2348,-627.9076\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112651025712 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>112651025712</title>\n",
       "<polygon fill=\"none\" points=\"159.8379,-657.5 159.8379,-693.5 303.752,-693.5 303.752,-657.5 159.8379,-657.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"231.7949\" y=\"-671.3\">INPUT_A: InputLayer</text>\n",
       "</g>\n",
       "<!-- 112651025712&#45;&gt;112650075272 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>112651025712-&gt;112650075272</title>\n",
       "<path d=\"M231.7949,-657.4551C231.7949,-649.3828 231.7949,-639.6764 231.7949,-630.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"235.295,-630.5903 231.7949,-620.5904 228.295,-630.5904 235.295,-630.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112650428712 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>112650428712</title>\n",
       "<polygon fill=\"none\" points=\"321.8379,-657.5 321.8379,-693.5 465.752,-693.5 465.752,-657.5 321.8379,-657.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"393.7949\" y=\"-671.3\">INPUT_Q: InputLayer</text>\n",
       "</g>\n",
       "<!-- 112642598672 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>112642598672</title>\n",
       "<polygon fill=\"none\" points=\"336.3276,-584.5 336.3276,-620.5 445.2622,-620.5 445.2622,-584.5 336.3276,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"390.7949\" y=\"-598.3\">model_2: Model</text>\n",
       "</g>\n",
       "<!-- 112650428712&#45;&gt;112642598672 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>112650428712-&gt;112642598672</title>\n",
       "<path d=\"M393.0533,-657.4551C392.7216,-649.3828 392.3227,-639.6764 391.9531,-630.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"395.4461,-630.4382 391.5384,-620.5904 388.452,-630.7257 395.4461,-630.4382\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112599670512 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>112599670512</title>\n",
       "<polygon fill=\"none\" points=\"186.3276,-511.5 186.3276,-547.5 295.2622,-547.5 295.2622,-511.5 186.3276,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"240.7949\" y=\"-525.3\">model_1: Model</text>\n",
       "</g>\n",
       "<!-- 112650075272&#45;&gt;112599670512 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>112650075272-&gt;112599670512</title>\n",
       "<path d=\"M234.0196,-584.4551C235.0148,-576.3828 236.2115,-566.6764 237.3205,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"240.8146,-557.9435 238.5646,-547.5904 233.8672,-557.0869 240.8146,-557.9435\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112649299952 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>112649299952</title>\n",
       "<polygon fill=\"none\" points=\"316.8413,-511.5 316.8413,-547.5 460.7485,-547.5 460.7485,-511.5 316.8413,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"388.7949\" y=\"-525.3\">Q_ENC: RepeatVector</text>\n",
       "</g>\n",
       "<!-- 112642598672&#45;&gt;112649299952 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>112642598672-&gt;112649299952</title>\n",
       "<path d=\"M390.3005,-584.4551C390.0794,-576.3828 389.8135,-566.6764 389.567,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"393.0632,-557.4907 389.2905,-547.5904 386.0658,-557.6825 393.0632,-557.4907\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112649461712 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>112649461712</title>\n",
       "<polygon fill=\"none\" points=\"229.1655,-438.5 229.1655,-474.5 396.4243,-474.5 396.4243,-438.5 229.1655,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.7949\" y=\"-452.3\">FEA_COMB: Concatenate</text>\n",
       "</g>\n",
       "<!-- 112599670512&#45;&gt;112649461712 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>112599670512-&gt;112649461712</title>\n",
       "<path d=\"M258.5927,-511.4551C267.4197,-502.5054 278.228,-491.547 287.8642,-481.7769\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"290.4221,-484.1678 294.9524,-474.5904 285.4383,-479.2523 290.4221,-484.1678\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112649299952&#45;&gt;112649461712 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>112649299952-&gt;112649461712</title>\n",
       "<path d=\"M370.0084,-511.4551C360.691,-502.5054 349.2822,-491.547 339.1106,-481.7769\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"341.2653,-478.9935 331.6287,-474.5904 336.4162,-484.0419 341.2653,-478.9935\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112659520536 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>112659520536</title>\n",
       "<polygon fill=\"none\" points=\"191.0483,-365.5 191.0483,-401.5 434.5415,-401.5 434.5415,-365.5 191.0483,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.7949\" y=\"-379.3\">MLP(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 112649461712&#45;&gt;112659520536 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>112649461712-&gt;112659520536</title>\n",
       "<path d=\"M312.7949,-438.4551C312.7949,-430.3828 312.7949,-420.6764 312.7949,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"316.295,-411.5903 312.7949,-401.5904 309.295,-411.5904 316.295,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112661681208 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>112661681208</title>\n",
       "<polygon fill=\"none\" points=\"234.6172,-292.5 234.6172,-328.5 390.9727,-328.5 390.9727,-292.5 234.6172,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.7949\" y=\"-306.3\">BN: BatchNormalization</text>\n",
       "</g>\n",
       "<!-- 112659520536&#45;&gt;112661681208 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>112659520536-&gt;112661681208</title>\n",
       "<path d=\"M312.7949,-365.4551C312.7949,-357.3828 312.7949,-347.6764 312.7949,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"316.295,-338.5903 312.7949,-328.5904 309.295,-338.5904 316.295,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112661765088 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>112661765088</title>\n",
       "<polygon fill=\"none\" points=\"253.6587,-219.5 253.6587,-255.5 371.9312,-255.5 371.9312,-219.5 253.6587,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.7949\" y=\"-233.3\">RELU: Activation</text>\n",
       "</g>\n",
       "<!-- 112661681208&#45;&gt;112661765088 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>112661681208-&gt;112661765088</title>\n",
       "<path d=\"M312.7949,-292.4551C312.7949,-284.3828 312.7949,-274.6764 312.7949,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"316.295,-265.5903 312.7949,-255.5904 309.295,-265.5904 316.295,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112662051192 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>112662051192</title>\n",
       "<polygon fill=\"none\" points=\"237.7104,-146.5 237.7104,-182.5 387.8794,-182.5 387.8794,-146.5 237.7104,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.7949\" y=\"-160.3\">DROPOUT_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 112661765088&#45;&gt;112662051192 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>112661765088-&gt;112662051192</title>\n",
       "<path d=\"M312.7949,-219.4551C312.7949,-211.3828 312.7949,-201.6764 312.7949,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"316.295,-192.5903 312.7949,-182.5904 309.295,-192.5904 316.295,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112662272880 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>112662272880</title>\n",
       "<polygon fill=\"none\" points=\"257.1621,-73.5 257.1621,-109.5 368.4277,-109.5 368.4277,-73.5 257.1621,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.7949\" y=\"-87.3\">flatten_1: Flatten</text>\n",
       "</g>\n",
       "<!-- 112662051192&#45;&gt;112662272880 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>112662051192-&gt;112662272880</title>\n",
       "<path d=\"M312.7949,-146.4551C312.7949,-138.3828 312.7949,-128.6764 312.7949,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"316.295,-119.5903 312.7949,-109.5904 309.295,-119.5904 316.295,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 112662411864 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>112662411864</title>\n",
       "<polygon fill=\"none\" points=\"256.3452,-.5 256.3452,-36.5 369.2446,-36.5 369.2446,-.5 256.3452,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"312.7949\" y=\"-14.3\">OUTPUT: Dense</text>\n",
       "</g>\n",
       "<!-- 112662272880&#45;&gt;112662411864 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>112662272880-&gt;112662411864</title>\n",
       "<path d=\"M312.7949,-73.4551C312.7949,-65.3828 312.7949,-55.6764 312.7949,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"316.295,-46.5903 312.7949,-36.5904 309.295,-46.5904 316.295,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "model = relation_networks()\n",
    "model.summary()\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(p, a1, a2, q, actu, show=True):\n",
    "    \"\"\"\n",
    "    Calculate Accuracy\n",
    "    \"\"\"\n",
    "    A1 = model.predict([p, a1, q])\n",
    "    A2 = model.predict([p, a2, q])\n",
    "    pred = []\n",
    "    for i in range(len(A1)):\n",
    "        if A1[i] > A2[i]:\n",
    "            pred.append(1)\n",
    "        else:\n",
    "            pred.append(2)\n",
    "    S = sum([1 for i in range(len(pred)) if pred[i] == actu[i]])\n",
    "    ACC = S / len(actu)\n",
    "    if show:\n",
    "        print('Accuracy: \\t%.9f' % (ACC))\n",
    "    return np.array([ACC])\n",
    "\n",
    "def plot_acc(acc, num_epochs):\n",
    "    \"\"\"\n",
    "    Plot Accuracy\n",
    "    \"\"\"\n",
    "    print('MAX Accuracy: \\t%.3f' % (max(acc)))\n",
    "    epochs = list(range(1, num_epochs+1))\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.plot(epochs, acc, label=\"Accuracy\", color=\"red\", linewidth=1)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xticks([i for i in range(1, len(acc), len(acc)//10)])\n",
    "    plt.grid(True)  \n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_loss(log):\n",
    "    \"\"\"\n",
    "    Plot Loss\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    loss = log['loss']\n",
    "    if 'val_loss' in log:\n",
    "        val_loss = log['val_loss']\n",
    "        plt.plot(val_loss, color=\"r\", label=\"Val Loss\")\n",
    "    plt.plot(loss, color=\"g\", label=\"Train Loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(model, num_epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, verbose=1, show=True, plot=True):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    model :                  training model          \n",
    "    num_epochs 128:          training epochs   \n",
    "    batch_size 200:          size of batch \n",
    "    verbose :                1\n",
    "    show True:               show accuracy every epoch\n",
    "    plot True:               plot accuracy and loss or not\n",
    "    Returns\n",
    "    ----------\n",
    "    The training results\n",
    "    \"\"\"\n",
    "    ACC = []\n",
    "    history = {}\n",
    "    for e in range(num_epochs):\n",
    "        print('EPOCHS', e+1)\n",
    "        t = model.fit([xpTrain, xaTrain, xqTrain], \n",
    "                      yhiTrain,\n",
    "                      batch_size=batch_size,\n",
    "                      epochs=1,\n",
    "                      shuffle=True,\n",
    "                      verbose=verbose)\n",
    "        for i, j in t.history.items():\n",
    "            history[i] = history.get(i, []) + j\n",
    "        ACC.append(accuracy(xpTest, xa1Test, xa2Test, xqTest, yTest, show=show))\n",
    "    if plot:\n",
    "        plot_acc(ACC, num_epochs)\n",
    "        plot_loss(history)\n",
    "    ACC = sum([list(i) for i in ACC], [])\n",
    "    return max(ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS 1\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 17s - loss: 0.6038    \n",
      "Accuracy: \t0.496000000\n",
      "EPOCHS 2\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s - loss: 0.6057    \n",
      "Accuracy: \t0.496000000\n",
      "EPOCHS 3\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s - loss: 0.5796    \n",
      "Accuracy: \t0.496000000\n",
      "EPOCHS 4\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s - loss: 0.5812    \n",
      "Accuracy: \t0.496000000\n",
      "EPOCHS 5\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s - loss: 0.5833    \n",
      "Accuracy: \t0.496000000\n",
      "EPOCHS 6\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s - loss: 0.5778    \n",
      "Accuracy: \t0.496000000\n",
      "EPOCHS 7\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s - loss: 0.5823    \n",
      "Accuracy: \t0.496000000\n",
      "EPOCHS 8\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s - loss: 0.5755    \n",
      "Accuracy: \t0.496000000\n",
      "EPOCHS 9\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s - loss: 0.5665    \n",
      "Accuracy: \t0.496000000\n",
      "EPOCHS 10\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s - loss: 0.5867    \n",
      "Accuracy: \t0.496000000\n",
      "EPOCHS 11\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s - loss: 0.5752    \n",
      "Accuracy: \t0.496000000\n",
      "EPOCHS 12\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s - loss: 0.5794    \n",
      "Accuracy: \t0.496000000\n",
      "EPOCHS 13\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s - loss: 0.5765    \n",
      "Accuracy: \t0.496000000\n",
      "EPOCHS 14\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s - loss: 0.5732    \n",
      "Accuracy: \t0.496000000\n",
      "EPOCHS 15\n",
      "Epoch 1/1\n",
      "1000/2000 [==============>...............] - ETA: 7s - loss: 0.5725"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-15e25f3631a5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelation_networks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-d93b23755fb4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, num_epochs, batch_size, verbose, show, plot)\u001b[0m\n\u001b[1;32m     22\u001b[0m                       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                       \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                       verbose=verbose)\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(relation_networks())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 8s - loss: 0.0935     \n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 6s - loss: 0.0638     \n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 6s - loss: 0.0529     \n"
     ]
    }
   ],
   "source": [
    "history = model.fit([xpTrain, xaTrain, xqTrain], \n",
    "                    yceTrain,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=3,\n",
    "                    shuffle=True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]], dtype=bool)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([xpTest, xa1Test, xqTest]) == model.predict([xpTest, xa2Test, xqTest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04006713],\n",
       "       [ 0.04317438],\n",
       "       [ 0.05277794],\n",
       "       [ 0.0330967 ],\n",
       "       [ 0.04245253],\n",
       "       [ 0.04038421],\n",
       "       [ 0.05393065],\n",
       "       [ 0.04121786],\n",
       "       [ 0.03302476],\n",
       "       [ 0.05620285],\n",
       "       [ 0.03949131],\n",
       "       [ 0.03207621],\n",
       "       [ 0.0378809 ],\n",
       "       [ 0.05519846],\n",
       "       [ 0.04921759],\n",
       "       [ 0.037997  ],\n",
       "       [ 0.04572457],\n",
       "       [ 0.06853228],\n",
       "       [ 0.03380357],\n",
       "       [ 0.04441269],\n",
       "       [ 0.03775113],\n",
       "       [ 0.06172223],\n",
       "       [ 0.05329597],\n",
       "       [ 0.06474978],\n",
       "       [ 0.04547671],\n",
       "       [ 0.05316555],\n",
       "       [ 0.04448027],\n",
       "       [ 0.03722025],\n",
       "       [ 0.04629617],\n",
       "       [ 0.05081072],\n",
       "       [ 0.04030119],\n",
       "       [ 0.0381727 ],\n",
       "       [ 0.0391874 ],\n",
       "       [ 0.04003835],\n",
       "       [ 0.04010185],\n",
       "       [ 0.04204791],\n",
       "       [ 0.03639166],\n",
       "       [ 0.03304909],\n",
       "       [ 0.03497537],\n",
       "       [ 0.03433217],\n",
       "       [ 0.03903621],\n",
       "       [ 0.03275463],\n",
       "       [ 0.04556612],\n",
       "       [ 0.03986829],\n",
       "       [ 0.05578475],\n",
       "       [ 0.04395832],\n",
       "       [ 0.04644228],\n",
       "       [ 0.02753446],\n",
       "       [ 0.03810566],\n",
       "       [ 0.03288704],\n",
       "       [ 0.04849708],\n",
       "       [ 0.03388911],\n",
       "       [ 0.03312086],\n",
       "       [ 0.04705543],\n",
       "       [ 0.10350499],\n",
       "       [ 0.04982309],\n",
       "       [ 0.03263544],\n",
       "       [ 0.03357043],\n",
       "       [ 0.04261139],\n",
       "       [ 0.08569978],\n",
       "       [ 0.04134544],\n",
       "       [ 0.03435485],\n",
       "       [ 0.03670896],\n",
       "       [ 0.0451143 ],\n",
       "       [ 0.0580676 ],\n",
       "       [ 0.05793938],\n",
       "       [ 0.04909617],\n",
       "       [ 0.05493255],\n",
       "       [ 0.07099713],\n",
       "       [ 0.03963391],\n",
       "       [ 0.04575185],\n",
       "       [ 0.05757344],\n",
       "       [ 0.03580958],\n",
       "       [ 0.03438941],\n",
       "       [ 0.03928765],\n",
       "       [ 0.04753852],\n",
       "       [ 0.05517763],\n",
       "       [ 0.03724819],\n",
       "       [ 0.04558859],\n",
       "       [ 0.0503263 ],\n",
       "       [ 0.03234161],\n",
       "       [ 0.03911715],\n",
       "       [ 0.05297889],\n",
       "       [ 0.06603786],\n",
       "       [ 0.03609088],\n",
       "       [ 0.03963833],\n",
       "       [ 0.07573447],\n",
       "       [ 0.06665716],\n",
       "       [ 0.03314289],\n",
       "       [ 0.0494393 ],\n",
       "       [ 0.04684274],\n",
       "       [ 0.04953152],\n",
       "       [ 0.04713985],\n",
       "       [ 0.0396267 ],\n",
       "       [ 0.03653334],\n",
       "       [ 0.04084512],\n",
       "       [ 0.03716893],\n",
       "       [ 0.04763226],\n",
       "       [ 0.03954289],\n",
       "       [ 0.04484127],\n",
       "       [ 0.04825737],\n",
       "       [ 0.03307502],\n",
       "       [ 0.0331872 ],\n",
       "       [ 0.07239824],\n",
       "       [ 0.0410643 ],\n",
       "       [ 0.04611079],\n",
       "       [ 0.04772803],\n",
       "       [ 0.05647425],\n",
       "       [ 0.03961864],\n",
       "       [ 0.0373649 ],\n",
       "       [ 0.03382229],\n",
       "       [ 0.03867087],\n",
       "       [ 0.04942246],\n",
       "       [ 0.03775347],\n",
       "       [ 0.0330767 ],\n",
       "       [ 0.03685027],\n",
       "       [ 0.05813931],\n",
       "       [ 0.04537407],\n",
       "       [ 0.03513933],\n",
       "       [ 0.03184344],\n",
       "       [ 0.05462327],\n",
       "       [ 0.05767277],\n",
       "       [ 0.05228956],\n",
       "       [ 0.03731494],\n",
       "       [ 0.04016697],\n",
       "       [ 0.03168994],\n",
       "       [ 0.04408277],\n",
       "       [ 0.03386662],\n",
       "       [ 0.07860471],\n",
       "       [ 0.04814353],\n",
       "       [ 0.06152626],\n",
       "       [ 0.0545482 ],\n",
       "       [ 0.06030769],\n",
       "       [ 0.03081905],\n",
       "       [ 0.10530834],\n",
       "       [ 0.0363786 ],\n",
       "       [ 0.04698267],\n",
       "       [ 0.04495453],\n",
       "       [ 0.08147979],\n",
       "       [ 0.03781825],\n",
       "       [ 0.03829515],\n",
       "       [ 0.08470779],\n",
       "       [ 0.04806828],\n",
       "       [ 0.08258957],\n",
       "       [ 0.04576003],\n",
       "       [ 0.05013552],\n",
       "       [ 0.03694827],\n",
       "       [ 0.05549217],\n",
       "       [ 0.03513249],\n",
       "       [ 0.03704568],\n",
       "       [ 0.05615099],\n",
       "       [ 0.0495779 ],\n",
       "       [ 0.03247269],\n",
       "       [ 0.04355912],\n",
       "       [ 0.03166695],\n",
       "       [ 0.05350016],\n",
       "       [ 0.04670271],\n",
       "       [ 0.03435293],\n",
       "       [ 0.03890326],\n",
       "       [ 0.0390978 ],\n",
       "       [ 0.03492763],\n",
       "       [ 0.03246816],\n",
       "       [ 0.04981017],\n",
       "       [ 0.04059013],\n",
       "       [ 0.05137453],\n",
       "       [ 0.03794677],\n",
       "       [ 0.05557026],\n",
       "       [ 0.04204563],\n",
       "       [ 0.04555709],\n",
       "       [ 0.05448764],\n",
       "       [ 0.04193845],\n",
       "       [ 0.06470858],\n",
       "       [ 0.03515819],\n",
       "       [ 0.03724895],\n",
       "       [ 0.06446793],\n",
       "       [ 0.06798662],\n",
       "       [ 0.03732461],\n",
       "       [ 0.04448901],\n",
       "       [ 0.0514021 ],\n",
       "       [ 0.06541658],\n",
       "       [ 0.08442938],\n",
       "       [ 0.04728749],\n",
       "       [ 0.06802519],\n",
       "       [ 0.08554811],\n",
       "       [ 0.06052734],\n",
       "       [ 0.0668102 ],\n",
       "       [ 0.03872604],\n",
       "       [ 0.05914998],\n",
       "       [ 0.03885282],\n",
       "       [ 0.0385512 ],\n",
       "       [ 0.03826902],\n",
       "       [ 0.03585368],\n",
       "       [ 0.03609   ],\n",
       "       [ 0.05103591],\n",
       "       [ 0.04630971],\n",
       "       [ 0.0422407 ],\n",
       "       [ 0.03689301],\n",
       "       [ 0.0474193 ],\n",
       "       [ 0.04432292],\n",
       "       [ 0.04813907],\n",
       "       [ 0.04182113],\n",
       "       [ 0.03664819],\n",
       "       [ 0.04004436],\n",
       "       [ 0.03370444],\n",
       "       [ 0.0514474 ],\n",
       "       [ 0.05062658],\n",
       "       [ 0.06326666],\n",
       "       [ 0.05785513],\n",
       "       [ 0.0309593 ],\n",
       "       [ 0.0392164 ],\n",
       "       [ 0.0334456 ],\n",
       "       [ 0.07052089],\n",
       "       [ 0.03213812],\n",
       "       [ 0.04660576],\n",
       "       [ 0.05689188],\n",
       "       [ 0.06162158],\n",
       "       [ 0.05754763],\n",
       "       [ 0.05791067],\n",
       "       [ 0.07244613],\n",
       "       [ 0.04460344],\n",
       "       [ 0.0434719 ],\n",
       "       [ 0.04241389],\n",
       "       [ 0.04995234],\n",
       "       [ 0.06814826],\n",
       "       [ 0.04047604],\n",
       "       [ 0.05419758],\n",
       "       [ 0.08792802],\n",
       "       [ 0.03497065],\n",
       "       [ 0.06244554],\n",
       "       [ 0.03285672],\n",
       "       [ 0.0496557 ],\n",
       "       [ 0.03506862],\n",
       "       [ 0.03748099],\n",
       "       [ 0.03739803],\n",
       "       [ 0.04251526],\n",
       "       [ 0.0560731 ],\n",
       "       [ 0.04165617],\n",
       "       [ 0.0339753 ],\n",
       "       [ 0.03260542],\n",
       "       [ 0.04344824],\n",
       "       [ 0.03225192],\n",
       "       [ 0.06010161],\n",
       "       [ 0.04046479],\n",
       "       [ 0.04889742],\n",
       "       [ 0.06364474],\n",
       "       [ 0.04401898],\n",
       "       [ 0.04465111],\n",
       "       [ 0.04941688],\n",
       "       [ 0.03411803],\n",
       "       [ 0.03937017],\n",
       "       [ 0.03807604],\n",
       "       [ 0.04672576],\n",
       "       [ 0.07904179],\n",
       "       [ 0.04258927],\n",
       "       [ 0.06323929],\n",
       "       [ 0.05030255],\n",
       "       [ 0.03667512],\n",
       "       [ 0.03213549],\n",
       "       [ 0.03937485],\n",
       "       [ 0.0424446 ],\n",
       "       [ 0.03615233],\n",
       "       [ 0.03577757],\n",
       "       [ 0.04969116],\n",
       "       [ 0.05439329],\n",
       "       [ 0.04352452],\n",
       "       [ 0.03668539],\n",
       "       [ 0.04065402],\n",
       "       [ 0.03289357],\n",
       "       [ 0.05503359],\n",
       "       [ 0.04827139],\n",
       "       [ 0.07270844],\n",
       "       [ 0.04002059],\n",
       "       [ 0.06946751],\n",
       "       [ 0.03679457],\n",
       "       [ 0.0388554 ],\n",
       "       [ 0.03515124],\n",
       "       [ 0.04083681],\n",
       "       [ 0.04048944],\n",
       "       [ 0.03217958],\n",
       "       [ 0.03457111],\n",
       "       [ 0.05596242],\n",
       "       [ 0.05776826],\n",
       "       [ 0.04271863],\n",
       "       [ 0.05182239],\n",
       "       [ 0.04869407],\n",
       "       [ 0.04104928],\n",
       "       [ 0.03299642],\n",
       "       [ 0.03778207],\n",
       "       [ 0.04729168],\n",
       "       [ 0.04372547],\n",
       "       [ 0.04868531],\n",
       "       [ 0.04154722],\n",
       "       [ 0.05193008],\n",
       "       [ 0.04766619],\n",
       "       [ 0.04580433],\n",
       "       [ 0.04561304],\n",
       "       [ 0.0397527 ],\n",
       "       [ 0.04819524],\n",
       "       [ 0.04175286],\n",
       "       [ 0.03480482],\n",
       "       [ 0.03630045],\n",
       "       [ 0.03474239],\n",
       "       [ 0.04270617],\n",
       "       [ 0.03931192],\n",
       "       [ 0.04913902],\n",
       "       [ 0.04972794],\n",
       "       [ 0.04405881],\n",
       "       [ 0.04046157],\n",
       "       [ 0.05116009],\n",
       "       [ 0.03603726],\n",
       "       [ 0.03499575],\n",
       "       [ 0.03467332],\n",
       "       [ 0.04638849],\n",
       "       [ 0.0488072 ],\n",
       "       [ 0.04599245],\n",
       "       [ 0.03398409],\n",
       "       [ 0.10038517],\n",
       "       [ 0.04026793],\n",
       "       [ 0.03827621],\n",
       "       [ 0.04677852],\n",
       "       [ 0.04709239],\n",
       "       [ 0.11603825],\n",
       "       [ 0.03728541],\n",
       "       [ 0.04631985],\n",
       "       [ 0.04417618],\n",
       "       [ 0.04520443],\n",
       "       [ 0.03548127],\n",
       "       [ 0.0391835 ],\n",
       "       [ 0.05426753],\n",
       "       [ 0.03931654],\n",
       "       [ 0.0573581 ],\n",
       "       [ 0.04063943],\n",
       "       [ 0.04661042],\n",
       "       [ 0.03979393],\n",
       "       [ 0.04141743],\n",
       "       [ 0.03740849],\n",
       "       [ 0.04471723],\n",
       "       [ 0.04142053],\n",
       "       [ 0.05377692],\n",
       "       [ 0.03699639],\n",
       "       [ 0.07945035],\n",
       "       [ 0.09628882],\n",
       "       [ 0.0584921 ],\n",
       "       [ 0.06266896],\n",
       "       [ 0.03917779],\n",
       "       [ 0.0438173 ],\n",
       "       [ 0.03893353],\n",
       "       [ 0.04744764],\n",
       "       [ 0.04088759],\n",
       "       [ 0.06454359],\n",
       "       [ 0.04711629],\n",
       "       [ 0.04261088],\n",
       "       [ 0.03227202],\n",
       "       [ 0.08393472],\n",
       "       [ 0.05188165],\n",
       "       [ 0.06850773],\n",
       "       [ 0.03288781],\n",
       "       [ 0.0402943 ],\n",
       "       [ 0.03570914],\n",
       "       [ 0.03300611],\n",
       "       [ 0.05212867],\n",
       "       [ 0.03976627],\n",
       "       [ 0.03835059],\n",
       "       [ 0.05820035],\n",
       "       [ 0.03570613],\n",
       "       [ 0.03185807],\n",
       "       [ 0.05398975],\n",
       "       [ 0.03852849],\n",
       "       [ 0.04598144],\n",
       "       [ 0.06160367],\n",
       "       [ 0.04812422],\n",
       "       [ 0.04614103],\n",
       "       [ 0.0319262 ],\n",
       "       [ 0.03962808],\n",
       "       [ 0.04475469],\n",
       "       [ 0.03807273],\n",
       "       [ 0.03750793],\n",
       "       [ 0.05823995],\n",
       "       [ 0.04150497],\n",
       "       [ 0.03452265],\n",
       "       [ 0.03721148],\n",
       "       [ 0.03386733],\n",
       "       [ 0.04810409],\n",
       "       [ 0.05636682],\n",
       "       [ 0.09700754],\n",
       "       [ 0.03471123],\n",
       "       [ 0.05834159],\n",
       "       [ 0.06255621],\n",
       "       [ 0.03343127],\n",
       "       [ 0.04170282],\n",
       "       [ 0.03375864],\n",
       "       [ 0.04479574],\n",
       "       [ 0.04223802],\n",
       "       [ 0.03960047],\n",
       "       [ 0.03578312],\n",
       "       [ 0.03795378],\n",
       "       [ 0.05173247],\n",
       "       [ 0.06120658],\n",
       "       [ 0.03765394],\n",
       "       [ 0.04839524],\n",
       "       [ 0.03472617],\n",
       "       [ 0.041563  ],\n",
       "       [ 0.03282487],\n",
       "       [ 0.05631291],\n",
       "       [ 0.03334724],\n",
       "       [ 0.06192775],\n",
       "       [ 0.03168578],\n",
       "       [ 0.07576029],\n",
       "       [ 0.03883862],\n",
       "       [ 0.03372903],\n",
       "       [ 0.05855637],\n",
       "       [ 0.05576249],\n",
       "       [ 0.03988538],\n",
       "       [ 0.04858581],\n",
       "       [ 0.03896903],\n",
       "       [ 0.07619873],\n",
       "       [ 0.04416167],\n",
       "       [ 0.03344662],\n",
       "       [ 0.05285318],\n",
       "       [ 0.06246176],\n",
       "       [ 0.0601542 ],\n",
       "       [ 0.05344002],\n",
       "       [ 0.04112852],\n",
       "       [ 0.03680422],\n",
       "       [ 0.04082358],\n",
       "       [ 0.03867542],\n",
       "       [ 0.06110285],\n",
       "       [ 0.04404113],\n",
       "       [ 0.04685011],\n",
       "       [ 0.04267619],\n",
       "       [ 0.04543348],\n",
       "       [ 0.04061494],\n",
       "       [ 0.04101665],\n",
       "       [ 0.05306254],\n",
       "       [ 0.03366448],\n",
       "       [ 0.03475266],\n",
       "       [ 0.04569378],\n",
       "       [ 0.0376463 ],\n",
       "       [ 0.03244257],\n",
       "       [ 0.03312947],\n",
       "       [ 0.05778471],\n",
       "       [ 0.03480839],\n",
       "       [ 0.03188426],\n",
       "       [ 0.04589475],\n",
       "       [ 0.03763355],\n",
       "       [ 0.04071958],\n",
       "       [ 0.03613152],\n",
       "       [ 0.06099769],\n",
       "       [ 0.04173196],\n",
       "       [ 0.03681421],\n",
       "       [ 0.04819939],\n",
       "       [ 0.03678665],\n",
       "       [ 0.06300892],\n",
       "       [ 0.05375587],\n",
       "       [ 0.03953968],\n",
       "       [ 0.07172292],\n",
       "       [ 0.05343935],\n",
       "       [ 0.03320362],\n",
       "       [ 0.04875275],\n",
       "       [ 0.04538729],\n",
       "       [ 0.03219583],\n",
       "       [ 0.07808544],\n",
       "       [ 0.05287019],\n",
       "       [ 0.07317557],\n",
       "       [ 0.09178598],\n",
       "       [ 0.03812075],\n",
       "       [ 0.04683277],\n",
       "       [ 0.05731329],\n",
       "       [ 0.03597862],\n",
       "       [ 0.03547149],\n",
       "       [ 0.03922757],\n",
       "       [ 0.05426577],\n",
       "       [ 0.03643119],\n",
       "       [ 0.05310242],\n",
       "       [ 0.03564195],\n",
       "       [ 0.03682902],\n",
       "       [ 0.04836709],\n",
       "       [ 0.04758046],\n",
       "       [ 0.04383408],\n",
       "       [ 0.03165343],\n",
       "       [ 0.05201285],\n",
       "       [ 0.03906054],\n",
       "       [ 0.03221901],\n",
       "       [ 0.04978304],\n",
       "       [ 0.03126203],\n",
       "       [ 0.05160467],\n",
       "       [ 0.0570005 ],\n",
       "       [ 0.07745946],\n",
       "       [ 0.03456919],\n",
       "       [ 0.04335526],\n",
       "       [ 0.04584849],\n",
       "       [ 0.03152955],\n",
       "       [ 0.03770709],\n",
       "       [ 0.03319777],\n",
       "       [ 0.03619159],\n",
       "       [ 0.04592002],\n",
       "       [ 0.03661365],\n",
       "       [ 0.04850953],\n",
       "       [ 0.0341229 ],\n",
       "       [ 0.0339121 ]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([xpTest, xa1Test, xqTest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01095546],\n",
       "       [ 0.01095458],\n",
       "       [ 0.01095464],\n",
       "       [ 0.01095479],\n",
       "       [ 0.01095467],\n",
       "       [ 0.0109553 ],\n",
       "       [ 0.01095562],\n",
       "       [ 0.01095474],\n",
       "       [ 0.01095529],\n",
       "       [ 0.01095544],\n",
       "       [ 0.01095471],\n",
       "       [ 0.01095476],\n",
       "       [ 0.01095471],\n",
       "       [ 0.01095537],\n",
       "       [ 0.01095461],\n",
       "       [ 0.0109547 ],\n",
       "       [ 0.01095566],\n",
       "       [ 0.0109555 ],\n",
       "       [ 0.01095474],\n",
       "       [ 0.0109546 ],\n",
       "       [ 0.01095472],\n",
       "       [ 0.01095541],\n",
       "       [ 0.01095547],\n",
       "       [ 0.01095559],\n",
       "       [ 0.01095464],\n",
       "       [ 0.01095538],\n",
       "       [ 0.01095566],\n",
       "       [ 0.01095472],\n",
       "       [ 0.01095456],\n",
       "       [ 0.01095463],\n",
       "       [ 0.01095532],\n",
       "       [ 0.01095463],\n",
       "       [ 0.0109546 ],\n",
       "       [ 0.01095471],\n",
       "       [ 0.01095542],\n",
       "       [ 0.01095461],\n",
       "       [ 0.01095473],\n",
       "       [ 0.01095469],\n",
       "       [ 0.01095531],\n",
       "       [ 0.01095477],\n",
       "       [ 0.01095556],\n",
       "       [ 0.01095472],\n",
       "       [ 0.01095459],\n",
       "       [ 0.01095467],\n",
       "       [ 0.01095473],\n",
       "       [ 0.01095557],\n",
       "       [ 0.01095567],\n",
       "       [ 0.01095523],\n",
       "       [ 0.01095531],\n",
       "       [ 0.0109553 ],\n",
       "       [ 0.01095568],\n",
       "       [ 0.01095525],\n",
       "       [ 0.01095466],\n",
       "       [ 0.01095561],\n",
       "       [ 0.01095526],\n",
       "       [ 0.01095542],\n",
       "       [ 0.01095468],\n",
       "       [ 0.01095468],\n",
       "       [ 0.01095534],\n",
       "       [ 0.01095519],\n",
       "       [ 0.0109546 ],\n",
       "       [ 0.01095527],\n",
       "       [ 0.01095475],\n",
       "       [ 0.01095459],\n",
       "       [ 0.01095419],\n",
       "       [ 0.01095542],\n",
       "       [ 0.0109557 ],\n",
       "       [ 0.01095547],\n",
       "       [ 0.0109555 ],\n",
       "       [ 0.01095536],\n",
       "       [ 0.01095462],\n",
       "       [ 0.01095421],\n",
       "       [ 0.0109547 ],\n",
       "       [ 0.01095479],\n",
       "       [ 0.01095536],\n",
       "       [ 0.01095565],\n",
       "       [ 0.01095421],\n",
       "       [ 0.01095537],\n",
       "       [ 0.01095474],\n",
       "       [ 0.01095561],\n",
       "       [ 0.01095478],\n",
       "       [ 0.01095534],\n",
       "       [ 0.01095546],\n",
       "       [ 0.01095562],\n",
       "       [ 0.01095528],\n",
       "       [ 0.01095475],\n",
       "       [ 0.01095563],\n",
       "       [ 0.01095547],\n",
       "       [ 0.01095483],\n",
       "       [ 0.01095568],\n",
       "       [ 0.01095462],\n",
       "       [ 0.01095566],\n",
       "       [ 0.01095463],\n",
       "       [ 0.01095468],\n",
       "       [ 0.01095469],\n",
       "       [ 0.01095531],\n",
       "       [ 0.01095526],\n",
       "       [ 0.01095558],\n",
       "       [ 0.01095468],\n",
       "       [ 0.01095552],\n",
       "       [ 0.0109556 ],\n",
       "       [ 0.0109552 ],\n",
       "       [ 0.01095529],\n",
       "       [ 0.01095556],\n",
       "       [ 0.0109547 ],\n",
       "       [ 0.01095458],\n",
       "       [ 0.01095568],\n",
       "       [ 0.01095419],\n",
       "       [ 0.01095529],\n",
       "       [ 0.01095473],\n",
       "       [ 0.0109552 ],\n",
       "       [ 0.01095476],\n",
       "       [ 0.01095568],\n",
       "       [ 0.0109548 ],\n",
       "       [ 0.01095462],\n",
       "       [ 0.01095474],\n",
       "       [ 0.0109554 ],\n",
       "       [ 0.01095562],\n",
       "       [ 0.01095534],\n",
       "       [ 0.01095527],\n",
       "       [ 0.01095564],\n",
       "       [ 0.01095543],\n",
       "       [ 0.01095548],\n",
       "       [ 0.0109554 ],\n",
       "       [ 0.01095467],\n",
       "       [ 0.01095472],\n",
       "       [ 0.01095468],\n",
       "       [ 0.01095539],\n",
       "       [ 0.0109556 ],\n",
       "       [ 0.01095568],\n",
       "       [ 0.01095552],\n",
       "       [ 0.01095564],\n",
       "       [ 0.01095542],\n",
       "       [ 0.01095473],\n",
       "       [ 0.0109554 ],\n",
       "       [ 0.01095532],\n",
       "       [ 0.01095459],\n",
       "       [ 0.01095566],\n",
       "       [ 0.01095539],\n",
       "       [ 0.01095526],\n",
       "       [ 0.01095473],\n",
       "       [ 0.01095542],\n",
       "       [ 0.01095555],\n",
       "       [ 0.01095532],\n",
       "       [ 0.01095567],\n",
       "       [ 0.01095562],\n",
       "       [ 0.01095469],\n",
       "       [ 0.01095569],\n",
       "       [ 0.01095533],\n",
       "       [ 0.01095534],\n",
       "       [ 0.01095546],\n",
       "       [ 0.01095421],\n",
       "       [ 0.01095565],\n",
       "       [ 0.01095461],\n",
       "       [ 0.01095476],\n",
       "       [ 0.01095562],\n",
       "       [ 0.01095462],\n",
       "       [ 0.01095525],\n",
       "       [ 0.01095475],\n",
       "       [ 0.01095485],\n",
       "       [ 0.01095532],\n",
       "       [ 0.01095472],\n",
       "       [ 0.01095565],\n",
       "       [ 0.01095563],\n",
       "       [ 0.01095557],\n",
       "       [ 0.01095473],\n",
       "       [ 0.01095548],\n",
       "       [ 0.01095533],\n",
       "       [ 0.0109557 ],\n",
       "       [ 0.01095419],\n",
       "       [ 0.01095538],\n",
       "       [ 0.01095546],\n",
       "       [ 0.01095518],\n",
       "       [ 0.01095463],\n",
       "       [ 0.01095542],\n",
       "       [ 0.01095551],\n",
       "       [ 0.01095529],\n",
       "       [ 0.0109556 ],\n",
       "       [ 0.01095557],\n",
       "       [ 0.0109542 ],\n",
       "       [ 0.0109554 ],\n",
       "       [ 0.01095463],\n",
       "       [ 0.01095562],\n",
       "       [ 0.01095533],\n",
       "       [ 0.01095551],\n",
       "       [ 0.01095377],\n",
       "       [ 0.0109547 ],\n",
       "       [ 0.0109555 ],\n",
       "       [ 0.01095472],\n",
       "       [ 0.0109556 ],\n",
       "       [ 0.01095474],\n",
       "       [ 0.0109556 ],\n",
       "       [ 0.01095535],\n",
       "       [ 0.01095563],\n",
       "       [ 0.01095471],\n",
       "       [ 0.01095531],\n",
       "       [ 0.01095476],\n",
       "       [ 0.01095462],\n",
       "       [ 0.01095538],\n",
       "       [ 0.01095564],\n",
       "       [ 0.01095471],\n",
       "       [ 0.01095473],\n",
       "       [ 0.01095467],\n",
       "       [ 0.01095531],\n",
       "       [ 0.01095542],\n",
       "       [ 0.01095458],\n",
       "       [ 0.01095553],\n",
       "       [ 0.01095422],\n",
       "       [ 0.01095471],\n",
       "       [ 0.01095563],\n",
       "       [ 0.01095526],\n",
       "       [ 0.01095557],\n",
       "       [ 0.01095466],\n",
       "       [ 0.01095558],\n",
       "       [ 0.01095423],\n",
       "       [ 0.01095548],\n",
       "       [ 0.01095418],\n",
       "       [ 0.01095543],\n",
       "       [ 0.01095549],\n",
       "       [ 0.01095566],\n",
       "       [ 0.01095466],\n",
       "       [ 0.01095522],\n",
       "       [ 0.01095564],\n",
       "       [ 0.01095377],\n",
       "       [ 0.01095471],\n",
       "       [ 0.01095563],\n",
       "       [ 0.01095539],\n",
       "       [ 0.01095528],\n",
       "       [ 0.01095544],\n",
       "       [ 0.01095473],\n",
       "       [ 0.01095562],\n",
       "       [ 0.01095526],\n",
       "       [ 0.01095523],\n",
       "       [ 0.01095531],\n",
       "       [ 0.01095466],\n",
       "       [ 0.01095418],\n",
       "       [ 0.0109546 ],\n",
       "       [ 0.0109552 ],\n",
       "       [ 0.01095535],\n",
       "       [ 0.01095564],\n",
       "       [ 0.01095474],\n",
       "       [ 0.01095549],\n",
       "       [ 0.01095465],\n",
       "       [ 0.01095561],\n",
       "       [ 0.01095548],\n",
       "       [ 0.01095566],\n",
       "       [ 0.01095463],\n",
       "       [ 0.01095562],\n",
       "       [ 0.01095471],\n",
       "       [ 0.01095469],\n",
       "       [ 0.01095471],\n",
       "       [ 0.01095541],\n",
       "       [ 0.01095551],\n",
       "       [ 0.01095463],\n",
       "       [ 0.01095552],\n",
       "       [ 0.01095563],\n",
       "       [ 0.01095529],\n",
       "       [ 0.01095477],\n",
       "       [ 0.01095467],\n",
       "       [ 0.01095561],\n",
       "       [ 0.0109547 ],\n",
       "       [ 0.01095528],\n",
       "       [ 0.01095562],\n",
       "       [ 0.01095559],\n",
       "       [ 0.01095559],\n",
       "       [ 0.01095525],\n",
       "       [ 0.0109546 ],\n",
       "       [ 0.0109553 ],\n",
       "       [ 0.01095423],\n",
       "       [ 0.01095567],\n",
       "       [ 0.01095548],\n",
       "       [ 0.01095531],\n",
       "       [ 0.01095557],\n",
       "       [ 0.01095471],\n",
       "       [ 0.01095533],\n",
       "       [ 0.01095534],\n",
       "       [ 0.0109553 ],\n",
       "       [ 0.01095526],\n",
       "       [ 0.01095526],\n",
       "       [ 0.01095532],\n",
       "       [ 0.01095414],\n",
       "       [ 0.01095534],\n",
       "       [ 0.0109554 ],\n",
       "       [ 0.01095423],\n",
       "       [ 0.01095563],\n",
       "       [ 0.01095465],\n",
       "       [ 0.01095526],\n",
       "       [ 0.01095469],\n",
       "       [ 0.01095569],\n",
       "       [ 0.01095465],\n",
       "       [ 0.01095465],\n",
       "       [ 0.01095474],\n",
       "       [ 0.01095544],\n",
       "       [ 0.01095557],\n",
       "       [ 0.01095563],\n",
       "       [ 0.01095564],\n",
       "       [ 0.01095528],\n",
       "       [ 0.01095458],\n",
       "       [ 0.01095463],\n",
       "       [ 0.01095472],\n",
       "       [ 0.01095532],\n",
       "       [ 0.01095542],\n",
       "       [ 0.01095533],\n",
       "       [ 0.01095524],\n",
       "       [ 0.01095569],\n",
       "       [ 0.01095563],\n",
       "       [ 0.01095567],\n",
       "       [ 0.01095526],\n",
       "       [ 0.01095567],\n",
       "       [ 0.01095533],\n",
       "       [ 0.01095528],\n",
       "       [ 0.01095472],\n",
       "       [ 0.01095464],\n",
       "       [ 0.01095535],\n",
       "       [ 0.01095552],\n",
       "       [ 0.01095534],\n",
       "       [ 0.01095513],\n",
       "       [ 0.01095478],\n",
       "       [ 0.01095517],\n",
       "       [ 0.01095464],\n",
       "       [ 0.01095566],\n",
       "       [ 0.01095568],\n",
       "       [ 0.01095534],\n",
       "       [ 0.01095568],\n",
       "       [ 0.01095464],\n",
       "       [ 0.01095459],\n",
       "       [ 0.01095475],\n",
       "       [ 0.01095531],\n",
       "       [ 0.0109554 ],\n",
       "       [ 0.01095477],\n",
       "       [ 0.01095419],\n",
       "       [ 0.01095477],\n",
       "       [ 0.01095459],\n",
       "       [ 0.01095465],\n",
       "       [ 0.01095467],\n",
       "       [ 0.01095476],\n",
       "       [ 0.01095472],\n",
       "       [ 0.0109546 ],\n",
       "       [ 0.0109555 ],\n",
       "       [ 0.01095528],\n",
       "       [ 0.01095535],\n",
       "       [ 0.0109551 ],\n",
       "       [ 0.01095547],\n",
       "       [ 0.01095544],\n",
       "       [ 0.01095473],\n",
       "       [ 0.01095552],\n",
       "       [ 0.01095467],\n",
       "       [ 0.01095461],\n",
       "       [ 0.01095469],\n",
       "       [ 0.01095552],\n",
       "       [ 0.0109547 ],\n",
       "       [ 0.01095472],\n",
       "       [ 0.0109553 ],\n",
       "       [ 0.01095532],\n",
       "       [ 0.01095561],\n",
       "       [ 0.0109556 ],\n",
       "       [ 0.01095529],\n",
       "       [ 0.01095462],\n",
       "       [ 0.01095469],\n",
       "       [ 0.01095479],\n",
       "       [ 0.01095572],\n",
       "       [ 0.01095478],\n",
       "       [ 0.01095472],\n",
       "       [ 0.01095559],\n",
       "       [ 0.01095528],\n",
       "       [ 0.01095477],\n",
       "       [ 0.01095419],\n",
       "       [ 0.01095529],\n",
       "       [ 0.0109546 ],\n",
       "       [ 0.01095541],\n",
       "       [ 0.01095559],\n",
       "       [ 0.01095462],\n",
       "       [ 0.01095533],\n",
       "       [ 0.01095457],\n",
       "       [ 0.01095462],\n",
       "       [ 0.01095468],\n",
       "       [ 0.01095476],\n",
       "       [ 0.01095551],\n",
       "       [ 0.01095532],\n",
       "       [ 0.01095467],\n",
       "       [ 0.01095469],\n",
       "       [ 0.01095529],\n",
       "       [ 0.01095458],\n",
       "       [ 0.01095544],\n",
       "       [ 0.01095523],\n",
       "       [ 0.01095469],\n",
       "       [ 0.01095422],\n",
       "       [ 0.01095543],\n",
       "       [ 0.01095533],\n",
       "       [ 0.01095522],\n",
       "       [ 0.01095475],\n",
       "       [ 0.01095562],\n",
       "       [ 0.01095461],\n",
       "       [ 0.01095472],\n",
       "       [ 0.01095468],\n",
       "       [ 0.01095477],\n",
       "       [ 0.01095564],\n",
       "       [ 0.0109555 ],\n",
       "       [ 0.01095469],\n",
       "       [ 0.01095557],\n",
       "       [ 0.01095522],\n",
       "       [ 0.01095567],\n",
       "       [ 0.01095535],\n",
       "       [ 0.01095566],\n",
       "       [ 0.01095472],\n",
       "       [ 0.01095547],\n",
       "       [ 0.01095535],\n",
       "       [ 0.01095528],\n",
       "       [ 0.01095523],\n",
       "       [ 0.01095536],\n",
       "       [ 0.01095547],\n",
       "       [ 0.01095544],\n",
       "       [ 0.01095535],\n",
       "       [ 0.0109557 ],\n",
       "       [ 0.01095467],\n",
       "       [ 0.01095556],\n",
       "       [ 0.01095466],\n",
       "       [ 0.01095473],\n",
       "       [ 0.01095548],\n",
       "       [ 0.01095547],\n",
       "       [ 0.01095538],\n",
       "       [ 0.01095548],\n",
       "       [ 0.01095467],\n",
       "       [ 0.01095474],\n",
       "       [ 0.0109554 ],\n",
       "       [ 0.01095473],\n",
       "       [ 0.01095547],\n",
       "       [ 0.01095567],\n",
       "       [ 0.01095466],\n",
       "       [ 0.01095526],\n",
       "       [ 0.01095564],\n",
       "       [ 0.01095465],\n",
       "       [ 0.01095536],\n",
       "       [ 0.01095571],\n",
       "       [ 0.01095526],\n",
       "       [ 0.01095527],\n",
       "       [ 0.01095458],\n",
       "       [ 0.01095472],\n",
       "       [ 0.01095469],\n",
       "       [ 0.0109553 ],\n",
       "       [ 0.01095418],\n",
       "       [ 0.01095535],\n",
       "       [ 0.01095532],\n",
       "       [ 0.01095461],\n",
       "       [ 0.01095472],\n",
       "       [ 0.01095475],\n",
       "       [ 0.01095532],\n",
       "       [ 0.01095559],\n",
       "       [ 0.0109546 ],\n",
       "       [ 0.01095487],\n",
       "       [ 0.01095567],\n",
       "       [ 0.01095474],\n",
       "       [ 0.01095542],\n",
       "       [ 0.01095565],\n",
       "       [ 0.01095536],\n",
       "       [ 0.01095556],\n",
       "       [ 0.01095419],\n",
       "       [ 0.01095469],\n",
       "       [ 0.01095452],\n",
       "       [ 0.01095459],\n",
       "       [ 0.01095474],\n",
       "       [ 0.01095538],\n",
       "       [ 0.01095561],\n",
       "       [ 0.01095551],\n",
       "       [ 0.0109553 ],\n",
       "       [ 0.01095526],\n",
       "       [ 0.01095555],\n",
       "       [ 0.01095421],\n",
       "       [ 0.0109547 ],\n",
       "       [ 0.01095463],\n",
       "       [ 0.01095471],\n",
       "       [ 0.01095419],\n",
       "       [ 0.0109557 ],\n",
       "       [ 0.0109542 ],\n",
       "       [ 0.01095533],\n",
       "       [ 0.0109548 ],\n",
       "       [ 0.01095563],\n",
       "       [ 0.01095557],\n",
       "       [ 0.01095463],\n",
       "       [ 0.01095531],\n",
       "       [ 0.01095573],\n",
       "       [ 0.01095534],\n",
       "       [ 0.01095466],\n",
       "       [ 0.01095463],\n",
       "       [ 0.01095472],\n",
       "       [ 0.01095545],\n",
       "       [ 0.01095565],\n",
       "       [ 0.01095553],\n",
       "       [ 0.01095473],\n",
       "       [ 0.01095566],\n",
       "       [ 0.01095463],\n",
       "       [ 0.01095473],\n",
       "       [ 0.01095528],\n",
       "       [ 0.01095533],\n",
       "       [ 0.01095472],\n",
       "       [ 0.01095542],\n",
       "       [ 0.01095532],\n",
       "       [ 0.01095546],\n",
       "       [ 0.01095532],\n",
       "       [ 0.01095529]], dtype=float32)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([xpTest, xa2Test, xqTest])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
