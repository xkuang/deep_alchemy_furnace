{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load Data</a></div><div class=\"lev1 toc-item\"><a href=\"#Word-Segmentation\" data-toc-modified-id=\"Word-Segmentation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Word Segmentation</a></div><div class=\"lev1 toc-item\"><a href=\"#Tokenize-Text\" data-toc-modified-id=\"Tokenize-Text-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Tokenize Text</a></div><div class=\"lev1 toc-item\"><a href=\"#Load-Model\" data-toc-modified-id=\"Load-Model-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Load Model</a></div><div class=\"lev2 toc-item\"><a href=\"#Set-Hyperparameters\" data-toc-modified-id=\"Set-Hyperparameters-41\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Set Hyperparameters</a></div><div class=\"lev2 toc-item\"><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-42\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Import Libraries</a></div><div class=\"lev2 toc-item\"><a href=\"#Build-Graph\" data-toc-modified-id=\"Build-Graph-43\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Build Graph</a></div><div class=\"lev3 toc-item\"><a href=\"#Language-Model\" data-toc-modified-id=\"Language-Model-431\"><span class=\"toc-item-num\">4.3.1&nbsp;&nbsp;</span>Language Model</a></div><div class=\"lev3 toc-item\"><a href=\"#Qustion-Answering-Model\" data-toc-modified-id=\"Qustion-Answering-Model-432\"><span class=\"toc-item-num\">4.3.2&nbsp;&nbsp;</span>Qustion Answering Model</a></div><div class=\"lev1 toc-item\"><a href=\"#Trian\" data-toc-modified-id=\"Trian-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Trian</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path, name):\n",
    "    \"\"\"\n",
    "    Load date from file\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file) as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        item = json.loads(line)\n",
    "        data.append(item[name])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "premise = load_data('/Users/lizhn7/Downloads/EXPERIMENT/COPA/LM/data/copa-test.json', 'premise')\n",
    "asks_for = load_data('/Users/lizhn7/Downloads/EXPERIMENT/COPA/LM/data/copa-test.json', 'asks-for')\n",
    "alternative1 = load_data('/Users/lizhn7/Downloads/EXPERIMENT/COPA/LM/data/copa-test.json', 'alternative1')\n",
    "alternative2 = load_data('/Users/lizhn7/Downloads/EXPERIMENT/COPA/LM/data/copa-test.json', 'alternative2')\n",
    "\n",
    "for i in range(len(premise)):\n",
    "    if asks_for[i] == 'cause':\n",
    "        premise[i] += ' What was the CAUSE of this?'\n",
    "    else:\n",
    "        premise[i] += ' What happened as a RESULT'\n",
    "\n",
    "premise.extend(premise)\n",
    "alternative = []\n",
    "alternative.extend(alternative1)\n",
    "alternative.extend(alternative2)\n",
    "\n",
    "rawLabel = load_data('/Users/lizhn7/Downloads/EXPERIMENT/COPA/LM/data/copa-test.json', 'most-plausible-alternative')\n",
    "rawLabel = [int(l) for l in rawLabel]\n",
    "\n",
    "l = [0] * len(premise)\n",
    "for i in range(len(rawLabel)):\n",
    "    if rawLabel[i] == 1:\n",
    "        l[i] = 1\n",
    "        l[i+len(rawLabel)] = 0\n",
    "    if rawLabel[i] == 2:\n",
    "        l[i] = 0\n",
    "        l[i+len(rawLabel)] = 1\n",
    "        \n",
    "label = l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import regexp_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replDict = {'tattled': 'tattle', 'shirtsleeve': 'shirtsleeves', 'pruny': 'prune', \n",
    "            'dry-cleaned': 'dry-clean', 'illegibly': 'illegible', 'unlaced': 'untie', \n",
    "            \"woman's\": 'woman', \"man's\": 'man', \"patient's\": 'patient', \"student's\": 'student', \"boy's\": 'boy', \n",
    "            \"friend's\": 'friend', \"enemy's\": 'enemy', \"parent's\": 'parent', \"humanitarian's\": 'humanitarian', \n",
    "            \"child's\": 'child', \"professor's\": 'professor', \"daughter's\": 'daughter', \"mother's\": 'mother', \n",
    "            \"children's\": 'children', \"teller's\": 'teller', \"company's\": 'company', \"group's\": 'group', \n",
    "            \"laptop's\": 'laptop', \"girl's\": 'girl', \"salesman's\": 'salesman', \"cook's\": 'cook', \"car's\": 'car', \n",
    "            \"offender's\": 'offender', \"detective's\": 'detective', \"librarian's\": 'librarian', \"caller's\": 'caller', \n",
    "            \"victim's\": 'victim', \"interviewer's\": 'interviewer', \"ship's\": 'ship', \"site's\": 'site', \n",
    "            \"chandelier's\": 'chandelier', \"bully's\": 'bully', \"river's\": 'river', \"puppy's\": 'puppy', \n",
    "            \"pilot's\": 'pilot', \"girlfriend's\": 'girlfriend', \"politician's\": 'politician', \"couple's\": 'couple', \n",
    "            \"son's\": 'son', \"actor's\": 'actor', \"neighbor's\": 'neighbor', \"nation's\": 'nation', \n",
    "            \"classmate's\": 'classmate', \"businessman's\": 'businessman', \"architect's\": 'architect', \n",
    "            \"imposter's\": 'imposter', \"kidnapper's\": 'kidnapper', \"colleague's\": 'colleague', \"flower's\": 'flower',\n",
    "            \"bull's\": 'bull', \"employee's\": 'employee', \"wouldn't\": 'wouldn', \"team's\": 'team', \"other's\": 'other', \n",
    "            \"writer's\": 'writer', \"baby's\": 'baby', \"attacker's\": 'attacker', \"uncle's\": 'uncle', \"driver's\": 'driver'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut(s):\n",
    "    \"\"\"\n",
    "    Word segmentation\n",
    "    \"\"\"\n",
    "    pattern = r'''\n",
    "              (?x)                   # set flag to allow verbose regexps \n",
    "              (?:[A-Z]\\.)+           # abbreviations, e.g. U.S.A. \n",
    "              |\\w+(?:[-&']\\w+)*      # words w/ optional internal hyphens/apostrophe  \n",
    "            '''  \n",
    "    return regexp_tokenize(s, pattern=pattern)\n",
    "\n",
    "def clean(s):\n",
    "    \"\"\"\n",
    "    Clean data\n",
    "    \"\"\"\n",
    "    for i in range(len(s)):\n",
    "        for d in ['0', '1', '2', '3', '4', '5' ,'6', '7', '8', '9']:\n",
    "            if d in s[i]:\n",
    "                s[i] = '0'\n",
    "        if s[i] == 'p' and i < len(s)-1:\n",
    "            if s[i+1] == 'm':\n",
    "                s[i] = 'pm'\n",
    "                s[i+1] = ''\n",
    "        if s[i] == 'a' and i < len(s)-1:\n",
    "            if s[i+1] == 'm':\n",
    "                s[i] = 'am'\n",
    "                s[i+1] = ''\n",
    "        if s[i] == 's':\n",
    "            s[i] = ''\n",
    "        if s[i].endswith(\"'s\"):\n",
    "            s[i] = s[i][:-2]\n",
    "        if s[i] == \"couldn't\":\n",
    "            s[i] = 'could'\n",
    "            s.insert(i+1, 'not')\n",
    "    s = [i for i in s if i != '']\n",
    "    return [replDict.get(i.lower(), i.lower()) for i in s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pWords = [clean(cut(s)) for s in premise]\n",
    "aWords = [clean(cut(s)) for s in alternative]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_P_LEN = 19\n",
    "MAX_A_LEN = 11\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from nltk import PorterStemmer, LancasterStemmer, WordNetLemmatizer\n",
    "import pickle\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/lizhn7/Downloads/EXPERIMENT/COPA/LM/data/index.pkl', 'rb') as fp:\n",
    "    word2index, index2word, glove_index2index = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103-34.68% tokens was replaced.\n"
     ]
    }
   ],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "\n",
    "R = []\n",
    "for i in sum(pWords+aWords, []):\n",
    "    if word2index[i] > 19994:\n",
    "        R.append(i)\n",
    "N = {i: i for i in R}\n",
    "\n",
    "mini_word2index = {i: word2index[i] for i in word2index if word2index[i] <= 19994}\n",
    "count = 0\n",
    "for i in N:\n",
    "    w = N[i]\n",
    "    g = mini_word2index.get(w)\n",
    "    if g is None:\n",
    "        ww = wnl.lemmatize(w)\n",
    "        g = mini_word2index.get(ww)\n",
    "    if g is None:\n",
    "        ww = porter.stem(w)\n",
    "        g = mini_word2index.get(ww)\n",
    "    if g is None:\n",
    "        ww = lancaster.stem(w)\n",
    "        g = mini_word2index.get(ww)\n",
    "    if g is None:\n",
    "        if w.endswith('ed') or w.endswith('s'):\n",
    "            ww = w[:-1]\n",
    "            g = mini_word2index.get(ww)\n",
    "    if g is None:\n",
    "        if w.endswith('ed') or w.endswith('es') or w.endswith('er') or w.endswith('ly'):\n",
    "            ww = w[:-2]\n",
    "            g = mini_word2index.get(ww)\n",
    "    if g is None:\n",
    "        if w.endswith('ily') or w.endswith('ing'):\n",
    "            ww = w[:-3]\n",
    "            g = mini_word2index.get(ww)\n",
    "    if g is not None:\n",
    "        N[i] = index2word[g]\n",
    "        count += 1\n",
    "print('{num_tokens}-{per:.2f}% tokens was replaced.'.format(num_tokens=count, per=count/float(len(N))*100))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pWords = [[N.get(i.lower(), i.lower()) for i in s] for s in pWords]\n",
    "aWords = [[N.get(i.lower(), i.lower()) for i in s] for s in aWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_GRAMS = 25\n",
    "NUM_UNK_WORDS = 5\n",
    "VOCAB_SIZE = 20000\n",
    "MAX_P_LEN = 19\n",
    "MAX_A_LEN = 11\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(NUM_UNK_WORDS):\n",
    "    index2word[VOCAB_SIZE-1-i] = '<%d>'%i\n",
    "\n",
    "unk0 = VOCAB_SIZE - NUM_UNK_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vocab_fold(xs):\n",
    "    \"\"\"\n",
    "    Convert list of word indexes that may contain words outside vocab_size to words inside.\n",
    "    If a word is outside, try first to use glove_idx2idx to find a similar word inside.\n",
    "    If none exist then replace all accurancies of the same unknown word with <0>, <1>, ...\n",
    "    \"\"\"\n",
    "    xs = [x if x < unk0 else glove_index2index.get(x, x) for x in xs]\n",
    "    # the more popular word is <0> and so on\n",
    "    outside = sorted([x for x in xs if x >= unk0])\n",
    "    # if there are more than unknown_words unk words then put them all in unknown_words-1\n",
    "    outside = {x: VOCAB_SIZE-1-min(i, NUM_UNK_WORDS-1) for i, x in enumerate(outside)}\n",
    "    xs = [outside.get(x, x) for x in xs]\n",
    "    return xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pSeq = [[word2index.get(w, w) for w in s] for s in pWords]\n",
    "pSeq = [vocab_fold(s) for s in pSeq]\n",
    "aSeq = [[word2index.get(w, w) for w in s] for s in aWords]\n",
    "aSeq = [vocab_fold(s) for s in aSeq]\n",
    "\n",
    "xp = pad_sequences(pSeq, maxlen=MAX_P_LEN)\n",
    "xa = pad_sequences(aSeq, maxlen=MAX_A_LEN)\n",
    "#y = np.array(label)\n",
    "\n",
    "#xpTrain, _, yTrain, _ = train_test_split(xp, y, test_size=0., random_state=SEED)\n",
    "#xaTrain, _ = train_test_split(xa, test_size=0., random_state=SEED)\n",
    "\n",
    "xpTest = xp[:500]\n",
    "xa1Test = xa[:500]\n",
    "xa2Test =  xa[500:]\n",
    "yTest = np.array(rawLabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fh = h5py.File('/Users/lizhn7/Downloads/EXPERIMENT/COPA/Question_Answering_Hinge/data/test.h5', 'w')\n",
    "fh['xpTest'] = xpTest\n",
    "fh['xa1Test'] = xa1Test\n",
    "fh['xa2Test'] = xa2Test\n",
    "fh['yTest'] = yTest\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fh = h5py.File('/Users/lizhn7/Downloads/EXPERIMENT/COPA/Question_Answering_Hinge/data/train.h5', 'w')\n",
    "fh['xpTrain'] = xpTrain\n",
    "fh['xaTrain'] = xaTrain\n",
    "fh['yTrain'] = yTrain\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_GRAMS = 25\n",
    "MAX_P_LEN = 21\n",
    "MAX_A_LEN = 12\n",
    "VOCAB_SIZE = 20000\n",
    "EMBEDDING_DIM = 200\n",
    "TUNE = True\n",
    "BATCH_SIZE = 1024\n",
    "RNN_SIZE = 1024\n",
    "HIDDEN_SIZE_1 = 8\n",
    "HIDDEN_SIZE_2 = 256\n",
    "NUM_EPOCHS = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, LSTM, Reshape, MaxPooling1D, Flatten, Activation, dot, Dense, Dropout\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import*\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('/Users/lizhn7/Downloads/EXPERIMENT/COPA/LM/data/embedding.h5', 'r') as fh:\n",
    "    embedding = fh['embedding'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "# Encoder\n",
    "inputs = Input(shape=(None,), name='EN_INPUT', dtype='int64')\n",
    "emb_seq = Embedding(VOCAB_SIZE, \n",
    "                    EMBEDDING_DIM, \n",
    "                    weights=[embedding], \n",
    "                    mask_zero=True, \n",
    "                    trainable=TUNE, \n",
    "                    name='EN_EMBEDDING')(inputs)\n",
    "lstm = LSTM(RNN_SIZE, return_sequences=False, implementation=0, name='EN_LSTM')(emb_seq)\n",
    "encoder = Model(inputs=inputs, outputs=lstm)\n",
    "\n",
    "# Language Model\n",
    "input_grams = Input(shape=(NUM_GRAMS,), name='LM_INPUT', dtype='int64')\n",
    "encoded_grams = encoder(input_grams)\n",
    "outputs = Dense(VOCAB_SIZE, activation='softmax', name='LM_OUTPUT')(encoded_grams)\n",
    "lm = Model(inputs=input_grams, outputs=outputs)\n",
    "lm.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "EN_INPUT (InputLayer)        (None, None)              0         \n",
      "_________________________________________________________________\n",
      "EN_EMBEDDING (Embedding)     (None, None, 200)         4000000   \n",
      "_________________________________________________________________\n",
      "EN_LSTM (LSTM)               (None, 1024)              5017600   \n",
      "=================================================================\n",
      "Total params: 9,017,600\n",
      "Trainable params: 9,017,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"191pt\" viewBox=\"0.00 0.00 205.59 191.00\" width=\"206pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 187)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-187 201.5898,-187 201.5898,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 4734862224 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>4734862224</title>\n",
       "<polygon fill=\"none\" points=\"22.9106,-146.5 22.9106,-182.5 174.6792,-182.5 174.6792,-146.5 22.9106,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.7949\" y=\"-160.3\">EN_INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 4401996912 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4401996912</title>\n",
       "<polygon fill=\"none\" points=\"0,-73.5 0,-109.5 197.5898,-109.5 197.5898,-73.5 0,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.7949\" y=\"-87.3\">EN_EMBEDDING: Embedding</text>\n",
       "</g>\n",
       "<!-- 4734862224&#45;&gt;4401996912 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>4734862224-&gt;4401996912</title>\n",
       "<path d=\"M98.7949,-146.4551C98.7949,-138.3828 98.7949,-128.6764 98.7949,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"102.295,-119.5903 98.7949,-109.5904 95.295,-119.5904 102.295,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4546371656 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4546371656</title>\n",
       "<polygon fill=\"none\" points=\"36.9312,-.5 36.9312,-36.5 160.6587,-36.5 160.6587,-.5 36.9312,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"98.7949\" y=\"-14.3\">EN_LSTM: LSTM</text>\n",
       "</g>\n",
       "<!-- 4401996912&#45;&gt;4546371656 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4401996912-&gt;4546371656</title>\n",
       "<path d=\"M98.7949,-73.4551C98.7949,-65.3828 98.7949,-55.6764 98.7949,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"102.295,-46.5903 98.7949,-36.5904 95.295,-46.5904 102.295,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.summary()\n",
    "SVG(model_to_dot(encoder).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LM_INPUT (InputLayer)        (None, 25)                0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1024)              9017600   \n",
      "_________________________________________________________________\n",
      "LM_OUTPUT (Dense)            (None, 20000)             20500000  \n",
      "=================================================================\n",
      "Total params: 29,517,600\n",
      "Trainable params: 29,517,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"191pt\" viewBox=\"0.00 0.00 162.11 191.00\" width=\"162pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 187)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-187 158.1064,-187 158.1064,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 5147525584 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>5147525584</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 154.1064,-182.5 154.1064,-146.5 0,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"77.0532\" y=\"-160.3\">LM_INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 4547322040 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4547322040</title>\n",
       "<polygon fill=\"none\" points=\"22.5859,-73.5 22.5859,-109.5 131.5205,-109.5 131.5205,-73.5 22.5859,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"77.0532\" y=\"-87.3\">model_1: Model</text>\n",
       "</g>\n",
       "<!-- 5147525584&#45;&gt;4547322040 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>5147525584-&gt;4547322040</title>\n",
       "<path d=\"M77.0532,-146.4551C77.0532,-138.3828 77.0532,-128.6764 77.0532,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"80.5533,-119.5903 77.0532,-109.5904 73.5533,-119.5904 80.5533,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5487036232 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>5487036232</title>\n",
       "<polygon fill=\"none\" points=\"6.6035,-.5 6.6035,-36.5 147.5029,-36.5 147.5029,-.5 6.6035,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"77.0532\" y=\"-14.3\">LM_OUTPUT: Dense</text>\n",
       "</g>\n",
       "<!-- 4547322040&#45;&gt;5487036232 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4547322040-&gt;5487036232</title>\n",
       "<path d=\"M77.0532,-73.4551C77.0532,-65.3828 77.0532,-55.6764 77.0532,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"80.5533,-46.5903 77.0532,-36.5904 73.5533,-46.5904 80.5533,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm.summary()\n",
    "SVG(model_to_dot(lm).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qustion Answering Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(x, y):\n",
    "    \"\"\"\n",
    "    Compute_cosine_similarity\n",
    "    \"\"\"\n",
    "    return np.dot(x, y) / (np.linalg.norm(x, 2) * np.linalg.norm(y, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filename = '/Users/lizhn7/Downloads/EXPERIMENT/COPA/LM/cp_logs/weights.053-4.498228.hdf5'\n",
    "lm.load_weights(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for layer in encoder.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "def build():\n",
    "    \"\"\"\n",
    "    Build encoder model\n",
    "    \"\"\"\n",
    "    sentence = Input(shape=(None,))\n",
    "    encoded_sentence = encoder(sentence)\n",
    "    encoded_sentence = Reshape((RNN_SIZE, 1))(encoded_sentence)\n",
    "    encoded_sentence = MaxPooling1D(pool_size=2)(encoded_sentence)\n",
    "    encoded_sentence = Flatten()(encoded_sentence)\n",
    "    encoded_sentence = Activation('tanh')(encoded_sentence)\n",
    "    model = Model(inputs=sentence, outputs=encoded_sentence)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p, a = Input(shape=(MAX_P_LEN,)), Input(shape=(MAX_A_LEN,))\n",
    "pSeq, aSeq = model(p), model(a)\n",
    "pSeq = Dense(HIDDEN_SIZE_1, activation='tanh')(pSeq)\n",
    "aSeq = Dense(HIDDEN_SIZE_1, activation='tanh')(aSeq)\n",
    "#pSeq = Dense(HIDDEN_SIZE_2, activation='tanh')(pSeq)\n",
    "#aSeq = Dense(HIDDEN_SIZE_2, activation='tanh')(aSeq)\n",
    "similarity = dot([pSeq, aSeq], axes=-1, normalize=True)\n",
    "model = Model(inputs=[p, a], outputs=[similarity])\n",
    "model.compile(loss='categorical_hinge', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_67 (InputLayer)            (None, 21)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_68 (InputLayer)            (None, 12)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_40 (Model)                 (None, 512)           9017600     input_67[0][0]                   \n",
      "                                                                   input_68[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_29 (Dense)                 (None, 8)             4104        model_40[1][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dense_30 (Dense)                 (None, 8)             4104        model_40[2][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dot_17 (Dot)                     (None, 1)             0           dense_29[0][0]                   \n",
      "                                                                   dense_30[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 9,025,808\n",
      "Trainable params: 8,208\n",
      "Non-trainable params: 9,017,600\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 800 samples, validate on 200 samples\n",
      "Epoch 1/64\n",
      "800/800 [==============================] - 11s - loss: 1.0215 - acc: 0.4487 - val_loss: 0.9625 - val_acc: 0.4800\n",
      "Epoch 2/64\n",
      "800/800 [==============================] - 10s - loss: 1.0209 - acc: 0.4525 - val_loss: 0.9638 - val_acc: 0.4800\n",
      "Epoch 3/64\n",
      "800/800 [==============================] - 10s - loss: 1.0203 - acc: 0.4563 - val_loss: 0.9651 - val_acc: 0.4950\n",
      "Epoch 4/64\n",
      "800/800 [==============================] - 9s - loss: 1.0196 - acc: 0.4575 - val_loss: 0.9664 - val_acc: 0.5100\n",
      "Epoch 5/64\n",
      "800/800 [==============================] - 9s - loss: 1.0190 - acc: 0.4575 - val_loss: 0.9677 - val_acc: 0.5150\n",
      "Epoch 6/64\n",
      "800/800 [==============================] - 9s - loss: 1.0184 - acc: 0.4625 - val_loss: 0.9691 - val_acc: 0.5200\n",
      "Epoch 7/64\n",
      "800/800 [==============================] - 9s - loss: 1.0178 - acc: 0.4638 - val_loss: 0.9705 - val_acc: 0.5300\n",
      "Epoch 8/64\n",
      "800/800 [==============================] - 9s - loss: 1.0171 - acc: 0.4663 - val_loss: 0.9719 - val_acc: 0.5300\n",
      "Epoch 9/64\n",
      "800/800 [==============================] - 9s - loss: 1.0165 - acc: 0.4700 - val_loss: 0.9734 - val_acc: 0.5350\n",
      "Epoch 10/64\n",
      "800/800 [==============================] - 9s - loss: 1.0158 - acc: 0.4712 - val_loss: 0.9748 - val_acc: 0.5350\n",
      "Epoch 11/64\n",
      "800/800 [==============================] - 9s - loss: 1.0152 - acc: 0.4712 - val_loss: 0.9763 - val_acc: 0.5350\n",
      "Epoch 12/64\n",
      "800/800 [==============================] - 9s - loss: 1.0145 - acc: 0.4725 - val_loss: 0.9778 - val_acc: 0.5400\n",
      "Epoch 13/64\n",
      "800/800 [==============================] - 9s - loss: 1.0138 - acc: 0.4775 - val_loss: 0.9793 - val_acc: 0.5400\n",
      "Epoch 14/64\n",
      "800/800 [==============================] - 9s - loss: 1.0132 - acc: 0.4812 - val_loss: 0.9809 - val_acc: 0.5500\n",
      "Epoch 15/64\n",
      "800/800 [==============================] - 8s - loss: 1.0125 - acc: 0.4825 - val_loss: 0.9824 - val_acc: 0.5500\n",
      "Epoch 16/64\n",
      "800/800 [==============================] - 9s - loss: 1.0118 - acc: 0.4825 - val_loss: 0.9840 - val_acc: 0.5500\n",
      "Epoch 17/64\n",
      "800/800 [==============================] - 9s - loss: 1.0111 - acc: 0.4825 - val_loss: 0.9856 - val_acc: 0.5500\n",
      "Epoch 18/64\n",
      "800/800 [==============================] - 8s - loss: 1.0104 - acc: 0.4850 - val_loss: 0.9872 - val_acc: 0.5500\n",
      "Epoch 19/64\n",
      "800/800 [==============================] - 8s - loss: 1.0098 - acc: 0.4850 - val_loss: 0.9888 - val_acc: 0.5500\n",
      "Epoch 20/64\n",
      "800/800 [==============================] - 9s - loss: 1.0091 - acc: 0.4863 - val_loss: 0.9904 - val_acc: 0.5500\n",
      "Epoch 21/64\n",
      "800/800 [==============================] - 9s - loss: 1.0084 - acc: 0.4875 - val_loss: 0.9920 - val_acc: 0.5500\n",
      "Epoch 22/64\n",
      "800/800 [==============================] - 9s - loss: 1.0077 - acc: 0.4875 - val_loss: 0.9937 - val_acc: 0.5500\n",
      "Epoch 23/64\n",
      "800/800 [==============================] - 9s - loss: 1.0070 - acc: 0.4850 - val_loss: 0.9953 - val_acc: 0.5500\n",
      "Epoch 24/64\n",
      "800/800 [==============================] - 9s - loss: 1.0063 - acc: 0.4850 - val_loss: 0.9969 - val_acc: 0.5500\n",
      "Epoch 25/64\n",
      "800/800 [==============================] - 9s - loss: 1.0056 - acc: 0.4825 - val_loss: 0.9985 - val_acc: 0.5450\n",
      "Epoch 26/64\n",
      "800/800 [==============================] - 9s - loss: 1.0049 - acc: 0.4812 - val_loss: 1.0002 - val_acc: 0.5450\n",
      "Epoch 27/64\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-201-b953acdb7f45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0;31m#callbacks=callbacks_list,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mxpVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxaVal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myVal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1428\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1430\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1077\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1079\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1080\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2267\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2269\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit([xpTrain, xaTrain], \n",
    "                    yTrain,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    #callbacks=callbacks_list,\n",
    "                    validation_data=([xpVal, xaVal], yVal),\n",
    "                    shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "66px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
