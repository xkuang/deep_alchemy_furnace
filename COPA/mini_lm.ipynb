{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "from keras.datasets import imdb\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "\n",
    "max_features = 10000 #保留前max_features个词\n",
    "maxlen = 100 #填充/阶段到100词\n",
    "batch_size = 1000\n",
    "nb_grams = 25 #训练一个10-gram的语言模型\n",
    "nb_train = 1000 #训练样本数\n",
    "\n",
    "#加载内置的IMDB数据集\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(path='/Users/lizhn7/Downloads/EXPERIMENT/COPA/mini_lm/data/imdb.npz',\n",
    "                                                      num_words=max_features)\n",
    "x_lm_ = np.append(x_train, x_test)\n",
    "\n",
    "#构造用来训练语言模型的数据\n",
    "#这里只用了已有数据，实际环境中，可以补充其他数据使得训练更加充分\n",
    "x_lm = []\n",
    "y_lm = []\n",
    "for x in x_lm_:\n",
    "\t\tfor i in range(len(x)):\n",
    "\t\t\tx_lm.append([0]*(nb_grams - i + max(0,i-nb_grams))+x[max(0,i-nb_grams):i])\n",
    "\t\t\ty_lm.append([x[i]])\n",
    "\n",
    "x_lm = np.array(x_lm)\n",
    "y_lm = np.array(y_lm)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "x = np.vstack([x_train, x_test])\n",
    "y = np.hstack([y_train, y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1],\n",
       "       [  14],\n",
       "       [  22],\n",
       "       [  16],\n",
       "       [  43],\n",
       "       [ 530],\n",
       "       [ 973],\n",
       "       [1622],\n",
       "       [1385],\n",
       "       [  65]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lm[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11737946, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_lm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11737946, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_lm = []\n",
    "y_lm = []\n",
    "for x in x_lm_:\n",
    "\t\tfor i in range(len(x)):\n",
    "\t\t\tx_lm.append([0]*(nb_grams - i + max(0,i-nb_grams))+x[max(0,i-nb_grams):i])\n",
    "\t\t\ty_lm.append([x[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11737946"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_lm.extend(y_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93903568"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_lm = np.array(y_lm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93903568, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_lm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_lm = np.vstack([x_lm, x_lm, x_lm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35213838, 25)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_lm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "fh = h5py.File('/Users/lizhn7/Downloads/EXPERIMENT/COPA/mini_lm/data/train.h5', 'w')\n",
    "fh['x_lm'] = np.vstack([x_lm, x_lm])\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('/Users/lizhn7/Downloads/EXPERIMENT/COPA/mini_lm/data/train.h5', 'r') as fh:\n",
    "    test = fh['x_lm'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93903568, 25)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#重新划分训练集和测试集\n",
    "#合并原来的训练集和测试集，随机挑选1000个样本，作为新的训练集，剩下为测试集\n",
    "idx = range(len(x))\n",
    "np.random.shuffle(idx)\n",
    "x_train = x[idx[:nb_train]]\n",
    "y_train = y[idx[:nb_train]]\n",
    "x_test = x[idx[nb_train:]]\n",
    "y_test = y[idx[nb_train:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5ce606ead9cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_lm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedded_size = 100 #词向量维度\n",
    "hidden_size = 1000 #LSTM的维度，可以理解为编码后的句向量维度。\n",
    "\n",
    "#encoder部分\n",
    "inputs = Input(shape=(None,), dtype='int32')\n",
    "embedded = Embedding(max_features, embedded_size)(inputs)\n",
    "lstm = LSTM(hidden_size)(embedded)\n",
    "encoder = Model(inputs=inputs, outputs=lstm)\n",
    "\n",
    "#完全用ngram模型训练encode部分\n",
    "input_grams = Input(shape=(nb_grams,), dtype='int32')\n",
    "encoded_grams = encoder(input_grams)\n",
    "softmax = Dense(max_features, activation='softmax')(encoded_grams)\n",
    "lm = Model(inputs=input_grams, outputs=softmax)\n",
    "lm.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "#用sparse交叉熵，可以不用事先将类别转换为one hot形式。\n",
    "\n",
    "#情感分析部分\n",
    "#固定encoder，后面接一个简单的Dense层（相当于逻辑回归）\n",
    "#这时候训练的只有hidden_size+1=1001个参数\n",
    "#因此理论上来说，少量标注样本就可以训练充分\n",
    "for layer in encoder.layers:\n",
    "    layer.trainable=False\n",
    "\n",
    "sentence = Input(shape=(maxlen,), dtype='int32')\n",
    "encoded_sentence = encoder(sentence)\n",
    "sigmoid = Dense(10, activation='relu')(encoded_sentence)\n",
    "sigmoid = Dropout(0.5)(sigmoid)\n",
    "sigmoid = Dense(1, activation='sigmoid')(sigmoid)\n",
    "model = Model(inputs=sentence, outputs=sigmoid)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.engine.topology.InputLayer at 0x1379e1c50>,\n",
       " <keras.layers.embeddings.Embedding at 0x1379e1c88>,\n",
       " <keras.layers.recurrent.LSTM at 0x1379e1eb8>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, None, 100)         1000000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1000)              4404000   \n",
      "=================================================================\n",
      "Total params: 5,404,000\n",
      "Trainable params: 0\n",
      "Non-trainable params: 5,404,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1000)              5404000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10000)             10010000  \n",
      "=================================================================\n",
      "Total params: 15,414,000\n",
      "Trainable params: 10,010,000\n",
      "Non-trainable params: 5,404,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "model_1 (Model)              (None, 1000)              5404000   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10010     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 5,414,021\n",
      "Trainable params: 10,021\n",
      "Non-trainable params: 5,404,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
