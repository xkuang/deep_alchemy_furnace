{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Checkpoint\" data-toc-modified-id=\"Checkpoint-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Checkpoint</a></div><div class=\"lev1 toc-item\"><a href=\"#Build-Model\" data-toc-modified-id=\"Build-Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Build Model</a></div><div class=\"lev2 toc-item\"><a href=\"#Set-Hyperparameters\" data-toc-modified-id=\"Set-Hyperparameters-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Set Hyperparameters</a></div><div class=\"lev2 toc-item\"><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Import Libraries</a></div><div class=\"lev2 toc-item\"><a href=\"#Build-Graph\" data-toc-modified-id=\"Build-Graph-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Build Graph</a></div><div class=\"lev2 toc-item\"><a href=\"#Model-Visualization\" data-toc-modified-id=\"Model-Visualization-24\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Model Visualization</a></div><div class=\"lev2 toc-item\"><a href=\"#Train\" data-toc-modified-id=\"Train-25\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Train</a></div><div class=\"lev1 toc-item\"><a href=\"#Evaluate\" data-toc-modified-id=\"Evaluate-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Evaluate</a></div><div class=\"lev2 toc-item\"><a href=\"#Naive-Evaluate\" data-toc-modified-id=\"Naive-Evaluate-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Naive Evaluate</a></div><div class=\"lev2 toc-item\"><a href=\"#Greedy-1-best-Search-Evaluate\" data-toc-modified-id=\"Greedy-1-best-Search-Evaluate-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Greedy 1-best Search Evaluate</a></div><div class=\"lev2 toc-item\"><a href=\"#Beam-Search-Evaluate\" data-toc-modified-id=\"Beam-Search-Evaluate-33\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Beam Search Evaluate</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('allData.h5', 'r') as fh:\n",
    "    x_train = fh['x_train'][:]\n",
    "    tf_train = fh['tf_train'][:]\n",
    "    y_train = fh['y_train'][:]\n",
    "    x_val = fh['x_val'][:]\n",
    "    tf_val = fh['tf_val'][:]\n",
    "    y_val = fh['y_val'][:]\n",
    "    x_train_all = fh['x_train_all'][:]\n",
    "    tf_train_all = fh['tf_train_all'][:]\n",
    "    y_train_all = fh['y_train_all'][:]\n",
    "    x_test = fh['x_test'][:]\n",
    "    tf_test = fh['tf_test'][:]\n",
    "    y_test = fh['y_test'][:]\n",
    "    embedding = fh['embedding'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('index.pkl', 'rb') as fp:\n",
    "    word2index, index2word = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SENT_LEN = 64\n",
    "MAX_ADJL_LEN = 3\n",
    "VOCAB_SIZE = len(word2index)+1\n",
    "NUM_CLASSES = VOCAB_SIZE\n",
    "EMBEDDING_SIZE = 300\n",
    "TF_EMBEDDING_SIZE = 300\n",
    "\n",
    "ENC_1_RNN_SIZE = 300\n",
    "ENC_2_RNN_SIZE = 150\n",
    "DEC_RNN_SIZE = 150\n",
    "DROPOUT_RATE = 0.5\n",
    "RNN_DROPOUT_RATE = 0.2\n",
    "NUM_EPOCHS = 512\n",
    "BATCH_SIZE = 79\n",
    "STEPS_PER_EPOCH = 20\n",
    "TEST_STEPS = len(x_test)//BATCH_SIZE\n",
    "\n",
    "VALIDATION_STEPS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Dropout, Bidirectional, LSTM, RepeatVector, concatenate, TimeDistributed, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import*\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "sequence = Input(shape=(MAX_SENT_LEN,), name='INPUT') \n",
    "emb_seq = Embedding(VOCAB_SIZE, EMBEDDING_SIZE, weights=[embedding], mask_zero=True, input_length=MAX_SENT_LEN, trainable=False, name='EMBEDDING')(sequence)\n",
    "tf_seq = Input(shape=(MAX_ADJL_LEN,), name='TF_INPUT')\n",
    "tf_emb = Embedding(NUM_CLASSES, TF_EMBEDDING_SIZE, weights=[embedding], mask_zero=True, input_length=MAX_ADJL_LEN, trainable=False, name='TF_EMBEDDING')(tf_seq)\n",
    "blstm = Bidirectional(LSTM(ENC_1_RNN_SIZE, return_sequences=True, implementation=0, dropout=RNN_DROPOUT_RATE, recurrent_dropout=RNN_DROPOUT_RATE), merge_mode='concat', name='ENC_BLSTM_1')(emb_seq)\n",
    "blstm = Dropout(DROPOUT_RATE)(blstm)\n",
    "blstm = Bidirectional(LSTM(ENC_2_RNN_SIZE, return_sequences=False, implementation=0, dropout=RNN_DROPOUT_RATE, recurrent_dropout=RNN_DROPOUT_RATE), merge_mode='concat', name='ENC_BLSTM_2')(blstm)\n",
    "blstm = Dropout(DROPOUT_RATE)(blstm)\n",
    "context = RepeatVector(MAX_ADJL_LEN, name='CONTEXT')(blstm)\n",
    "context = concatenate([context, tf_emb], axis=-1)\n",
    "blstm = Bidirectional(LSTM(DEC_RNN_SIZE, return_sequences=True, implementation=0, dropout=RNN_DROPOUT_RATE, recurrent_dropout=RNN_DROPOUT_RATE, name='DEC_LSTM'), merge_mode='concat', name='DEC_BLSTM')(context)\n",
    "lstm = Dropout(DROPOUT_RATE)(blstm)\n",
    "output = TimeDistributed(Dense(NUM_CLASSES, activation='softmax'), name='OUTPUT')(lstm)\n",
    "model = Model(inputs=[sequence, tf_seq], outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "INPUT (InputLayer)               (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "EMBEDDING (Embedding)            (None, 64, 300)       17652300    INPUT[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "ENC_BLSTM_1 (Bidirectional)      (None, 64, 600)       1442400     EMBEDDING[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 64, 600)       0           ENC_BLSTM_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "ENC_BLSTM_2 (Bidirectional)      (None, 300)           901200      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 300)           0           ENC_BLSTM_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "TF_INPUT (InputLayer)            (None, 3)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "CONTEXT (RepeatVector)           (None, 3, 300)        0           dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "TF_EMBEDDING (Embedding)         (None, 3, 300)        17652300    TF_INPUT[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 3, 600)        0           CONTEXT[0][0]                    \n",
      "                                                                   TF_EMBEDDING[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "DEC_BLSTM (Bidirectional)        (None, 3, 300)        901200      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 3, 300)        0           DEC_BLSTM[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "OUTPUT (TimeDistributed)         (None, 3, 58841)      17711141    dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 56,260,541\n",
      "Trainable params: 20,955,941\n",
      "Non-trainable params: 35,304,600\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_label(s):\n",
    "    \"\"\"\n",
    "    One-hot encoding\n",
    "    \"\"\"\n",
    "    gen = to_categorical(s, num_classes=NUM_CLASSES)\n",
    "    return gen\n",
    "\n",
    "def data_generator_all(data, label, batch_size):\n",
    "    \"\"\"\n",
    "    Yield batches of all data\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    while True:\n",
    "        if count >= len(data[0]): \n",
    "            count = 0\n",
    "        x_1 = np.zeros((batch_size, MAX_SENT_LEN))\n",
    "        x_2 = np.zeros((batch_size, MAX_ADJL_LEN))\n",
    "        y = np.zeros((batch_size, MAX_ADJL_LEN, NUM_CLASSES))\n",
    "        for i in range(batch_size):\n",
    "            n = i + count\n",
    "            if n > len(data[0])-1:\n",
    "                break\n",
    "            x_1[i, :] = data[0][n]\n",
    "            x_2[i, :] = data[1][n]\n",
    "            y[i, :, :] = gen_label(label[n])\n",
    "        count += batch_size\n",
    "        yield ([x_1, x_2], y)\n",
    "        \n",
    "def data_generator(data, label, batch_size): \n",
    "    \"\"\"\n",
    "    Yield batches \n",
    "    \"\"\"\n",
    "    index = np.arange(len(data[0]))\n",
    "    np.random.shuffle(index)    \n",
    "    batches = [index[range(batch_size*i, min(len(data[0]), batch_size*(i+1)))] for i in range(len(data[0])//batch_size)]\n",
    "    while True:\n",
    "        for i in batches:\n",
    "            x_1 = data[0][i]\n",
    "            x_2 = data[1][i]\n",
    "            y = np.array(list(map(gen_label, label[i])))\n",
    "            yield ([x_1, x_2], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_train_all = data_generator([x_train_all, tf_train_all], y_train_all, BATCH_SIZE)\n",
    "gen_test = data_generator_all([x_test, tf_test], y_test, BATCH_SIZE)\n",
    "#gen_train = data_generator(x_train, y_train, BATCH_SIZE)\n",
    "#gen_val = data_generator(x_val, y_val, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continue Trian\n",
    "# filename = 'cp_logs/.hdf5'\n",
    "# model.load_weights(filename)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = 'cp_logs/weights.{epoch:03d}-{val_loss:.6f}.hdf5'\n",
    "log_string = 'tb_logs/tf'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir=log_string, \n",
    "                          histogram_freq=1, \n",
    "                          write_graph=False, \n",
    "                          write_grads=False, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          write_images=True, \n",
    "                          embeddings_freq=1, \n",
    "                          embeddings_layer_names=None,\n",
    "                          embeddings_metadata=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/512\n",
      "19/20 [===========================>..] - ETA: 0s - loss: 7.7977Epoch 00000: val_loss improved from inf to 6.53663, saving model to cp_logs/weights.000-6.536634.hdf5\n",
      "20/20 [==============================] - 23s - loss: 7.7333 - val_loss: 6.5366\n",
      "Epoch 2/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 6.1214Epoch 00001: val_loss improved from 6.53663 to 6.18263, saving model to cp_logs/weights.001-6.182635.hdf5\n",
      "20/20 [==============================] - 45s - loss: 6.1098 - val_loss: 6.1826\n",
      "Epoch 3/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 5.7459Epoch 00002: val_loss improved from 6.18263 to 5.88942, saving model to cp_logs/weights.002-5.889424.hdf5\n",
      "20/20 [==============================] - 50s - loss: 5.7357 - val_loss: 5.8894\n",
      "Epoch 4/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 5.4773Epoch 00003: val_loss improved from 5.88942 to 5.73879, saving model to cp_logs/weights.003-5.738791.hdf5\n",
      "20/20 [==============================] - 46s - loss: 5.4694 - val_loss: 5.7388\n",
      "Epoch 5/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 5.3601Epoch 00004: val_loss improved from 5.73879 to 5.72002, saving model to cp_logs/weights.004-5.720018.hdf5\n",
      "20/20 [==============================] - 48s - loss: 5.3558 - val_loss: 5.7200\n",
      "Epoch 6/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 5.2745Epoch 00005: val_loss improved from 5.72002 to 5.68498, saving model to cp_logs/weights.005-5.684980.hdf5\n",
      "20/20 [==============================] - 50s - loss: 5.2756 - val_loss: 5.6850\n",
      "Epoch 7/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 5.1402Epoch 00006: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 5.1401 - val_loss: 5.7224\n",
      "Epoch 8/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 5.1603Epoch 00007: val_loss improved from 5.68498 to 5.62030, saving model to cp_logs/weights.007-5.620303.hdf5\n",
      "20/20 [==============================] - 54s - loss: 5.1572 - val_loss: 5.6203\n",
      "Epoch 9/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 5.1081Epoch 00008: val_loss improved from 5.62030 to 5.45774, saving model to cp_logs/weights.008-5.457744.hdf5\n",
      "20/20 [==============================] - 50s - loss: 5.1001 - val_loss: 5.4577\n",
      "Epoch 10/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 5.0152Epoch 00009: val_loss improved from 5.45774 to 5.29912, saving model to cp_logs/weights.009-5.299119.hdf5\n",
      "20/20 [==============================] - 56s - loss: 5.0194 - val_loss: 5.2991\n",
      "Epoch 11/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 4.9019Epoch 00010: val_loss improved from 5.29912 to 5.28285, saving model to cp_logs/weights.010-5.282846.hdf5\n",
      "20/20 [==============================] - 56s - loss: 4.8899 - val_loss: 5.2828\n",
      "Epoch 12/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 4.7427Epoch 00011: val_loss improved from 5.28285 to 5.07335, saving model to cp_logs/weights.011-5.073348.hdf5\n",
      "20/20 [==============================] - 49s - loss: 4.7359 - val_loss: 5.0733\n",
      "Epoch 13/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 4.6585Epoch 00012: val_loss improved from 5.07335 to 4.94798, saving model to cp_logs/weights.012-4.947981.hdf5\n",
      "20/20 [==============================] - 54s - loss: 4.6626 - val_loss: 4.9480\n",
      "Epoch 14/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 4.4918Epoch 00013: val_loss improved from 4.94798 to 4.89725, saving model to cp_logs/weights.013-4.897245.hdf5\n",
      "20/20 [==============================] - 54s - loss: 4.5027 - val_loss: 4.8972\n",
      "Epoch 15/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 4.4339Epoch 00014: val_loss improved from 4.89725 to 4.88075, saving model to cp_logs/weights.014-4.880746.hdf5\n",
      "20/20 [==============================] - 55s - loss: 4.4107 - val_loss: 4.8807\n",
      "Epoch 16/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 4.2852Epoch 00015: val_loss improved from 4.88075 to 4.78101, saving model to cp_logs/weights.015-4.781013.hdf5\n",
      "20/20 [==============================] - 55s - loss: 4.2816 - val_loss: 4.7810\n",
      "Epoch 17/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 4.2826Epoch 00016: val_loss improved from 4.78101 to 4.72170, saving model to cp_logs/weights.016-4.721702.hdf5\n",
      "20/20 [==============================] - 56s - loss: 4.2825 - val_loss: 4.7217\n",
      "Epoch 18/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 4.1476Epoch 00017: val_loss improved from 4.72170 to 4.71909, saving model to cp_logs/weights.017-4.719093.hdf5\n",
      "20/20 [==============================] - 55s - loss: 4.1456 - val_loss: 4.7191\n",
      "Epoch 19/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 4.0709Epoch 00018: val_loss improved from 4.71909 to 4.63538, saving model to cp_logs/weights.018-4.635380.hdf5\n",
      "20/20 [==============================] - 55s - loss: 4.0780 - val_loss: 4.6354\n",
      "Epoch 20/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 4.0666Epoch 00019: val_loss improved from 4.63538 to 4.58259, saving model to cp_logs/weights.019-4.582587.hdf5\n",
      "20/20 [==============================] - 56s - loss: 4.0700 - val_loss: 4.5826\n",
      "Epoch 21/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 4.0113Epoch 00020: val_loss did not improve\n",
      "20/20 [==============================] - 55s - loss: 4.0204 - val_loss: 4.5910\n",
      "Epoch 22/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.9651Epoch 00021: val_loss improved from 4.58259 to 4.53329, saving model to cp_logs/weights.021-4.533293.hdf5\n",
      "20/20 [==============================] - 55s - loss: 3.9737 - val_loss: 4.5333\n",
      "Epoch 23/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.9258Epoch 00022: val_loss improved from 4.53329 to 4.48964, saving model to cp_logs/weights.022-4.489637.hdf5\n",
      "20/20 [==============================] - 55s - loss: 3.9139 - val_loss: 4.4896\n",
      "Epoch 24/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.8493Epoch 00023: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 3.8468 - val_loss: 4.5234\n",
      "Epoch 25/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.8311Epoch 00024: val_loss improved from 4.48964 to 4.36087, saving model to cp_logs/weights.024-4.360868.hdf5\n",
      "20/20 [==============================] - 56s - loss: 3.8347 - val_loss: 4.3609\n",
      "Epoch 26/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.7711Epoch 00025: val_loss did not improve\n",
      "20/20 [==============================] - 55s - loss: 3.7863 - val_loss: 4.3942\n",
      "Epoch 27/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.7903Epoch 00026: val_loss improved from 4.36087 to 4.26640, saving model to cp_logs/weights.026-4.266399.hdf5\n",
      "20/20 [==============================] - 55s - loss: 3.7802 - val_loss: 4.2664\n",
      "Epoch 28/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.6525Epoch 00027: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 3.6296 - val_loss: 4.2885\n",
      "Epoch 29/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.6298Epoch 00028: val_loss improved from 4.26640 to 4.24777, saving model to cp_logs/weights.028-4.247769.hdf5\n",
      "20/20 [==============================] - 55s - loss: 3.6201 - val_loss: 4.2478\n",
      "Epoch 30/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.6413Epoch 00029: val_loss improved from 4.24777 to 4.18317, saving model to cp_logs/weights.029-4.183168.hdf5\n",
      "20/20 [==============================] - 55s - loss: 3.6435 - val_loss: 4.1832\n",
      "Epoch 31/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.6100Epoch 00030: val_loss improved from 4.18317 to 4.16960, saving model to cp_logs/weights.030-4.169597.hdf5\n",
      "20/20 [==============================] - 55s - loss: 3.6187 - val_loss: 4.1696\n",
      "Epoch 32/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.5962Epoch 00031: val_loss improved from 4.16960 to 4.06326, saving model to cp_logs/weights.031-4.063255.hdf5\n",
      "20/20 [==============================] - 56s - loss: 3.6165 - val_loss: 4.0633\n",
      "Epoch 33/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.4885Epoch 00032: val_loss improved from 4.06326 to 4.06092, saving model to cp_logs/weights.032-4.060922.hdf5\n",
      "20/20 [==============================] - 55s - loss: 3.4828 - val_loss: 4.0609\n",
      "Epoch 34/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.4861Epoch 00033: val_loss improved from 4.06092 to 4.01754, saving model to cp_logs/weights.033-4.017538.hdf5\n",
      "20/20 [==============================] - 55s - loss: 3.4991 - val_loss: 4.0175\n",
      "Epoch 35/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.3805Epoch 00034: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 3.3844 - val_loss: 4.0435\n",
      "Epoch 36/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.3478Epoch 00035: val_loss improved from 4.01754 to 3.96555, saving model to cp_logs/weights.035-3.965554.hdf5\n",
      "20/20 [==============================] - 52s - loss: 3.3478 - val_loss: 3.9656\n",
      "Epoch 37/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.3589Epoch 00036: val_loss improved from 3.96555 to 3.96335, saving model to cp_logs/weights.036-3.963350.hdf5\n",
      "20/20 [==============================] - 55s - loss: 3.3555 - val_loss: 3.9634\n",
      "Epoch 38/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.3730Epoch 00037: val_loss improved from 3.96335 to 3.94490, saving model to cp_logs/weights.037-3.944905.hdf5\n",
      "20/20 [==============================] - 54s - loss: 3.3719 - val_loss: 3.9449\n",
      "Epoch 39/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.3004Epoch 00038: val_loss improved from 3.94490 to 3.87692, saving model to cp_logs/weights.038-3.876922.hdf5\n",
      "20/20 [==============================] - 50s - loss: 3.2977 - val_loss: 3.8769\n",
      "Epoch 40/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.3015Epoch 00039: val_loss improved from 3.87692 to 3.84271, saving model to cp_logs/weights.039-3.842708.hdf5\n",
      "20/20 [==============================] - 50s - loss: 3.2913 - val_loss: 3.8427\n",
      "Epoch 41/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.2493Epoch 00040: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 3.2385 - val_loss: 3.8876\n",
      "Epoch 42/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 3.2267Epoch 00041: val_loss improved from 3.84271 to 3.83850, saving model to cp_logs/weights.041-3.838501.hdf5\n",
      "20/20 [==============================] - 44s - loss: 3.2154 - val_loss: 3.8385\n",
      "Epoch 43/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.1626Epoch 00042: val_loss improved from 3.83850 to 3.74500, saving model to cp_logs/weights.042-3.744998.hdf5\n",
      "20/20 [==============================] - 50s - loss: 3.1721 - val_loss: 3.7450\n",
      "Epoch 44/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 3.2133Epoch 00043: val_loss did not improve\n",
      "20/20 [==============================] - 46s - loss: 3.2075 - val_loss: 3.7544\n",
      "Epoch 45/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.0880Epoch 00044: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 3.0792 - val_loss: 3.7877\n",
      "Epoch 46/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 3.0706Epoch 00045: val_loss improved from 3.74500 to 3.62313, saving model to cp_logs/weights.045-3.623131.hdf5\n",
      "20/20 [==============================] - 48s - loss: 3.1008 - val_loss: 3.6231\n",
      "Epoch 47/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 3.1715Epoch 00046: val_loss did not improve\n",
      "20/20 [==============================] - 46s - loss: 3.1496 - val_loss: 3.7286\n",
      "Epoch 48/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 3.0438Epoch 00047: val_loss did not improve\n",
      "20/20 [==============================] - 45s - loss: 3.0319 - val_loss: 3.6977\n",
      "Epoch 49/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 3.0314Epoch 00048: val_loss improved from 3.62313 to 3.60268, saving model to cp_logs/weights.048-3.602676.hdf5\n",
      "20/20 [==============================] - 48s - loss: 3.0265 - val_loss: 3.6027\n",
      "Epoch 50/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 3.0368Epoch 00049: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 3.0417 - val_loss: 3.6072\n",
      "Epoch 51/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.9941Epoch 00050: val_loss improved from 3.60268 to 3.56895, saving model to cp_logs/weights.050-3.568953.hdf5\n",
      "20/20 [==============================] - 49s - loss: 2.9972 - val_loss: 3.5690\n",
      "Epoch 52/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 3.0270Epoch 00051: val_loss did not improve\n",
      "20/20 [==============================] - 44s - loss: 3.0002 - val_loss: 3.6580\n",
      "Epoch 53/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.9260Epoch 00052: val_loss improved from 3.56895 to 3.48690, saving model to cp_logs/weights.052-3.486902.hdf5\n",
      "20/20 [==============================] - 51s - loss: 2.9109 - val_loss: 3.4869\n",
      "Epoch 54/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.8797Epoch 00053: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 2.8846 - val_loss: 3.5021\n",
      "Epoch 55/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.9319Epoch 00054: val_loss improved from 3.48690 to 3.43217, saving model to cp_logs/weights.054-3.432168.hdf5\n",
      "20/20 [==============================] - 49s - loss: 2.9183 - val_loss: 3.4322\n",
      "Epoch 56/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 2.8976Epoch 00055: val_loss did not improve\n",
      "20/20 [==============================] - 47s - loss: 2.8970 - val_loss: 3.4508\n",
      "Epoch 57/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 2.8675Epoch 00056: val_loss did not improve\n",
      "20/20 [==============================] - 44s - loss: 2.8596 - val_loss: 3.4583\n",
      "Epoch 58/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.7752Epoch 00057: val_loss improved from 3.43217 to 3.42922, saving model to cp_logs/weights.057-3.429218.hdf5\n",
      "20/20 [==============================] - 51s - loss: 2.7807 - val_loss: 3.4292\n",
      "Epoch 59/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.8117Epoch 00058: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 2.8071 - val_loss: 3.4725\n",
      "Epoch 60/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 2.8151Epoch 00059: val_loss improved from 3.42922 to 3.40129, saving model to cp_logs/weights.059-3.401290.hdf5\n",
      "20/20 [==============================] - 41s - loss: 2.7925 - val_loss: 3.4013\n",
      "Epoch 61/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.8087Epoch 00060: val_loss improved from 3.40129 to 3.32316, saving model to cp_logs/weights.060-3.323155.hdf5\n",
      "20/20 [==============================] - 53s - loss: 2.8233 - val_loss: 3.3232\n",
      "Epoch 62/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 2.7923Epoch 00061: val_loss did not improve\n",
      "20/20 [==============================] - 46s - loss: 2.7994 - val_loss: 3.3447\n",
      "Epoch 63/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.6868Epoch 00062: val_loss did not improve\n",
      "20/20 [==============================] - 48s - loss: 2.6840 - val_loss: 3.3543\n",
      "Epoch 64/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 2.6618Epoch 00063: val_loss did not improve\n",
      "20/20 [==============================] - 45s - loss: 2.6521 - val_loss: 3.3777\n",
      "Epoch 65/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.6703Epoch 00064: val_loss improved from 3.32316 to 3.29176, saving model to cp_logs/weights.064-3.291760.hdf5\n",
      "20/20 [==============================] - 53s - loss: 2.6707 - val_loss: 3.2918\n",
      "Epoch 66/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 2.5939Epoch 00065: val_loss improved from 3.29176 to 3.26117, saving model to cp_logs/weights.065-3.261171.hdf5\n",
      "20/20 [==============================] - 44s - loss: 2.6136 - val_loss: 3.2612\n",
      "Epoch 67/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 2.6711Epoch 00066: val_loss did not improve\n",
      "20/20 [==============================] - 48s - loss: 2.6753 - val_loss: 3.3039\n",
      "Epoch 68/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.6170Epoch 00067: val_loss did not improve\n",
      "20/20 [==============================] - 44s - loss: 2.6069 - val_loss: 3.2725\n",
      "Epoch 69/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.6314Epoch 00068: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 51s - loss: 2.6373 - val_loss: 3.2684\n",
      "Epoch 70/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 2.6609Epoch 00069: val_loss improved from 3.26117 to 3.24261, saving model to cp_logs/weights.069-3.242606.hdf5\n",
      "20/20 [==============================] - 48s - loss: 2.6424 - val_loss: 3.2426\n",
      "Epoch 71/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.5811Epoch 00070: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 2.5667 - val_loss: 3.2615\n",
      "Epoch 72/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.5730Epoch 00071: val_loss improved from 3.24261 to 3.16253, saving model to cp_logs/weights.071-3.162531.hdf5\n",
      "20/20 [==============================] - 50s - loss: 2.5732 - val_loss: 3.1625\n",
      "Epoch 73/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.6768Epoch 00072: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 2.6622 - val_loss: 3.2125\n",
      "Epoch 74/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.5262Epoch 00073: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 2.5197 - val_loss: 3.2710\n",
      "Epoch 75/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.4986Epoch 00074: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 2.4910 - val_loss: 3.1932\n",
      "Epoch 76/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.6470Epoch 00075: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 2.6736 - val_loss: 3.1642\n",
      "Epoch 77/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.4581Epoch 00076: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.4572 - val_loss: 3.2532\n",
      "Epoch 78/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.4645Epoch 00077: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 2.4602 - val_loss: 3.1684\n",
      "Epoch 79/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.5493Epoch 00078: val_loss improved from 3.16253 to 3.15687, saving model to cp_logs/weights.078-3.156871.hdf5\n",
      "20/20 [==============================] - 50s - loss: 2.5453 - val_loss: 3.1569\n",
      "Epoch 80/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.5264Epoch 00079: val_loss improved from 3.15687 to 3.12886, saving model to cp_logs/weights.079-3.128860.hdf5\n",
      "20/20 [==============================] - 52s - loss: 2.5234 - val_loss: 3.1289\n",
      "Epoch 81/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.4636Epoch 00080: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.4846 - val_loss: 3.1546\n",
      "Epoch 82/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.4368Epoch 00081: val_loss improved from 3.12886 to 3.09069, saving model to cp_logs/weights.081-3.090686.hdf5\n",
      "20/20 [==============================] - 54s - loss: 2.4644 - val_loss: 3.0907\n",
      "Epoch 83/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.3572Epoch 00082: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 2.3580 - val_loss: 3.1870\n",
      "Epoch 84/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.5163Epoch 00083: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 2.5185 - val_loss: 3.1328\n",
      "Epoch 85/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.4169Epoch 00084: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.4232 - val_loss: 3.1492\n",
      "Epoch 86/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.4766Epoch 00085: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 2.4855 - val_loss: 3.1178\n",
      "Epoch 87/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.3066Epoch 00086: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 2.3122 - val_loss: 3.1198\n",
      "Epoch 88/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.3413Epoch 00087: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 2.3744 - val_loss: 3.1553\n",
      "Epoch 89/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.4090Epoch 00088: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.4254 - val_loss: 3.1016\n",
      "Epoch 90/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.4332Epoch 00089: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 2.4310 - val_loss: 3.1355\n",
      "Epoch 91/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.4544Epoch 00090: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 2.4592 - val_loss: 3.1104\n",
      "Epoch 92/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.3071Epoch 00091: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 2.3182 - val_loss: 3.1401\n",
      "Epoch 93/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2984Epoch 00092: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.3030 - val_loss: 3.1417\n",
      "Epoch 94/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.3209Epoch 00093: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 2.3150 - val_loss: 3.0943\n",
      "Epoch 95/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2490Epoch 00094: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 2.2264 - val_loss: 3.1102\n",
      "Epoch 96/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.3104Epoch 00095: val_loss improved from 3.09069 to 3.04112, saving model to cp_logs/weights.095-3.041123.hdf5\n",
      "20/20 [==============================] - 54s - loss: 2.3315 - val_loss: 3.0411\n",
      "Epoch 97/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2845Epoch 00096: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.2785 - val_loss: 3.0876\n",
      "Epoch 98/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2709Epoch 00097: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 2.2626 - val_loss: 3.0854\n",
      "Epoch 99/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.3170Epoch 00098: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.3178 - val_loss: 3.1174\n",
      "Epoch 100/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2762Epoch 00099: val_loss improved from 3.04112 to 3.03783, saving model to cp_logs/weights.099-3.037833.hdf5\n",
      "20/20 [==============================] - 54s - loss: 2.2926 - val_loss: 3.0378\n",
      "Epoch 101/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2956Epoch 00100: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 2.2871 - val_loss: 3.1225\n",
      "Epoch 102/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.3129Epoch 00101: val_loss improved from 3.03783 to 3.02569, saving model to cp_logs/weights.101-3.025687.hdf5\n",
      "20/20 [==============================] - 55s - loss: 2.3264 - val_loss: 3.0257\n",
      "Epoch 103/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2436Epoch 00102: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 2.2272 - val_loss: 3.0452\n",
      "Epoch 104/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2388Epoch 00103: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.2446 - val_loss: 3.0706\n",
      "Epoch 105/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.3257Epoch 00104: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 2.3142 - val_loss: 3.0667\n",
      "Epoch 106/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2353Epoch 00105: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 2.2044 - val_loss: 3.1158\n",
      "Epoch 107/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2168Epoch 00106: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 2.2035 - val_loss: 3.0501\n",
      "Epoch 108/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2586Epoch 00107: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.2459 - val_loss: 3.0676\n",
      "Epoch 109/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2851Epoch 00108: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 2.3003 - val_loss: 3.0471\n",
      "Epoch 110/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.1834Epoch 00109: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 2.1744 - val_loss: 3.0538\n",
      "Epoch 111/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2211Epoch 00110: val_loss improved from 3.02569 to 3.01518, saving model to cp_logs/weights.110-3.015181.hdf5\n",
      "20/20 [==============================] - 54s - loss: 2.2321 - val_loss: 3.0152\n",
      "Epoch 112/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.1303Epoch 00111: val_loss improved from 3.01518 to 3.00125, saving model to cp_logs/weights.111-3.001249.hdf5\n",
      "20/20 [==============================] - 54s - loss: 2.1410 - val_loss: 3.0012\n",
      "Epoch 113/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2475Epoch 00112: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.2383 - val_loss: 3.0387\n",
      "Epoch 114/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.1709Epoch 00113: val_loss improved from 3.00125 to 2.99266, saving model to cp_logs/weights.113-2.992661.hdf5\n",
      "20/20 [==============================] - 55s - loss: 2.1748 - val_loss: 2.9927\n",
      "Epoch 115/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2789Epoch 00114: val_loss improved from 2.99266 to 2.97780, saving model to cp_logs/weights.114-2.977805.hdf5\n",
      "20/20 [==============================] - 51s - loss: 2.2752 - val_loss: 2.9778\n",
      "Epoch 116/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0683Epoch 00115: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.0852 - val_loss: 2.9831\n",
      "Epoch 117/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.1563Epoch 00116: val_loss improved from 2.97780 to 2.97762, saving model to cp_logs/weights.116-2.977624.hdf5\n",
      "20/20 [==============================] - 54s - loss: 2.1525 - val_loss: 2.9776\n",
      "Epoch 118/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2053Epoch 00117: val_loss improved from 2.97762 to 2.96504, saving model to cp_logs/weights.117-2.965044.hdf5\n",
      "20/20 [==============================] - 55s - loss: 2.1933 - val_loss: 2.9650\n",
      "Epoch 119/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2359Epoch 00118: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.2265 - val_loss: 3.0018\n",
      "Epoch 120/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.2463Epoch 00119: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.2300 - val_loss: 2.9805\n",
      "Epoch 121/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.1065Epoch 00120: val_loss improved from 2.96504 to 2.96202, saving model to cp_logs/weights.120-2.962019.hdf5\n",
      "20/20 [==============================] - 54s - loss: 2.1275 - val_loss: 2.9620\n",
      "Epoch 122/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.1312Epoch 00121: val_loss improved from 2.96202 to 2.95726, saving model to cp_logs/weights.121-2.957264.hdf5\n",
      "20/20 [==============================] - 54s - loss: 2.1230 - val_loss: 2.9573\n",
      "Epoch 123/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0663Epoch 00122: val_loss improved from 2.95726 to 2.95377, saving model to cp_logs/weights.122-2.953765.hdf5\n",
      "20/20 [==============================] - 54s - loss: 2.0604 - val_loss: 2.9538\n",
      "Epoch 124/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0425Epoch 00123: val_loss improved from 2.95377 to 2.93515, saving model to cp_logs/weights.123-2.935151.hdf5\n",
      "20/20 [==============================] - 54s - loss: 2.0535 - val_loss: 2.9352\n",
      "Epoch 125/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0885Epoch 00124: val_loss improved from 2.93515 to 2.87085, saving model to cp_logs/weights.124-2.870851.hdf5\n",
      "20/20 [==============================] - 55s - loss: 2.0966 - val_loss: 2.8709\n",
      "Epoch 126/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.1199Epoch 00125: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.0997 - val_loss: 2.9396\n",
      "Epoch 127/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0625Epoch 00126: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 2.0556 - val_loss: 2.8865\n",
      "Epoch 128/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0953Epoch 00127: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.0919 - val_loss: 2.9215\n",
      "Epoch 129/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0970Epoch 00128: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.0875 - val_loss: 2.9312\n",
      "Epoch 130/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.1017Epoch 00129: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 2.1068 - val_loss: 2.8745\n",
      "Epoch 131/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0855Epoch 00130: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 2.0895 - val_loss: 2.8758\n",
      "Epoch 132/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.1103Epoch 00131: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 2.0975 - val_loss: 2.8764\n",
      "Epoch 133/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9983Epoch 00132: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.0169 - val_loss: 2.8909\n",
      "Epoch 134/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0774Epoch 00133: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.1124 - val_loss: 2.9297\n",
      "Epoch 135/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0967Epoch 00134: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 2.0777 - val_loss: 2.9518\n",
      "Epoch 136/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0347Epoch 00135: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.0351 - val_loss: 2.9305\n",
      "Epoch 137/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0572Epoch 00136: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.0479 - val_loss: 2.9686\n",
      "Epoch 138/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0906Epoch 00137: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.0924 - val_loss: 2.9055\n",
      "Epoch 139/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0431Epoch 00138: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.0337 - val_loss: 2.9038\n",
      "Epoch 140/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.1102Epoch 00139: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 2.0971 - val_loss: 2.9246\n",
      "Epoch 141/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0130Epoch 00140: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.0043 - val_loss: 2.8973\n",
      "Epoch 142/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0278Epoch 00141: val_loss improved from 2.87085 to 2.86089, saving model to cp_logs/weights.141-2.860893.hdf5\n",
      "20/20 [==============================] - 53s - loss: 2.0375 - val_loss: 2.8609\n",
      "Epoch 143/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0449Epoch 00142: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.0342 - val_loss: 2.9181\n",
      "Epoch 144/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0912Epoch 00143: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 2.0838 - val_loss: 2.9271\n",
      "Epoch 145/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0306Epoch 00144: val_loss improved from 2.86089 to 2.85515, saving model to cp_logs/weights.144-2.855148.hdf5\n",
      "20/20 [==============================] - 51s - loss: 2.0034 - val_loss: 2.8551\n",
      "Epoch 146/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0050Epoch 00145: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 52s - loss: 2.0079 - val_loss: 2.9010\n",
      "Epoch 147/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0097Epoch 00146: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.9935 - val_loss: 2.9254\n",
      "Epoch 148/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0453Epoch 00147: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 2.0415 - val_loss: 2.8907\n",
      "Epoch 149/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0459Epoch 00148: val_loss improved from 2.85515 to 2.84020, saving model to cp_logs/weights.148-2.840202.hdf5\n",
      "20/20 [==============================] - 53s - loss: 2.0486 - val_loss: 2.8402\n",
      "Epoch 150/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0522Epoch 00149: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 2.0434 - val_loss: 2.9127\n",
      "Epoch 151/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9820Epoch 00150: val_loss did not improve\n",
      "20/20 [==============================] - 48s - loss: 1.9768 - val_loss: 2.9055\n",
      "Epoch 152/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9299Epoch 00151: val_loss improved from 2.84020 to 2.83359, saving model to cp_logs/weights.151-2.833587.hdf5\n",
      "20/20 [==============================] - 52s - loss: 1.9415 - val_loss: 2.8336\n",
      "Epoch 153/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9526Epoch 00152: val_loss improved from 2.83359 to 2.81048, saving model to cp_logs/weights.152-2.810483.hdf5\n",
      "20/20 [==============================] - 54s - loss: 1.9564 - val_loss: 2.8105\n",
      "Epoch 154/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9240Epoch 00153: val_loss improved from 2.81048 to 2.80184, saving model to cp_logs/weights.153-2.801835.hdf5\n",
      "20/20 [==============================] - 54s - loss: 1.9073 - val_loss: 2.8018\n",
      "Epoch 155/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0482Epoch 00154: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.0464 - val_loss: 2.8619\n",
      "Epoch 156/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9132Epoch 00155: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.9084 - val_loss: 2.8652\n",
      "Epoch 157/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.9791Epoch 00156: val_loss did not improve\n",
      "20/20 [==============================] - 46s - loss: 1.9754 - val_loss: 2.8394\n",
      "Epoch 158/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0116Epoch 00157: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 2.0198 - val_loss: 2.8211\n",
      "Epoch 159/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9451Epoch 00158: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.9742 - val_loss: 2.8423\n",
      "Epoch 160/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9385Epoch 00159: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.9413 - val_loss: 2.8595\n",
      "Epoch 161/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0215Epoch 00160: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 2.0225 - val_loss: 2.8808\n",
      "Epoch 162/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8984Epoch 00161: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.9070 - val_loss: 2.8733\n",
      "Epoch 163/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9149Epoch 00162: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.9167 - val_loss: 2.8126\n",
      "Epoch 164/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.1000Epoch 00163: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 2.0950 - val_loss: 2.8090\n",
      "Epoch 165/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8856Epoch 00164: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.8960 - val_loss: 2.8350\n",
      "Epoch 166/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.9260Epoch 00165: val_loss improved from 2.80184 to 2.79302, saving model to cp_logs/weights.165-2.793020.hdf5\n",
      "20/20 [==============================] - 46s - loss: 1.9305 - val_loss: 2.7930\n",
      "Epoch 167/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 2.0009Epoch 00166: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.9995 - val_loss: 2.8148\n",
      "Epoch 168/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9462Epoch 00167: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.9345 - val_loss: 2.8007\n",
      "Epoch 169/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9869Epoch 00168: val_loss improved from 2.79302 to 2.78595, saving model to cp_logs/weights.168-2.785949.hdf5\n",
      "20/20 [==============================] - 54s - loss: 1.9852 - val_loss: 2.7859\n",
      "Epoch 170/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9140Epoch 00169: val_loss improved from 2.78595 to 2.76865, saving model to cp_logs/weights.169-2.768648.hdf5\n",
      "20/20 [==============================] - 50s - loss: 1.9018 - val_loss: 2.7686\n",
      "Epoch 171/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8805Epoch 00170: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.8712 - val_loss: 2.8010\n",
      "Epoch 172/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9824Epoch 00171: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.9785 - val_loss: 2.8039\n",
      "Epoch 173/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9712Epoch 00172: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.9726 - val_loss: 2.8040\n",
      "Epoch 174/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9829Epoch 00173: val_loss improved from 2.76865 to 2.75551, saving model to cp_logs/weights.173-2.755514.hdf5\n",
      "20/20 [==============================] - 49s - loss: 1.9852 - val_loss: 2.7555\n",
      "Epoch 175/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8195Epoch 00174: val_loss improved from 2.75551 to 2.73202, saving model to cp_logs/weights.174-2.732015.hdf5\n",
      "20/20 [==============================] - 54s - loss: 1.8115 - val_loss: 2.7320\n",
      "Epoch 176/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9288Epoch 00175: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.9506 - val_loss: 2.7761\n",
      "Epoch 177/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9047Epoch 00176: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.9248 - val_loss: 2.7980\n",
      "Epoch 178/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9574Epoch 00177: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.9684 - val_loss: 2.7668\n",
      "Epoch 179/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9640Epoch 00178: val_loss did not improve\n",
      "20/20 [==============================] - 48s - loss: 1.9571 - val_loss: 2.7708\n",
      "Epoch 180/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8729Epoch 00179: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.8656 - val_loss: 2.8122\n",
      "Epoch 181/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8694Epoch 00180: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.8537 - val_loss: 2.7697\n",
      "Epoch 182/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8525Epoch 00181: val_loss did not improve\n",
      "20/20 [==============================] - 56s - loss: 1.8319 - val_loss: 2.8192\n",
      "Epoch 183/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8128Epoch 00182: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.8129 - val_loss: 2.7695\n",
      "Epoch 184/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8873Epoch 00183: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.8974 - val_loss: 2.7669\n",
      "Epoch 185/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8504Epoch 00184: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.8415 - val_loss: 2.8408\n",
      "Epoch 186/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8660Epoch 00185: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.8632 - val_loss: 2.7829\n",
      "Epoch 187/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9381Epoch 00186: val_loss did not improve\n",
      "20/20 [==============================] - 48s - loss: 1.9311 - val_loss: 2.7958\n",
      "Epoch 188/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8755Epoch 00187: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.8843 - val_loss: 2.7451\n",
      "Epoch 189/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8569Epoch 00188: val_loss did not improve\n",
      "20/20 [==============================] - 47s - loss: 1.8803 - val_loss: 2.7867\n",
      "Epoch 190/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9104Epoch 00189: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.9203 - val_loss: 2.7790\n",
      "Epoch 191/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8127Epoch 00190: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.8123 - val_loss: 2.7666\n",
      "Epoch 192/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8608Epoch 00191: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.8586 - val_loss: 2.8012\n",
      "Epoch 193/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9406Epoch 00192: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.9418 - val_loss: 2.7816\n",
      "Epoch 194/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8472Epoch 00193: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.8480 - val_loss: 2.7995\n",
      "Epoch 195/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8283Epoch 00194: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.8303 - val_loss: 2.7488\n",
      "Epoch 196/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8938Epoch 00195: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.8907 - val_loss: 2.7836\n",
      "Epoch 197/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8863Epoch 00196: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.8913 - val_loss: 2.7469\n",
      "Epoch 198/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7847Epoch 00197: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.7726 - val_loss: 2.7620\n",
      "Epoch 199/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8795Epoch 00198: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.8986 - val_loss: 2.7366\n",
      "Epoch 200/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7701Epoch 00199: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.7771 - val_loss: 2.7621\n",
      "Epoch 201/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8951Epoch 00200: val_loss improved from 2.73202 to 2.72594, saving model to cp_logs/weights.200-2.725944.hdf5\n",
      "20/20 [==============================] - 50s - loss: 1.8868 - val_loss: 2.7259\n",
      "Epoch 202/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.8302Epoch 00201: val_loss did not improve\n",
      "20/20 [==============================] - 47s - loss: 1.8334 - val_loss: 2.7515\n",
      "Epoch 203/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9148Epoch 00202: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.9207 - val_loss: 2.7289\n",
      "Epoch 204/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7660Epoch 00203: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.7742 - val_loss: 2.7305\n",
      "Epoch 205/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.8105Epoch 00204: val_loss did not improve\n",
      "20/20 [==============================] - 45s - loss: 1.8097 - val_loss: 2.7290\n",
      "Epoch 206/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8670Epoch 00205: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.8646 - val_loss: 2.7542\n",
      "Epoch 207/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8592Epoch 00206: val_loss improved from 2.72594 to 2.71749, saving model to cp_logs/weights.206-2.717494.hdf5\n",
      "20/20 [==============================] - 54s - loss: 1.8513 - val_loss: 2.7175\n",
      "Epoch 208/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.9208Epoch 00207: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.8992 - val_loss: 2.7683\n",
      "Epoch 209/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8069Epoch 00208: val_loss improved from 2.71749 to 2.70994, saving model to cp_logs/weights.208-2.709942.hdf5\n",
      "20/20 [==============================] - 52s - loss: 1.8171 - val_loss: 2.7099\n",
      "Epoch 210/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.8294Epoch 00209: val_loss did not improve\n",
      "20/20 [==============================] - 43s - loss: 1.8130 - val_loss: 2.7248\n",
      "Epoch 211/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7583Epoch 00210: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.7561 - val_loss: 2.7140\n",
      "Epoch 212/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7395Epoch 00211: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.7495 - val_loss: 2.7281\n",
      "Epoch 213/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7790Epoch 00212: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.7840 - val_loss: 2.7474\n",
      "Epoch 214/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7990Epoch 00213: val_loss did not improve\n",
      "20/20 [==============================] - 48s - loss: 1.7832 - val_loss: 2.7418\n",
      "Epoch 215/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7810Epoch 00214: val_loss improved from 2.70994 to 2.68171, saving model to cp_logs/weights.214-2.681709.hdf5\n",
      "20/20 [==============================] - 54s - loss: 1.7955 - val_loss: 2.6817\n",
      "Epoch 216/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.8120Epoch 00215: val_loss improved from 2.68171 to 2.66799, saving model to cp_logs/weights.215-2.667986.hdf5\n",
      "20/20 [==============================] - 46s - loss: 1.8245 - val_loss: 2.6680\n",
      "Epoch 217/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7903Epoch 00216: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.8031 - val_loss: 2.6913\n",
      "Epoch 218/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8408Epoch 00217: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.8530 - val_loss: 2.7057\n",
      "Epoch 219/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7801Epoch 00218: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.7832 - val_loss: 2.7536\n",
      "Epoch 220/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8167Epoch 00219: val_loss did not improve\n",
      "20/20 [==============================] - 48s - loss: 1.8184 - val_loss: 2.7313\n",
      "Epoch 221/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7421Epoch 00220: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.7483 - val_loss: 2.6968\n",
      "Epoch 222/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8688Epoch 00221: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.8560 - val_loss: 2.7522\n",
      "Epoch 223/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8181Epoch 00222: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.8312 - val_loss: 2.7176\n",
      "Epoch 224/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7629Epoch 00223: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.7541 - val_loss: 2.7042\n",
      "Epoch 225/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7775Epoch 00224: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.7847 - val_loss: 2.6926\n",
      "Epoch 226/512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8292Epoch 00225: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.8157 - val_loss: 2.6732\n",
      "Epoch 227/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7325Epoch 00226: val_loss improved from 2.66799 to 2.64560, saving model to cp_logs/weights.226-2.645598.hdf5\n",
      "20/20 [==============================] - 54s - loss: 1.7298 - val_loss: 2.6456\n",
      "Epoch 228/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8379Epoch 00227: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.8419 - val_loss: 2.6749\n",
      "Epoch 229/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7378Epoch 00228: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.7358 - val_loss: 2.7047\n",
      "Epoch 230/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7846Epoch 00229: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.7994 - val_loss: 2.6868\n",
      "Epoch 231/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7291Epoch 00230: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.7296 - val_loss: 2.7131\n",
      "Epoch 232/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8244Epoch 00231: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.8336 - val_loss: 2.6758\n",
      "Epoch 233/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7059Epoch 00232: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.7157 - val_loss: 2.7039\n",
      "Epoch 234/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7427Epoch 00233: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.7399 - val_loss: 2.7647\n",
      "Epoch 235/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7474Epoch 00234: val_loss did not improve\n",
      "20/20 [==============================] - 47s - loss: 1.7498 - val_loss: 2.6752\n",
      "Epoch 236/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7886Epoch 00235: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.7783 - val_loss: 2.7030\n",
      "Epoch 237/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8005Epoch 00236: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.8085 - val_loss: 2.7008\n",
      "Epoch 238/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7589Epoch 00237: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.7454 - val_loss: 2.6995\n",
      "Epoch 239/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7149Epoch 00238: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.7249 - val_loss: 2.6979\n",
      "Epoch 240/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6898Epoch 00239: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6936 - val_loss: 2.7044\n",
      "Epoch 241/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6912Epoch 00240: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.6811 - val_loss: 2.6622\n",
      "Epoch 242/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6828Epoch 00241: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6928 - val_loss: 2.7327\n",
      "Epoch 243/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7600Epoch 00242: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.7563 - val_loss: 2.7294\n",
      "Epoch 244/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6715Epoch 00243: val_loss improved from 2.64560 to 2.64387, saving model to cp_logs/weights.243-2.643872.hdf5\n",
      "20/20 [==============================] - 50s - loss: 1.6732 - val_loss: 2.6439\n",
      "Epoch 245/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7290Epoch 00244: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.7353 - val_loss: 2.6787\n",
      "Epoch 246/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.7342Epoch 00245: val_loss did not improve\n",
      "20/20 [==============================] - 47s - loss: 1.7286 - val_loss: 2.6632\n",
      "Epoch 247/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7534Epoch 00246: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.7387 - val_loss: 2.7023\n",
      "Epoch 248/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7039Epoch 00247: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6966 - val_loss: 2.7022\n",
      "Epoch 249/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.7842Epoch 00248: val_loss did not improve\n",
      "20/20 [==============================] - 45s - loss: 1.7669 - val_loss: 2.6566\n",
      "Epoch 250/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6721Epoch 00249: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6781 - val_loss: 2.7208\n",
      "Epoch 251/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7049Epoch 00250: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.7040 - val_loss: 2.6782\n",
      "Epoch 252/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.8434Epoch 00251: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.8439 - val_loss: 2.6442\n",
      "Epoch 253/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.6586Epoch 00252: val_loss did not improve\n",
      "20/20 [==============================] - 47s - loss: 1.6649 - val_loss: 2.7135\n",
      "Epoch 254/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6693Epoch 00253: val_loss improved from 2.64387 to 2.64161, saving model to cp_logs/weights.253-2.641608.hdf5\n",
      "20/20 [==============================] - 54s - loss: 1.6844 - val_loss: 2.6416\n",
      "Epoch 255/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7415Epoch 00254: val_loss did not improve\n",
      "20/20 [==============================] - 48s - loss: 1.7289 - val_loss: 2.6620\n",
      "Epoch 256/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7352Epoch 00255: val_loss improved from 2.64161 to 2.63928, saving model to cp_logs/weights.255-2.639278.hdf5\n",
      "20/20 [==============================] - 49s - loss: 1.7280 - val_loss: 2.6393\n",
      "Epoch 257/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7702Epoch 00256: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.7693 - val_loss: 2.6415\n",
      "Epoch 258/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6736Epoch 00257: val_loss improved from 2.63928 to 2.63319, saving model to cp_logs/weights.257-2.633191.hdf5\n",
      "20/20 [==============================] - 54s - loss: 1.6729 - val_loss: 2.6332\n",
      "Epoch 259/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.6569Epoch 00258: val_loss did not improve\n",
      "20/20 [==============================] - 47s - loss: 1.6669 - val_loss: 2.6731\n",
      "Epoch 260/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7357Epoch 00259: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.7479 - val_loss: 2.6668\n",
      "Epoch 261/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7336Epoch 00260: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.7300 - val_loss: 2.6957\n",
      "Epoch 262/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7456Epoch 00261: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.7393 - val_loss: 2.6550\n",
      "Epoch 263/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6105Epoch 00262: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.6147 - val_loss: 2.7055\n",
      "Epoch 264/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7017Epoch 00263: val_loss improved from 2.63319 to 2.62733, saving model to cp_logs/weights.263-2.627334.hdf5\n",
      "20/20 [==============================] - 53s - loss: 1.7161 - val_loss: 2.6273\n",
      "Epoch 265/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6827Epoch 00264: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.6871 - val_loss: 2.6799\n",
      "Epoch 266/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7260Epoch 00265: val_loss did not improve\n",
      "20/20 [==============================] - 48s - loss: 1.7110 - val_loss: 2.6323\n",
      "Epoch 267/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7388Epoch 00266: val_loss improved from 2.62733 to 2.62325, saving model to cp_logs/weights.266-2.623248.hdf5\n",
      "20/20 [==============================] - 54s - loss: 1.7430 - val_loss: 2.6232\n",
      "Epoch 268/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6318Epoch 00267: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6245 - val_loss: 2.6584\n",
      "Epoch 269/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6533Epoch 00268: val_loss improved from 2.62325 to 2.60006, saving model to cp_logs/weights.268-2.600060.hdf5\n",
      "20/20 [==============================] - 54s - loss: 1.6523 - val_loss: 2.6001\n",
      "Epoch 270/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6241Epoch 00269: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6101 - val_loss: 2.6395\n",
      "Epoch 271/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6024Epoch 00270: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.6046 - val_loss: 2.6238\n",
      "Epoch 272/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7070Epoch 00271: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.7133 - val_loss: 2.6770\n",
      "Epoch 273/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6290Epoch 00272: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.6349 - val_loss: 2.7080\n",
      "Epoch 274/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6496Epoch 00273: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6492 - val_loss: 2.6834\n",
      "Epoch 275/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7285Epoch 00274: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.7290 - val_loss: 2.6370\n",
      "Epoch 276/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6570Epoch 00275: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.6534 - val_loss: 2.6422\n",
      "Epoch 277/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7071Epoch 00276: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.6823 - val_loss: 2.6359\n",
      "Epoch 278/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7472Epoch 00277: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.7464 - val_loss: 2.6002\n",
      "Epoch 279/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6234Epoch 00278: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.6272 - val_loss: 2.6864\n",
      "Epoch 280/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6491Epoch 00279: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6526 - val_loss: 2.6463\n",
      "Epoch 281/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7590Epoch 00280: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.7856 - val_loss: 2.6320\n",
      "Epoch 282/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6184Epoch 00281: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6115 - val_loss: 2.6962\n",
      "Epoch 283/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.6758Epoch 00282: val_loss did not improve\n",
      "20/20 [==============================] - 48s - loss: 1.6673 - val_loss: 2.6657\n",
      "Epoch 284/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7286Epoch 00283: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.7363 - val_loss: 2.6379\n",
      "Epoch 285/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6911Epoch 00284: val_loss did not improve\n",
      "20/20 [==============================] - 47s - loss: 1.6835 - val_loss: 2.6741\n",
      "Epoch 286/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5968Epoch 00285: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6199 - val_loss: 2.6367\n",
      "Epoch 287/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7144Epoch 00286: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.7095 - val_loss: 2.6410\n",
      "Epoch 288/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6004Epoch 00287: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.6018 - val_loss: 2.6649\n",
      "Epoch 289/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7225Epoch 00288: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.7117 - val_loss: 2.6607\n",
      "Epoch 290/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6435Epoch 00289: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.6478 - val_loss: 2.6709\n",
      "Epoch 291/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.7505Epoch 00290: val_loss did not improve\n",
      "20/20 [==============================] - 45s - loss: 1.7396 - val_loss: 2.6919\n",
      "Epoch 292/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6259Epoch 00291: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6240 - val_loss: 2.6415\n",
      "Epoch 293/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6189Epoch 00292: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.6240 - val_loss: 2.6353\n",
      "Epoch 294/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6987Epoch 00293: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.6912 - val_loss: 2.6433\n",
      "Epoch 295/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6961Epoch 00294: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.6982 - val_loss: 2.6104\n",
      "Epoch 296/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7165Epoch 00295: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.7066 - val_loss: 2.6024\n",
      "Epoch 297/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6425Epoch 00296: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6436 - val_loss: 2.6196\n",
      "Epoch 298/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6162Epoch 00297: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.6123 - val_loss: 2.6559\n",
      "Epoch 299/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5930Epoch 00298: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.5948 - val_loss: 2.6152\n",
      "Epoch 300/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5574Epoch 00299: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5572 - val_loss: 2.6277\n",
      "Epoch 301/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6139Epoch 00300: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6108 - val_loss: 2.6596\n",
      "Epoch 302/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6008Epoch 00301: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5979 - val_loss: 2.6937\n",
      "Epoch 303/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6349Epoch 00302: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.6335 - val_loss: 2.6739\n",
      "Epoch 304/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6604Epoch 00303: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.6577 - val_loss: 2.6171\n",
      "Epoch 305/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5914Epoch 00304: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.5922 - val_loss: 2.6541\n",
      "Epoch 306/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7161Epoch 00305: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.7206 - val_loss: 2.6313\n",
      "Epoch 307/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6493Epoch 00306: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 53s - loss: 1.6604 - val_loss: 2.6714\n",
      "Epoch 308/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6373Epoch 00307: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.6298 - val_loss: 2.6866\n",
      "Epoch 309/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6163Epoch 00308: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6143 - val_loss: 2.6422\n",
      "Epoch 310/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7365Epoch 00309: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.7387 - val_loss: 2.6522\n",
      "Epoch 311/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6506Epoch 00310: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6386 - val_loss: 2.6611\n",
      "Epoch 312/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5702Epoch 00311: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5857 - val_loss: 2.6846\n",
      "Epoch 313/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6538Epoch 00312: val_loss did not improve\n",
      "20/20 [==============================] - 47s - loss: 1.6592 - val_loss: 2.6518\n",
      "Epoch 314/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6762Epoch 00313: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.6874 - val_loss: 2.6495\n",
      "Epoch 315/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5948Epoch 00314: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6100 - val_loss: 2.6327\n",
      "Epoch 316/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6697Epoch 00315: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.6607 - val_loss: 2.6518\n",
      "Epoch 317/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5953Epoch 00316: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.5902 - val_loss: 2.6617\n",
      "Epoch 318/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6786Epoch 00317: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6811 - val_loss: 2.6648\n",
      "Epoch 319/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6117Epoch 00318: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.6185 - val_loss: 2.6513\n",
      "Epoch 320/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.7006Epoch 00319: val_loss did not improve\n",
      "20/20 [==============================] - 48s - loss: 1.6925 - val_loss: 2.6786\n",
      "Epoch 321/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6170Epoch 00320: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.6036 - val_loss: 2.6805\n",
      "Epoch 322/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6323Epoch 00321: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6308 - val_loss: 2.6881\n",
      "Epoch 323/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6503Epoch 00322: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6578 - val_loss: 2.6368\n",
      "Epoch 324/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6396Epoch 00323: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6526 - val_loss: 2.6101\n",
      "Epoch 325/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6684Epoch 00324: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.6868 - val_loss: 2.6212\n",
      "Epoch 326/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5790Epoch 00325: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5775 - val_loss: 2.6834\n",
      "Epoch 327/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6204Epoch 00326: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6354 - val_loss: 2.6409\n",
      "Epoch 328/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5317Epoch 00327: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5276 - val_loss: 2.6292\n",
      "Epoch 329/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5362Epoch 00328: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.5372 - val_loss: 2.6576\n",
      "Epoch 330/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6121Epoch 00329: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.6144 - val_loss: 2.6661\n",
      "Epoch 331/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6386Epoch 00330: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6386 - val_loss: 2.6711\n",
      "Epoch 332/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.5709Epoch 00331: val_loss did not improve\n",
      "20/20 [==============================] - 47s - loss: 1.5700 - val_loss: 2.6891\n",
      "Epoch 333/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6078Epoch 00332: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.6001 - val_loss: 2.6567\n",
      "Epoch 334/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6359Epoch 00333: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.6294 - val_loss: 2.6499\n",
      "Epoch 335/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6476Epoch 00334: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.6392 - val_loss: 2.6130\n",
      "Epoch 336/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6442Epoch 00335: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6515 - val_loss: 2.6356\n",
      "Epoch 337/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6583Epoch 00336: val_loss improved from 2.60006 to 2.59997, saving model to cp_logs/weights.336-2.599974.hdf5\n",
      "20/20 [==============================] - 54s - loss: 1.6511 - val_loss: 2.6000\n",
      "Epoch 338/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5924Epoch 00337: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5799 - val_loss: 2.6392\n",
      "Epoch 339/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6225Epoch 00338: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6459 - val_loss: 2.6259\n",
      "Epoch 340/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7254Epoch 00339: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.7030 - val_loss: 2.6462\n",
      "Epoch 341/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6084Epoch 00340: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5930 - val_loss: 2.6434\n",
      "Epoch 342/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6185Epoch 00341: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.6152 - val_loss: 2.6407\n",
      "Epoch 343/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6501Epoch 00342: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.6661 - val_loss: 2.6230\n",
      "Epoch 344/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5768Epoch 00343: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5787 - val_loss: 2.6231\n",
      "Epoch 345/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7059Epoch 00344: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6829 - val_loss: 2.6247\n",
      "Epoch 346/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5758Epoch 00345: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5656 - val_loss: 2.6454\n",
      "Epoch 347/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5946Epoch 00346: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6061 - val_loss: 2.6496\n",
      "Epoch 348/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6385Epoch 00347: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.6304 - val_loss: 2.6515\n",
      "Epoch 349/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6783Epoch 00348: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 54s - loss: 1.6761 - val_loss: 2.6182\n",
      "Epoch 350/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6560Epoch 00349: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6448 - val_loss: 2.6436\n",
      "Epoch 351/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5802Epoch 00350: val_loss did not improve\n",
      "20/20 [==============================] - 48s - loss: 1.5834 - val_loss: 2.6817\n",
      "Epoch 352/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6197Epoch 00351: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.6114 - val_loss: 2.6793\n",
      "Epoch 353/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6337Epoch 00352: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6188 - val_loss: 2.6708\n",
      "Epoch 354/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6370Epoch 00353: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6528 - val_loss: 2.6025\n",
      "Epoch 355/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6320Epoch 00354: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.6348 - val_loss: 2.6504\n",
      "Epoch 356/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5407Epoch 00355: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5404 - val_loss: 2.6272\n",
      "Epoch 357/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5737Epoch 00356: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.5634 - val_loss: 2.6230\n",
      "Epoch 358/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5176Epoch 00357: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5334 - val_loss: 2.6073\n",
      "Epoch 359/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5252Epoch 00358: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5451 - val_loss: 2.6659\n",
      "Epoch 360/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6246Epoch 00359: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6212 - val_loss: 2.6519\n",
      "Epoch 361/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5636Epoch 00360: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5603 - val_loss: 2.6528\n",
      "Epoch 362/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5752Epoch 00361: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5766 - val_loss: 2.6638\n",
      "Epoch 363/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6308Epoch 00362: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6194 - val_loss: 2.6707\n",
      "Epoch 364/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5870Epoch 00363: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5747 - val_loss: 2.6087\n",
      "Epoch 365/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6010Epoch 00364: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6064 - val_loss: 2.6458\n",
      "Epoch 366/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6734Epoch 00365: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6633 - val_loss: 2.6517\n",
      "Epoch 367/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5757Epoch 00366: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5658 - val_loss: 2.6278\n",
      "Epoch 368/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5776Epoch 00367: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5739 - val_loss: 2.6182\n",
      "Epoch 369/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.6842Epoch 00368: val_loss did not improve\n",
      "20/20 [==============================] - 48s - loss: 1.7069 - val_loss: 2.6217\n",
      "Epoch 370/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5506Epoch 00369: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.5511 - val_loss: 2.6653\n",
      "Epoch 371/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5685Epoch 00370: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5686 - val_loss: 2.6489\n",
      "Epoch 372/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6552Epoch 00371: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6563 - val_loss: 2.6220\n",
      "Epoch 373/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6204Epoch 00372: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6182 - val_loss: 2.6431\n",
      "Epoch 374/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5827Epoch 00373: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6059 - val_loss: 2.6460\n",
      "Epoch 375/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5982Epoch 00374: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6179 - val_loss: 2.6570\n",
      "Epoch 376/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5280Epoch 00375: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5311 - val_loss: 2.6788\n",
      "Epoch 377/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6500Epoch 00376: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6494 - val_loss: 2.6480\n",
      "Epoch 378/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6005Epoch 00377: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.6044 - val_loss: 2.6514\n",
      "Epoch 379/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6903Epoch 00378: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6957 - val_loss: 2.6643\n",
      "Epoch 380/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5294Epoch 00379: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5330 - val_loss: 2.6584\n",
      "Epoch 381/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5659Epoch 00380: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5929 - val_loss: 2.6812\n",
      "Epoch 382/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6180Epoch 00381: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6433 - val_loss: 2.6825\n",
      "Epoch 383/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6310Epoch 00382: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6313 - val_loss: 2.6909\n",
      "Epoch 384/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6500Epoch 00383: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6530 - val_loss: 2.6621\n",
      "Epoch 385/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5513Epoch 00384: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5615 - val_loss: 2.6862\n",
      "Epoch 386/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5391Epoch 00385: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.5465 - val_loss: 2.6985\n",
      "Epoch 387/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5586Epoch 00386: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5472 - val_loss: 2.6684\n",
      "Epoch 388/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.5361Epoch 00387: val_loss did not improve\n",
      "20/20 [==============================] - 45s - loss: 1.5135 - val_loss: 2.7020\n",
      "Epoch 389/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5940Epoch 00388: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6115 - val_loss: 2.6591\n",
      "Epoch 390/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5601Epoch 00389: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5598 - val_loss: 2.7218\n",
      "Epoch 391/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5827Epoch 00390: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.5801 - val_loss: 2.6836\n",
      "Epoch 392/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6173Epoch 00391: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6157 - val_loss: 2.6782\n",
      "Epoch 393/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5419Epoch 00392: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.5642 - val_loss: 2.6697\n",
      "Epoch 394/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6478Epoch 00393: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.6405 - val_loss: 2.6509\n",
      "Epoch 395/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6171Epoch 00394: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6309 - val_loss: 2.6941\n",
      "Epoch 396/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5671Epoch 00395: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5514 - val_loss: 2.6757\n",
      "Epoch 397/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.5973Epoch 00396: val_loss did not improve\n",
      "20/20 [==============================] - 42s - loss: 1.6031 - val_loss: 2.6744\n",
      "Epoch 398/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6745Epoch 00397: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.6621 - val_loss: 2.6691\n",
      "Epoch 399/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6014Epoch 00398: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5759 - val_loss: 2.6724\n",
      "Epoch 400/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5851Epoch 00399: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5706 - val_loss: 2.6652\n",
      "Epoch 401/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6057Epoch 00400: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5964 - val_loss: 2.6715\n",
      "Epoch 402/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.6524Epoch 00401: val_loss did not improve\n",
      "20/20 [==============================] - 47s - loss: 1.6621 - val_loss: 2.6508\n",
      "Epoch 403/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5326Epoch 00402: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5283 - val_loss: 2.6392\n",
      "Epoch 404/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6209Epoch 00403: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6253 - val_loss: 2.6501\n",
      "Epoch 405/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5231Epoch 00404: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.5339 - val_loss: 2.6566\n",
      "Epoch 406/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6362Epoch 00405: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.6312 - val_loss: 2.6416\n",
      "Epoch 407/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5595Epoch 00406: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.5743 - val_loss: 2.6545\n",
      "Epoch 408/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6821Epoch 00407: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6836 - val_loss: 2.6407\n",
      "Epoch 409/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5210Epoch 00408: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5320 - val_loss: 2.6754\n",
      "Epoch 410/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5876Epoch 00409: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5874 - val_loss: 2.6644\n",
      "Epoch 411/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6305Epoch 00410: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.6225 - val_loss: 2.6908\n",
      "Epoch 412/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.6470Epoch 00411: val_loss did not improve\n",
      "20/20 [==============================] - 47s - loss: 1.6375 - val_loss: 2.6568\n",
      "Epoch 413/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6873Epoch 00412: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6729 - val_loss: 2.6486\n",
      "Epoch 414/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5473Epoch 00413: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.5619 - val_loss: 2.6590\n",
      "Epoch 415/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5848Epoch 00414: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5721 - val_loss: 2.6650\n",
      "Epoch 416/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5309Epoch 00415: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.5254 - val_loss: 2.6851\n",
      "Epoch 417/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5305Epoch 00416: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5361 - val_loss: 2.6933\n",
      "Epoch 418/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5732Epoch 00417: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5811 - val_loss: 2.6419\n",
      "Epoch 419/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6057Epoch 00418: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.5896 - val_loss: 2.6535\n",
      "Epoch 420/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5577Epoch 00419: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5515 - val_loss: 2.6526\n",
      "Epoch 421/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5934Epoch 00420: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5903 - val_loss: 2.7106\n",
      "Epoch 422/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5913Epoch 00421: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5809 - val_loss: 2.6826\n",
      "Epoch 423/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6237Epoch 00422: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6287 - val_loss: 2.6542\n",
      "Epoch 424/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.6204Epoch 00423: val_loss did not improve\n",
      "20/20 [==============================] - 47s - loss: 1.6222 - val_loss: 2.6356\n",
      "Epoch 425/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6348Epoch 00424: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.6249 - val_loss: 2.6531\n",
      "Epoch 426/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5313Epoch 00425: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.5495 - val_loss: 2.6534\n",
      "Epoch 427/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6093Epoch 00426: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.6446 - val_loss: 2.6363\n",
      "Epoch 428/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6427Epoch 00427: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6205 - val_loss: 2.6987\n",
      "Epoch 429/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5420Epoch 00428: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5465 - val_loss: 2.6625\n",
      "Epoch 430/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6025Epoch 00429: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5893 - val_loss: 2.6720\n",
      "Epoch 431/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6428Epoch 00430: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6403 - val_loss: 2.6779\n",
      "Epoch 432/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5662Epoch 00431: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.5558 - val_loss: 2.6566\n",
      "Epoch 433/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6605Epoch 00432: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 50s - loss: 1.6463 - val_loss: 2.6741\n",
      "Epoch 434/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5740Epoch 00433: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.5621 - val_loss: 2.7166\n",
      "Epoch 435/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5771Epoch 00434: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.5797 - val_loss: 2.6679\n",
      "Epoch 436/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5896Epoch 00435: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5803 - val_loss: 2.6914\n",
      "Epoch 437/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6875Epoch 00436: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6687 - val_loss: 2.6452\n",
      "Epoch 438/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6245Epoch 00437: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.6003 - val_loss: 2.6929\n",
      "Epoch 439/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5951Epoch 00438: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5896 - val_loss: 2.7183\n",
      "Epoch 440/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6162Epoch 00439: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5993 - val_loss: 2.7054\n",
      "Epoch 441/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6452Epoch 00440: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6379 - val_loss: 2.6711\n",
      "Epoch 442/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6367Epoch 00441: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6386 - val_loss: 2.6810\n",
      "Epoch 443/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6195Epoch 00442: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6136 - val_loss: 2.7149\n",
      "Epoch 444/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5681Epoch 00443: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5625 - val_loss: 2.7220\n",
      "Epoch 445/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5536Epoch 00444: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5643 - val_loss: 2.6867\n",
      "Epoch 446/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5250Epoch 00445: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5303 - val_loss: 2.6771\n",
      "Epoch 447/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5451Epoch 00446: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5274 - val_loss: 2.6980\n",
      "Epoch 448/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6392Epoch 00447: val_loss did not improve\n",
      "20/20 [==============================] - 47s - loss: 1.6388 - val_loss: 2.7291\n",
      "Epoch 449/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5564Epoch 00448: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5522 - val_loss: 2.6949\n",
      "Epoch 450/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5861Epoch 00449: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5828 - val_loss: 2.7121\n",
      "Epoch 451/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6174Epoch 00450: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.6315 - val_loss: 2.6880\n",
      "Epoch 452/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5815Epoch 00451: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.6130 - val_loss: 2.6874\n",
      "Epoch 453/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5790Epoch 00452: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5794 - val_loss: 2.6699\n",
      "Epoch 454/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6500Epoch 00453: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.6496 - val_loss: 2.6789\n",
      "Epoch 455/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5589Epoch 00454: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5686 - val_loss: 2.6937\n",
      "Epoch 456/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5951Epoch 00455: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.5899 - val_loss: 2.6764\n",
      "Epoch 457/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.7210Epoch 00456: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.7210 - val_loss: 2.7065\n",
      "Epoch 458/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5338Epoch 00457: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5404 - val_loss: 2.7235\n",
      "Epoch 459/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5809Epoch 00458: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5849 - val_loss: 2.6817\n",
      "Epoch 460/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6400Epoch 00459: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.6408 - val_loss: 2.6788\n",
      "Epoch 461/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5873Epoch 00460: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5721 - val_loss: 2.6615\n",
      "Epoch 462/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6727Epoch 00461: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6693 - val_loss: 2.6719\n",
      "Epoch 463/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5588Epoch 00462: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5534 - val_loss: 2.7031\n",
      "Epoch 464/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5489Epoch 00463: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5364 - val_loss: 2.7009\n",
      "Epoch 465/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6420Epoch 00464: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.6417 - val_loss: 2.7147\n",
      "Epoch 466/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.6153Epoch 00465: val_loss did not improve\n",
      "20/20 [==============================] - 45s - loss: 1.6210 - val_loss: 2.6691\n",
      "Epoch 467/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6652Epoch 00466: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6640 - val_loss: 2.6861\n",
      "Epoch 468/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.4894Epoch 00467: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.4848 - val_loss: 2.6923\n",
      "Epoch 469/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6057Epoch 00468: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.6318 - val_loss: 2.6671\n",
      "Epoch 470/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5892Epoch 00469: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.6050 - val_loss: 2.6590\n",
      "Epoch 471/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.5955Epoch 00470: val_loss did not improve\n",
      "20/20 [==============================] - 47s - loss: 1.6115 - val_loss: 2.6707\n",
      "Epoch 472/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6269Epoch 00471: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.6193 - val_loss: 2.6994\n",
      "Epoch 473/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5656Epoch 00472: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5532 - val_loss: 2.6875\n",
      "Epoch 474/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5755Epoch 00473: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.5667 - val_loss: 2.6711\n",
      "Epoch 475/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.5178Epoch 00474: val_loss did not improve\n",
      "20/20 [==============================] - 46s - loss: 1.5015 - val_loss: 2.6849\n",
      "Epoch 476/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5238Epoch 00475: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5272 - val_loss: 2.6734\n",
      "Epoch 477/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.6236Epoch 00476: val_loss did not improve\n",
      "20/20 [==============================] - 46s - loss: 1.6289 - val_loss: 2.6891\n",
      "Epoch 478/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5453Epoch 00477: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5356 - val_loss: 2.6850\n",
      "Epoch 479/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5895Epoch 00478: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.5834 - val_loss: 2.6434\n",
      "Epoch 480/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6032Epoch 00479: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6016 - val_loss: 2.6927\n",
      "Epoch 481/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5526Epoch 00480: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.5585 - val_loss: 2.6757\n",
      "Epoch 482/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5768Epoch 00481: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5986 - val_loss: 2.6846\n",
      "Epoch 483/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6220Epoch 00482: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6263 - val_loss: 2.6862\n",
      "Epoch 484/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5211Epoch 00483: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.5190 - val_loss: 2.6944\n",
      "Epoch 485/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5964Epoch 00484: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5910 - val_loss: 2.6926\n",
      "Epoch 486/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.6560Epoch 00485: val_loss did not improve\n",
      "20/20 [==============================] - 48s - loss: 1.6587 - val_loss: 2.6567\n",
      "Epoch 487/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5770Epoch 00486: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5746 - val_loss: 2.7014\n",
      "Epoch 488/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5638Epoch 00487: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5643 - val_loss: 2.6551\n",
      "Epoch 489/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5929Epoch 00488: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5926 - val_loss: 2.6835\n",
      "Epoch 490/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6555Epoch 00489: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.6502 - val_loss: 2.6906\n",
      "Epoch 491/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5109Epoch 00490: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.4984 - val_loss: 2.6780\n",
      "Epoch 492/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6231Epoch 00491: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.6356 - val_loss: 2.6519\n",
      "Epoch 493/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.4894Epoch 00492: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.4930 - val_loss: 2.6769\n",
      "Epoch 494/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6158Epoch 00493: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6120 - val_loss: 2.6443\n",
      "Epoch 495/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5640Epoch 00494: val_loss did not improve\n",
      "20/20 [==============================] - 48s - loss: 1.5686 - val_loss: 2.6496\n",
      "Epoch 496/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6515Epoch 00495: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6567 - val_loss: 2.6270\n",
      "Epoch 497/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.4972Epoch 00496: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5037 - val_loss: 2.6704\n",
      "Epoch 498/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5517Epoch 00497: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5523 - val_loss: 2.6603\n",
      "Epoch 499/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6251Epoch 00498: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6217 - val_loss: 2.6732\n",
      "Epoch 500/512\n",
      "19/20 [===========================>..] - ETA: 1s - loss: 1.5841Epoch 00499: val_loss did not improve\n",
      "20/20 [==============================] - 47s - loss: 1.5772 - val_loss: 2.6585\n",
      "Epoch 501/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.6490Epoch 00500: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6312 - val_loss: 2.6659\n",
      "Epoch 502/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5527Epoch 00501: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.5647 - val_loss: 2.6637\n",
      "Epoch 503/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5288Epoch 00502: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5106 - val_loss: 2.6494\n",
      "Epoch 504/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5268Epoch 00503: val_loss did not improve\n",
      "20/20 [==============================] - 49s - loss: 1.5212 - val_loss: 2.6217\n",
      "Epoch 505/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.4680Epoch 00504: val_loss did not improve\n",
      "20/20 [==============================] - 51s - loss: 1.4803 - val_loss: 2.6636\n",
      "Epoch 506/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5345Epoch 00505: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5351 - val_loss: 2.6356\n",
      "Epoch 507/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5397Epoch 00506: val_loss did not improve\n",
      "20/20 [==============================] - 52s - loss: 1.5300 - val_loss: 2.6582\n",
      "Epoch 508/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5493Epoch 00507: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5665 - val_loss: 2.6441\n",
      "Epoch 509/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5282Epoch 00508: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.5404 - val_loss: 2.6661\n",
      "Epoch 510/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5268Epoch 00509: val_loss did not improve\n",
      "20/20 [==============================] - 50s - loss: 1.5375 - val_loss: 2.6737\n",
      "Epoch 511/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5915Epoch 00510: val_loss did not improve\n",
      "20/20 [==============================] - 53s - loss: 1.6095 - val_loss: 2.6539\n",
      "Epoch 512/512\n",
      "19/20 [===========================>..] - ETA: 2s - loss: 1.5828Epoch 00511: val_loss did not improve\n",
      "20/20 [==============================] - 54s - loss: 1.5883 - val_loss: 2.6889\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(gen_train_all, \n",
    "                              steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                              epochs=NUM_EPOCHS, \n",
    "                              verbose=1,\n",
    "                              callbacks=[checkpoint, tensorboard],\n",
    "                              validation_data=gen_test, \n",
    "                              validation_steps=TEST_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 1s     \n"
     ]
    }
   ],
   "source": [
    "filename = 'cp_logs/weights.336-2.599974.hdf5'\n",
    "model.load_weights(filename)\n",
    "\n",
    "result = np.argmax(model.predict([x_test, tf_test], batch_size=BATCH_SIZE, verbose=1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1 Accuracy: \t\t0.600000\n",
      "E2 Accuracy: \t\t0.653165\n",
      "En Accuracy: \t\t0.362025\n",
      "Triple Accuracy: \t0.278481\n"
     ]
    }
   ],
   "source": [
    "preResult = [[index2word[i] for i in sent if i != 0] for sent in result]\n",
    "actResult = [[index2word[i] for i in sent if i != 0] for sent in y_test]\n",
    "e1Count = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0]])\n",
    "e2Count = sum([1 for i in range(395) if actResult[i][1] == preResult[i][1]])\n",
    "enCount = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0] and actResult[i][1] == preResult[i][1]])\n",
    "tripleCount = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0] and actResult[i][1] == preResult[i][1] and actResult[i][2] == preResult[i][2]])\n",
    "print('E1 Accuracy: \\t\\t%.6f' % (e1Count/395))\n",
    "print('E2 Accuracy: \\t\\t%.6f' % (e2Count/395))\n",
    "print('En Accuracy: \\t\\t%.6f' % (enCount/395))\n",
    "print('Triple Accuracy: \\t%.6f' % (tripleCount/395))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: \teurope italy /location/country/administrative_divisions\n",
      "Ground-Truth: \tspain italy /location/administrative_division/country\n",
      "---\n",
      "Predict: \twestchester connecticut /location/location/contains\n",
      "Ground-Truth: \twestchester connecticut /location/administrative_division/country\n",
      "---\n",
      "Predict: \tariel israel /people/person/nationality\n",
      "Ground-Truth: \tdalia israel /people/person/nationality\n",
      "---\n",
      "Predict: \tbangalore bihar /location/location/contains\n",
      "Ground-Truth: \thyderabad potti /location/location/contains\n",
      "---\n",
      "Predict: \telizabeth north /people/person/place_lived\n",
      "Ground-Truth: \tkent north /people/person/place_lived\n",
      "---\n",
      "Predict: \tontario waterloo /location/location/contains\n",
      "Ground-Truth: \tontario waterloo /location/location/contains\n",
      "---\n",
      "Predict: \tbaltimore american /business/company/founders\n",
      "Ground-Truth: \tblackstone stephen /business/company/founders\n",
      "---\n",
      "Predict: \teurope italy /location/country/administrative_divisions\n",
      "Ground-Truth: \tfrance italy /location/administrative_division/country\n",
      "---\n",
      "Predict: \teurope russia /location/administrative_division/country\n",
      "Ground-Truth: \tiran russia /location/administrative_division/country\n",
      "---\n",
      "Predict: \tfrance paris /location/country/administrative_divisions\n",
      "Ground-Truth: \tfrance paris /location/location/contains\n",
      "---\n",
      "Predict: \tgeorge abc /business/person/company\n",
      "Ground-Truth: \tgeorge abc /business/person/company\n",
      "---\n",
      "Predict: \tflorida jacksonville /location/location/contains\n",
      "Ground-Truth: \tflorida jacksonville /location/location/contains\n",
      "---\n",
      "Predict: \tnigeria nigeria /location/location/contains\n",
      "Ground-Truth: \tnigeria uyo /location/location/contains\n",
      "---\n",
      "Predict: \tsusan rhode /people/person/place_lived\n",
      "Ground-Truth: \tsheldon rhode /people/person/place_lived\n",
      "---\n",
      "Predict: \tlong hempstead /people/person/place_lived\n",
      "Ground-Truth: \tpatrick huntington /people/person/place_lived\n",
      "---\n",
      "Predict: \tberlin germany /location/administrative_division/country\n",
      "Ground-Truth: \tberlin germany /location/administrative_division/country\n",
      "---\n",
      "Predict: \tbruce lazard /business/person/company\n",
      "Ground-Truth: \tjeffrey lazard /business/person/company\n",
      "---\n",
      "Predict: \tmiddle israel /location/administrative_division/country\n",
      "Ground-Truth: \tgaza israel /location/administrative_division/country\n",
      "---\n",
      "Predict: \tseoul south /location/administrative_division/country\n",
      "Ground-Truth: \tseoul south /location/administrative_division/country\n",
      "---\n",
      "Predict: \tmichael york /business/person/company\n",
      "Ground-Truth: \tmark york /business/person/company\n",
      "---\n",
      "Predict: \tbihar australia /people/person/nationality\n",
      "Ground-Truth: \tmarkus australia /people/person/nationality\n",
      "---\n",
      "Predict: \talan princeton /business/person/company\n",
      "Ground-Truth: \tkwame princeton /business/person/company\n",
      "---\n",
      "Predict: \tjack john /business/company/founders\n",
      "Ground-Truth: \tendemol john /business/company/founders\n",
      "---\n",
      "Predict: \ttom minnesota /people/person/place_lived\n",
      "Ground-Truth: \ttim minnesota /people/person/place_lived\n",
      "---\n",
      "Predict: \tconnecticut haven /location/location/contains\n",
      "Ground-Truth: \tconnecticut haven /location/location/contains\n",
      "---\n",
      "Predict: \teurope russia /location/administrative_division/country\n",
      "Ground-Truth: \tiran russia /location/administrative_division/country\n",
      "---\n",
      "Predict: \tbihar india /location/administrative_division/country\n",
      "Ground-Truth: \tbihar india /location/administrative_division/country\n",
      "---\n",
      "Predict: \tbob bihar /people/person/place_lived\n",
      "Ground-Truth: \tbill dawsonville /people/person/place_lived\n",
      "---\n",
      "Predict: \tdavid university /business/person/company\n",
      "Ground-Truth: \tdaniel university /business/person/company\n",
      "---\n",
      "Predict: \tchechnya russia /people/person/nationality\n",
      "Ground-Truth: \tsoviet russia /location/administrative_division/country\n",
      "---\n",
      "Predict: \tboston fenway /location/location/contains\n",
      "Ground-Truth: \tboston wbz-tv /location/location/contains\n",
      "---\n",
      "Predict: \tehud israel /people/person/nationality\n",
      "Ground-Truth: \tehud israel /people/person/nationality\n",
      "---\n",
      "Predict: \tvirginia united /location/location/contains\n",
      "Ground-Truth: \tvirginia united /location/administrative_division/country\n",
      "---\n",
      "Predict: \tbenjamin general /business/person/company\n",
      "Ground-Truth: \tira system /business/person/company\n",
      "---\n",
      "Predict: \tcuba cuba /location/location/contains\n",
      "Ground-Truth: \tcuba guantanamo /location/location/contains\n",
      "---\n",
      "Predict: \tmichael york /people/person/place_lived\n",
      "Ground-Truth: \tanthony york /business/person/company\n",
      "---\n",
      "Predict: \teric google /business/person/company\n",
      "Ground-Truth: \tchad google /business/person/company\n",
      "---\n",
      "Predict: \twashington mount /location/location/contains\n",
      "Ground-Truth: \twashington bainbridge /location/location/contains\n",
      "---\n",
      "Predict: \twashington capitol /location/location/contains\n",
      "Ground-Truth: \twashington olympia /location/location/contains\n",
      "---\n",
      "Predict: \tsouth seoul /location/country/administrative_divisions\n",
      "Ground-Truth: \tsouth seoul /location/location/contains\n",
      "---\n",
      "Predict: \teurope spain /location/country/administrative_divisions\n",
      "Ground-Truth: \tfrance spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \tchuck nebraska /people/person/place_lived\n",
      "Ground-Truth: \tchuck nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \teurope italy /location/country/administrative_divisions\n",
      "Ground-Truth: \tfrance italy /location/administrative_division/country\n",
      "---\n",
      "Predict: \tsyria syria /location/location/contains\n",
      "Ground-Truth: \tiran syria /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcolorado colorado /people/person/place_lived\n",
      "Ground-Truth: \tkellen colorado /people/person/place_of_birth\n",
      "---\n",
      "Predict: \tjacques france /people/person/nationality\n",
      "Ground-Truth: \ttony france /people/person/nationality\n",
      "---\n",
      "Predict: \tcarlos spain /people/person/nationality\n",
      "Ground-Truth: \tjose spain /people/person/nationality\n",
      "---\n",
      "Predict: \teurope italy /location/country/administrative_divisions\n",
      "Ground-Truth: \tfrance italy /location/administrative_division/country\n",
      "---\n",
      "Predict: \tchuck nebraska /people/person/place_lived\n",
      "Ground-Truth: \tchuck nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tyork staten /location/location/contains\n",
      "Ground-Truth: \tyork staten /location/location/contains\n",
      "---\n",
      "Predict: \tchuck nebraska /people/person/place_lived\n",
      "Ground-Truth: \tchuck nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tmiddle israel /location/administrative_division/country\n",
      "Ground-Truth: \tgaza israel /location/administrative_division/country\n",
      "---\n",
      "Predict: \th. wal-mart /business/person/company\n",
      "Ground-Truth: \tralph at&t /business/person/company\n",
      "---\n",
      "Predict: \tconnecticut haven /location/location/contains\n",
      "Ground-Truth: \tconnecticut haven /location/location/contains\n",
      "---\n",
      "Predict: \tsudan basra /location/country/administrative_divisions\n",
      "Ground-Truth: \tsomalia puntland /location/location/contains\n",
      "---\n",
      "Predict: \triga latvia /location/administrative_division/country\n",
      "Ground-Truth: \triga latvia /location/administrative_division/country\n",
      "---\n",
      "Predict: \tswitzerland davos /location/location/contains\n",
      "Ground-Truth: \tswitzerland davos /location/location/contains\n",
      "---\n",
      "Predict: \tcolorado lake /location/location/contains\n",
      "Ground-Truth: \tcolorado vail /location/location/contains\n",
      "---\n",
      "Predict: \tparis france /location/administrative_division/country\n",
      "Ground-Truth: \tparis france /location/administrative_division/country\n",
      "---\n",
      "Predict: \thudson hudson /location/location/contains\n",
      "Ground-Truth: \tlower hudson /location/location/contains\n",
      "---\n",
      "Predict: \tsan north /location/location/contains\n",
      "Ground-Truth: \tsan north /location/location/contains\n",
      "---\n",
      "Predict: \tnassau suffolk /location/location/contains\n",
      "Ground-Truth: \tnassau suffolk /location/administrative_division/country\n",
      "---\n",
      "Predict: \teric google /business/person/company\n",
      "Ground-Truth: \tchad youtube /business/person/company\n",
      "---\n",
      "Predict: \twestchester upper /location/location/contains\n",
      "Ground-Truth: \twestchester kensico /location/location/contains\n",
      "---\n",
      "Predict: \tben nebraska /people/person/place_lived\n",
      "Ground-Truth: \tben nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \titaly florence /location/location/contains\n",
      "Ground-Truth: \titaly orvieto /location/location/contains\n",
      "---\n",
      "Predict: \tmonmouth vanderbilt /location/location/contains\n",
      "Ground-Truth: \tgreenville furman /location/location/contains\n",
      "---\n",
      "Predict: \tpaul princeton /business/person/company\n",
      "Ground-Truth: \tcharles princeton /business/person/company\n",
      "---\n",
      "Predict: \tcanada ontario /location/country/administrative_divisions\n",
      "Ground-Truth: \tcanada ontario /location/location/contains\n",
      "---\n",
      "Predict: \tflorida boca /location/location/contains\n",
      "Ground-Truth: \tflorida boca /location/location/contains\n",
      "---\n",
      "Predict: \tmiddle israel /location/administrative_division/country\n",
      "Ground-Truth: \tgaza israel /location/administrative_division/country\n",
      "---\n",
      "Predict: \tbaltimore john /location/location/contains\n",
      "Ground-Truth: \tbaltimore john /location/location/contains\n",
      "---\n",
      "Predict: \tbihar india /people/person/nationality\n",
      "Ground-Truth: \tsamantha india /people/person/place_lived\n",
      "---\n",
      "Predict: \tdavid lazard /business/person/company\n",
      "Ground-Truth: \tdavid digitas /business/person/company\n",
      "---\n",
      "Predict: \tjim iowa /people/person/place_lived\n",
      "Ground-Truth: \ttom iowa /people/person/place_lived\n",
      "---\n",
      "Predict: \trafik lebanon /people/person/nationality\n",
      "Ground-Truth: \trafik lebanon /people/person/nationality\n",
      "---\n",
      "Predict: \tnigeria nigeria /people/person/nationality\n",
      "Ground-Truth: \tatiku nigeria /people/person/nationality\n",
      "---\n",
      "Predict: \twestchester scarsdale /location/location/contains\n",
      "Ground-Truth: \twestchester mamaroneck /location/location/contains\n",
      "---\n",
      "Predict: \tflorida miami /location/location/contains\n",
      "Ground-Truth: \tflorida panama /location/location/contains\n",
      "---\n",
      "Predict: \tiran north /location/location/contains\n",
      "Ground-Truth: \tiran north /location/administrative_division/country\n",
      "---\n",
      "Predict: \tfrance paris /location/country/administrative_divisions\n",
      "Ground-Truth: \tfrance paris /location/location/contains\n",
      "---\n",
      "Predict: \teurope spain /location/country/administrative_divisions\n",
      "Ground-Truth: \tfrance spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \tkansa kansa /location/location/contains\n",
      "Ground-Truth: \tclarkstown city /location/location/contains\n",
      "---\n",
      "Predict: \tindia mumbai /location/country/administrative_divisions\n",
      "Ground-Truth: \tindia delhi /location/location/contains\n",
      "---\n",
      "Predict: \ttrent mississippi /people/person/place_lived\n",
      "Ground-Truth: \thaley mississippi /people/person/place_lived\n",
      "---\n",
      "Predict: \tflorida boca /location/location/contains\n",
      "Ground-Truth: \tflorida boca /location/location/contains\n",
      "---\n",
      "Predict: \tmartin national /business/person/company\n",
      "Ground-Truth: \tgordon continental /business/person/company\n",
      "---\n",
      "Predict: \tparis france /location/administrative_division/country\n",
      "Ground-Truth: \tparis france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcalifornia long /location/location/contains\n",
      "Ground-Truth: \tcalifornia long /location/location/contains\n",
      "---\n",
      "Predict: \tfrance strasbourg /location/country/administrative_divisions\n",
      "Ground-Truth: \tfrance correze /location/location/contains\n",
      "---\n",
      "Predict: \tfairfield waterloo /location/location/contains\n",
      "Ground-Truth: \tfairfax westfield /location/location/contains\n",
      "---\n",
      "Predict: \tmiddle israel /location/administrative_division/country\n",
      "Ground-Truth: \tgaza israel /location/administrative_division/country\n",
      "---\n",
      "Predict: \tspain barcelona /location/location/contains\n",
      "Ground-Truth: \tspain valencia /location/location/contains\n",
      "---\n",
      "Predict: \tchuck nebraska /people/person/place_lived\n",
      "Ground-Truth: \tchuck nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tmanhattan franklin /location/location/contains\n",
      "Ground-Truth: \tgreenwich jefferson /location/location/contains\n",
      "---\n",
      "Predict: \tisrael west /location/location/contains\n",
      "Ground-Truth: \tisrael west /location/administrative_division/country\n",
      "---\n",
      "Predict: \tjacques france /people/person/nationality\n",
      "Ground-Truth: \tjacques france /people/person/nationality\n",
      "---\n",
      "Predict: \tbergen toledo /location/location/contains\n",
      "Ground-Truth: \tmahwah ramapo /location/location/contains\n",
      "---\n",
      "Predict: \tzimbabwe windsor /location/location/contains\n",
      "Ground-Truth: \tguyana linden /location/location/contains\n",
      "---\n",
      "Predict: \tindia bangalore /location/country/administrative_divisions\n",
      "Ground-Truth: \tindia punjab /location/location/contains\n",
      "---\n",
      "Predict: \tontario waterloo /location/location/contains\n",
      "Ground-Truth: \tontario tobermory /location/location/contains\n",
      "---\n",
      "Predict: \tmiddle iran /location/location/contains\n",
      "Ground-Truth: \tmiddle iran /location/location/contains\n",
      "---\n",
      "Predict: \tcuba cuba /location/location/contains\n",
      "Ground-Truth: \tcuba guantanamo /location/location/contains\n",
      "---\n",
      "Predict: \teurope israel /location/location/contains\n",
      "Ground-Truth: \titaly israel /location/administrative_division/country\n",
      "---\n",
      "Predict: \teurope spain /location/country/administrative_divisions\n",
      "Ground-Truth: \tgermany spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \teric google /business/person/company\n",
      "Ground-Truth: \tchad google /business/person/company\n",
      "---\n",
      "Predict: \tehud israel /people/person/nationality\n",
      "Ground-Truth: \tehud israel /people/person/nationality\n",
      "---\n",
      "Predict: \tben minnesota /people/person/place_lived\n",
      "Ground-Truth: \tamy minnesota /people/person/place_lived\n",
      "---\n",
      "Predict: \tjohn australia /people/person/nationality\n",
      "Ground-Truth: \tjohn australia /people/person/nationality\n",
      "---\n",
      "Predict: \tmitch kentucky /people/person/place_lived\n",
      "Ground-Truth: \ternie kentucky /people/person/place_lived\n",
      "---\n",
      "Predict: \tiran north /location/location/contains\n",
      "Ground-Truth: \tiran north /location/administrative_division/country\n",
      "---\n",
      "Predict: \tindia bihar /location/country/administrative_divisions\n",
      "Ground-Truth: \tindia bihar /location/country/administrative_divisions\n",
      "---\n",
      "Predict: \tireland kentucky /location/location/contains\n",
      "Ground-Truth: \tireland county /location/location/contains\n",
      "---\n",
      "Predict: \thavana cuba /location/administrative_division/country\n",
      "Ground-Truth: \thavana cuba /location/administrative_division/country\n",
      "---\n",
      "Predict: \titaly florence /location/country/administrative_divisions\n",
      "Ground-Truth: \titaly umbria /location/location/contains\n",
      "---\n",
      "Predict: \ttuscany italy /location/administrative_division/country\n",
      "Ground-Truth: \tcampania italy /location/administrative_division/country\n",
      "---\n",
      "Predict: \tiran middle /location/location/contains\n",
      "Ground-Truth: \tiran middle /location/administrative_division/country\n",
      "---\n",
      "Predict: \tflorida boca /location/location/contains\n",
      "Ground-Truth: \tflorida boca /location/location/contains\n",
      "---\n",
      "Predict: \teurope spain /location/country/administrative_divisions\n",
      "Ground-Truth: \tgermany spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \tparis france /location/administrative_division/country\n",
      "Ground-Truth: \tparis france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcleveland canton /location/location/contains\n",
      "Ground-Truth: \tcleveland karamu /location/location/contains\n",
      "---\n",
      "Predict: \tireland kentucky /location/location/contains\n",
      "Ground-Truth: \tireland county /location/location/contains\n",
      "---\n",
      "Predict: \tcalifornia san /location/location/contains\n",
      "Ground-Truth: \tcalifornia san /location/location/contains\n",
      "---\n",
      "Predict: \tfrance lake /location/location/contains\n",
      "Ground-Truth: \tfrance albertville /location/location/contains\n",
      "---\n",
      "Predict: \tcroatia haditha /location/location/contains\n",
      "Ground-Truth: \tbosnia srebrenica /location/location/contains\n",
      "---\n",
      "Predict: \tfort fort /location/location/contains\n",
      "Ground-Truth: \tupper fort /location/location/contains\n",
      "---\n",
      "Predict: \tfrance verona /location/location/contains\n",
      "Ground-Truth: \tfrance valence /location/location/contains\n",
      "---\n",
      "Predict: \tjohn tampa /people/person/place_lived\n",
      "Ground-Truth: \tjames tampa /people/person/place_lived\n",
      "---\n",
      "Predict: \tsyria damascus /location/country/administrative_divisions\n",
      "Ground-Truth: \tsyria damascus /location/country/administrative_divisions\n",
      "---\n",
      "Predict: \talan bridgeport /people/person/place_lived\n",
      "Ground-Truth: \tmarshall fremont /people/deceased_person/place_of_death\n",
      "---\n",
      "Predict: \tisrael east /location/location/contains\n",
      "Ground-Truth: \tisrael jerusalem /location/location/contains\n",
      "---\n",
      "Predict: \tsyria syria /location/country/administrative_divisions\n",
      "Ground-Truth: \tiran syria /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcambridge bard /location/location/contains\n",
      "Ground-Truth: \tcambridge lesley /location/location/contains\n",
      "---\n",
      "Predict: \talexander australia /people/person/nationality\n",
      "Ground-Truth: \tchris australia /people/person/nationality\n",
      "---\n",
      "Predict: \tjeff hollywood /business/person/company\n",
      "Ground-Truth: \tdennis disney /business/person/company\n",
      "---\n",
      "Predict: \tcolorado park /location/location/contains\n",
      "Ground-Truth: \tcolorado aspen /location/location/contains\n",
      "---\n",
      "Predict: \tsouth seoul /location/country/administrative_divisions\n",
      "Ground-Truth: \tsouth seoul /location/location/contains\n",
      "---\n",
      "Predict: \tstaten fort /location/location/contains\n",
      "Ground-Truth: \tstaten fort /location/location/contains\n",
      "---\n",
      "Predict: \tdamascus syria /location/administrative_division/country\n",
      "Ground-Truth: \tdamascus syria /location/administrative_division/country\n",
      "---\n",
      "Predict: \tmexico mexico /location/country/administrative_divisions\n",
      "Ground-Truth: \tmexico mexico /location/administrative_division/country\n",
      "---\n",
      "Predict: \tjacques france /people/person/nationality\n",
      "Ground-Truth: \tjean-louis france /people/person/nationality\n",
      "---\n",
      "Predict: \tfrance strasbourg /location/location/contains\n",
      "Ground-Truth: \tfrance toulouse /location/location/contains\n",
      "---\n",
      "Predict: \tjim kentucky /people/person/place_lived\n",
      "Ground-Truth: \tjim kentucky /people/person/place_lived\n",
      "---\n",
      "Predict: \tberlin germany /location/administrative_division/country\n",
      "Ground-Truth: \tberlin germany /location/administrative_division/country\n",
      "---\n",
      "Predict: \tisrael lebanon /location/location/contains\n",
      "Ground-Truth: \tisrael lebanon /location/administrative_division/country\n",
      "---\n",
      "Predict: \tbruce lazard /business/person/company\n",
      "Ground-Truth: \tbrett priceline /business/person/company\n",
      "---\n",
      "Predict: \tnewark jersey /location/location/contains\n",
      "Ground-Truth: \tnewark jersey /location/location/contains\n",
      "---\n",
      "Predict: \tpeter columbia /business/person/company\n",
      "Ground-Truth: \tpeter columbia /business/person/company\n",
      "---\n",
      "Predict: \tst louvre /location/location/contains\n",
      "Ground-Truth: \tleningrad vaganova /location/location/contains\n",
      "---\n",
      "Predict: \tmexico santa /location/location/contains\n",
      "Ground-Truth: \tmexico jalisco /location/country/administrative_divisions\n",
      "---\n",
      "Predict: \twestchester mamaroneck /location/location/contains\n",
      "Ground-Truth: \twestchester mamaroneck /location/location/contains\n",
      "---\n",
      "Predict: \tmiddle iran /location/administrative_division/country\n",
      "Ground-Truth: \tsyria iran /location/administrative_division/country\n",
      "---\n",
      "Predict: \tbihar nottingham /people/person/place_of_birth\n",
      "Ground-Truth: \tbrittany seminole /people/person/place_lived\n",
      "---\n",
      "Predict: \tmexico mexico /location/country/administrative_divisions\n",
      "Ground-Truth: \tmexico mexico /location/administrative_division/country\n",
      "---\n",
      "Predict: \tgermany munich /location/location/contains\n",
      "Ground-Truth: \tgermany munich /location/location/contains\n",
      "---\n",
      "Predict: \tswitzerland davos /people/deceased_person/place_of_death\n",
      "Ground-Truth: \ternst davos /people/deceased_person/place_of_death\n",
      "---\n",
      "Predict: \tcuba cuba /location/location/contains\n",
      "Ground-Truth: \tcuba guantanamo /location/location/contains\n",
      "---\n",
      "Predict: \thavana cuba /location/administrative_division/country\n",
      "Ground-Truth: \thavana cuba /location/administrative_division/country\n",
      "---\n",
      "Predict: \tgermany stuttgart /location/location/contains\n",
      "Ground-Truth: \tgermany stuttgart /location/location/contains\n",
      "---\n",
      "Predict: \tjeffrey general /business/person/company\n",
      "Ground-Truth: \tjeffrey general /business/person/company\n",
      "---\n",
      "Predict: \tpoland poland /location/location/contains\n",
      "Ground-Truth: \tpoland cracow /location/location/contains\n",
      "---\n",
      "Predict: \tjeff minnesota /people/person/place_lived\n",
      "Ground-Truth: \tnorm minnesota /people/person/place_lived\n",
      "---\n",
      "Predict: \tsouth iowa /location/location/contains\n",
      "Ground-Truth: \tsouth iowa /location/administrative_division/country\n",
      "---\n",
      "Predict: \tseoul south /location/administrative_division/country\n",
      "Ground-Truth: \tseoul south /location/administrative_division/country\n",
      "---\n",
      "Predict: \tfrance paris /location/country/administrative_divisions\n",
      "Ground-Truth: \tfrance paris /location/location/contains\n",
      "---\n",
      "Predict: \tfrance paris /location/country/administrative_divisions\n",
      "Ground-Truth: \tfrance paris /location/location/contains\n",
      "---\n",
      "Predict: \tjordan abu /people/person/place_lived\n",
      "Ground-Truth: \tjordan amman /location/location/contains\n",
      "---\n",
      "Predict: \trobert robert /business/company/founders\n",
      "Ground-Truth: \tblack robert /business/company/founders\n",
      "---\n",
      "Predict: \tarkansas boise /location/location/contains\n",
      "Ground-Truth: \tarkansas arkadelphia /location/location/contains\n",
      "---\n",
      "Predict: \tbihar spain /location/administrative_division/country\n",
      "Ground-Truth: \tnavarre spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \ttoronto canada /location/administrative_division/country\n",
      "Ground-Truth: \ttoronto canada /location/administrative_division/country\n",
      "---\n",
      "Predict: \tvalhalla york /location/location/contains\n",
      "Ground-Truth: \tconey york /location/location/contains\n",
      "---\n",
      "Predict: \tport roslyn /location/location/contains\n",
      "Ground-Truth: \tport harborside /location/location/contains\n",
      "---\n",
      "Predict: \tjim iowa /people/person/place_lived\n",
      "Ground-Truth: \ttom iowa /people/person/place_lived\n",
      "---\n",
      "Predict: \tmiddle israel /location/administrative_division/country\n",
      "Ground-Truth: \tgaza israel /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcalifornia hudson /location/location/contains\n",
      "Ground-Truth: \tcalifornia lawrence /location/location/contains\n",
      "---\n",
      "Predict: \tparis france /location/administrative_division/country\n",
      "Ground-Truth: \tparis france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tmexico cancun /location/location/contains\n",
      "Ground-Truth: \tmexico guadalajara /location/location/contains\n",
      "---\n",
      "Predict: \tvalhalla york /location/location/contains\n",
      "Ground-Truth: \tlower york /location/neighborhood/neighborhood_of\n",
      "---\n",
      "Predict: \teurope italy /location/country/administrative_divisions\n",
      "Ground-Truth: \tfrance italy /location/administrative_division/country\n",
      "---\n",
      "Predict: \torange sonoma /location/location/contains\n",
      "Ground-Truth: \tsonoma occidental /location/location/contains\n",
      "---\n",
      "Predict: \tchristopher bank /business/person/company\n",
      "Ground-Truth: \tchristopher security /business/person/company\n",
      "---\n",
      "Predict: \tindia bangalore /location/location/contains\n",
      "Ground-Truth: \tindia hyderabad /location/location/contains\n",
      "---\n",
      "Predict: \tmitch kentucky /people/person/place_lived\n",
      "Ground-Truth: \tmitch kentucky /people/person/place_lived\n",
      "---\n",
      "Predict: \tben nebraska /people/person/place_lived\n",
      "Ground-Truth: \tben nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tjeff wisconsin /people/person/place_lived\n",
      "Ground-Truth: \ttommy wisconsin /people/person/place_lived\n",
      "---\n",
      "Predict: \tbangkok thailand /location/administrative_division/country\n",
      "Ground-Truth: \tbangkok thailand /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcalifornia santa /location/location/contains\n",
      "Ground-Truth: \tcalifornia malibu /location/location/contains\n",
      "---\n",
      "Predict: \tbihar berkeley /people/person/place_lived\n",
      "Ground-Truth: \tayelet berkeley /people/person/place_lived\n",
      "---\n",
      "Predict: \tcuba cuba /location/location/contains\n",
      "Ground-Truth: \tcuba guantanamo /location/location/contains\n",
      "---\n",
      "Predict: \tsam kansa /people/person/place_lived\n",
      "Ground-Truth: \tkathleen kansa /people/person/place_lived\n",
      "---\n",
      "Predict: \tyork greenwich /location/location/contains\n",
      "Ground-Truth: \tyork greenwich /location/location/contains\n",
      "---\n",
      "Predict: \tmitch kentucky /people/person/place_lived\n",
      "Ground-Truth: \tmitch kentucky /people/person/place_lived\n",
      "---\n",
      "Predict: \tisrael west /location/location/contains\n",
      "Ground-Truth: \tisrael west /location/administrative_division/country\n",
      "---\n",
      "Predict: \tmount kenya /location/administrative_division/country\n",
      "Ground-Truth: \tmount tanzania /location/administrative_division/country\n",
      "---\n",
      "Predict: \tisrael lebanon /location/location/contains\n",
      "Ground-Truth: \tisrael lebanon /location/administrative_division/country\n",
      "---\n",
      "Predict: \tireland bihar /location/location/contains\n",
      "Ground-Truth: \tireland athenry /location/location/contains\n",
      "---\n",
      "Predict: \teurope russia /location/administrative_division/country\n",
      "Ground-Truth: \tiran russia /location/administrative_division/country\n",
      "---\n",
      "Predict: \tberlin germany /location/administrative_division/country\n",
      "Ground-Truth: \tberlin germany /location/administrative_division/country\n",
      "---\n",
      "Predict: \tisrael lebanon /location/location/contains\n",
      "Ground-Truth: \tisrael lebanon /location/administrative_division/country\n",
      "---\n",
      "Predict: \teurope iran /location/country/administrative_divisions\n",
      "Ground-Truth: \trussia iran /location/administrative_division/country\n",
      "---\n",
      "Predict: \tgainesville university /business/person/company\n",
      "Ground-Truth: \teugene university /location/location/contains\n",
      "---\n",
      "Predict: \tbarcelona spain /location/administrative_division/country\n",
      "Ground-Truth: \tcatalonia spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \taustralia port /location/location/contains\n",
      "Ground-Truth: \taustralia port /location/location/contains\n",
      "---\n",
      "Predict: \tevo bolivia /people/person/nationality\n",
      "Ground-Truth: \tevo bolivia /people/person/nationality\n",
      "---\n",
      "Predict: \tberlin germany /location/administrative_division/country\n",
      "Ground-Truth: \tberlin germany /location/administrative_division/country\n",
      "---\n",
      "Predict: \tsouth nottingham /location/location/contains\n",
      "Ground-Truth: \tsouth darlington /location/location/contains\n",
      "---\n",
      "Predict: \tharare zimbabwe /people/person/nationality\n",
      "Ground-Truth: \tnelson zimbabwe /people/person/nationality\n",
      "---\n",
      "Predict: \tisrael haifa /location/location/contains\n",
      "Ground-Truth: \tisrael ra'anana /location/location/contains\n",
      "---\n",
      "Predict: \tindia bihar /location/country/administrative_divisions\n",
      "Ground-Truth: \tindia bihar /location/location/contains\n",
      "---\n",
      "Predict: \tehud israel /people/person/nationality\n",
      "Ground-Truth: \tehud israel /people/person/nationality\n",
      "---\n",
      "Predict: \tbihar india /location/administrative_division/country\n",
      "Ground-Truth: \tgujarat india /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcleveland cleveland /location/location/contains\n",
      "Ground-Truth: \tcuyahoga cleveland /location/location/contains\n",
      "---\n",
      "Predict: \tflorida atlantic /location/location/contains\n",
      "Ground-Truth: \tflorida gulf /location/location/contains\n",
      "---\n",
      "Predict: \tindia mumbai /location/country/administrative_divisions\n",
      "Ground-Truth: \tindia delhi /location/location/contains\n",
      "---\n",
      "Predict: \tmexico mexico /location/administrative_division/country\n",
      "Ground-Truth: \tmexico mexico /location/location/contains\n",
      "---\n",
      "Predict: \tindia india /location/administrative_division/country\n",
      "Ground-Truth: \titaly india /location/administrative_division/country\n",
      "---\n",
      "Predict: \tisrael west /location/location/contains\n",
      "Ground-Truth: \tisrael west /location/administrative_division/country\n",
      "---\n",
      "Predict: \tdavid haifa /location/location/contains\n",
      "Ground-Truth: \tjerusalem yad /location/location/contains\n",
      "---\n",
      "Predict: \tehud israel /people/person/nationality\n",
      "Ground-Truth: \tehud israel /people/person/nationality\n",
      "---\n",
      "Predict: \titaly turin /location/location/contains\n",
      "Ground-Truth: \titaly maranello /location/location/contains\n",
      "---\n",
      "Predict: \tisrael west /location/location/contains\n",
      "Ground-Truth: \tisrael west /location/administrative_division/country\n",
      "---\n",
      "Predict: \tben nebraska /people/person/place_lived\n",
      "Ground-Truth: \tben nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tindia bangalore /location/country/administrative_divisions\n",
      "Ground-Truth: \tindia bihar /location/location/contains\n",
      "---\n",
      "Predict: \tbashar syria /people/person/nationality\n",
      "Ground-Truth: \tbashar syria /people/person/nationality\n",
      "---\n",
      "Predict: \tlouisiana baton /location/location/contains\n",
      "Ground-Truth: \tlouisiana baton /location/location/contains\n",
      "---\n",
      "Predict: \tiran middle /location/location/contains\n",
      "Ground-Truth: \tiran middle /location/administrative_division/country\n",
      "---\n",
      "Predict: \tjapan sony /business/company/founders\n",
      "Ground-Truth: \tsony akio /business/company/founders\n",
      "---\n",
      "Predict: \tehud israel /people/person/nationality\n",
      "Ground-Truth: \tshimon israel /people/person/nationality\n",
      "---\n",
      "Predict: \tindia india /location/administrative_division/country\n",
      "Ground-Truth: \titaly india /location/administrative_division/country\n",
      "---\n",
      "Predict: \titaly verona /location/location/contains\n",
      "Ground-Truth: \tcalabria crotone /location/location/contains\n",
      "---\n",
      "Predict: \tflorida boca /location/location/contains\n",
      "Ground-Truth: \tflorida boca /location/location/contains\n",
      "---\n",
      "Predict: \tmexico cancun /location/location/contains\n",
      "Ground-Truth: \tmexico guadalajara /location/location/contains\n",
      "---\n",
      "Predict: \tcarlos toyota /business/person/company\n",
      "Ground-Truth: \tderrick ford /business/person/company\n",
      "---\n",
      "Predict: \tchicago west /location/location/contains\n",
      "Ground-Truth: \tchicago west /location/location/contains\n",
      "---\n",
      "Predict: \tvirginia richmond /location/location/contains\n",
      "Ground-Truth: \tvirginia middleburg /location/location/contains\n",
      "---\n",
      "Predict: \ttom oklahoma /people/person/place_lived\n",
      "Ground-Truth: \tbrad oklahoma /people/person/place_lived\n",
      "---\n",
      "Predict: \tcalifornia berkeley /location/location/contains\n",
      "Ground-Truth: \tcalifornia berkeley /location/location/contains\n",
      "---\n",
      "Predict: \teurope germany /location/administrative_division/country\n",
      "Ground-Truth: \titaly germany /location/administrative_division/country\n",
      "---\n",
      "Predict: \tmichael chicago /location/location/contains\n",
      "Ground-Truth: \tcook chicago /location/location/contains\n",
      "---\n",
      "Predict: \tnassau orange /location/location/contains\n",
      "Ground-Truth: \tfire ocean /location/location/contains\n",
      "---\n",
      "Predict: \tmexico mexico /location/administrative_division/country\n",
      "Ground-Truth: \tmexico mexico /location/administrative_division/country\n",
      "---\n",
      "Predict: \tmitch kentucky /people/person/place_lived\n",
      "Ground-Truth: \tmitch kentucky /people/person/place_lived\n",
      "---\n",
      "Predict: \teric google /business/person/company\n",
      "Ground-Truth: \tshona google /business/person/company\n",
      "---\n",
      "Predict: \tparis france /location/administrative_division/country\n",
      "Ground-Truth: \tparis france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tvicente mexico /location/administrative_division/country\n",
      "Ground-Truth: \tjuarez mexico /location/administrative_division/country\n",
      "---\n",
      "Predict: \tehud israel /people/person/nationality\n",
      "Ground-Truth: \tehud israel /people/person/nationality\n",
      "---\n",
      "Predict: \tisrael haifa /location/location/contains\n",
      "Ground-Truth: \tisrael rehovot /location/location/contains\n",
      "---\n",
      "Predict: \tvalhalla york /business/person/company\n",
      "Ground-Truth: \twill york /business/person/company\n",
      "---\n",
      "Predict: \talan boston /business/person/company\n",
      "Ground-Truth: \tjuliet boston /business/person/company\n",
      "---\n",
      "Predict: \teurope france /location/country/administrative_divisions\n",
      "Ground-Truth: \titaly france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tmitch kentucky /people/person/place_lived\n",
      "Ground-Truth: \tmitch kentucky /people/person/place_lived\n",
      "---\n",
      "Predict: \tmexico puerto /location/country/administrative_divisions\n",
      "Ground-Truth: \tmexico puebla /location/location/contains\n",
      "---\n",
      "Predict: \tspain barcelona /location/location/contains\n",
      "Ground-Truth: \tspain cordoba /location/location/contains\n",
      "---\n",
      "Predict: \tmitch kentucky /people/person/place_lived\n",
      "Ground-Truth: \tmitch kentucky /people/person/place_lived\n",
      "---\n",
      "Predict: \tisrael west /location/location/contains\n",
      "Ground-Truth: \tisrael west /location/administrative_division/country\n",
      "---\n",
      "Predict: \ttoronto mount /location/location/contains\n",
      "Ground-Truth: \ttoronto mount /location/location/contains\n",
      "---\n",
      "Predict: \tdelhi india /location/administrative_division/country\n",
      "Ground-Truth: \tdelhi india /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcanada calgary /location/location/contains\n",
      "Ground-Truth: \tcanada calgary /location/location/contains\n",
      "---\n",
      "Predict: \tontario canada /location/administrative_division/country\n",
      "Ground-Truth: \tontario canada /location/administrative_division/country\n",
      "---\n",
      "Predict: \talexander russia /people/person/nationality\n",
      "Ground-Truth: \tnikolay russia /people/person/nationality\n",
      "---\n",
      "Predict: \tbihar basra /business/person/company\n",
      "Ground-Truth: \tvali naval /business/person/company\n",
      "---\n",
      "Predict: \teurope italy /location/country/administrative_divisions\n",
      "Ground-Truth: \tspain italy /location/administrative_division/country\n",
      "---\n",
      "Predict: \tparis louvre /location/location/contains\n",
      "Ground-Truth: \tparis ecole /location/location/contains\n",
      "---\n",
      "Predict: \tjordan abu /people/person/place_lived\n",
      "Ground-Truth: \tjordan amman /location/location/contains\n",
      "---\n",
      "Predict: \tlouisiana basra /location/country/administrative_divisions\n",
      "Ground-Truth: \talgeria algiers /location/country/capital\n",
      "---\n",
      "Predict: \tindia dharamsala /location/location/contains\n",
      "Ground-Truth: \tindia dharamsala /location/location/contains\n",
      "---\n",
      "Predict: \tflorida lake /location/location/contains\n",
      "Ground-Truth: \tflorida lake /location/location/contains\n",
      "---\n",
      "Predict: \tdonald washington /business/person/company\n",
      "Ground-Truth: \tdonald washington /business/person/company\n",
      "---\n",
      "Predict: \tontario canada /location/administrative_division/country\n",
      "Ground-Truth: \tontario canada /location/administrative_division/country\n",
      "---\n",
      "Predict: \tbill california /people/person/place_lived\n",
      "Ground-Truth: \tdana california /people/person/place_lived\n",
      "---\n",
      "Predict: \tgermany hamburg /location/location/contains\n",
      "Ground-Truth: \tgermany nuremberg /location/location/contains\n",
      "---\n",
      "Predict: \tpaul bank /business/person/company\n",
      "Ground-Truth: \tstanley bank /business/person/company\n",
      "---\n",
      "Predict: \tlong upper /location/location/contains\n",
      "Ground-Truth: \tlower battery /location/location/contains\n",
      "---\n",
      "Predict: \tmichael nottingham /business/person/company\n",
      "Ground-Truth: \tfrank lloyd /people/person/children\n",
      "---\n",
      "Predict: \tmexico cancun /location/location/contains\n",
      "Ground-Truth: \tmexico guadalajara /location/location/contains\n",
      "---\n",
      "Predict: \tdamascus syria /location/administrative_division/country\n",
      "Ground-Truth: \tdamascus syria /location/administrative_division/country\n",
      "---\n",
      "Predict: \tfrance paris /location/country/administrative_divisions\n",
      "Ground-Truth: \tfrance paris /location/location/contains\n",
      "---\n",
      "Predict: \tyork great /location/location/contains\n",
      "Ground-Truth: \tyork peck /location/location/contains\n",
      "---\n",
      "Predict: \teurope russia /location/administrative_division/country\n",
      "Ground-Truth: \tiran russia /location/administrative_division/country\n",
      "---\n",
      "Predict: \ttaiwan taipei /location/location/contains\n",
      "Ground-Truth: \ttaiwan taipei /location/location/contains\n",
      "---\n",
      "Predict: \tdamascus syria /location/administrative_division/country\n",
      "Ground-Truth: \tdamascus syria /location/administrative_division/country\n",
      "---\n",
      "Predict: \teurope spain /location/administrative_division/country\n",
      "Ground-Truth: \titaly spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \tontario waterloo /location/location/contains\n",
      "Ground-Truth: \tontario kingston /location/location/contains\n",
      "---\n",
      "Predict: \tehud israel /people/person/nationality\n",
      "Ground-Truth: \tshimon israel /people/person/nationality\n",
      "---\n",
      "Predict: \tmexico santa /location/location/contains\n",
      "Ground-Truth: \tmexico baja /location/location/contains\n",
      "---\n",
      "Predict: \tindia bihar /location/country/administrative_divisions\n",
      "Ground-Truth: \tindia chhattisgarh /location/location/contains\n",
      "---\n",
      "Predict: \toaxaca mexico /location/administrative_division/country\n",
      "Ground-Truth: \tmichoacan mexico /location/administrative_division/country\n",
      "---\n",
      "Predict: \tmexico monterrey /location/location/contains\n",
      "Ground-Truth: \tmexico tulum /location/location/contains\n",
      "---\n",
      "Predict: \tatlanta georgia /location/location/contains\n",
      "Ground-Truth: \tatlanta georgia /location/location/contains\n",
      "---\n",
      "Predict: \tberkeley nottingham /location/location/contains\n",
      "Ground-Truth: \tberkeley chez /location/location/contains\n",
      "---\n",
      "Predict: \tbihar australia /people/person/nationality\n",
      "Ground-Truth: \tlibby australia /people/person/nationality\n",
      "---\n",
      "Predict: \tcarlos spain /people/person/nationality\n",
      "Ground-Truth: \tjose spain /people/person/nationality\n",
      "---\n",
      "Predict: \tmiddle iran /location/location/contains\n",
      "Ground-Truth: \twashington iran /location/administrative_division/country\n",
      "---\n",
      "Predict: \tmark hewlett-packard /business/person/company\n",
      "Ground-Truth: \tmark hewlett-packard /business/person/company\n",
      "---\n",
      "Predict: \tparis louvre /location/location/contains\n",
      "Ground-Truth: \tparis musee /location/location/contains\n",
      "---\n",
      "Predict: \tparis france /location/administrative_division/country\n",
      "Ground-Truth: \tparis france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tharris houston /location/location/contains\n",
      "Ground-Truth: \tharris houston /location/location/contains\n",
      "---\n",
      "Predict: \thavana cuba /location/administrative_division/country\n",
      "Ground-Truth: \thavana cuba /location/administrative_division/country\n",
      "---\n",
      "Predict: \tgreat great /business/person/company\n",
      "Ground-Truth: \twill time /business/person/company\n",
      "---\n",
      "Predict: \tisrael west /location/location/contains\n",
      "Ground-Truth: \tisrael west /location/administrative_division/country\n",
      "---\n",
      "Predict: \tchicago franklin /location/location/contains\n",
      "Ground-Truth: \tchicago winston /location/location/contains\n",
      "---\n",
      "Predict: \tjacob mount /business/person/company\n",
      "Ground-Truth: \tamory rocky /business/person/company\n",
      "---\n",
      "Predict: \trochester george /location/location/contains\n",
      "Ground-Truth: \trochester george /location/location/contains\n",
      "---\n",
      "Predict: \tmexico cancun /location/location/contains\n",
      "Ground-Truth: \tmexico cancun /location/location/contains\n",
      "---\n",
      "Predict: \tidaho lake /location/location/contains\n",
      "Ground-Truth: \tidaho salmon /location/location/contains\n",
      "---\n",
      "Predict: \twest west /location/location/contains\n",
      "Ground-Truth: \twest senegal /location/location/contains\n",
      "---\n",
      "Predict: \tyork staten /location/location/contains\n",
      "Ground-Truth: \tyork staten /location/location/contains\n",
      "---\n",
      "Predict: \tstephen morgan /business/person/company\n",
      "Ground-Truth: \tstephen blackstone /business/person/company\n",
      "---\n",
      "Predict: \tontario waterloo /location/location/contains\n",
      "Ground-Truth: \tontario kingston /location/location/contains\n",
      "---\n",
      "Predict: \tfairfield roslyn /location/location/contains\n",
      "Ground-Truth: \twestport winslow /location/location/contains\n",
      "---\n",
      "Predict: \tbaltimore fenway /location/location/contains\n",
      "Ground-Truth: \tbaltimore m&t /location/location/contains\n",
      "---\n",
      "Predict: \twashington capitol /location/location/contains\n",
      "Ground-Truth: \twashington walter /location/location/contains\n",
      "---\n",
      "Predict: \toaxaca mexico /location/administrative_division/country\n",
      "Ground-Truth: \tguanajuato mexico /location/administrative_division/country\n",
      "---\n",
      "Predict: \tbihar india /location/administrative_division/country\n",
      "Ground-Truth: \tbihar india /location/administrative_division/country\n",
      "---\n",
      "Predict: \teurope france /people/person/nationality\n",
      "Ground-Truth: \titaly france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tbruce york /business/person/company\n",
      "Ground-Truth: \tdennis york /business/person/company\n",
      "---\n",
      "Predict: \tkansa kansa /location/location/contains\n",
      "Ground-Truth: \tkansa atchison /location/location/contains\n",
      "---\n",
      "Predict: \tboston massachusetts /location/location/contains\n",
      "Ground-Truth: \tboston massachusetts /location/location/contains\n",
      "---\n",
      "Predict: \twashington mount /location/location/contains\n",
      "Ground-Truth: \twashington mount /location/location/contains\n",
      "---\n",
      "Predict: \tcuba cuba /location/location/contains\n",
      "Ground-Truth: \tcuba guantanamo /location/location/contains\n",
      "---\n",
      "Predict: \twashington united /location/location/contains\n",
      "Ground-Truth: \twashington united /location/location/contains\n",
      "---\n",
      "Predict: \tflorida boca /location/location/contains\n",
      "Ground-Truth: \tflorida boca /location/location/contains\n",
      "---\n",
      "Predict: \teurope spain /location/administrative_division/country\n",
      "Ground-Truth: \titaly spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \tbruce fenway /business/person/company\n",
      "Ground-Truth: \teddie reebok /business/person/company\n",
      "---\n",
      "Predict: \tontario st /location/location/contains\n",
      "Ground-Truth: \tontario st /location/location/contains\n",
      "---\n",
      "Predict: \tchuck nebraska /people/person/place_lived\n",
      "Ground-Truth: \tchuck nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tflorida boca /location/location/contains\n",
      "Ground-Truth: \tflorida ponte /location/location/contains\n",
      "---\n",
      "Predict: \tseoul south /location/administrative_division/country\n",
      "Ground-Truth: \tseoul south /location/administrative_division/country\n",
      "---\n",
      "Predict: \tflorida lake /location/location/contains\n",
      "Ground-Truth: \tflorida lake /location/location/contains\n",
      "---\n",
      "Predict: \tchicago fenway /location/location/contains\n",
      "Ground-Truth: \tchicago sears /location/location/contains\n",
      "---\n",
      "Predict: \tontario waterloo /location/location/contains\n",
      "Ground-Truth: \tontario woodbridge /location/location/contains\n",
      "---\n",
      "Predict: \twashington national /location/location/contains\n",
      "Ground-Truth: \twashington national /location/location/contains\n",
      "---\n",
      "Predict: \tzimbabwe haditha /location/country/administrative_divisions\n",
      "Ground-Truth: \tguinea conakry /location/country/capital\n",
      "---\n",
      "Predict: \tiowa dayton /location/location/contains\n",
      "Ground-Truth: \tiowa waterloo /location/location/contains\n",
      "---\n",
      "Predict: \titaly florence /location/location/contains\n",
      "Ground-Truth: \titaly amalfi /location/location/contains\n",
      "---\n",
      "Predict: \teurope france /location/administrative_division/country\n",
      "Ground-Truth: \titaly france /location/administrative_division/country\n",
      "---\n",
      "Predict: \twestchester hudson /location/location/contains\n",
      "Ground-Truth: \twestchester hudson /location/location/contains\n",
      "---\n",
      "Predict: \th. georgia /business/person/company\n",
      "Ground-Truth: \tg. georgia /business/person/company\n",
      "---\n",
      "Predict: \tcuba cuba /location/location/contains\n",
      "Ground-Truth: \tcuba guantanamo /location/location/contains\n",
      "---\n",
      "Predict: \tberkeley rochelle /location/location/contains\n",
      "Ground-Truth: \tberkeley chez /location/location/contains\n",
      "---\n",
      "Predict: \tmiddle israel /location/administrative_division/country\n",
      "Ground-Truth: \tgaza israel /location/administrative_division/country\n",
      "---\n",
      "Predict: \tchuck nebraska /people/person/place_lived\n",
      "Ground-Truth: \tchuck nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tmonmouth york /people/person/place_lived\n",
      "Ground-Truth: \ttyler york /business/person/company\n",
      "---\n",
      "Predict: \tindia india /location/administrative_division/country\n",
      "Ground-Truth: \titaly india /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcanada ontario /location/country/administrative_divisions\n",
      "Ground-Truth: \tcanada ontario /location/location/contains\n",
      "---\n",
      "Predict: \tottawa ottawa /location/location/contains\n",
      "Ground-Truth: \ttoledo ottawa /location/location/contains\n",
      "---\n",
      "Predict: \tzimbabwe bihar /location/location/contains\n",
      "Ground-Truth: \tnamibia windhoek /location/location/contains\n",
      "---\n",
      "Predict: \tcleveland united /location/location/contains\n",
      "Ground-Truth: \tmamaroneck united /location/location/contains\n",
      "---\n",
      "Predict: \tvermont burlington /location/location/contains\n",
      "Ground-Truth: \tvermont stowe /location/location/contains\n",
      "---\n",
      "Predict: \teurope spain /location/administrative_division/country\n",
      "Ground-Truth: \titaly spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \tfrance strasbourg /location/location/contains\n",
      "Ground-Truth: \tfrance toulouse /location/location/contains\n",
      "---\n",
      "Predict: \tmiddle iran /location/location/contains\n",
      "Ground-Truth: \twashington iran /location/administrative_division/country\n",
      "---\n",
      "Predict: \tjacques france /location/administrative_division/country\n",
      "Ground-Truth: \tcorsica france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tsyria damascus /location/country/administrative_divisions\n",
      "Ground-Truth: \tsyria damascus /location/location/contains\n",
      "---\n",
      "Predict: \tbihar india /people/person/nationality\n",
      "Ground-Truth: \tshilpa india /people/person/nationality\n",
      "---\n",
      "Predict: \tfinland stuttgart /location/location/contains\n",
      "Ground-Truth: \tfinland turku /location/location/contains\n",
      "---\n",
      "Predict: \tgermany stuttgart /location/location/contains\n",
      "Ground-Truth: \tgermany stuttgart /location/location/contains\n",
      "---\n",
      "Predict: \tboston beth /location/location/contains\n",
      "Ground-Truth: \tboston beth /location/location/contains\n",
      "---\n",
      "Predict: \ttom minnesota /people/person/place_lived\n",
      "Ground-Truth: \ttim minnesota /people/person/place_lived\n",
      "---\n",
      "Predict: \trockland kansa /location/location/contains\n",
      "Ground-Truth: \trockland city /location/location/contains\n",
      "---\n",
      "Predict: \tmartin national /business/person/company\n",
      "Ground-Truth: \tmartin national /business/person/company\n",
      "---\n",
      "Predict: \ttoronto solomon /location/location/contains\n",
      "Ground-Truth: \ttoronto barrick /location/location/contains\n",
      "---\n",
      "Predict: \tlake chicago /location/location/contains\n",
      "Ground-Truth: \tlake chicago /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcambridge waterloo /location/location/contains\n",
      "Ground-Truth: \tmarlborough cytyc /location/location/contains\n",
      "---\n",
      "Predict: \tfrance /people/person/nationality /location/location/contains\n",
      "Ground-Truth: \tfrance alzonne /location/location/contains\n",
      "---\n",
      "Predict: \twashington national /location/location/contains\n",
      "Ground-Truth: \twashington national /location/location/contains\n",
      "---\n",
      "Predict: \tmexico santa /location/location/contains\n",
      "Ground-Truth: \tmexico ciudad /location/location/contains\n",
      "---\n",
      "Predict: \tsyria syria /location/location/contains\n",
      "Ground-Truth: \tiran syria /location/administrative_division/country\n",
      "---\n",
      "Predict: \tisrael west /location/location/contains\n",
      "Ground-Truth: \tisrael west /location/administrative_division/country\n",
      "---\n",
      "Predict: \tvermont burlington /location/location/contains\n",
      "Ground-Truth: \tvermont stowe /location/location/contains\n",
      "---\n",
      "Predict: \tconnecticut haven /location/location/contains\n",
      "Ground-Truth: \tconnecticut hamden /location/location/contains\n",
      "---\n",
      "Predict: \tiran iran /location/country/administrative_divisions\n",
      "Ground-Truth: \trussia iran /location/administrative_division/country\n",
      "---\n",
      "Predict: \tmiddle iran /location/administrative_division/country\n",
      "Ground-Truth: \tsyria iran /location/administrative_division/country\n",
      "---\n",
      "Predict: \tchuck nebraska /people/person/place_lived\n",
      "Ground-Truth: \tchuck nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tchuck nebraska /people/person/place_lived\n",
      "Ground-Truth: \tchuck nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tiowa beth /location/location/contains\n",
      "Ground-Truth: \tiowa waverly /location/location/contains\n",
      "---\n",
      "Predict: \tcuba havana /location/location/contains\n",
      "Ground-Truth: \tcuba bayamo /location/location/contains\n",
      "---\n",
      "Predict: \tkim south /people/person/nationality\n",
      "Ground-Truth: \taziz south /people/person/nationality\n",
      "---\n",
      "Predict: \titaly florence /location/location/contains\n",
      "Ground-Truth: \titaly reggio /location/location/contains\n",
      "---\n",
      "Predict: \twashington washington /location/location/contains\n",
      "Ground-Truth: \tiran washington /location/administrative_division/country\n",
      "---\n",
      "Predict: \tconnecticut clark /location/location/contains\n",
      "Ground-Truth: \thampshire cannon /location/location/contains\n",
      "---\n",
      "Predict: \tjacob bolivia /people/person/nationality\n",
      "Ground-Truth: \thelen guatemala /people/person/place_lived\n",
      "---\n",
      "Predict: \tukraine white /location/location/contains\n",
      "Ground-Truth: \tromania black /location/location/contains\n",
      "---\n",
      "Predict: \tsyria syria /location/country/administrative_divisions\n",
      "Ground-Truth: \tiran syria /location/administrative_division/country\n",
      "---\n",
      "Predict: \tflorence columbus /location/location/contains\n",
      "Ground-Truth: \tdecatur agnes /location/location/contains\n",
      "---\n",
      "Predict: \tkim north /people/person/place_lived\n",
      "Ground-Truth: \trobin north /business/person/company\n",
      "---\n",
      "Predict: \tbihar philippine /people/person/nationality\n",
      "Ground-Truth: \timelda philippine /people/person/nationality\n",
      "---\n",
      "Predict: \twilliam franklin /people/person/children\n",
      "Ground-Truth: \tcharles woody /people/person/children\n",
      "---\n",
      "Predict: \tmaryland baltimore /location/location/contains\n",
      "Ground-Truth: \tmaryland annapolis /location/location/contains\n",
      "---\n",
      "Predict: \tparis louvre /location/location/contains\n",
      "Ground-Truth: \tparis gare /location/location/contains\n",
      "---\n",
      "Predict: \tdavid case /business/person/company\n",
      "Ground-Truth: \tstephen case /business/person/company\n",
      "---\n",
      "Predict: \tboston great /location/location/contains\n",
      "Ground-Truth: \tboston church /location/location/contains\n",
      "---\n",
      "Predict: \ttrent mississippi /people/person/place_lived\n",
      "Ground-Truth: \thaley mississippi /people/person/place_lived\n",
      "---\n",
      "Predict: \tsheldon rhode /people/person/place_lived\n",
      "Ground-Truth: \tsheldon rhode /people/person/place_lived\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in range(395):\n",
    "    print('Predict: \\t%s' % ' '.join(preResult[i]))\n",
    "    print('Ground-Truth: \\t%s' % ' '.join(actResult[i]))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy 1-best Search Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'cp_logs/weights.336-2.599974.hdf5'\n",
    "model.load_weights(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/395 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/395 [00:00<02:25,  2.70it/s]\u001b[A\n",
      "  1%|          | 2/395 [00:00<02:27,  2.66it/s]\u001b[A\n",
      "  1%|          | 3/395 [00:01<02:29,  2.62it/s]\u001b[A\n",
      "  1%|          | 4/395 [00:01<02:29,  2.61it/s]\u001b[A\n",
      "  1%|▏         | 5/395 [00:01<02:32,  2.56it/s]\u001b[A\n",
      "100%|██████████| 395/395 [02:18<00:00,  2.93it/s]\n"
     ]
    }
   ],
   "source": [
    "preResult = []\n",
    "for i in tqdm(range(395)):\n",
    "    pR = []\n",
    "    tag = 0\n",
    "    fb_words = np.array([58840])\n",
    "    x = np.array([x_test[i]])\n",
    "    \n",
    "    for j in range(MAX_ADJL_LEN):\n",
    "        fb_input = pad_sequences([fb_words], maxlen=MAX_ADJL_LEN, padding='post', truncating='post')\n",
    "        prob = model.predict([x, fb_input], batch_size=BATCH_SIZE)[0][j]\n",
    "        if j < 2:\n",
    "            for item in [i for i in x_test[i] if i != 0]:\n",
    "                prob[item] = float(prob[item]+1)\n",
    "        if j == 2:\n",
    "            prob[:58828] = -1\n",
    "        prob[0] = -1\n",
    "        prob[tag] = -1\n",
    "        result = prob.argmax()\n",
    "        tag = result\n",
    "        pR.append(result)\n",
    "        fb_words = np.append(fb_words, result)\n",
    "    preResult.append(pR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1 Accuracy: \t\t0.291139\n",
      "E2 Accuracy: \t\t0.281013\n",
      "En Accuracy: \t\t0.139241\n",
      "Triple Accuracy: \t0.113924\n"
     ]
    }
   ],
   "source": [
    "preResult = [[index2word[i] for i in sent if i != 0] for sent in preResult]\n",
    "actResult = [[index2word[i] for i in sent if i != 0] for sent in y_test]\n",
    "e1Count = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0]])\n",
    "e2Count = sum([1 for i in range(395) if actResult[i][1] == preResult[i][1]])\n",
    "enCount = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0] and actResult[i][1] == preResult[i][1]])\n",
    "tripleCount = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0] and actResult[i][1] == preResult[i][1] and actResult[i][2] == preResult[i][2]])\n",
    "print('E1 Accuracy: \\t\\t%.6f' % (e1Count/395))\n",
    "print('E2 Accuracy: \\t\\t%.6f' % (e2Count/395))\n",
    "print('En Accuracy: \\t\\t%.6f' % (enCount/395))\n",
    "print('Triple Accuracy: \\t%.6f' % (tripleCount/395))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: \tmexico spain /location/country/administrative_divisions\n",
      "Ground-Truth: \tspain italy /location/administrative_division/country\n",
      "---\n",
      "Predict: \twestchester long /location/location/contains\n",
      "Ground-Truth: \twestchester connecticut /location/administrative_division/country\n",
      "---\n",
      "Predict: \tisrael saudi /location/location/contains\n",
      "Ground-Truth: \tdalia israel /people/person/nationality\n",
      "---\n",
      "Predict: \tindia university /location/location/contains\n",
      "Ground-Truth: \thyderabad potti /location/location/contains\n",
      "---\n",
      "Predict: \tnorth bush /location/location/contains\n",
      "Ground-Truth: \tkent north /people/person/place_lived\n",
      "---\n",
      "Predict: \tontario waterloo /location/location/contains\n",
      "Ground-Truth: \tontario waterloo /location/location/contains\n",
      "---\n",
      "Predict: \tstephen a. /business/person/company\n",
      "Ground-Truth: \tblackstone stephen /business/company/founders\n",
      "---\n",
      "Predict: \tmexico spain /location/country/administrative_divisions\n",
      "Ground-Truth: \tfrance italy /location/administrative_division/country\n",
      "---\n",
      "Predict: \tiran russia /location/administrative_division/country\n",
      "Ground-Truth: \tiran russia /location/administrative_division/country\n",
      "---\n",
      "Predict: \tparis france /location/administrative_division/country\n",
      "Ground-Truth: \tfrance paris /location/location/contains\n",
      "---\n",
      "Predict: \tgeorge american /business/person/company\n",
      "Ground-Truth: \tgeorge abc /business/person/company\n",
      "---\n",
      "Predict: \tflorida jacksonville /location/location/contains\n",
      "Ground-Truth: \tflorida jacksonville /location/location/contains\n",
      "---\n",
      "Predict: \tnigeria resort /location/location/contains\n",
      "Ground-Truth: \tnigeria uyo /location/location/contains\n",
      "---\n",
      "Predict: \trhode vermont /location/location/contains\n",
      "Ground-Truth: \tsheldon rhode /people/person/place_lived\n",
      "---\n",
      "Predict: \tkentucky patrick /location/location/contains\n",
      "Ground-Truth: \tpatrick huntington /people/person/place_lived\n",
      "---\n",
      "Predict: \teuropean berlin /location/location/contains\n",
      "Ground-Truth: \tberlin germany /location/administrative_division/country\n",
      "---\n",
      "Predict: \ta weinberg /business/person/company\n",
      "Ground-Truth: \tjeffrey lazard /business/person/company\n",
      "---\n",
      "Predict: \tisrael gaza /location/location/contains\n",
      "Ground-Truth: \tgaza israel /location/administrative_division/country\n",
      "---\n",
      "Predict: \tu.s. a /location/location/contains\n",
      "Ground-Truth: \tseoul south /location/administrative_division/country\n",
      "---\n",
      "Predict: \tmark york /business/person/company\n",
      "Ground-Truth: \tmark york /business/person/company\n",
      "---\n",
      "Predict: \tnetherlands united /location/administrative_division/country\n",
      "Ground-Truth: \tmarkus australia /people/person/nationality\n",
      "---\n",
      "Predict: \tmartin university /business/person/company\n",
      "Ground-Truth: \tkwame princeton /business/person/company\n",
      "---\n",
      "Predict: \tdeal a /location/location/contains\n",
      "Ground-Truth: \tendemol john /business/company/founders\n",
      "---\n",
      "Predict: \tstate month /location/location/contains\n",
      "Ground-Truth: \ttim minnesota /people/person/place_lived\n",
      "---\n",
      "Predict: \tgeorge connecticut /people/person/place_lived\n",
      "Ground-Truth: \tconnecticut haven /location/location/contains\n",
      "---\n",
      "Predict: \tiran american /location/location/contains\n",
      "Ground-Truth: \tiran russia /location/administrative_division/country\n",
      "---\n",
      "Predict: \tindia state /location/location/contains\n",
      "Ground-Truth: \tbihar india /location/administrative_division/country\n",
      "---\n",
      "Predict: \tbill elliott /people/person/children\n",
      "Ground-Truth: \tbill dawsonville /people/person/place_lived\n",
      "---\n",
      "Predict: \tbritish columbia /location/location/contains\n",
      "Ground-Truth: \tdaniel university /business/person/company\n",
      "---\n",
      "Predict: \tsoviet russia /people/person/nationality\n",
      "Ground-Truth: \tsoviet russia /location/administrative_division/country\n",
      "---\n",
      "Predict: \tboston johnson /location/location/contains\n",
      "Ground-Truth: \tboston wbz-tv /location/location/contains\n",
      "---\n",
      "Predict: \tehud israel /people/person/nationality\n",
      "Ground-Truth: \tehud israel /people/person/nationality\n",
      "---\n",
      "Predict: \ta united /business/person/company\n",
      "Ground-Truth: \tvirginia united /location/administrative_division/country\n",
      "---\n",
      "Predict: \tpresident security /business/person/company\n",
      "Ground-Truth: \tira system /business/person/company\n",
      "---\n",
      "Predict: \ta legal /business/person/company\n",
      "Ground-Truth: \tcuba guantanamo /location/location/contains\n",
      "---\n",
      "Predict: \ta hoboken /location/location/contains\n",
      "Ground-Truth: \tanthony york /business/person/company\n",
      "---\n",
      "Predict: \ta google /business/person/company\n",
      "Ground-Truth: \tchad google /business/person/company\n",
      "---\n",
      "Predict: \tevans a /business/person/company\n",
      "Ground-Truth: \twashington bainbridge /location/location/contains\n",
      "---\n",
      "Predict: \tcross lrb /location/location/contains\n",
      "Ground-Truth: \twashington olympia /location/location/contains\n",
      "---\n",
      "Predict: \tsouth seoul /location/country/administrative_divisions\n",
      "Ground-Truth: \tsouth seoul /location/location/contains\n",
      "---\n",
      "Predict: \tlong spain /people/person/nationality\n",
      "Ground-Truth: \tfrance spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \tchuck nebraska /people/person/place_lived\n",
      "Ground-Truth: \tchuck nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \ta italy /people/person/nationality\n",
      "Ground-Truth: \tfrance italy /location/administrative_division/country\n",
      "---\n",
      "Predict: \ta iraq /people/person/nationality\n",
      "Ground-Truth: \tiran syria /location/administrative_division/country\n",
      "---\n",
      "Predict: \tplayer north /people/person/place_lived\n",
      "Ground-Truth: \tkellen colorado /people/person/place_of_birth\n",
      "---\n",
      "Predict: \tunited argentina /location/location/contains\n",
      "Ground-Truth: \ttony france /people/person/nationality\n",
      "---\n",
      "Predict: \tspain e. /location/location/contains\n",
      "Ground-Truth: \tjose spain /people/person/nationality\n",
      "---\n",
      "Predict: \tinclude germany /people/person/nationality\n",
      "Ground-Truth: \tfrance italy /location/administrative_division/country\n",
      "---\n",
      "Predict: \tchuck nebraska /people/person/place_lived\n",
      "Ground-Truth: \tchuck nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tisland staten /location/location/contains\n",
      "Ground-Truth: \tyork staten /location/location/contains\n",
      "---\n",
      "Predict: \talternative nebraska /people/person/place_lived\n",
      "Ground-Truth: \tchuck nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \twest israel /location/location/contains\n",
      "Ground-Truth: \tgaza israel /location/administrative_division/country\n",
      "---\n",
      "Predict: \tat&t san /location/location/contains\n",
      "Ground-Truth: \tralph at&t /business/person/company\n",
      "---\n",
      "Predict: \tconnecticut hartford /location/location/contains\n",
      "Ground-Truth: \tconnecticut haven /location/location/contains\n",
      "---\n",
      "Predict: \tsomalia american /location/location/contains\n",
      "Ground-Truth: \tsomalia puntland /location/location/contains\n",
      "---\n",
      "Predict: \tlatvia riga /location/country/administrative_divisions\n",
      "Ground-Truth: \triga latvia /location/administrative_division/country\n",
      "---\n",
      "Predict: \twest iran /location/location/contains\n",
      "Ground-Truth: \tswitzerland davos /location/location/contains\n",
      "---\n",
      "Predict: \tfree resort /location/location/contains\n",
      "Ground-Truth: \tcolorado vail /location/location/contains\n",
      "---\n",
      "Predict: \tfrance paris /location/country/administrative_divisions\n",
      "Ground-Truth: \tparis france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tsouth staten /location/location/contains\n",
      "Ground-Truth: \tlower hudson /location/location/contains\n",
      "---\n",
      "Predict: \ta north /location/location/contains\n",
      "Ground-Truth: \tsan north /location/location/contains\n",
      "---\n",
      "Predict: \tyork county /location/location/contains\n",
      "Ground-Truth: \tnassau suffolk /location/administrative_division/country\n",
      "---\n",
      "Predict: \tyoutube chad /business/company/founders\n",
      "Ground-Truth: \tchad youtube /business/person/company\n",
      "---\n",
      "Predict: \twestchester city /location/location/contains\n",
      "Ground-Truth: \twestchester kensico /location/location/contains\n",
      "---\n",
      "Predict: \tsusan maine /people/person/place_lived\n",
      "Ground-Truth: \tben nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \titaly town /location/location/contains\n",
      "Ground-Truth: \titaly orvieto /location/location/contains\n",
      "---\n",
      "Predict: \tuniversity local /location/location/contains\n",
      "Ground-Truth: \tgreenville furman /location/location/contains\n",
      "---\n",
      "Predict: \ta university /business/person/company\n",
      "Ground-Truth: \tcharles princeton /business/person/company\n",
      "---\n",
      "Predict: \tontario canada /location/administrative_division/country\n",
      "Ground-Truth: \tcanada ontario /location/location/contains\n",
      "---\n",
      "Predict: \tflorida boca /location/location/contains\n",
      "Ground-Truth: \tflorida boca /location/location/contains\n",
      "---\n",
      "Predict: \tegypt israel /location/location/contains\n",
      "Ground-Truth: \tgaza israel /location/administrative_division/country\n",
      "---\n",
      "Predict: \tbaltimore john /location/location/contains\n",
      "Ground-Truth: \tbaltimore john /location/location/contains\n",
      "---\n",
      "Predict: \ta india /people/person/nationality\n",
      "Ground-Truth: \tsamantha india /people/person/place_lived\n",
      "---\n",
      "Predict: \tdavid kenny /business/person/company\n",
      "Ground-Truth: \tdavid digitas /business/person/company\n",
      "---\n",
      "Predict: \ttom ohio /people/person/place_lived\n",
      "Ground-Truth: \ttom iowa /people/person/place_lived\n",
      "---\n",
      "Predict: \tunited lebanon /location/country/administrative_divisions\n",
      "Ground-Truth: \trafik lebanon /people/person/nationality\n",
      "---\n",
      "Predict: \tpresident party /business/person/company\n",
      "Ground-Truth: \tatiku nigeria /people/person/nationality\n",
      "---\n",
      "Predict: \ta watching /location/location/contains\n",
      "Ground-Truth: \twestchester mamaroneck /location/location/contains\n",
      "---\n",
      "Predict: \ta florida /location/location/contains\n",
      "Ground-Truth: \tflorida panama /location/location/contains\n",
      "---\n",
      "Predict: \tiraq iran /location/location/contains\n",
      "Ground-Truth: \tiran north /location/administrative_division/country\n",
      "---\n",
      "Predict: \tfrance paris /location/country/administrative_divisions\n",
      "Ground-Truth: \tfrance paris /location/location/contains\n",
      "---\n",
      "Predict: \tpercent will /location/location/contains\n",
      "Ground-Truth: \tfrance spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \ttown wall /location/location/contains\n",
      "Ground-Truth: \tclarkstown city /location/location/contains\n",
      "---\n",
      "Predict: \tindia mumbai /location/location/contains\n",
      "Ground-Truth: \tindia delhi /location/location/contains\n",
      "---\n",
      "Predict: \tmississippi state /location/location/contains\n",
      "Ground-Truth: \thaley mississippi /people/person/place_lived\n",
      "---\n",
      "Predict: \tflorida boca /location/location/contains\n",
      "Ground-Truth: \tflorida boca /location/location/contains\n",
      "---\n",
      "Predict: \tchief jetblue /business/person/company\n",
      "Ground-Truth: \tgordon continental /business/person/company\n",
      "---\n",
      "Predict: \thenry france /people/person/nationality\n",
      "Ground-Truth: \tparis france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tsan percent /location/location/contains\n",
      "Ground-Truth: \tcalifornia long /location/location/contains\n",
      "---\n",
      "Predict: \tgeorge france /people/person/nationality\n",
      "Ground-Truth: \tfrance correze /location/location/contains\n",
      "---\n",
      "Predict: \tschool county /location/location/contains\n",
      "Ground-Truth: \tfairfax westfield /location/location/contains\n",
      "---\n",
      "Predict: \ta palestinian /people/person/place_of_birth\n",
      "Ground-Truth: \tgaza israel /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcity spain /location/administrative_division/country\n",
      "Ground-Truth: \tspain valencia /location/location/contains\n",
      "---\n",
      "Predict: \tiraq a /location/location/contains\n",
      "Ground-Truth: \tchuck nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tgreenwich jefferson /location/location/contains\n",
      "Ground-Truth: \tgreenwich jefferson /location/location/contains\n",
      "---\n",
      "Predict: \ta hamas /business/person/company\n",
      "Ground-Truth: \tisrael west /location/administrative_division/country\n",
      "---\n",
      "Predict: \tfrance jacques /location/location/contains\n",
      "Ground-Truth: \tjacques france /people/person/nationality\n",
      "---\n",
      "Predict: \tramapo mahwah /location/location/contains\n",
      "Ground-Truth: \tmahwah ramapo /location/location/contains\n",
      "---\n",
      "Predict: \tguyana money /location/country/administrative_divisions\n",
      "Ground-Truth: \tguyana linden /location/location/contains\n",
      "---\n",
      "Predict: \tdr singh /people/person/children\n",
      "Ground-Truth: \tindia punjab /location/location/contains\n",
      "---\n",
      "Predict: \tontario a /location/location/contains\n",
      "Ground-Truth: \tontario tobermory /location/location/contains\n",
      "---\n",
      "Predict: \ta iran /people/person/nationality\n",
      "Ground-Truth: \tmiddle iran /location/location/contains\n",
      "---\n",
      "Predict: \ta africa /people/person/nationality\n",
      "Ground-Truth: \tcuba guantanamo /location/location/contains\n",
      "---\n",
      "Predict: \ta italy /people/person/nationality\n",
      "Ground-Truth: \titaly israel /location/administrative_division/country\n",
      "---\n",
      "Predict: \tspain france /location/country/administrative_divisions\n",
      "Ground-Truth: \tgermany spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \ta google /business/person/company\n",
      "Ground-Truth: \tchad google /business/person/company\n",
      "---\n",
      "Predict: \tisrael palestinian /location/location/contains\n",
      "Ground-Truth: \tehud israel /people/person/nationality\n",
      "---\n",
      "Predict: \tminnesota amy /location/location/contains\n",
      "Ground-Truth: \tamy minnesota /people/person/place_lived\n",
      "---\n",
      "Predict: \taustralian american /business/person/company\n",
      "Ground-Truth: \tjohn australia /people/person/nationality\n",
      "---\n",
      "Predict: \tkentucky ernie /location/location/contains\n",
      "Ground-Truth: \ternie kentucky /people/person/place_lived\n",
      "---\n",
      "Predict: \tnorth iran /location/location/contains\n",
      "Ground-Truth: \tiran north /location/administrative_division/country\n",
      "---\n",
      "Predict: \tnorthern india /location/administrative_division/country\n",
      "Ground-Truth: \tindia bihar /location/country/administrative_divisions\n",
      "---\n",
      "Predict: \ta ireland /people/person/nationality\n",
      "Ground-Truth: \tireland county /location/location/contains\n",
      "---\n",
      "Predict: \t1 cuba /location/administrative_division/country\n",
      "Ground-Truth: \thavana cuba /location/administrative_division/country\n",
      "---\n",
      "Predict: \titaly town /location/location/contains\n",
      "Ground-Truth: \titaly umbria /location/location/contains\n",
      "---\n",
      "Predict: \tspain italy /location/country/administrative_divisions\n",
      "Ground-Truth: \tcampania italy /location/administrative_division/country\n",
      "---\n",
      "Predict: \ta iraq /people/person/nationality\n",
      "Ground-Truth: \tiran middle /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcity sahn /location/location/contains\n",
      "Ground-Truth: \tflorida boca /location/location/contains\n",
      "---\n",
      "Predict: \tspain germany /location/country/administrative_divisions\n",
      "Ground-Truth: \tgermany spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \tbritish france /location/administrative_division/country\n",
      "Ground-Truth: \tparis france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcleveland manhattan /location/location/contains\n",
      "Ground-Truth: \tcleveland karamu /location/location/contains\n",
      "---\n",
      "Predict: \tairport ireland /location/administrative_division/country\n",
      "Ground-Truth: \tireland county /location/location/contains\n",
      "---\n",
      "Predict: \tschool york /location/location/contains\n",
      "Ground-Truth: \tcalifornia san /location/location/contains\n",
      "---\n",
      "Predict: \tfrance joyce /location/location/contains\n",
      "Ground-Truth: \tfrance albertville /location/location/contains\n",
      "---\n",
      "Predict: \teastern time /location/location/contains\n",
      "Ground-Truth: \tbosnia srebrenica /location/location/contains\n",
      "---\n",
      "Predict: \ta washington /people/person/place_lived\n",
      "Ground-Truth: \tupper fort /location/location/contains\n",
      "---\n",
      "Predict: \tchef pic /business/person/company\n",
      "Ground-Truth: \tfrance valence /location/location/contains\n",
      "---\n",
      "Predict: \tjames spain /people/person/nationality\n",
      "Ground-Truth: \tjames tampa /people/person/place_lived\n",
      "---\n",
      "Predict: \tpresident house /people/person/place_lived\n",
      "Ground-Truth: \tsyria damascus /location/country/administrative_divisions\n",
      "---\n",
      "Predict: \ta marshall /location/location/contains\n",
      "Ground-Truth: \tmarshall fremont /people/deceased_person/place_of_death\n",
      "---\n",
      "Predict: \tjerusalem israel /location/location/contains\n",
      "Ground-Truth: \tisrael jerusalem /location/location/contains\n",
      "---\n",
      "Predict: \tsunni iraq /location/location/contains\n",
      "Ground-Truth: \tiran syria /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcambridge university /location/location/contains\n",
      "Ground-Truth: \tcambridge lesley /location/location/contains\n",
      "---\n",
      "Predict: \tchris australia /people/person/nationality\n",
      "Ground-Truth: \tchris australia /people/person/nationality\n",
      "---\n",
      "Predict: \tdennis rice /business/person/company\n",
      "Ground-Truth: \tdennis disney /business/person/company\n",
      "---\n",
      "Predict: \taspen company /location/location/contains\n",
      "Ground-Truth: \tcolorado aspen /location/location/contains\n",
      "---\n",
      "Predict: \tsouth seoul /location/country/administrative_divisions\n",
      "Ground-Truth: \tsouth seoul /location/location/contains\n",
      "---\n",
      "Predict: \tstaten fort /location/location/contains\n",
      "Ground-Truth: \tstaten fort /location/location/contains\n",
      "---\n",
      "Predict: \tsyria damascus /location/country/administrative_divisions\n",
      "Ground-Truth: \tdamascus syria /location/administrative_division/country\n",
      "---\n",
      "Predict: \tmexico city /location/country/administrative_divisions\n",
      "Ground-Truth: \tmexico mexico /location/administrative_division/country\n",
      "---\n",
      "Predict: \ta france /people/person/nationality\n",
      "Ground-Truth: \tjean-louis france /people/person/nationality\n",
      "---\n",
      "Predict: \tfrance airbus /location/location/contains\n",
      "Ground-Truth: \tfrance toulouse /location/location/contains\n",
      "---\n",
      "Predict: \tjim kentucky /people/person/place_lived\n",
      "Ground-Truth: \tjim kentucky /people/person/place_lived\n",
      "---\n",
      "Predict: \tberlin germany /location/administrative_division/country\n",
      "Ground-Truth: \tberlin germany /location/administrative_division/country\n",
      "---\n",
      "Predict: \tisrael lebanon /location/location/contains\n",
      "Ground-Truth: \tisrael lebanon /location/administrative_division/country\n",
      "---\n",
      "Predict: \tjames brett /business/person/company\n",
      "Ground-Truth: \tbrett priceline /business/person/company\n",
      "---\n",
      "Predict: \tcenter jersey /location/location/contains\n",
      "Ground-Truth: \tnewark jersey /location/location/contains\n",
      "---\n",
      "Predict: \tpeter columbia /business/person/company\n",
      "Ground-Truth: \tpeter columbia /business/person/company\n",
      "---\n",
      "Predict: \tmikhail academy /business/person/company\n",
      "Ground-Truth: \tleningrad vaganova /location/location/contains\n",
      "---\n",
      "Predict: \ta mexico /people/person/nationality\n",
      "Ground-Truth: \tmexico jalisco /location/country/administrative_divisions\n",
      "---\n",
      "Predict: \twestchester york /location/location/contains\n",
      "Ground-Truth: \twestchester mamaroneck /location/location/contains\n",
      "---\n",
      "Predict: \teurope united /location/location/contains\n",
      "Ground-Truth: \tsyria iran /location/administrative_division/country\n",
      "---\n",
      "Predict: \tseminole a /location/location/contains\n",
      "Ground-Truth: \tbrittany seminole /people/person/place_lived\n",
      "---\n",
      "Predict: \tmexico city /location/country/administrative_divisions\n",
      "Ground-Truth: \tmexico mexico /location/administrative_division/country\n",
      "---\n",
      "Predict: \tgermany munich /location/location/contains\n",
      "Ground-Truth: \tgermany munich /location/location/contains\n",
      "---\n",
      "Predict: \ta switzerland /people/person/nationality\n",
      "Ground-Truth: \ternst davos /people/deceased_person/place_of_death\n",
      "---\n",
      "Predict: \ta review /business/person/company\n",
      "Ground-Truth: \tcuba guantanamo /location/location/contains\n",
      "---\n",
      "Predict: \ta baseball /business/person/company\n",
      "Ground-Truth: \thavana cuba /location/administrative_division/country\n",
      "---\n",
      "Predict: \tgermany stuttgart /location/location/contains\n",
      "Ground-Truth: \tgermany stuttgart /location/location/contains\n",
      "---\n",
      "Predict: \tjeffrey general /business/person/company\n",
      "Ground-Truth: \tjeffrey general /business/person/company\n",
      "---\n",
      "Predict: \ta poland /people/person/nationality\n",
      "Ground-Truth: \tpoland cracow /location/location/contains\n",
      "---\n",
      "Predict: \tsenator minnesota /people/person/place_lived\n",
      "Ground-Truth: \tnorm minnesota /people/person/place_lived\n",
      "---\n",
      "Predict: \thampshire york /location/location/contains\n",
      "Ground-Truth: \tsouth iowa /location/administrative_division/country\n",
      "---\n",
      "Predict: \tsouth seoul /location/country/administrative_divisions\n",
      "Ground-Truth: \tseoul south /location/administrative_division/country\n",
      "---\n",
      "Predict: \tkofmehl charleston /people/person/place_lived\n",
      "Ground-Truth: \tfrance paris /location/location/contains\n",
      "---\n",
      "Predict: \tkofmehl charleston /people/person/place_lived\n",
      "Ground-Truth: \tfrance paris /location/location/contains\n",
      "---\n",
      "Predict: \twill meet /people/person/place_lived\n",
      "Ground-Truth: \tjordan amman /location/location/contains\n",
      "---\n",
      "Predict: \tblack robert /business/company/founders\n",
      "Ground-Truth: \tblack robert /business/company/founders\n",
      "---\n",
      "Predict: \ta arkansas /people/person/place_lived\n",
      "Ground-Truth: \tarkansas arkadelphia /location/location/contains\n",
      "---\n",
      "Predict: \ta northern /location/administrative_division/country\n",
      "Ground-Truth: \tnavarre spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \ta grant /business/person/company\n",
      "Ground-Truth: \ttoronto canada /location/administrative_division/country\n",
      "---\n",
      "Predict: \twest york /location/location/contains\n",
      "Ground-Truth: \tconey york /location/location/contains\n",
      "---\n",
      "Predict: \twashington amsterdam /location/location/contains\n",
      "Ground-Truth: \tport harborside /location/location/contains\n",
      "---\n",
      "Predict: \ttom iowa /people/person/place_lived\n",
      "Ground-Truth: \ttom iowa /people/person/place_lived\n",
      "---\n",
      "Predict: \tnorthern israel /location/location/contains\n",
      "Ground-Truth: \tgaza israel /location/administrative_division/country\n",
      "---\n",
      "Predict: \tnational california /location/location/contains\n",
      "Ground-Truth: \tcalifornia lawrence /location/location/contains\n",
      "---\n",
      "Predict: \tamerican france /people/person/nationality\n",
      "Ground-Truth: \tparis france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tlatin mexico /location/location/contains\n",
      "Ground-Truth: \tmexico guadalajara /location/location/contains\n",
      "---\n",
      "Predict: \tyork city /location/location/contains\n",
      "Ground-Truth: \tlower york /location/neighborhood/neighborhood_of\n",
      "---\n",
      "Predict: \tcruise lrb /location/location/contains\n",
      "Ground-Truth: \tfrance italy /location/administrative_division/country\n",
      "---\n",
      "Predict: \tsan francisco /location/location/contains\n",
      "Ground-Truth: \tsonoma occidental /location/location/contains\n",
      "---\n",
      "Predict: \ta christopher /business/company/founders\n",
      "Ground-Truth: \tchristopher security /business/person/company\n",
      "---\n",
      "Predict: \ta india /people/person/nationality\n",
      "Ground-Truth: \tindia hyderabad /location/location/contains\n",
      "---\n",
      "Predict: \tsubject kentucky /people/person/place_lived\n",
      "Ground-Truth: \tmitch kentucky /people/person/place_lived\n",
      "---\n",
      "Predict: \tbill nebraska /people/person/place_lived\n",
      "Ground-Truth: \tben nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tgov rep /people/person/place_lived\n",
      "Ground-Truth: \ttommy wisconsin /people/person/place_lived\n",
      "---\n",
      "Predict: \tthailand bangkok /location/country/administrative_divisions\n",
      "Ground-Truth: \tbangkok thailand /location/administrative_division/country\n",
      "---\n",
      "Predict: \tparent foundation /location/location/contains\n",
      "Ground-Truth: \tcalifornia malibu /location/location/contains\n",
      "---\n",
      "Predict: \tberkeley boy /location/location/contains\n",
      "Ground-Truth: \tayelet berkeley /people/person/place_lived\n",
      "---\n",
      "Predict: \tcuba american /location/location/contains\n",
      "Ground-Truth: \tcuba guantanamo /location/location/contains\n",
      "---\n",
      "Predict: \tkansa kathleen /location/location/contains\n",
      "Ground-Truth: \tkathleen kansa /people/person/place_lived\n",
      "---\n",
      "Predict: \tyork city /location/location/contains\n",
      "Ground-Truth: \tyork greenwich /location/location/contains\n",
      "---\n",
      "Predict: \tsenator kentucky /people/person/place_lived\n",
      "Ground-Truth: \tmitch kentucky /people/person/place_lived\n",
      "---\n",
      "Predict: \twest bank /location/location/contains\n",
      "Ground-Truth: \tisrael west /location/administrative_division/country\n",
      "---\n",
      "Predict: \ttanzania mount /location/location/contains\n",
      "Ground-Truth: \tmount tanzania /location/administrative_division/country\n",
      "---\n",
      "Predict: \tisrael lebanon /location/location/contains\n",
      "Ground-Truth: \tisrael lebanon /location/administrative_division/country\n",
      "---\n",
      "Predict: \tireland margaret /location/location/contains\n",
      "Ground-Truth: \tireland athenry /location/location/contains\n",
      "---\n",
      "Predict: \tunited iran /location/country/administrative_divisions\n",
      "Ground-Truth: \tiran russia /location/administrative_division/country\n",
      "---\n",
      "Predict: \tberlin germany /location/administrative_division/country\n",
      "Ground-Truth: \tberlin germany /location/administrative_division/country\n",
      "---\n",
      "Predict: \ta lebanon /people/person/nationality\n",
      "Ground-Truth: \tisrael lebanon /location/administrative_division/country\n",
      "---\n",
      "Predict: \ta russia /people/person/nationality\n",
      "Ground-Truth: \trussia iran /location/administrative_division/country\n",
      "---\n",
      "Predict: \ta university /location/location/contains\n",
      "Ground-Truth: \teugene university /location/location/contains\n",
      "---\n",
      "Predict: \tspain well /location/location/contains\n",
      "Ground-Truth: \tcatalonia spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \tsouth australia /location/location/contains\n",
      "Ground-Truth: \taustralia port /location/location/contains\n",
      "---\n",
      "Predict: \ta indigenous /people/person/nationality\n",
      "Ground-Truth: \tevo bolivia /people/person/nationality\n",
      "---\n",
      "Predict: \theart germany /location/administrative_division/country\n",
      "Ground-Truth: \tberlin germany /location/administrative_division/country\n",
      "---\n",
      "Predict: \tsouth will /location/location/contains\n",
      "Ground-Truth: \tsouth darlington /location/location/contains\n",
      "---\n",
      "Predict: \ta official /business/person/company\n",
      "Ground-Truth: \tnelson zimbabwe /people/person/nationality\n",
      "---\n",
      "Predict: \ta israel /people/person/nationality\n",
      "Ground-Truth: \tisrael ra'anana /location/location/contains\n",
      "---\n",
      "Predict: \tindia state /location/location/contains\n",
      "Ground-Truth: \tindia bihar /location/location/contains\n",
      "---\n",
      "Predict: \tehud israel /people/person/nationality\n",
      "Ground-Truth: \tehud israel /people/person/nationality\n",
      "---\n",
      "Predict: \tindia a /location/location/contains\n",
      "Ground-Truth: \tgujarat india /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcleveland cuyahoga /location/location/contains\n",
      "Ground-Truth: \tcuyahoga cleveland /location/location/contains\n",
      "---\n",
      "Predict: \tflorida princeton /location/location/contains\n",
      "Ground-Truth: \tflorida gulf /location/location/contains\n",
      "---\n",
      "Predict: \tindia delhi /location/country/administrative_divisions\n",
      "Ground-Truth: \tindia delhi /location/location/contains\n",
      "---\n",
      "Predict: \tmexico 30 /location/location/contains\n",
      "Ground-Truth: \tmexico mexico /location/location/contains\n",
      "---\n",
      "Predict: \tindonesia india /location/administrative_division/country\n",
      "Ground-Truth: \titaly india /location/administrative_division/country\n",
      "---\n",
      "Predict: \ta east /people/person/place_lived\n",
      "Ground-Truth: \tisrael west /location/administrative_division/country\n",
      "---\n",
      "Predict: \tjerusalem mother /location/location/contains\n",
      "Ground-Truth: \tjerusalem yad /location/location/contains\n",
      "---\n",
      "Predict: \tehud israel /people/person/nationality\n",
      "Ground-Truth: \tehud israel /people/person/nationality\n",
      "---\n",
      "Predict: \titaly well /location/location/contains\n",
      "Ground-Truth: \titaly maranello /location/location/contains\n",
      "---\n",
      "Predict: \twest israel /location/location/contains\n",
      "Ground-Truth: \tisrael west /location/administrative_division/country\n",
      "---\n",
      "Predict: \tben nebraska /people/person/place_lived\n",
      "Ground-Truth: \tben nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tafrica india /location/location/contains\n",
      "Ground-Truth: \tindia bihar /location/location/contains\n",
      "---\n",
      "Predict: \tbashar syria /people/person/nationality\n",
      "Ground-Truth: \tbashar syria /people/person/nationality\n",
      "---\n",
      "Predict: \tlouisiana baton /location/location/contains\n",
      "Ground-Truth: \tlouisiana baton /location/location/contains\n",
      "---\n",
      "Predict: \tnuclear iran /location/location/contains\n",
      "Ground-Truth: \tiran middle /location/administrative_division/country\n",
      "---\n",
      "Predict: \tsony united /business/person/company\n",
      "Ground-Truth: \tsony akio /business/company/founders\n",
      "---\n",
      "Predict: \tisrael brad /location/location/contains\n",
      "Ground-Truth: \tshimon israel /people/person/nationality\n",
      "---\n",
      "Predict: \tindonesia india /location/administrative_division/country\n",
      "Ground-Truth: \titaly india /location/administrative_division/country\n",
      "---\n",
      "Predict: \tsouthern art /location/location/contains\n",
      "Ground-Truth: \tcalabria crotone /location/location/contains\n",
      "---\n",
      "Predict: \tflorida boca /location/location/contains\n",
      "Ground-Truth: \tflorida boca /location/location/contains\n",
      "---\n",
      "Predict: \ta claim /location/location/contains\n",
      "Ground-Truth: \tmexico guadalajara /location/location/contains\n",
      "---\n",
      "Predict: \tgroup congress /location/location/contains\n",
      "Ground-Truth: \tderrick ford /business/person/company\n",
      "---\n",
      "Predict: \twest chicago /location/location/contains\n",
      "Ground-Truth: \tchicago west /location/location/contains\n",
      "---\n",
      "Predict: \tcarter virginia /people/person/place_lived\n",
      "Ground-Truth: \tvirginia middleburg /location/location/contains\n",
      "---\n",
      "Predict: \tstate oklahoma /location/location/contains\n",
      "Ground-Truth: \tbrad oklahoma /people/person/place_lived\n",
      "---\n",
      "Predict: \tcalifornia berkeley /location/location/contains\n",
      "Ground-Truth: \tcalifornia berkeley /location/location/contains\n",
      "---\n",
      "Predict: \titaly germany /location/administrative_division/country\n",
      "Ground-Truth: \titaly germany /location/administrative_division/country\n",
      "---\n",
      "Predict: \tchicago state /location/location/contains\n",
      "Ground-Truth: \tcook chicago /location/location/contains\n",
      "---\n",
      "Predict: \tsuffolk ocean /location/location/contains\n",
      "Ground-Truth: \tfire ocean /location/location/contains\n",
      "---\n",
      "Predict: \tmexico central /location/country/administrative_divisions\n",
      "Ground-Truth: \tmexico mexico /location/administrative_division/country\n",
      "---\n",
      "Predict: \trepublican kentucky /people/person/place_lived\n",
      "Ground-Truth: \tmitch kentucky /people/person/place_lived\n",
      "---\n",
      "Predict: \tpresident chief /business/person/company\n",
      "Ground-Truth: \tshona google /business/person/company\n",
      "---\n",
      "Predict: \tgeorge france /people/person/nationality\n",
      "Ground-Truth: \tparis france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tnorth mexico /location/location/contains\n",
      "Ground-Truth: \tjuarez mexico /location/administrative_division/country\n",
      "---\n",
      "Predict: \tminister work /people/person/nationality\n",
      "Ground-Truth: \tehud israel /people/person/nationality\n",
      "---\n",
      "Predict: \tpavony israel /people/person/nationality\n",
      "Ground-Truth: \tisrael rehovot /location/location/contains\n",
      "---\n",
      "Predict: \tzeitlin york /business/person/company\n",
      "Ground-Truth: \twill york /business/person/company\n",
      "---\n",
      "Predict: \tboston college /location/location/contains\n",
      "Ground-Truth: \tjuliet boston /business/person/company\n",
      "---\n",
      "Predict: \tgreece italy /location/location/contains\n",
      "Ground-Truth: \titaly france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tleader kentucky /people/person/place_lived\n",
      "Ground-Truth: \tmitch kentucky /people/person/place_lived\n",
      "---\n",
      "Predict: \tcapuchinas mexico /location/administrative_division/country\n",
      "Ground-Truth: \tmexico puebla /location/location/contains\n",
      "---\n",
      "Predict: \tlrb rrb /location/location/contains\n",
      "Ground-Truth: \tspain cordoba /location/location/contains\n",
      "---\n",
      "Predict: \tsenator kentucky /people/person/place_lived\n",
      "Ground-Truth: \tmitch kentucky /people/person/place_lived\n",
      "---\n",
      "Predict: \tisrael gaza /location/location/contains\n",
      "Ground-Truth: \tisrael west /location/administrative_division/country\n",
      "---\n",
      "Predict: \ttoronto university /location/location/contains\n",
      "Ground-Truth: \ttoronto mount /location/location/contains\n",
      "---\n",
      "Predict: \tunited delhi /location/country/administrative_divisions\n",
      "Ground-Truth: \tdelhi india /location/administrative_division/country\n",
      "---\n",
      "Predict: \toregon portland /location/location/contains\n",
      "Ground-Truth: \tcanada calgary /location/location/contains\n",
      "---\n",
      "Predict: \tp.m. american /location/location/contains\n",
      "Ground-Truth: \tontario canada /location/administrative_division/country\n",
      "---\n",
      "Predict: \twoman player /people/person/children\n",
      "Ground-Truth: \tnikolay russia /people/person/nationality\n",
      "---\n",
      "Predict: \ta national /business/person/company\n",
      "Ground-Truth: \tvali naval /business/person/company\n",
      "---\n",
      "Predict: \tmexico spain /location/country/administrative_divisions\n",
      "Ground-Truth: \tspain italy /location/administrative_division/country\n",
      "---\n",
      "Predict: \tparis de /location/location/contains\n",
      "Ground-Truth: \tparis ecole /location/location/contains\n",
      "---\n",
      "Predict: \ta jersey /people/person/place_lived\n",
      "Ground-Truth: \tjordan amman /location/location/contains\n",
      "---\n",
      "Predict: \teurope a /location/location/contains\n",
      "Ground-Truth: \talgeria algiers /location/country/capital\n",
      "---\n",
      "Predict: \ta northern /people/person/nationality\n",
      "Ground-Truth: \tindia dharamsala /location/location/contains\n",
      "---\n",
      "Predict: \tflorida lake /location/location/contains\n",
      "Ground-Truth: \tflorida lake /location/location/contains\n",
      "---\n",
      "Predict: \ttime washington /business/person/company\n",
      "Ground-Truth: \tdonald washington /business/person/company\n",
      "---\n",
      "Predict: \tontario canada /location/administrative_division/country\n",
      "Ground-Truth: \tontario canada /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcalifornia republican /location/location/contains\n",
      "Ground-Truth: \tdana california /people/person/place_lived\n",
      "---\n",
      "Predict: \tmiddle germany /location/location/contains\n",
      "Ground-Truth: \tgermany nuremberg /location/location/contains\n",
      "---\n",
      "Predict: \tpaul bank /business/person/company\n",
      "Ground-Truth: \tstanley bank /business/person/company\n",
      "---\n",
      "Predict: \tpark city /location/location/contains\n",
      "Ground-Truth: \tlower battery /location/location/contains\n",
      "---\n",
      "Predict: \tlloyd museum /people/person/place_lived\n",
      "Ground-Truth: \tfrank lloyd /people/person/children\n",
      "---\n",
      "Predict: \tmexico state /location/country/administrative_divisions\n",
      "Ground-Truth: \tmexico guadalajara /location/location/contains\n",
      "---\n",
      "Predict: \tstate lebanon /location/location/contains\n",
      "Ground-Truth: \tdamascus syria /location/administrative_division/country\n",
      "---\n",
      "Predict: \tparis france /location/administrative_division/country\n",
      "Ground-Truth: \tfrance paris /location/location/contains\n",
      "---\n",
      "Predict: \tpeck york /people/person/place_lived\n",
      "Ground-Truth: \tyork peck /location/location/contains\n",
      "---\n",
      "Predict: \tchina iran /location/country/administrative_divisions\n",
      "Ground-Truth: \tiran russia /location/administrative_division/country\n",
      "---\n",
      "Predict: \twest east /location/location/contains\n",
      "Ground-Truth: \ttaiwan taipei /location/location/contains\n",
      "---\n",
      "Predict: \tsex iraqi /location/location/contains\n",
      "Ground-Truth: \tdamascus syria /location/administrative_division/country\n",
      "---\n",
      "Predict: \ta italy /people/person/nationality\n",
      "Ground-Truth: \titaly spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \tontario andrew /location/location/contains\n",
      "Ground-Truth: \tontario kingston /location/location/contains\n",
      "---\n",
      "Predict: \tisrael shimon /location/location/contains\n",
      "Ground-Truth: \tshimon israel /people/person/nationality\n",
      "---\n",
      "Predict: \tbaja a /location/location/contains\n",
      "Ground-Truth: \tmexico baja /location/location/contains\n",
      "---\n",
      "Predict: \tpolice india /location/administrative_division/country\n",
      "Ground-Truth: \tindia chhattisgarh /location/location/contains\n",
      "---\n",
      "Predict: \tmichoacan mexico /location/administrative_division/country\n",
      "Ground-Truth: \tmichoacan mexico /location/administrative_division/country\n",
      "---\n",
      "Predict: \tamansala mexico /location/administrative_division/country\n",
      "Ground-Truth: \tmexico tulum /location/location/contains\n",
      "---\n",
      "Predict: \tgeorgia atlanta /location/location/contains\n",
      "Ground-Truth: \tatlanta georgia /location/location/contains\n",
      "---\n",
      "Predict: \twater year /location/location/contains\n",
      "Ground-Truth: \tberkeley chez /location/location/contains\n",
      "---\n",
      "Predict: \taustralia 4 /location/location/contains\n",
      "Ground-Truth: \tlibby australia /people/person/nationality\n",
      "---\n",
      "Predict: \tspain general /location/location/contains\n",
      "Ground-Truth: \tjose spain /people/person/nationality\n",
      "---\n",
      "Predict: \ta american /business/person/company\n",
      "Ground-Truth: \twashington iran /location/administrative_division/country\n",
      "---\n",
      "Predict: \tmark hewlett-packard /business/person/company\n",
      "Ground-Truth: \tmark hewlett-packard /business/person/company\n",
      "---\n",
      "Predict: \tparis national /location/location/contains\n",
      "Ground-Truth: \tparis musee /location/location/contains\n",
      "---\n",
      "Predict: \ta 1938 /people/person/place_of_birth\n",
      "Ground-Truth: \tparis france /location/administrative_division/country\n",
      "---\n",
      "Predict: \thouston charles /location/location/contains\n",
      "Ground-Truth: \tharris houston /location/location/contains\n",
      "---\n",
      "Predict: \ta cuba /people/person/nationality\n",
      "Ground-Truth: \thavana cuba /location/administrative_division/country\n",
      "---\n",
      "Predict: \tpuzzle time /business/person/company\n",
      "Ground-Truth: \twill time /business/person/company\n",
      "---\n",
      "Predict: \twest israel /location/location/contains\n",
      "Ground-Truth: \tisrael west /location/administrative_division/country\n",
      "---\n",
      "Predict: \tchicago york /location/location/contains\n",
      "Ground-Truth: \tchicago winston /location/location/contains\n",
      "---\n",
      "Predict: \tenergy iraq /location/location/contains\n",
      "Ground-Truth: \tamory rocky /business/person/company\n",
      "---\n",
      "Predict: \tgeorge rochester /people/person/place_lived\n",
      "Ground-Truth: \trochester george /location/location/contains\n",
      "---\n",
      "Predict: \tmexico cancun /location/location/contains\n",
      "Ground-Truth: \tmexico cancun /location/location/contains\n",
      "---\n",
      "Predict: \triver a /location/location/contains\n",
      "Ground-Truth: \tidaho salmon /location/location/contains\n",
      "---\n",
      "Predict: \tafrica west /location/location/contains\n",
      "Ground-Truth: \twest senegal /location/location/contains\n",
      "---\n",
      "Predict: \ta york /people/person/place_lived\n",
      "Ground-Truth: \tyork staten /location/location/contains\n",
      "---\n",
      "Predict: \ttxu group /business/person/company\n",
      "Ground-Truth: \tstephen blackstone /business/person/company\n",
      "---\n",
      "Predict: \tontario university /location/location/contains\n",
      "Ground-Truth: \tontario kingston /location/location/contains\n",
      "---\n",
      "Predict: \tpark a /location/location/contains\n",
      "Ground-Truth: \twestport winslow /location/location/contains\n",
      "---\n",
      "Predict: \tbaltimore bank /location/location/contains\n",
      "Ground-Truth: \tbaltimore m&t /location/location/contains\n",
      "---\n",
      "Predict: \twashington walter /location/location/contains\n",
      "Ground-Truth: \twashington walter /location/location/contains\n",
      "---\n",
      "Predict: \tunited mexico /location/country/administrative_divisions\n",
      "Ground-Truth: \tguanajuato mexico /location/administrative_division/country\n",
      "---\n",
      "Predict: \tindia central /location/country/administrative_divisions\n",
      "Ground-Truth: \tbihar india /location/administrative_division/country\n",
      "---\n",
      "Predict: \titaly france /people/person/nationality\n",
      "Ground-Truth: \titaly france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tyork university /location/location/contains\n",
      "Ground-Truth: \tdennis york /business/person/company\n",
      "---\n",
      "Predict: \t5 east /location/location/contains\n",
      "Ground-Truth: \tkansa atchison /location/location/contains\n",
      "---\n",
      "Predict: \thospital massachusetts /location/location/contains\n",
      "Ground-Truth: \tboston massachusetts /location/location/contains\n",
      "---\n",
      "Predict: \tmount a /location/location/contains\n",
      "Ground-Truth: \twashington mount /location/location/contains\n",
      "---\n",
      "Predict: \tcuba american /location/location/contains\n",
      "Ground-Truth: \tcuba guantanamo /location/location/contains\n",
      "---\n",
      "Predict: \tdepartment right /location/location/contains\n",
      "Ground-Truth: \twashington united /location/location/contains\n",
      "---\n",
      "Predict: \tflorida boca /location/location/contains\n",
      "Ground-Truth: \tflorida boca /location/location/contains\n",
      "---\n",
      "Predict: \tfree spain /people/person/nationality\n",
      "Ground-Truth: \titaly spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \tbill white /business/person/company\n",
      "Ground-Truth: \teddie reebok /business/person/company\n",
      "---\n",
      "Predict: \tontario st /location/location/contains\n",
      "Ground-Truth: \tontario st /location/location/contains\n",
      "---\n",
      "Predict: \tiraq nebraska /people/person/place_lived\n",
      "Ground-Truth: \tchuck nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tflorida john /location/location/contains\n",
      "Ground-Truth: \tflorida ponte /location/location/contains\n",
      "---\n",
      "Predict: \tkorea a /location/location/contains\n",
      "Ground-Truth: \tseoul south /location/administrative_division/country\n",
      "---\n",
      "Predict: \tflorida lake /location/location/contains\n",
      "Ground-Truth: \tflorida lake /location/location/contains\n",
      "---\n",
      "Predict: \tmiami chicago /location/location/contains\n",
      "Ground-Truth: \tchicago sears /location/location/contains\n",
      "---\n",
      "Predict: \twebkinz ontario /people/person/place_lived\n",
      "Ground-Truth: \tontario woodbridge /location/location/contains\n",
      "---\n",
      "Predict: \twashington congress /location/location/contains\n",
      "Ground-Truth: \twashington national /location/location/contains\n",
      "---\n",
      "Predict: \tguinea people /location/country/administrative_divisions\n",
      "Ground-Truth: \tguinea conakry /location/country/capital\n",
      "---\n",
      "Predict: \tiowa waterloo /location/location/contains\n",
      "Ground-Truth: \tiowa waterloo /location/location/contains\n",
      "---\n",
      "Predict: \titaly pizza /location/location/contains\n",
      "Ground-Truth: \titaly amalfi /location/location/contains\n",
      "---\n",
      "Predict: \ta lrb /business/person/company\n",
      "Ground-Truth: \titaly france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tjersey delaware /location/location/contains\n",
      "Ground-Truth: \twestchester hudson /location/location/contains\n",
      "---\n",
      "Predict: \ta institute /business/person/company\n",
      "Ground-Truth: \tg. georgia /business/person/company\n",
      "---\n",
      "Predict: \tcuba bush /location/location/contains\n",
      "Ground-Truth: \tcuba guantanamo /location/location/contains\n",
      "---\n",
      "Predict: \thill blue /location/location/contains\n",
      "Ground-Truth: \tberkeley chez /location/location/contains\n",
      "---\n",
      "Predict: \tisrael gaza /location/location/contains\n",
      "Ground-Truth: \tgaza israel /location/administrative_division/country\n",
      "---\n",
      "Predict: \tchuck nebraska /people/person/place_lived\n",
      "Ground-Truth: \tchuck nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tphotographer time /business/person/company\n",
      "Ground-Truth: \ttyler york /business/person/company\n",
      "---\n",
      "Predict: \tindonesia india /location/administrative_division/country\n",
      "Ground-Truth: \titaly india /location/administrative_division/country\n",
      "---\n",
      "Predict: \tontario canada /location/administrative_division/country\n",
      "Ground-Truth: \tcanada ontario /location/location/contains\n",
      "---\n",
      "Predict: \tgovernment federal /location/location/contains\n",
      "Ground-Truth: \ttoledo ottawa /location/location/contains\n",
      "---\n",
      "Predict: \talexander namibia /people/person/nationality\n",
      "Ground-Truth: \tnamibia windhoek /location/location/contains\n",
      "---\n",
      "Predict: \tunited mamaroneck /location/location/contains\n",
      "Ground-Truth: \tmamaroneck united /location/location/contains\n",
      "---\n",
      "Predict: \tvermont long /location/location/contains\n",
      "Ground-Truth: \tvermont stowe /location/location/contains\n",
      "---\n",
      "Predict: \twork netherlands /people/person/nationality\n",
      "Ground-Truth: \titaly spain /location/administrative_division/country\n",
      "---\n",
      "Predict: \thamburg france /location/administrative_division/country\n",
      "Ground-Truth: \tfrance toulouse /location/location/contains\n",
      "---\n",
      "Predict: \tiraq iran /location/location/contains\n",
      "Ground-Truth: \twashington iran /location/administrative_division/country\n",
      "---\n",
      "Predict: \tfrance corsica /location/country/administrative_divisions\n",
      "Ground-Truth: \tcorsica france /location/administrative_division/country\n",
      "---\n",
      "Predict: \tsyria damascus /location/country/administrative_divisions\n",
      "Ground-Truth: \tsyria damascus /location/location/contains\n",
      "---\n",
      "Predict: \tbritish india /location/administrative_division/country\n",
      "Ground-Truth: \tshilpa india /people/person/nationality\n",
      "---\n",
      "Predict: \tfinland a /location/location/contains\n",
      "Ground-Truth: \tfinland turku /location/location/contains\n",
      "---\n",
      "Predict: \tdirector germany /people/person/nationality\n",
      "Ground-Truth: \tgermany stuttgart /location/location/contains\n",
      "---\n",
      "Predict: \tboston beth /location/location/contains\n",
      "Ground-Truth: \tboston beth /location/location/contains\n",
      "---\n",
      "Predict: \tchairman gov /people/person/place_lived\n",
      "Ground-Truth: \ttim minnesota /people/person/place_lived\n",
      "---\n",
      "Predict: \tdrexler york /people/person/place_lived\n",
      "Ground-Truth: \trockland city /location/location/contains\n",
      "---\n",
      "Predict: \ta harvard /business/person/company\n",
      "Ground-Truth: \tmartin national /business/person/company\n",
      "---\n",
      "Predict: \tpeter toronto /people/person/place_lived\n",
      "Ground-Truth: \ttoronto barrick /location/location/contains\n",
      "---\n",
      "Predict: \tlake northern /location/location/contains\n",
      "Ground-Truth: \tlake chicago /location/administrative_division/country\n",
      "---\n",
      "Predict: \tmass bedford /location/location/contains\n",
      "Ground-Truth: \tmarlborough cytyc /location/location/contains\n",
      "---\n",
      "Predict: \tfrance southern /location/country/administrative_divisions\n",
      "Ground-Truth: \tfrance alzonne /location/location/contains\n",
      "---\n",
      "Predict: \tafrican art /location/location/contains\n",
      "Ground-Truth: \twashington national /location/location/contains\n",
      "---\n",
      "Predict: \tmexico juarez /location/location/contains\n",
      "Ground-Truth: \tmexico ciudad /location/location/contains\n",
      "---\n",
      "Predict: \tamerican administration /location/location/contains\n",
      "Ground-Truth: \tiran syria /location/administrative_division/country\n",
      "---\n",
      "Predict: \twest bank /location/location/contains\n",
      "Ground-Truth: \tisrael west /location/administrative_division/country\n",
      "---\n",
      "Predict: \taudubon vermont /location/location/contains\n",
      "Ground-Truth: \tvermont stowe /location/location/contains\n",
      "---\n",
      "Predict: \ta north /location/location/contains\n",
      "Ground-Truth: \tconnecticut hamden /location/location/contains\n",
      "---\n",
      "Predict: \trussia system /location/location/contains\n",
      "Ground-Truth: \trussia iran /location/administrative_division/country\n",
      "---\n",
      "Predict: \tsyria iran /location/administrative_division/country\n",
      "Ground-Truth: \tsyria iran /location/administrative_division/country\n",
      "---\n",
      "Predict: \ta nebraska /people/person/place_lived\n",
      "Ground-Truth: \tchuck nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tchuck nebraska /people/person/place_lived\n",
      "Ground-Truth: \tchuck nebraska /people/person/place_lived\n",
      "---\n",
      "Predict: \tiowa university /location/location/contains\n",
      "Ground-Truth: \tiowa waverly /location/location/contains\n",
      "---\n",
      "Predict: \tcuba boston /location/location/contains\n",
      "Ground-Truth: \tcuba bayamo /location/location/contains\n",
      "---\n",
      "Predict: \tafrica south /location/location/contains\n",
      "Ground-Truth: \taziz south /people/person/nationality\n",
      "---\n",
      "Predict: \tuniversity canada /location/administrative_division/country\n",
      "Ground-Truth: \titaly reggio /location/location/contains\n",
      "---\n",
      "Predict: \tiran washington /location/location/contains\n",
      "Ground-Truth: \tiran washington /location/administrative_division/country\n",
      "---\n",
      "Predict: \tpark mountain /location/location/contains\n",
      "Ground-Truth: \thampshire cannon /location/location/contains\n",
      "---\n",
      "Predict: \tguatemala mother /location/location/contains\n",
      "Ground-Truth: \thelen guatemala /people/person/place_lived\n",
      "---\n",
      "Predict: \tiraq afghanistan /location/location/contains\n",
      "Ground-Truth: \tromania black /location/location/contains\n",
      "---\n",
      "Predict: \tsyria iran /location/administrative_division/country\n",
      "Ground-Truth: \tiran syria /location/administrative_division/country\n",
      "---\n",
      "Predict: \tcollege florida /location/location/contains\n",
      "Ground-Truth: \tdecatur agnes /location/location/contains\n",
      "---\n",
      "Predict: \tnatural north /location/location/contains\n",
      "Ground-Truth: \trobin north /business/person/company\n",
      "---\n",
      "Predict: \tlove philippine /people/person/nationality\n",
      "Ground-Truth: \timelda philippine /people/person/nationality\n",
      "---\n",
      "Predict: \tharrelson federal /business/person/company\n",
      "Ground-Truth: \tcharles woody /people/person/children\n",
      "---\n",
      "Predict: \ta maryland /location/location/contains\n",
      "Ground-Truth: \tmaryland annapolis /location/location/contains\n",
      "---\n",
      "Predict: \tparis gare /location/location/contains\n",
      "Ground-Truth: \tparis gare /location/location/contains\n",
      "---\n",
      "Predict: \tgood case /business/person/company\n",
      "Ground-Truth: \tstephen case /business/person/company\n",
      "---\n",
      "Predict: \tboston bay /location/location/contains\n",
      "Ground-Truth: \tboston church /location/location/contains\n",
      "---\n",
      "Predict: \tmississippi haley /location/location/contains\n",
      "Ground-Truth: \thaley mississippi /people/person/place_lived\n",
      "---\n",
      "Predict: \tdemocrat rhode /people/person/place_lived\n",
      "Ground-Truth: \tsheldon rhode /people/person/place_lived\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in range(395):\n",
    "    print('Predict: \\t%s' % ' '.join(preResult[i]))\n",
    "    print('Ground-Truth: \\t%s' % ' '.join(actResult[i]))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'cp_logs/weights.336-2.599974.hdf5'\n",
    "model.load_weights(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def beamsearch(NUM_BEAMS):\n",
    "    preResult = []\n",
    "    for i in tqdm(range(395)):\n",
    "        fb_words = np.array([58840])\n",
    "        x = np.array([x_test[i]])\n",
    "    \n",
    "        st_words = np.array([58840])\n",
    "        st_input = pad_sequences([st_words], maxlen=MAX_ADJL_LEN, padding='post', truncating='post')\n",
    "        prob = model.predict([x, st_input], batch_size=BATCH_SIZE)[0][0]\n",
    "        prob[0] = -1\n",
    "        for item in [i for i in x_test[i] if i != 0]:\n",
    "            prob[item] = float(prob[item]+1)\n",
    "        beam = {}\n",
    "        for _ in range(NUM_BEAMS):\n",
    "            b = prob.argmax()\n",
    "            beam[b] = float(prob[b])\n",
    "            prob[b] = -1\n",
    "        \n",
    "        allResult = []\n",
    "        for b, s in beam.items():\n",
    "            pR = [b]\n",
    "            fb_words = np.append(fb_words, b)\n",
    "            tag = b\n",
    "            for j in range(1, MAX_ADJL_LEN):\n",
    "                fb_input = pad_sequences([fb_words], maxlen=MAX_ADJL_LEN, padding='post', truncating='post')\n",
    "                prob = model.predict([x, fb_input], batch_size=BATCH_SIZE)[0][j]\n",
    "                if j == 1:\n",
    "                    for item in [i for i in x_test[i] if i != 0]:\n",
    "                        prob[item] = float(prob[item]+1)\n",
    "                if j == 2:\n",
    "                    prob[:58828] = -1\n",
    "                prob[0] = -1\n",
    "                prob[tag] = -1\n",
    "                result = prob.argmax()\n",
    "                beam[b] += float(prob[result])\n",
    "                tag = result\n",
    "                pR.append(result)\n",
    "                fb_words = np.append(fb_words, result)            \n",
    "            allResult.append(pR)\n",
    "        pR = sum([i for i in allResult if i[0] == max(beam, key=lambda x: beam[x])], [])\n",
    "        preResult.append(pR)\n",
    "\n",
    "    preResult = [[index2word[i] for i in sent if i != 0] for sent in preResult]\n",
    "    actResult = [[index2word[i] for i in sent if i != 0] for sent in y_test]\n",
    "    e1Count = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0]])\n",
    "    e2Count = sum([1 for i in range(395) if actResult[i][1] == preResult[i][1]])\n",
    "    enCount = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0] and actResult[i][1] == preResult[i][1]])\n",
    "    reCount = sum([1 for i in range(395) if actResult[i][2] == preResult[i][2]])\n",
    "    tripleCount = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0] and actResult[i][1] == preResult[i][1] and actResult[i][2] == preResult[i][2]])\n",
    "    print('Beam: \\t\\t\\t%d' % NUM_BEAMS)\n",
    "    print('E1 Accuracy: \\t\\t%.6f' % (e1Count/395))\n",
    "    print('E2 Accuracy: \\t\\t%.6f' % (e2Count/395))\n",
    "    print('En Accuracy: \\t\\t%.6f' % (enCount/395))\n",
    "    print('Re Accuracy: \\t\\t%.6f' % (reCount/395))\n",
    "    print('Triple Accuracy: \\t%.6f' % (tripleCount/395))\n",
    "    print('--------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395/395 [02:13<00:00,  2.97it/s]\n",
      "  0%|          | 0/395 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam: \t\t\t1\n",
      "E1 Accuracy: \t\t0.291139\n",
      "E2 Accuracy: \t\t0.281013\n",
      "En Accuracy: \t\t0.139241\n",
      "Re Accuracy: \t\t0.506329\n",
      "Triple Accuracy: \t0.113924\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 395/395 [03:46<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beam: \t\t\t2\n",
      "E1 Accuracy: \t\t0.278481\n",
      "E2 Accuracy: \t\t0.298734\n",
      "En Accuracy: \t\t0.113924\n",
      "Re Accuracy: \t\t0.506329\n",
      "Triple Accuracy: \t0.075949\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for NUM_BEAMS in range(1, 3):\n",
    "    beamsearch(NUM_BEAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(395):\n",
    "    print('Predict: \\t%s' % ' '.join(preResult[i]))\n",
    "    print('Ground-Truth: \\t%s' % ' '.join(actResult[i]))\n",
    "    print('---')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
