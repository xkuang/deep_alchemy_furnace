{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#GPU\" data-toc-modified-id=\"GPU-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>GPU</a></div><div class=\"lev1 toc-item\"><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Preprocessing</a></div><div class=\"lev2 toc-item\"><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Load Data</a></div><div class=\"lev3 toc-item\"><a href=\"#Load-Train-Data\" data-toc-modified-id=\"Load-Train-Data-211\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Load Train Data</a></div><div class=\"lev3 toc-item\"><a href=\"#Load-Test-Data\" data-toc-modified-id=\"Load-Test-Data-212\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Load Test Data</a></div><div class=\"lev3 toc-item\"><a href=\"#Relation-Types\" data-toc-modified-id=\"Relation-Types-213\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Relation Types</a></div><div class=\"lev2 toc-item\"><a href=\"#Participle\" data-toc-modified-id=\"Participle-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Participle</a></div><div class=\"lev2 toc-item\"><a href=\"#Make-Adjacency-List\" data-toc-modified-id=\"Make-Adjacency-List-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Make Adjacency List</a></div><div class=\"lev3 toc-item\"><a href=\"#Make-Adjacency-List-of-Train-Data\" data-toc-modified-id=\"Make-Adjacency-List-of-Train-Data-231\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Make Adjacency List of Train Data</a></div><div class=\"lev3 toc-item\"><a href=\"#Make-Adjacency-List-of-Test-Data\" data-toc-modified-id=\"Make-Adjacency-List-of-Test-Data-232\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Make Adjacency List of Test Data</a></div><div class=\"lev1 toc-item\"><a href=\"#Word-to-Vector\" data-toc-modified-id=\"Word-to-Vector-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Word to Vector</a></div><div class=\"lev2 toc-item\"><a href=\"#Tokenize-Text\" data-toc-modified-id=\"Tokenize-Text-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Tokenize Text</a></div><div class=\"lev2 toc-item\"><a href=\"#Create-Word-Embeddings-with-GloVe\" data-toc-modified-id=\"Create-Word-Embeddings-with-GloVe-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Create Word Embeddings with GloVe</a></div><div class=\"lev3 toc-item\"><a href=\"#Read-GloVe\" data-toc-modified-id=\"Read-GloVe-321\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Read GloVe</a></div><div class=\"lev3 toc-item\"><a href=\"#Use-Glove-to-Initialize-Embedding-Matrix\" data-toc-modified-id=\"Use-Glove-to-Initialize-Embedding-Matrix-322\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Use Glove to Initialize Embedding Matrix</a></div><div class=\"lev1 toc-item\"><a href=\"#Build-Dateset\" data-toc-modified-id=\"Build-Dateset-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Build Dateset</a></div><div class=\"lev1 toc-item\"><a href=\"#Save-Dataset\" data-toc-modified-id=\"Save-Dataset-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Save Dataset</a></div><div class=\"lev1 toc-item\"><a href=\"#Checkpoint\" data-toc-modified-id=\"Checkpoint-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Checkpoint</a></div><div class=\"lev1 toc-item\"><a href=\"#Build-Model\" data-toc-modified-id=\"Build-Model-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Build Model</a></div><div class=\"lev2 toc-item\"><a href=\"#Set-Hyperparameters\" data-toc-modified-id=\"Set-Hyperparameters-71\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Set Hyperparameters</a></div><div class=\"lev2 toc-item\"><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-72\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Import Libraries</a></div><div class=\"lev2 toc-item\"><a href=\"#Build-Graph\" data-toc-modified-id=\"Build-Graph-73\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Build Graph</a></div><div class=\"lev2 toc-item\"><a href=\"#Model-Visualization\" data-toc-modified-id=\"Model-Visualization-74\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Model Visualization</a></div><div class=\"lev2 toc-item\"><a href=\"#Train\" data-toc-modified-id=\"Train-75\"><span class=\"toc-item-num\">7.5&nbsp;&nbsp;</span>Train</a></div><div class=\"lev1 toc-item\"><a href=\"#Evaluate\" data-toc-modified-id=\"Evaluate-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Evaluate</a></div><div class=\"lev1 toc-item\"><a href=\"#Play\" data-toc-modified-id=\"Play-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Play</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentText = []\n",
    "relationMentions = []\n",
    "relationLabels = []\n",
    "entityMentions = []\n",
    "entityLabels = []\n",
    "em1Text = []\n",
    "em2Text = []\n",
    "\n",
    "with open(\"/Users/lizhn7/Downloads/DATA/nyt/train.json\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    item = json.loads(line)\n",
    "    # Exclude \"None\" label\n",
    "    if not all(i['label'] == 'None' for i in item['relationMentions']):\n",
    "        sentText.append(item['sentText'])\n",
    "        relationMentions.append(item['relationMentions'])\n",
    "        entityMentions.append(item['entityMentions'])\n",
    "    \n",
    "relationLabels = [[i['label'].split('/')[-1] for i in rM] for rM in relationMentions]\n",
    "entityLabels = [[i['text'] for i in eM] for eM in entityMentions]\n",
    "em1Text = [[i['em1Text'] for i in rM] for rM in relationMentions]\n",
    "em2Text = [[i['em2Text'] for i in rM] for rM in relationMentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean words\n",
    "replaceDict = {\n",
    "               'ā': 'a', 'á': 'a', 'ǎ': 'a', 'à': 'a',\n",
    "               'ō': 'o', 'ó': 'o', 'ǒ': 'o', 'ò': 'o', 'ô': 'o', 'ö': 'o',\n",
    "               'ē': 'e', 'é': 'e', 'ě': 'e', 'è': 'e', \n",
    "               'ī': 'i', 'í': 'i', 'ǐ': 'i', 'ì': 'i',\n",
    "               'ū': 'u', 'ú': 'u', 'ǔ': 'u', 'ù': 'u', 'ü': 'u',\n",
    "               'ñ': 'n',\n",
    "               'É': 'E'\n",
    "              }\n",
    "em1Text = [[''.join([replaceDict.get(i, i) for i in e]) for e in eT] for eT in em1Text]\n",
    "em2Text = [[''.join([replaceDict.get(i, i) for i in e]) for e in eT] for eT in em2Text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_sentText = []\n",
    "t_relationMentions = []\n",
    "t_relationLabels = []\n",
    "t_entityMentions = []\n",
    "t_entityLabels = []\n",
    "t_em1Text = []\n",
    "t_em2Text = []\n",
    "\n",
    "with open(\"/Users/lizhn7/Downloads/DATA/nyt/test.json\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    item = json.loads(line)\n",
    "    t_sentText.append(item['sentText'])\n",
    "    t_relationMentions.append(item['relationMentions'])\n",
    "    t_entityMentions.append(item['entityMentions'])\n",
    "    \n",
    "t_relationLabels = [[i['label'].split('/')[-1] for i in rM] for rM in t_relationMentions]\n",
    "t_entityLabels = [[i['text'] for i in eM] for eM in t_entityMentions]\n",
    "t_em1Text = [[i['em1Text'] for i in rM] for rM in t_relationMentions]\n",
    "t_em2Text = [[i['em2Text'] for i in rM] for rM in t_relationMentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean words\n",
    "t_replaceDict = {\n",
    "               'ā': 'a', 'á': 'a', 'ǎ': 'a', 'à': 'a',\n",
    "               'ō': 'o', 'ó': 'o', 'ǒ': 'o', 'ò': 'o', 'ô': 'o', 'ö': 'o',\n",
    "               'ē': 'e', 'é': 'e', 'ě': 'e', 'è': 'e', \n",
    "               'ī': 'i', 'í': 'i', 'ǐ': 'i', 'ì': 'i',\n",
    "               'ū': 'u', 'ú': 'u', 'ǔ': 'u', 'ù': 'u', 'ü': 'u',\n",
    "               'ñ': 'n',\n",
    "               'É': 'E'\n",
    "              }\n",
    "t_em1Text = [[''.join([t_replaceDict.get(i, i) for i in e]) for e in eT] for eT in t_em1Text]\n",
    "t_em2Text = [[''.join([t_replaceDict.get(i, i) for i in e]) for e in eT] for eT in t_em2Text]\n",
    "t_entityLabels = [[''.join([t_replaceDict.get(i, i) for i in e]) for e in eT] for eT in t_entityLabels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Relation Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contains',\n",
       " 'advisors',\n",
       " 'founders',\n",
       " 'ethnicity',\n",
       " 'location',\n",
       " 'capital',\n",
       " 'profession',\n",
       " 'teams',\n",
       " 'neighborhood_of',\n",
       " 'major_shareholder_of',\n",
       " 'place_lived',\n",
       " 'religion',\n",
       " 'major_shareholders',\n",
       " 'administrative_divisions',\n",
       " 'place_of_birth',\n",
       " 'place_founded',\n",
       " 'company',\n",
       " 'children',\n",
       " 'people',\n",
       " 'nationality',\n",
       " 'place_of_death',\n",
       " 'country',\n",
       " 'industry',\n",
       " 'geographic_distribution']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationTypes = list(set([r for rl in relationLabels for r in rl]))\n",
    "relationTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['contains',\n",
       " 'neighborhood_of',\n",
       " 'administrative_divisions',\n",
       " 'place_of_birth',\n",
       " 'place_lived',\n",
       " 'founders',\n",
       " 'place_of_death',\n",
       " 'company',\n",
       " 'capital',\n",
       " 'children',\n",
       " 'country',\n",
       " 'nationality']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_relationTypes = list(set([r for rl in t_relationLabels for r in rl if r != 'None']))\n",
    "t_relationTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut(s):\n",
    "    \"\"\"\n",
    "    Participle\n",
    "    \"\"\"\n",
    "    pattern = r'''\n",
    "              (?x)                   # set flag to allow verbose regexps \n",
    "              (?:[A-Z]\\.)+           # abbreviations, e.g. U.S.A. \n",
    "              |\\d+(?:\\.\\d+)?%?       # numbers, incl. currency and percentages \n",
    "              |\\w+(?:[-&']\\w+)*       # words w/ optional internal hyphens/apostrophe  \n",
    "           '''  \n",
    "    return regexp_tokenize(s, pattern=pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"stopwords_666.txt\"\n",
    "stopWords = {w: None for w in open(filename).read().split()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentWords = [cut(s) for s in sentText]\n",
    "entlabWords = [[cut(s) for s in eL] for eL in entityLabels]\n",
    "em1Words = [[cut(s) for s in eL] for eL in em1Text]\n",
    "em2Words = [[cut(s) for s in eL] for eL in em2Text]\n",
    "t_sentWords = [cut(s) for s in t_sentText]\n",
    "t_entlabWords = [[cut(s) for s in eL] for eL in t_entityLabels]\n",
    "t_em1Words = [[cut(s) for s in eL] for eL in t_em1Text]\n",
    "t_em2Words = [[cut(s) for s in eL] for eL in t_em2Text]\n",
    "# Clean words\n",
    "t_sentWords = [[''.join([t_replaceDict.get(i, i) for i in e]) for e in eT] for eT in t_sentWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Delete stopwords\n",
    "for n in range(len(sentWords)):\n",
    "    sentWords[n] = [i for i in [stopWords.get(i.lower(), i) for i in sentWords[n]] if i != None]\n",
    "    entlabWords[n] = [[stopWords.get(i.lower(), i) for i in item] for item in entlabWords[n]]\n",
    "    entlabWords[n] = [[i for i in item if i != None] for item in entlabWords[n]]\n",
    "    em1Words[n] = [[stopWords.get(i.lower(), i) for i in item] for item in em1Words[n]]\n",
    "    em1Words[n] = [[i for i in item if i != None] for item in em1Words[n]]\n",
    "    em2Words[n] = [[stopWords.get(i.lower(), i) for i in item] for item in em2Words[n]]\n",
    "    em2Words[n] = [[i for i in item if i != None] for item in em2Words[n]] \n",
    "\n",
    "for n in range(len(t_sentWords)):\n",
    "    t_sentWords[n] = [i for i in [stopWords.get(i.lower(), i) for i in t_sentWords[n]] if i != None]\n",
    "    t_entlabWords[n] = [[stopWords.get(i.lower(), i) for i in item] for item in t_entlabWords[n]]\n",
    "    t_entlabWords[n] = [[i for i in item if i != None] for item in t_entlabWords[n]]\n",
    "    t_em1Words[n] = [[stopWords.get(i.lower(), i) for i in item] for item in t_em1Words[n]]\n",
    "    t_em1Words[n] = [[i for i in item if i != None] for item in t_em1Words[n]]\n",
    "    t_em2Words[n] = [[stopWords.get(i.lower(), i) for i in item] for item in t_em2Words[n]]\n",
    "    t_em2Words[n] = [[i for i in item if i != None] for item in t_em2Words[n]]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#max([len(i) for i in t_sentWords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SENT_LEN = 64\n",
    "MAX_ADJL_LEN = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Adjacency List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Adjacency List of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_entityLabels = []\n",
    "for i in range(len(sentWords)):\n",
    "    eL = []\n",
    "    sDict = list(enumerate(sentWords[i]))\n",
    "    j = 0\n",
    "    for item in entlabWords[i]:\n",
    "        el = []\n",
    "        for e in item:\n",
    "            while j < len(sDict):\n",
    "                if e == sDict[j][1]:\n",
    "                    el.append(sDict[j][0])\n",
    "                    j += 1\n",
    "                    break\n",
    "                j += 1\n",
    "        eL.append(el)\n",
    "    i_entityLabels.append(eL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmSet = []\n",
    "for item in range(len(relationMentions)):\n",
    "    rms = [(em1Words[item][i][0], em2Words[item][i][0], relationLabels[item][i]) for i in range(len(relationLabels[item]))]\n",
    "    rms = [' '.join(list(i)) for i in rms]\n",
    "    rmSet.append(rms)\n",
    "rmSet = [set(i) for i in rmSet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_adjacencyList = []\n",
    "new_sentWords = []\n",
    "pad = ['EOP']\n",
    "for n in range(len(sentWords)):\n",
    "    aL = []\n",
    "    for l in range(len(relationLabels[n])):\n",
    "        e1 = []\n",
    "        e2 = []\n",
    "        for item in i_entityLabels[n]:\n",
    "            if ' '.join([sentWords[n][i] for i in item]) == ' '.join(em1Words[n][l]):\n",
    "                e1.append(item[0])\n",
    "            if ' '.join([sentWords[n][i] for i in item]) == ' '.join(em2Words[n][l]):\n",
    "                e2.append(item[0])\n",
    "        c1 = [(a, b) for a in e1 for b in e2 if ' '.join([sentWords[n][a], sentWords[n][b], relationLabels[n][l]]) in rmSet[n]]\n",
    "        c2 = [(a, b) for a in e2 for b in e1 if ' '.join([sentWords[n][b], sentWords[n][a], relationLabels[n][l]]) in rmSet[n]]\n",
    "        c = c1 + c2\n",
    "        m = min([(i, abs(j[0]-j[1])) for i, j in enumerate(c)], key=lambda x: x[-1])[-1]\n",
    "        r = [i[0] for i in [(i, abs(j[0]-j[1])) for i, j in enumerate(c)] if i[-1] == m]\n",
    "        for i in r:\n",
    "            if ' '.join([sentWords[n][c[i][0]], sentWords[n][c[i][1]], relationLabels[n][l]]) in rmSet[n]:\n",
    "                al = (c[i][0], c[i][1], relationLabels[n][l], pad[0])\n",
    "                if al[2] in t_relationTypes and al[0] < MAX_SENT_LEN and al[1] < MAX_SENT_LEN: \n",
    "                    aL.append(al)\n",
    "    aL = sorted([list(i) for i in set(aL)])\n",
    "    if len(aL) == 1 or len(aL) == 2:\n",
    "        i_adjacencyList.append(aL)\n",
    "        new_sentWords.append(sentWords[n])\n",
    "i_adjacencyList = [sum(i, []) for i in i_adjacencyList]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#([len(i) for i in t_sentWords])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Adjacency List of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ti_entityLabels = []\n",
    "for i in range(len(t_sentWords)):\n",
    "    eL = []\n",
    "    t_sDict = list(enumerate(t_sentWords[i]))\n",
    "    j = 0\n",
    "    for item in t_entlabWords[i]:\n",
    "        el = []\n",
    "        for e in item:\n",
    "            while j < len(t_sDict):\n",
    "                if e == t_sDict[j][1]:\n",
    "                    el.append(t_sDict[j][0])\n",
    "                    j += 1\n",
    "                    break\n",
    "                j += 1\n",
    "        eL.append(el)\n",
    "    ti_entityLabels.append(eL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ti_trueLables = [[i for i, j in enumerate(rl) if j != 'None'] for rl in t_relationLabels]\n",
    "t_trueMentions = [[j for i, j in enumerate(rl) if j['label'] != 'None'] for rl in t_relationMentions]\n",
    "pad = ['EOP']\n",
    "ti_adjacencyList = []\n",
    "for n in range(len(t_sentWords)): \n",
    "    e1 = []\n",
    "    e2 = []\n",
    "    aL = []\n",
    "    for l in ti_trueLables[n]:\n",
    "        for item in ti_entityLabels[n]:\n",
    "            if ' '.join([t_sentWords[n][i] for i in item]) == ' '.join(t_em1Words[n][l]):\n",
    "                e1.append(item[0])\n",
    "            if ' '.join([t_sentWords[n][i] for i in item]) == ' '.join(t_em2Words[n][l]):\n",
    "                e2.append(item[0])\n",
    "    c = [(a, b) for a in e1 for b in e2]\n",
    "    r = c[min([(i, abs(j[0]-j[1])) for i, j in enumerate(c)], key=lambda x: x[-1])[0]]\n",
    "    aL = aL + [r[0], r[1], t_relationLabels[n][l], pad[0]]\n",
    "    ti_adjacencyList.append(aL)\n",
    "\n",
    "# Modify \n",
    "ti_adjacencyList[26] = [18, 20, 'founders', 'EOP']\n",
    "ti_adjacencyList[191] = [13, 19, 'country', 'EOP', 18, 19, 'country', 'EOP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#max([max(sum(i, [])) for i in ti_entityLabels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word to Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "sentWords = [[wnl.lemmatize(t.lower()) for t in toks] for toks in new_sentWords]\n",
    "t_sentWords = [[wnl.lemmatize(t.lower()) for t in toks] for toks in t_sentWords]\n",
    "tok_sentWords = sentWords.copy()\n",
    "tok_sentWords.extend(t_sentWords)\n",
    "tokTexts = [' '.join(i) for i in tok_sentWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 65131 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(tokTexts)\n",
    "word2index = tokenizer.word_index\n",
    "index2word = {i: w for w, i in word2index.items()}\n",
    "print('Found %s unique tokens.' % len(word2index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Word Embeddings with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 65132\n",
    "EMBEDDING_SIZE = 300\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#glove_n_symbols = !wc -l /Users/lizhn7/Downloads/DATA/Glove/glove.42B.300d.txt\n",
    "#glove_n_symbols = int(glove_n_symbols[0].split()[0])\n",
    "glove_n_symbols = 1917495"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_index_dict = {}\n",
    "glove_embedding_weights = np.empty((glove_n_symbols, EMBEDDING_SIZE))\n",
    "globale_scale = 0.1\n",
    "with open('/Users/lizhn7/Downloads/DATA/Glove/glove.42B.300d.txt', 'r') as fp:\n",
    "    index = 0\n",
    "    for l in fp:\n",
    "        l = l.strip().split()\n",
    "        word = l[0]\n",
    "        glove_index_dict[word] = index\n",
    "        glove_embedding_weights[index, :] = [float(n) for n in l[1:]]\n",
    "        index += 1\n",
    "glove_embedding_weights *= globale_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Glove to Initialize Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer, LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate random embedding with same scale as glove\n",
    "np.random.seed(SEED)\n",
    "shape = (VOCAB_SIZE, EMBEDDING_SIZE)\n",
    "scale = glove_embedding_weights.std() * np.sqrt(12) / 2 \n",
    "embedding = np.random.uniform(low=-scale, high=scale, size=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60641-93.10% tokens in vocab found in glove and copied to embedding.\n"
     ]
    }
   ],
   "source": [
    "# Copy from glove weights of words that appear in index2word\n",
    "count = 0 \n",
    "for i in range(1, VOCAB_SIZE):\n",
    "    w = index2word[i]\n",
    "    g = glove_index_dict.get(w)\n",
    "    if g is None:\n",
    "        w = porter.stem(w)\n",
    "        g = glove_index_dict.get(w)\n",
    "    if g is None:\n",
    "        w = lancaster.stem(w)\n",
    "        g = glove_index_dict.get(w)\n",
    "    if g is not None:\n",
    "        embedding[i, :] = glove_embedding_weights[g, :]\n",
    "        count += 1\n",
    "print('{num_tokens}-{per:.2f}% tokens in vocab found in glove and copied to embedding.'.format(num_tokens=count, per=count/float(VOCAB_SIZE)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dateset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_sentText = [' '.join(i) for i in sentWords]\n",
    "sentSeq = tokenizer.texts_to_sequences(new_sentText)\n",
    "sentData = pad_sequences(sentSeq, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
    "\n",
    "t_new_sentText = [' '.join(i) for i in t_sentWords]\n",
    "t_sentSeq = tokenizer.texts_to_sequences(t_new_sentText)\n",
    "t_sentData = pad_sequences(t_sentSeq, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
    "\n",
    "token2index = dict((j, i+MAX_SENT_LEN) for i, j in enumerate(pad+t_relationTypes))\n",
    "token2index['PAD'] = 0\n",
    "token2index['GO'] = 77\n",
    "index2token = {i: w for w, i in token2index.items()}\n",
    "\n",
    "\n",
    "newi_adjacencyList = [[token2index[i] if i in token2index else i+1 for i in aL] for aL in i_adjacencyList]\n",
    "oi_adjacencyList = pad_sequences(newi_adjacencyList, maxlen=MAX_ADJL_LEN, padding='post', truncating='post')\n",
    "[i.insert(0, 77) for i in newi_adjacencyList];\n",
    "tFi_adjacencyList = pad_sequences(newi_adjacencyList, maxlen=MAX_ADJL_LEN, padding='post', truncating='post')\n",
    "\n",
    "newti_adjacencyList = [[token2index[i] if i in token2index else i+1 for i in aL] for aL in ti_adjacencyList]\n",
    "oti_adjacencyList = pad_sequences(newti_adjacencyList, maxlen=MAX_ADJL_LEN, padding='post', truncating='post')\n",
    "[i.insert(0, 77) for i in newti_adjacencyList];\n",
    "tFti_adjacencyList = pad_sequences(newti_adjacencyList, maxlen=MAX_ADJL_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into a training set, a validation set and a test set\n",
    "x_train_all = sentData\n",
    "tf_train_all = tFi_adjacencyList\n",
    "y_train_all = oi_adjacencyList\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, test_size=0.15, random_state=SEED)\n",
    "tf_train, tf_val, _, _ = train_test_split(tf_train_all, tf_train_all, test_size=0.15, random_state=SEED)\n",
    "\n",
    "x_train_all, _, y_train_all, _  = train_test_split(x_train_all, y_train_all, test_size=0., random_state=SEED)\n",
    "tf_train_all, _, _, _ = train_test_split(tf_train_all, tf_train_all, test_size=0., random_state=SEED)\n",
    " \n",
    "x_test = t_sentData\n",
    "tf_test = tFti_adjacencyList\n",
    "y_test = oti_adjacencyList\n",
    "\n",
    "x_test, _, y_test, _ = train_test_split(x_test, y_test, test_size=0., random_state=SEED)\n",
    "tf_test, _, _, _ = train_test_split(tf_test, tf_test, test_size=0., random_state=SEED)\n",
    "\n",
    "t_sentWords, _, _, _ = train_test_split(t_sentWords, t_sentWords, test_size=0., random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fh = h5py.File('/Users/lizhn7/Downloads/DATA/nyt/experiment_5_1/allData_666.h5', 'w')\n",
    "fh['x_train'] = x_train\n",
    "fh['tf_train'] = tf_train\n",
    "fh['y_train'] = y_train\n",
    "fh['x_val'] = x_val\n",
    "fh['tf_val'] = tf_val\n",
    "fh['y_val'] = y_val\n",
    "fh['x_train_all'] = x_train_all\n",
    "fh['tf_train_all'] = tf_train_all\n",
    "fh['y_train_all'] = y_train_all\n",
    "fh['x_test'] = x_test\n",
    "fh['tf_test'] = tf_test\n",
    "fh['y_test'] = y_test\n",
    "fh['embedding'] = embedding\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/lizhn7/Downloads/DATA/nyt/experiment_5_1/index_666.pkl', 'wb') as fp:\n",
    "    pickle.dump((word2index, index2word, token2index, index2token, t_sentWords), fp, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('/Users/lizhn7/Downloads/DATA/nyt/experiment_5_1/allData_666.h5', 'r') as fh:\n",
    "    x_train = fh['x_train'][:]\n",
    "    tf_train = fh['tf_train'][:]\n",
    "    y_train = fh['y_train'][:]\n",
    "    x_val = fh['x_val'][:]\n",
    "    tf_val = fh['tf_val'][:]\n",
    "    y_val = fh['y_val'][:]\n",
    "    x_train_all = fh['x_train_all'][:]\n",
    "    tf_train_all = fh['tf_train_all'][:]\n",
    "    y_train_all = fh['y_train_all'][:]\n",
    "    x_test = fh['x_test'][:]\n",
    "    tf_test = fh['tf_test'][:]\n",
    "    y_test = fh['y_test'][:]\n",
    "    embedding = fh['embedding'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/lizhn7/Downloads/DATA/nyt/experiment_5_1/index_666.pkl', 'rb') as fp:\n",
    "    word2index, index2word, token2index, index2token, t_sentWords = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SENT_LEN = 64\n",
    "MAX_ADJL_LEN = 8\n",
    "VOCAB_SIZE = len(word2index)+1\n",
    "NUM_CLASSES = MAX_SENT_LEN+len(token2index)\n",
    "EMBEDDING_SIZE = 300\n",
    "TF_EMBEDDING_SIZE = 50\n",
    "\n",
    "ENC_RNN_SIZE = 300\n",
    "DEC_RNN_SIZE = 150\n",
    "DROPOUT_RATE = 0.5\n",
    "RNN_DROPOUT_RATE = 0.2\n",
    "NUM_EPOCHS = 256\n",
    "BATCH_SIZE = 79\n",
    "STEPS_PER_EPOCH = 20\n",
    "TEST_STEPS = len(x_test)//BATCH_SIZE\n",
    "\n",
    "VALIDATION_STEPS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_EPOCHS: \t\t256\n",
      "STEPS_PER_EPOCH: \t20\n",
      "TEST_STEPS: \t\t5\n",
      "VALIDATION_STEPS: \t3\n",
      "TRAIN_BATCHES: \t\t5120\n",
      "NUM_BATCHES \t\t612\n"
     ]
    }
   ],
   "source": [
    "print('NUM_EPOCHS: \\t\\t%d' % NUM_EPOCHS)\n",
    "print('STEPS_PER_EPOCH: \\t%d' % STEPS_PER_EPOCH)\n",
    "print('TEST_STEPS: \\t\\t%d' % TEST_STEPS)\n",
    "print('VALIDATION_STEPS: \\t%d' % VALIDATION_STEPS)\n",
    "print('TRAIN_BATCHES: \\t\\t%d' % (NUM_EPOCHS * STEPS_PER_EPOCH))\n",
    "print('NUM_BATCHES \\t\\t%d' % (len(x_train)//BATCH_SIZE+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Dropout, Bidirectional, LSTM, RepeatVector, concatenate, TimeDistributed, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import*\n",
    "from keras.utils import to_categorical\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "sequence = Input(shape=(MAX_SENT_LEN,), name='INPUT') \n",
    "emb_seq = Embedding(VOCAB_SIZE, EMBEDDING_SIZE, weights=[embedding], mask_zero=True, input_length=MAX_SENT_LEN, trainable=True, name='EMBEDDING')(sequence)\n",
    "emb_seq = Dropout(DROPOUT_RATE)(emb_seq)\n",
    "tf_seq = Input(shape=(MAX_ADJL_LEN,), name='TF_INPUT')\n",
    "tf_emb = Embedding(NUM_CLASSES, TF_EMBEDDING_SIZE, mask_zero=True, input_length=MAX_ADJL_LEN, name='TF_EMBEDDING')(tf_seq)\n",
    "tf_emb = Dropout(DROPOUT_RATE)(tf_emb)\n",
    "blstm = Bidirectional(LSTM(ENC_RNN_SIZE, return_sequences=True, implementation=0, dropout=RNN_DROPOUT_RATE, recurrent_dropout=RNN_DROPOUT_RATE), merge_mode='concat', name='ENC_BLSTM_1')(emb_seq)\n",
    "blstm = Dropout(DROPOUT_RATE)(blstm)\n",
    "blstm = Bidirectional(LSTM(ENC_RNN_SIZE, return_sequences=False, implementation=0, dropout=RNN_DROPOUT_RATE, recurrent_dropout=RNN_DROPOUT_RATE), merge_mode='concat', name='ENC_BLSTM_2')(blstm)\n",
    "blstm = Dropout(DROPOUT_RATE)(blstm)\n",
    "context = RepeatVector(MAX_ADJL_LEN, name='CONTEXT')(blstm)\n",
    "context = concatenate([context, tf_emb], axis=-1)\n",
    "blstm = Bidirectional(LSTM(DEC_RNN_SIZE, return_sequences=True, implementation=2, dropout=RNN_DROPOUT_RATE, recurrent_dropout=RNN_DROPOUT_RATE, name='DEC_LSTM'), merge_mode='concat', name='DEC_BLSTM')(context)\n",
    "lstm = Dropout(DROPOUT_RATE)(blstm)\n",
    "output = TimeDistributed(Dense(NUM_CLASSES, activation='softmax'), name='OUTPUT')(lstm)\n",
    "model = Model(inputs=[sequence, tf_seq], outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "INPUT (InputLayer)               (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "EMBEDDING (Embedding)            (None, 64, 300)       19539600    INPUT[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 64, 300)       0           EMBEDDING[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "ENC_BLSTM_1 (Bidirectional)      (None, 64, 600)       1442400     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 64, 600)       0           ENC_BLSTM_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "ENC_BLSTM_2 (Bidirectional)      (None, 600)           2162400     dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "TF_INPUT (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 600)           0           ENC_BLSTM_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "TF_EMBEDDING (Embedding)         (None, 8, 50)         3950        TF_INPUT[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "CONTEXT (RepeatVector)           (None, 8, 600)        0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 8, 50)         0           TF_EMBEDDING[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 8, 650)        0           CONTEXT[0][0]                    \n",
      "                                                                   dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "DEC_BLSTM (Bidirectional)        (None, 8, 300)        961200      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 8, 300)        0           DEC_BLSTM[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "OUTPUT (TimeDistributed)         (None, 8, 79)         23779       dropout_5[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 24,133,329\n",
      "Trainable params: 24,133,329\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"848pt\" viewBox=\"0.00 0.00 469.76 848.00\" width=\"470pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 844)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-844 465.7622,-844 465.7622,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 10646263456 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>10646263456</title>\n",
       "<polygon fill=\"none\" points=\"80.0762,-803.5 80.0762,-839.5 206.1826,-839.5 206.1826,-803.5 80.0762,-803.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-817.3\">INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 5252990064 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>5252990064</title>\n",
       "<polygon fill=\"none\" points=\"57.1655,-730.5 57.1655,-766.5 229.0933,-766.5 229.0933,-730.5 57.1655,-730.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-744.3\">EMBEDDING: Embedding</text>\n",
       "</g>\n",
       "<!-- 10646263456&#45;&gt;5252990064 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>10646263456-&gt;5252990064</title>\n",
       "<path d=\"M143.1294,-803.4551C143.1294,-795.3828 143.1294,-785.6764 143.1294,-776.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-776.5903 143.1294,-766.5904 139.6295,-776.5904 146.6295,-776.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10476077968 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>10476077968</title>\n",
       "<polygon fill=\"none\" points=\"79.3276,-657.5 79.3276,-693.5 206.9312,-693.5 206.9312,-657.5 79.3276,-657.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-671.3\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 5252990064&#45;&gt;10476077968 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>5252990064-&gt;10476077968</title>\n",
       "<path d=\"M143.1294,-730.4551C143.1294,-722.3828 143.1294,-712.6764 143.1294,-703.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-703.5903 143.1294,-693.5904 139.6295,-703.5904 146.6295,-703.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10141161848 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>10141161848</title>\n",
       "<polygon fill=\"none\" points=\"0,-584.5 0,-620.5 286.2588,-620.5 286.2588,-584.5 0,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-598.3\">ENC_BLSTM_1(lstm_1): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 10476077968&#45;&gt;10141161848 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>10476077968-&gt;10141161848</title>\n",
       "<path d=\"M143.1294,-657.4551C143.1294,-649.3828 143.1294,-639.6764 143.1294,-630.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-630.5903 143.1294,-620.5904 139.6295,-630.5904 146.6295,-630.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10476191696 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>10476191696</title>\n",
       "<polygon fill=\"none\" points=\"79.3276,-511.5 79.3276,-547.5 206.9312,-547.5 206.9312,-511.5 79.3276,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-525.3\">dropout_3: Dropout</text>\n",
       "</g>\n",
       "<!-- 10141161848&#45;&gt;10476191696 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>10141161848-&gt;10476191696</title>\n",
       "<path d=\"M143.1294,-584.4551C143.1294,-576.3828 143.1294,-566.6764 143.1294,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-557.5903 143.1294,-547.5904 139.6295,-557.5904 146.6295,-557.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10661395424 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>10661395424</title>\n",
       "<polygon fill=\"none\" points=\"0,-438.5 0,-474.5 286.2588,-474.5 286.2588,-438.5 0,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-452.3\">ENC_BLSTM_2(lstm_2): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 10476191696&#45;&gt;10661395424 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>10476191696-&gt;10661395424</title>\n",
       "<path d=\"M143.1294,-511.4551C143.1294,-503.3828 143.1294,-493.6764 143.1294,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-484.5903 143.1294,-474.5904 139.6295,-484.5904 146.6295,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10141422704 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>10141422704</title>\n",
       "<polygon fill=\"none\" points=\"107.3276,-365.5 107.3276,-401.5 234.9312,-401.5 234.9312,-365.5 107.3276,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"171.1294\" y=\"-379.3\">dropout_4: Dropout</text>\n",
       "</g>\n",
       "<!-- 10661395424&#45;&gt;10141422704 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>10661395424-&gt;10141422704</title>\n",
       "<path d=\"M150.0507,-438.4551C153.2142,-430.2074 157.0321,-420.2536 160.5446,-411.0962\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.8772,-412.1806 164.1906,-401.5904 157.3415,-409.6737 163.8772,-412.1806\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10476078360 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>10476078360</title>\n",
       "<polygon fill=\"none\" points=\"304.4072,-438.5 304.4072,-474.5 453.8516,-474.5 453.8516,-438.5 304.4072,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"379.1294\" y=\"-452.3\">TF_INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 10476081048 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>10476081048</title>\n",
       "<polygon fill=\"none\" points=\"266.4966,-365.5 266.4966,-401.5 461.7622,-401.5 461.7622,-365.5 266.4966,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"364.1294\" y=\"-379.3\">TF_EMBEDDING: Embedding</text>\n",
       "</g>\n",
       "<!-- 10476078360&#45;&gt;10476081048 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>10476078360-&gt;10476081048</title>\n",
       "<path d=\"M375.4215,-438.4551C373.7448,-430.2951 371.725,-420.4652 369.8599,-411.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"373.2878,-410.6812 367.8466,-401.5904 366.431,-412.0902 373.2878,-410.6812\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10661606624 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>10661606624</title>\n",
       "<polygon fill=\"none\" points=\"96.4175,-292.5 96.4175,-328.5 259.8413,-328.5 259.8413,-292.5 96.4175,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"178.1294\" y=\"-306.3\">CONTEXT: RepeatVector</text>\n",
       "</g>\n",
       "<!-- 10141422704&#45;&gt;10661606624 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>10141422704-&gt;10661606624</title>\n",
       "<path d=\"M172.8597,-365.4551C173.6338,-357.3828 174.5645,-347.6764 175.427,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"178.9241,-338.8788 176.3947,-328.5904 171.9561,-338.2106 178.9241,-338.8788\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10476078304 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>10476078304</title>\n",
       "<polygon fill=\"none\" points=\"289.3276,-292.5 289.3276,-328.5 416.9312,-328.5 416.9312,-292.5 289.3276,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"353.1294\" y=\"-306.3\">dropout_2: Dropout</text>\n",
       "</g>\n",
       "<!-- 10476081048&#45;&gt;10476078304 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>10476081048-&gt;10476078304</title>\n",
       "<path d=\"M361.4103,-365.4551C360.1939,-357.3828 358.7313,-347.6764 357.376,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"360.8064,-337.9572 355.8553,-328.5904 353.8845,-339.0003 360.8064,-337.9572\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10682764200 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>10682764200</title>\n",
       "<polygon fill=\"none\" points=\"173.8101,-219.5 173.8101,-255.5 346.4487,-255.5 346.4487,-219.5 173.8101,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260.1294\" y=\"-233.3\">concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 10661606624&#45;&gt;10682764200 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>10661606624-&gt;10682764200</title>\n",
       "<path d=\"M198.3991,-292.4551C208.5506,-283.4177 221.0031,-272.3319 232.0585,-262.4899\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"234.6669,-264.8539 239.8087,-255.5904 230.0124,-259.6255 234.6669,-264.8539\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10476078304&#45;&gt;10682764200 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>10476078304-&gt;10682764200</title>\n",
       "<path d=\"M330.1406,-292.4551C318.4037,-283.2422 303.9548,-271.9006 291.2373,-261.918\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"293.2032,-259.0117 283.176,-255.5904 288.8811,-264.518 293.2032,-259.0117\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10683113200 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>10683113200</title>\n",
       "<polygon fill=\"none\" points=\"106.8896,-146.5 106.8896,-182.5 413.3691,-182.5 413.3691,-146.5 106.8896,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260.1294\" y=\"-160.3\">DEC_BLSTM(DEC_LSTM): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 10682764200&#45;&gt;10683113200 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>10682764200-&gt;10683113200</title>\n",
       "<path d=\"M260.1294,-219.4551C260.1294,-211.3828 260.1294,-201.6764 260.1294,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"263.6295,-192.5903 260.1294,-182.5904 256.6295,-192.5904 263.6295,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10661605952 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>10661605952</title>\n",
       "<polygon fill=\"none\" points=\"196.3276,-73.5 196.3276,-109.5 323.9312,-109.5 323.9312,-73.5 196.3276,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260.1294\" y=\"-87.3\">dropout_5: Dropout</text>\n",
       "</g>\n",
       "<!-- 10683113200&#45;&gt;10661605952 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>10683113200-&gt;10661605952</title>\n",
       "<path d=\"M260.1294,-146.4551C260.1294,-138.3828 260.1294,-128.6764 260.1294,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"263.6295,-119.5903 260.1294,-109.5904 256.6295,-119.5904 263.6295,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 11121679832 -->\n",
       "<g class=\"node\" id=\"node15\">\n",
       "<title>11121679832</title>\n",
       "<polygon fill=\"none\" points=\"125.1655,-.5 125.1655,-36.5 395.0933,-36.5 395.0933,-.5 125.1655,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"260.1294\" y=\"-14.3\">OUTPUT(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 10661605952&#45;&gt;11121679832 -->\n",
       "<g class=\"edge\" id=\"edge14\">\n",
       "<title>10661605952-&gt;11121679832</title>\n",
       "<path d=\"M260.1294,-73.4551C260.1294,-65.3828 260.1294,-55.6764 260.1294,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"263.6295,-46.5903 260.1294,-36.5904 256.6295,-46.5904 263.6295,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_label(s):\n",
    "    \"\"\"\n",
    "    One-hot encoding\n",
    "    \"\"\"\n",
    "    gen = to_categorical(s, num_classes=NUM_CLASSES)\n",
    "    return gen\n",
    "\n",
    "def data_generator_all(data, label, batch_size):\n",
    "    \"\"\"\n",
    "    Yield batches of all data\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    while True:\n",
    "        if count >= len(data[0]): \n",
    "            count = 0\n",
    "        x_1 = np.zeros((batch_size, MAX_SENT_LEN))\n",
    "        x_2 = np.zeros((batch_size, MAX_ADJL_LEN))\n",
    "        y = np.zeros((batch_size, MAX_ADJL_LEN, NUM_CLASSES))\n",
    "        for i in range(batch_size):\n",
    "            n = i + count\n",
    "            if n > len(data[0])-1:\n",
    "                break\n",
    "            x_1[i, :] = data[0][n]\n",
    "            x_2[i, :] = data[1][n]\n",
    "            y[i, :, :] = gen_label(label[n])\n",
    "        count += batch_size\n",
    "        yield ([x_1, x_2], y)\n",
    "        \n",
    "def data_generator(data, label, batch_size): \n",
    "    \"\"\"\n",
    "    Yield batches \n",
    "    \"\"\"\n",
    "    index = np.arange(len(data[0]))\n",
    "    np.random.shuffle(index)    \n",
    "    batches = [index[range(batch_size*i, min(len(data[0]), batch_size*(i+1)))] for i in range(len(data[0])//batch_size)]\n",
    "    while True:\n",
    "        for i in batches:\n",
    "            x_1 = data[0][i]\n",
    "            x_2 = data[1][i]\n",
    "            y = np.array(list(map(gen_label, label[i])))\n",
    "            yield ([x_1, x_2], y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_train_all = data_generator([x_train_all, tf_train_all], y_train_all, BATCH_SIZE)\n",
    "gen_test = data_generator_all([x_test, tf_test], y_test, BATCH_SIZE)\n",
    "#gen_train = data_generator(x_train, y_train, BATCH_SIZE)\n",
    "#gen_val = data_generator(x_val, y_val, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continue Trian\n",
    "# filename = 'cp_logs/.hdf5'\n",
    "# model.load_weights(filename)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = '/Users/lizhn7/Downloads/DATA/nyt/experiment_5_1/cp_logs/weights.{epoch:03d}-{val_loss:.6f}.hdf5'\n",
    "log_string = '/Users/lizhn7/Downloads/DATA/nyt/experiment_5_1/tb_logs/666'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir=log_string, \n",
    "                          histogram_freq=1, \n",
    "                          write_graph=False, \n",
    "                          write_grads=False, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          write_images=True, \n",
    "                          embeddings_freq=1, \n",
    "                          embeddings_layer_names=None,\n",
    "                          embeddings_metadata=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "15/20 [=====================>........] - ETA: 23s - loss: 2.6903"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(gen_train_all, \n",
    "                              steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                              epochs=NUM_EPOCHS, \n",
    "                              verbose=1,\n",
    "                              #callbacks=[checkpoint, tensorboard],\n",
    "                              validation_data=gen_test, \n",
    "                              validation_steps=TEST_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 8s     \n"
     ]
    }
   ],
   "source": [
    "filename = '/Users/lizhn7/Downloads/DATA/nyt/experiment_5_1/cp_logs/weights.189-0.172831.hdf5'\n",
    "model.load_weights(filename)\n",
    "\n",
    "result = np.argmax(model.predict([x_test, tf_test], batch_size=BATCH_SIZE, verbose=1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1 Accuracy: \t\t0.992405\n",
      "E2 Accuracy: \t\t0.994937\n",
      "En Accuracy: \t\t0.992405\n",
      "Triple Accuracy: \t0.825316\n"
     ]
    }
   ],
   "source": [
    "preResult = [[index2token.get(i, str(i)) for i in sent if i != 0] for sent in result]\n",
    "actResult = [[index2token.get(i, str(i)) for i in sent if i != 0] for sent in y_test]\n",
    "e1Count = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0]])\n",
    "e2Count = sum([1 for i in range(395) if actResult[i][1] == preResult[i][1]])\n",
    "enCount = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0] and actResult[i][1] == preResult[i][1]])\n",
    "tripleCount = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0] and actResult[i][1] == preResult[i][1] and actResult[i][2] == preResult[i][2]])\n",
    "print('E1 Accuracy: \\t\\t%.6f' % (e1Count/395))\n",
    "print('E2 Accuracy: \\t\\t%.6f' % (e2Count/395))\n",
    "print('En Accuracy: \\t\\t%.6f' % (enCount/395))\n",
    "print('Triple Accuracy: \\t%.6f' % (tripleCount/395))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: \t5 6 country EOP\n",
      "Ground-Truth: \t5 6 country EOP\n",
      "---\n",
      "Predict: \t9 8 country EOP\n",
      "Ground-Truth: \t9 8 country EOP\n",
      "---\n",
      "Predict: \t8 10 place_of_birth EOP\n",
      "Ground-Truth: \t8 10 nationality EOP\n",
      "---\n",
      "Predict: \t10 6 contains EOP\n",
      "Ground-Truth: \t10 6 contains EOP\n",
      "---\n",
      "Predict: \t7 10 place_lived EOP\n",
      "Ground-Truth: \t7 10 place_lived EOP\n",
      "---\n",
      "Predict: \t4 3 contains EOP 4 4 4\n",
      "Ground-Truth: \t4 3 contains EOP\n",
      "---\n",
      "Predict: \t5 1 founders EOP\n",
      "Ground-Truth: \t5 1 founders EOP\n",
      "---\n",
      "Predict: \t11 8 country EOP 8 8 8\n",
      "Ground-Truth: \t11 8 country EOP\n",
      "---\n",
      "Predict: \t12 9 country EOP\n",
      "Ground-Truth: \t12 9 country EOP\n",
      "---\n",
      "Predict: \t9 3 contains EOP\n",
      "Ground-Truth: \t9 3 contains EOP\n",
      "---\n",
      "Predict: \t18 20 administrative_divisions EOP\n",
      "Ground-Truth: \t18 20 company EOP\n",
      "---\n",
      "Predict: \t6 5 contains EOP\n",
      "Ground-Truth: \t6 5 contains EOP\n",
      "---\n",
      "Predict: \t1 4 contains EOP\n",
      "Ground-Truth: \t1 4 contains EOP\n",
      "---\n",
      "Predict: \t9 11 place_lived EOP 8 8 8\n",
      "Ground-Truth: \t9 11 place_lived EOP\n",
      "---\n",
      "Predict: \t3 5 place_lived EOP\n",
      "Ground-Truth: \t3 5 place_lived EOP\n",
      "---\n",
      "Predict: \t2 8 country EOP\n",
      "Ground-Truth: \t2 8 country EOP\n",
      "---\n",
      "Predict: \t15 17 administrative_divisions EOP\n",
      "Ground-Truth: \t15 17 company EOP\n",
      "---\n",
      "Predict: \t3 4 country EOP 4 4 4\n",
      "Ground-Truth: \t3 4 country EOP\n",
      "---\n",
      "Predict: \t12 13 country EOP 22 22 22\n",
      "Ground-Truth: \t12 13 country EOP\n",
      "---\n",
      "Predict: \t9 16 administrative_divisions EOP\n",
      "Ground-Truth: \t9 16 company EOP\n",
      "---\n",
      "Predict: \t8 10 place_of_birth EOP\n",
      "Ground-Truth: \t8 10 nationality EOP\n",
      "---\n",
      "Predict: \t5 10 administrative_divisions EOP\n",
      "Ground-Truth: \t5 10 company EOP\n",
      "---\n",
      "Predict: \t12 8 founders EOP\n",
      "Ground-Truth: \t12 8 founders EOP\n",
      "---\n",
      "Predict: \t2 4 place_lived EOP\n",
      "Ground-Truth: \t2 4 place_lived EOP\n",
      "---\n",
      "Predict: \t11 19 contains EOP\n",
      "Ground-Truth: \t11 19 contains EOP\n",
      "---\n",
      "Predict: \t9 7 country EOP 8 8 8\n",
      "Ground-Truth: \t9 7 country EOP\n",
      "---\n",
      "Predict: \t8 14 country EOP\n",
      "Ground-Truth: \t8 14 country EOP\n",
      "---\n",
      "Predict: \t2 5 administrative_divisions EOP 4 4 4\n",
      "Ground-Truth: \t2 5 place_lived EOP\n",
      "---\n",
      "Predict: \t3 8 administrative_divisions EOP\n",
      "Ground-Truth: \t3 8 company EOP\n",
      "---\n",
      "Predict: \t16 1 country EOP\n",
      "Ground-Truth: \t16 1 country EOP\n",
      "---\n",
      "Predict: \t10 9 contains EOP\n",
      "Ground-Truth: \t10 9 contains EOP\n",
      "---\n",
      "Predict: \t12 9 place_of_birth EOP\n",
      "Ground-Truth: \t12 9 nationality EOP\n",
      "---\n",
      "Predict: \t11 12 country EOP\n",
      "Ground-Truth: \t11 12 country EOP\n",
      "---\n",
      "Predict: \t5 9 administrative_divisions EOP\n",
      "Ground-Truth: \t5 9 company EOP\n",
      "---\n",
      "Predict: \t13 11 contains EOP\n",
      "Ground-Truth: \t13 11 contains EOP\n",
      "---\n",
      "Predict: \t22 26 administrative_divisions EOP 32 32 32\n",
      "Ground-Truth: \t22 26 company EOP\n",
      "---\n",
      "Predict: \t6 12 administrative_divisions EOP\n",
      "Ground-Truth: \t6 12 company EOP\n",
      "---\n",
      "Predict: \t9 7 contains EOP 32 32 32\n",
      "Ground-Truth: \t9 7 contains EOP\n",
      "---\n",
      "Predict: \t29 28 contains EOP 38 38 38\n",
      "Ground-Truth: \t29 28 contains EOP\n",
      "---\n",
      "Predict: \t6 5 contains EOP\n",
      "Ground-Truth: \t6 5 contains EOP\n",
      "---\n",
      "Predict: \t14 15 country EOP\n",
      "Ground-Truth: \t14 15 country EOP\n",
      "---\n",
      "Predict: \t3 5 place_lived EOP\n",
      "Ground-Truth: \t3 5 place_lived EOP\n",
      "---\n",
      "Predict: \t11 13 country EOP\n",
      "Ground-Truth: \t11 13 country EOP\n",
      "---\n",
      "Predict: \t25 18 country EOP 26 26 26\n",
      "Ground-Truth: \t25 18 country EOP\n",
      "---\n",
      "Predict: \t21 23 nationality EOP\n",
      "Ground-Truth: \t21 23 place_of_birth EOP\n",
      "---\n",
      "Predict: \t17 19 place_of_birth EOP\n",
      "Ground-Truth: \t17 19 nationality EOP\n",
      "---\n",
      "Predict: \t7 11 place_of_birth EOP\n",
      "Ground-Truth: \t7 11 nationality EOP\n",
      "---\n",
      "Predict: \t20 22 country EOP 20 20 20\n",
      "Ground-Truth: \t20 22 country EOP\n",
      "---\n",
      "Predict: \t3 6 place_lived EOP 4 4 4\n",
      "Ground-Truth: \t3 6 place_lived EOP\n",
      "---\n",
      "Predict: \t9 6 contains EOP\n",
      "Ground-Truth: \t9 6 contains EOP\n",
      "---\n",
      "Predict: \t8 11 place_lived EOP 8 8 8\n",
      "Ground-Truth: \t8 11 place_lived EOP\n",
      "---\n",
      "Predict: \t6 12 country EOP\n",
      "Ground-Truth: \t6 12 country EOP\n",
      "---\n",
      "Predict: \t6 3 administrative_divisions EOP\n",
      "Ground-Truth: \t6 3 company EOP\n",
      "---\n",
      "Predict: \t3 5 contains EOP 4 4 4\n",
      "Ground-Truth: \t3 5 contains EOP\n",
      "---\n",
      "Predict: \t9 5 contains EOP\n",
      "Ground-Truth: \t9 5 contains EOP\n",
      "---\n",
      "Predict: \t5 6 country EOP\n",
      "Ground-Truth: \t5 6 country EOP\n",
      "---\n",
      "Predict: \t4 3 contains EOP\n",
      "Ground-Truth: \t4 3 contains EOP\n",
      "---\n",
      "Predict: \t6 7 contains EOP\n",
      "Ground-Truth: \t6 7 contains EOP\n",
      "---\n",
      "Predict: \t7 11 country EOP\n",
      "Ground-Truth: \t7 11 country EOP\n",
      "---\n",
      "Predict: \t18 16 contains EOP 17 17 17\n",
      "Ground-Truth: \t18 16 contains EOP\n",
      "---\n",
      "Predict: \t6 3 contains EOP\n",
      "Ground-Truth: \t6 3 contains EOP\n",
      "---\n",
      "Predict: \t26 27 country EOP\n",
      "Ground-Truth: \t26 27 country EOP\n",
      "---\n",
      "Predict: \t1 6 administrative_divisions EOP 4 4 4\n",
      "Ground-Truth: \t1 6 company EOP\n",
      "---\n",
      "Predict: \t6 4 contains EOP\n",
      "Ground-Truth: \t6 4 contains EOP\n",
      "---\n",
      "Predict: \t8 11 place_lived EOP\n",
      "Ground-Truth: \t8 11 place_lived EOP\n",
      "---\n",
      "Predict: \t16 15 contains EOP\n",
      "Ground-Truth: \t16 15 contains EOP\n",
      "---\n",
      "Predict: \t5 3 contains EOP\n",
      "Ground-Truth: \t5 3 contains EOP\n",
      "---\n",
      "Predict: \t2 4 administrative_divisions EOP 4 4 4\n",
      "Ground-Truth: \t2 4 company EOP\n",
      "---\n",
      "Predict: \t4 3 contains EOP\n",
      "Ground-Truth: \t4 3 contains EOP\n",
      "---\n",
      "Predict: \t15 13 contains EOP\n",
      "Ground-Truth: \t15 13 contains EOP\n",
      "---\n",
      "Predict: \t5 7 country EOP\n",
      "Ground-Truth: \t5 7 country EOP\n",
      "---\n",
      "Predict: \t12 9 contains EOP\n",
      "Ground-Truth: \t12 9 contains EOP\n",
      "---\n",
      "Predict: \t2 12 place_lived EOP\n",
      "Ground-Truth: \t2 12 place_lived EOP\n",
      "---\n",
      "Predict: \t4 11 administrative_divisions EOP\n",
      "Ground-Truth: \t4 11 company EOP\n",
      "---\n",
      "Predict: \t13 15 place_lived EOP\n",
      "Ground-Truth: \t13 15 place_lived EOP\n",
      "---\n",
      "Predict: \t9 6 place_of_birth EOP\n",
      "Ground-Truth: \t9 6 nationality EOP\n",
      "---\n",
      "Predict: \t12 4 place_of_birth EOP\n",
      "Ground-Truth: \t12 4 nationality EOP\n",
      "---\n",
      "Predict: \t16 18 contains EOP 20 20 20\n",
      "Ground-Truth: \t16 18 contains EOP\n",
      "---\n",
      "Predict: \t8 1 contains EOP\n",
      "Ground-Truth: \t8 1 contains EOP\n",
      "---\n",
      "Predict: \t15 16 country EOP\n",
      "Ground-Truth: \t15 16 country EOP\n",
      "---\n",
      "Predict: \t11 10 contains EOP\n",
      "Ground-Truth: \t11 10 contains EOP\n",
      "---\n",
      "Predict: \t7 19 country EOP\n",
      "Ground-Truth: \t7 19 country EOP\n",
      "---\n",
      "Predict: \t3 5 contains EOP 4 4 4\n",
      "Ground-Truth: \t3 5 contains EOP\n",
      "---\n",
      "Predict: \t6 12 contains EOP\n",
      "Ground-Truth: \t6 12 contains EOP\n",
      "---\n",
      "Predict: \t5 7 place_lived EOP\n",
      "Ground-Truth: \t5 7 place_lived EOP\n",
      "---\n",
      "Predict: \t6 4 contains EOP 4 4 4\n",
      "Ground-Truth: \t6 4 contains EOP\n",
      "---\n",
      "Predict: \t1 6 administrative_divisions EOP\n",
      "Ground-Truth: \t1 6 company EOP\n",
      "---\n",
      "Predict: \t13 9 country EOP\n",
      "Ground-Truth: \t13 9 country EOP\n",
      "---\n",
      "Predict: \t20 21 contains EOP\n",
      "Ground-Truth: \t20 21 contains EOP\n",
      "---\n",
      "Predict: \t19 17 contains EOP\n",
      "Ground-Truth: \t19 17 contains EOP\n",
      "---\n",
      "Predict: \t6 1 contains EOP\n",
      "Ground-Truth: \t6 1 contains EOP\n",
      "---\n",
      "Predict: \t8 1 country EOP\n",
      "Ground-Truth: \t8 1 country EOP\n",
      "---\n",
      "Predict: \t3 6 contains EOP\n",
      "Ground-Truth: \t3 6 contains EOP\n",
      "---\n",
      "Predict: \t2 4 place_lived EOP\n",
      "Ground-Truth: \t2 4 place_lived EOP\n",
      "---\n",
      "Predict: \t6 3 contains EOP\n",
      "Ground-Truth: \t6 3 contains EOP\n",
      "---\n",
      "Predict: \t10 20 country EOP 32 32 32\n",
      "Ground-Truth: \t10 20 country EOP\n",
      "---\n",
      "Predict: \t3 5 place_of_birth EOP\n",
      "Ground-Truth: \t3 5 nationality EOP\n",
      "---\n",
      "Predict: \t19 13 contains EOP\n",
      "Ground-Truth: \t19 13 contains EOP\n",
      "---\n",
      "Predict: \t6 5 contains EOP\n",
      "Ground-Truth: \t6 5 contains EOP\n",
      "---\n",
      "Predict: \t22 21 contains EOP\n",
      "Ground-Truth: \t22 21 contains EOP\n",
      "---\n",
      "Predict: \t7 6 contains EOP 8 8 8\n",
      "Ground-Truth: \t7 6 contains EOP\n",
      "---\n",
      "Predict: \t4 1 contains EOP\n",
      "Ground-Truth: \t4 1 contains EOP\n",
      "---\n",
      "Predict: \t32 30 contains EOP 32 32 32\n",
      "Ground-Truth: \t32 30 contains EOP\n",
      "---\n",
      "Predict: \t24 7 country EOP 22 22 22\n",
      "Ground-Truth: \t24 7 country EOP\n",
      "---\n",
      "Predict: \t9 13 country EOP\n",
      "Ground-Truth: \t9 13 country EOP\n",
      "---\n",
      "Predict: \t6 14 administrative_divisions EOP\n",
      "Ground-Truth: \t6 14 company EOP\n",
      "---\n",
      "Predict: \t8 7 place_of_birth EOP\n",
      "Ground-Truth: \t8 7 nationality EOP\n",
      "---\n",
      "Predict: \t3 8 place_lived EOP\n",
      "Ground-Truth: \t3 8 place_lived EOP\n",
      "---\n",
      "Predict: \t5 9 place_of_birth EOP\n",
      "Ground-Truth: \t5 9 nationality EOP\n",
      "---\n",
      "Predict: \t3 5 place_lived EOP 4 4 4\n",
      "Ground-Truth: \t3 5 place_lived EOP\n",
      "---\n",
      "Predict: \t4 5 country EOP 4 4 4\n",
      "Ground-Truth: \t4 5 country EOP\n",
      "---\n",
      "Predict: \t5 2 administrative_divisions EOP 4 4 4\n",
      "Ground-Truth: \t5 2 administrative_divisions EOP\n",
      "---\n",
      "Predict: \t18 16 contains EOP\n",
      "Ground-Truth: \t18 16 contains EOP\n",
      "---\n",
      "Predict: \t10 6 country EOP\n",
      "Ground-Truth: \t10 6 country EOP\n",
      "---\n",
      "Predict: \t16 17 contains EOP\n",
      "Ground-Truth: \t16 17 contains EOP\n",
      "---\n",
      "Predict: \t10 12 country EOP\n",
      "Ground-Truth: \t10 12 country EOP\n",
      "---\n",
      "Predict: \t23 13 country EOP\n",
      "Ground-Truth: \t23 13 country EOP\n",
      "---\n",
      "Predict: \t21 19 contains EOP\n",
      "Ground-Truth: \t21 19 contains EOP\n",
      "---\n",
      "Predict: \t7 8 country EOP\n",
      "Ground-Truth: \t7 8 country EOP\n",
      "---\n",
      "Predict: \t17 8 country EOP\n",
      "Ground-Truth: \t17 8 country EOP\n",
      "---\n",
      "Predict: \t21 19 contains EOP 20 20 20\n",
      "Ground-Truth: \t21 19 contains EOP\n",
      "---\n",
      "Predict: \t16 14 contains EOP\n",
      "Ground-Truth: \t16 14 contains EOP\n",
      "---\n",
      "Predict: \t16 19 contains EOP 32 32 32\n",
      "Ground-Truth: \t16 19 contains EOP\n",
      "---\n",
      "Predict: \t20 19 contains EOP\n",
      "Ground-Truth: \t20 19 contains EOP\n",
      "---\n",
      "Predict: \t15 13 contains EOP\n",
      "Ground-Truth: \t15 13 contains EOP\n",
      "---\n",
      "Predict: \t18 16 contains EOP 17 17 17\n",
      "Ground-Truth: \t18 16 contains EOP\n",
      "---\n",
      "Predict: \t7 6 contains EOP\n",
      "Ground-Truth: \t7 6 contains EOP\n",
      "---\n",
      "Predict: \t8 10 place_lived EOP\n",
      "Ground-Truth: \t8 10 place_lived EOP\n",
      "---\n",
      "Predict: \t11 13 administrative_divisions EOP\n",
      "Ground-Truth: \t11 13 administrative_divisions EOP\n",
      "---\n",
      "Predict: \t1 17 place_of_death EOP\n",
      "Ground-Truth: \t1 17 place_of_death EOP\n",
      "---\n",
      "Predict: \t10 4 contains EOP\n",
      "Ground-Truth: \t10 4 contains EOP\n",
      "---\n",
      "Predict: \t12 3 country EOP\n",
      "Ground-Truth: \t12 3 country EOP\n",
      "---\n",
      "Predict: \t7 5 contains EOP\n",
      "Ground-Truth: \t7 5 contains EOP\n",
      "---\n",
      "Predict: \t2 4 place_of_birth EOP 4 4 4\n",
      "Ground-Truth: \t2 4 nationality EOP\n",
      "---\n",
      "Predict: \t10 16 administrative_divisions EOP\n",
      "Ground-Truth: \t10 16 company EOP\n",
      "---\n",
      "Predict: \t8 1 contains EOP\n",
      "Ground-Truth: \t8 1 contains EOP\n",
      "---\n",
      "Predict: \t4 8 contains EOP\n",
      "Ground-Truth: \t4 8 contains EOP\n",
      "---\n",
      "Predict: \t17 15 contains EOP 17 17 17\n",
      "Ground-Truth: \t17 15 contains EOP\n",
      "---\n",
      "Predict: \t5 6 country EOP\n",
      "Ground-Truth: \t5 6 country EOP\n",
      "---\n",
      "Predict: \t3 12 country EOP\n",
      "Ground-Truth: \t3 12 country EOP\n",
      "---\n",
      "Predict: \t5 11 place_of_birth EOP\n",
      "Ground-Truth: \t5 11 nationality EOP\n",
      "---\n",
      "Predict: \t4 3 contains EOP\n",
      "Ground-Truth: \t4 3 contains EOP\n",
      "---\n",
      "Predict: \t15 17 place_lived EOP 17 17 17\n",
      "Ground-Truth: \t15 17 place_lived EOP\n",
      "---\n",
      "Predict: \t7 6 country EOP\n",
      "Ground-Truth: \t7 6 country EOP\n",
      "---\n",
      "Predict: \t5 3 country EOP 4 4 4\n",
      "Ground-Truth: \t5 3 country EOP\n",
      "---\n",
      "Predict: \t1 6 administrative_divisions EOP\n",
      "Ground-Truth: \t1 6 company EOP\n",
      "---\n",
      "Predict: \t10 3 contains EOP\n",
      "Ground-Truth: \t10 3 contains EOP\n",
      "---\n",
      "Predict: \t2 6 administrative_divisions EOP\n",
      "Ground-Truth: \t2 6 company EOP\n",
      "---\n",
      "Predict: \t9 6 contains EOP\n",
      "Ground-Truth: \t9 6 contains EOP\n",
      "---\n",
      "Predict: \t14 21 administrative_divisions EOP\n",
      "Ground-Truth: \t14 21 administrative_divisions EOP\n",
      "---\n",
      "Predict: \t9 8 contains EOP\n",
      "Ground-Truth: \t9 8 contains EOP\n",
      "---\n",
      "Predict: \t20 19 country EOP\n",
      "Ground-Truth: \t20 19 country EOP\n",
      "---\n",
      "Predict: \t2 7 place_lived EOP\n",
      "Ground-Truth: \t2 7 place_lived EOP\n",
      "---\n",
      "Predict: \t6 2 country EOP\n",
      "Ground-Truth: \t6 2 country EOP\n",
      "---\n",
      "Predict: \t4 3 contains EOP 4 4 4\n",
      "Ground-Truth: \t4 3 contains EOP\n",
      "---\n",
      "Predict: \t1 15 place_of_death EOP\n",
      "Ground-Truth: \t1 15 place_of_death EOP\n",
      "---\n",
      "Predict: \t5 3 contains EOP\n",
      "Ground-Truth: \t5 3 contains EOP\n",
      "---\n",
      "Predict: \t11 24 country EOP\n",
      "Ground-Truth: \t11 24 country EOP\n",
      "---\n",
      "Predict: \t6 5 contains EOP\n",
      "Ground-Truth: \t6 5 contains EOP\n",
      "---\n",
      "Predict: \t2 7 administrative_divisions EOP\n",
      "Ground-Truth: \t2 7 company EOP\n",
      "---\n",
      "Predict: \t8 7 contains EOP\n",
      "Ground-Truth: \t8 7 contains EOP\n",
      "---\n",
      "Predict: \t13 15 place_lived EOP\n",
      "Ground-Truth: \t13 15 place_lived EOP\n",
      "---\n",
      "Predict: \t16 14 country EOP\n",
      "Ground-Truth: \t16 14 country EOP\n",
      "---\n",
      "Predict: \t12 13 country EOP\n",
      "Ground-Truth: \t12 13 country EOP\n",
      "---\n",
      "Predict: \t12 11 contains EOP\n",
      "Ground-Truth: \t12 11 contains EOP\n",
      "---\n",
      "Predict: \t12 11 contains EOP\n",
      "Ground-Truth: \t12 11 contains EOP\n",
      "---\n",
      "Predict: \t10 9 contains EOP\n",
      "Ground-Truth: \t10 9 contains EOP\n",
      "---\n",
      "Predict: \t27 23 founders EOP\n",
      "Ground-Truth: \t27 23 founders EOP\n",
      "---\n",
      "Predict: \t21 17 contains EOP\n",
      "Ground-Truth: \t21 17 contains EOP\n",
      "---\n",
      "Predict: \t2 7 country EOP\n",
      "Ground-Truth: \t2 7 country EOP\n",
      "---\n",
      "Predict: \t18 30 country EOP\n",
      "Ground-Truth: \t18 30 country EOP\n",
      "---\n",
      "Predict: \t14 7 contains EOP 17 17 17\n",
      "Ground-Truth: \t14 7 contains EOP\n",
      "---\n",
      "Predict: \t3 2 contains EOP 4 4 4\n",
      "Ground-Truth: \t3 2 contains EOP\n",
      "---\n",
      "Predict: \t2 5 place_lived EOP 4 4 4\n",
      "Ground-Truth: \t2 5 place_lived EOP\n",
      "---\n",
      "Predict: \t2 17 country EOP\n",
      "Ground-Truth: \t2 17 country EOP\n",
      "---\n",
      "Predict: \t8 4 contains EOP\n",
      "Ground-Truth: \t8 4 contains EOP\n",
      "---\n",
      "Predict: \t6 3 country EOP\n",
      "Ground-Truth: \t6 3 country EOP\n",
      "---\n",
      "Predict: \t13 12 contains EOP\n",
      "Ground-Truth: \t13 12 contains EOP\n",
      "---\n",
      "Predict: \t9 11 place_of_death EOP\n",
      "Ground-Truth: \t9 11 neighborhood_of EOP\n",
      "---\n",
      "Predict: \t20 25 country EOP 32 32 32\n",
      "Ground-Truth: \t20 25 country EOP\n",
      "---\n",
      "Predict: \t15 13 contains EOP\n",
      "Ground-Truth: \t15 13 contains EOP\n",
      "---\n",
      "Predict: \t6 3 administrative_divisions EOP\n",
      "Ground-Truth: \t6 3 company EOP\n",
      "---\n",
      "Predict: \t8 7 contains EOP\n",
      "Ground-Truth: \t8 7 contains EOP\n",
      "---\n",
      "Predict: \t10 12 place_lived EOP 12 12 12\n",
      "Ground-Truth: \t10 12 place_lived EOP\n",
      "---\n",
      "Predict: \t2 5 place_lived EOP 4 4 4\n",
      "Ground-Truth: \t2 5 place_lived EOP\n",
      "---\n",
      "Predict: \t22 24 place_lived EOP 35 35 35\n",
      "Ground-Truth: \t22 24 place_lived EOP\n",
      "---\n",
      "Predict: \t16 5 country EOP\n",
      "Ground-Truth: \t16 5 country EOP\n",
      "---\n",
      "Predict: \t1 17 contains EOP\n",
      "Ground-Truth: \t1 17 contains EOP\n",
      "---\n",
      "Predict: \t7 3 place_lived EOP\n",
      "Ground-Truth: \t7 3 place_lived EOP\n",
      "---\n",
      "Predict: \t9 7 contains EOP 8 8 8\n",
      "Ground-Truth: \t9 7 contains EOP\n",
      "---\n",
      "Predict: \t19 21 place_lived EOP\n",
      "Ground-Truth: \t19 21 place_lived EOP\n",
      "---\n",
      "Predict: \t15 17 contains EOP 17 17 17\n",
      "Ground-Truth: \t15 17 contains EOP\n",
      "---\n",
      "Predict: \t6 8 place_lived EOP\n",
      "Ground-Truth: \t6 8 place_lived EOP\n",
      "---\n",
      "Predict: \t9 14 country EOP\n",
      "Ground-Truth: \t9 14 country EOP\n",
      "---\n",
      "Predict: \t11 13 country EOP\n",
      "Ground-Truth: \t11 13 country EOP\n",
      "---\n",
      "Predict: \t2 6 country EOP\n",
      "Ground-Truth: \t2 6 country EOP\n",
      "---\n",
      "Predict: \t11 8 contains EOP\n",
      "Ground-Truth: \t11 8 contains EOP\n",
      "---\n",
      "Predict: \t6 12 country EOP\n",
      "Ground-Truth: \t6 12 country EOP\n",
      "---\n",
      "Predict: \t6 4 country EOP\n",
      "Ground-Truth: \t6 4 country EOP\n",
      "---\n",
      "Predict: \t10 13 country EOP\n",
      "Ground-Truth: \t10 13 country EOP\n",
      "---\n",
      "Predict: \t32 21 country EOP\n",
      "Ground-Truth: \t55 EOP country EOP\n",
      "---\n",
      "Predict: \t15 13 contains EOP\n",
      "Ground-Truth: \t15 13 contains EOP\n",
      "---\n",
      "Predict: \t18 16 country EOP\n",
      "Ground-Truth: \t18 16 country EOP\n",
      "---\n",
      "Predict: \t19 17 contains EOP\n",
      "Ground-Truth: \t19 17 contains EOP\n",
      "---\n",
      "Predict: \t19 21 place_of_birth EOP\n",
      "Ground-Truth: \t19 21 nationality EOP\n",
      "---\n",
      "Predict: \t10 13 country EOP\n",
      "Ground-Truth: \t10 13 country EOP\n",
      "---\n",
      "Predict: \t14 12 contains EOP\n",
      "Ground-Truth: \t14 12 contains EOP\n",
      "---\n",
      "Predict: \t1 5 place_of_birth EOP\n",
      "Ground-Truth: \t1 5 nationality EOP\n",
      "---\n",
      "Predict: \t3 2 contains EOP\n",
      "Ground-Truth: \t3 2 contains EOP\n",
      "---\n",
      "Predict: \t14 8 contains EOP\n",
      "Ground-Truth: \t14 8 contains EOP\n",
      "---\n",
      "Predict: \t17 14 place_of_birth EOP\n",
      "Ground-Truth: \t17 14 nationality EOP\n",
      "---\n",
      "Predict: \t17 24 country EOP\n",
      "Ground-Truth: \t17 24 country EOP\n",
      "---\n",
      "Predict: \t1 4 contains EOP\n",
      "Ground-Truth: \t1 4 contains EOP\n",
      "---\n",
      "Predict: \t10 8 contains EOP\n",
      "Ground-Truth: \t10 8 contains EOP\n",
      "---\n",
      "Predict: \t14 13 contains EOP\n",
      "Ground-Truth: \t14 13 contains EOP\n",
      "---\n",
      "Predict: \t10 15 contains EOP\n",
      "Ground-Truth: \t10 15 contains EOP\n",
      "---\n",
      "Predict: \t7 8 country EOP 8 8 8\n",
      "Ground-Truth: \t7 8 country EOP\n",
      "---\n",
      "Predict: \t10 20 country EOP\n",
      "Ground-Truth: \t10 20 country EOP\n",
      "---\n",
      "Predict: \t20 16 contains EOP\n",
      "Ground-Truth: \t20 16 contains EOP\n",
      "---\n",
      "Predict: \t8 10 place_of_birth EOP\n",
      "Ground-Truth: \t8 10 nationality EOP\n",
      "---\n",
      "Predict: \t16 15 contains EOP\n",
      "Ground-Truth: \t16 15 contains EOP\n",
      "---\n",
      "Predict: \t9 12 country EOP\n",
      "Ground-Truth: \t9 12 country EOP\n",
      "---\n",
      "Predict: \t5 8 place_lived EOP\n",
      "Ground-Truth: \t5 8 place_lived EOP\n",
      "---\n",
      "Predict: \t11 12 contains EOP\n",
      "Ground-Truth: \t11 12 contains EOP\n",
      "---\n",
      "Predict: \t22 20 place_of_birth EOP\n",
      "Ground-Truth: \t22 20 nationality EOP\n",
      "---\n",
      "Predict: \t2 4 contains EOP\n",
      "Ground-Truth: \t2 4 contains EOP\n",
      "---\n",
      "Predict: \t6 1 country EOP\n",
      "Ground-Truth: \t6 1 country EOP\n",
      "---\n",
      "Predict: \t19 21 founders EOP\n",
      "Ground-Truth: \t19 21 founders EOP\n",
      "---\n",
      "Predict: \t11 13 place_of_birth EOP\n",
      "Ground-Truth: \t11 13 nationality EOP\n",
      "---\n",
      "Predict: \t7 8 country EOP 8 8 8\n",
      "Ground-Truth: \t7 8 country EOP\n",
      "---\n",
      "Predict: \t16 14 contains EOP\n",
      "Ground-Truth: \t16 14 contains EOP\n",
      "---\n",
      "Predict: \t14 12 contains EOP\n",
      "Ground-Truth: \t14 12 contains EOP\n",
      "---\n",
      "Predict: \t18 17 contains EOP 35 35 35\n",
      "Ground-Truth: \t18 17 contains EOP\n",
      "---\n",
      "Predict: \t3 12 administrative_divisions EOP\n",
      "Ground-Truth: \t3 12 company EOP\n",
      "---\n",
      "Predict: \t8 9 contains EOP 8 8 8\n",
      "Ground-Truth: \t8 9 contains EOP\n",
      "---\n",
      "Predict: \t11 10 contains EOP\n",
      "Ground-Truth: \t11 10 contains EOP\n",
      "---\n",
      "Predict: \t3 5 place_lived EOP\n",
      "Ground-Truth: \t3 5 place_lived EOP\n",
      "---\n",
      "Predict: \t8 7 contains EOP\n",
      "Ground-Truth: \t8 7 contains EOP\n",
      "---\n",
      "Predict: \t2 1 country EOP\n",
      "Ground-Truth: \t2 1 country EOP\n",
      "---\n",
      "Predict: \t5 8 contains EOP\n",
      "Ground-Truth: \t5 8 contains EOP\n",
      "---\n",
      "Predict: \t11 9 contains EOP\n",
      "Ground-Truth: \t11 9 contains EOP\n",
      "---\n",
      "Predict: \t2 13 country EOP\n",
      "Ground-Truth: \t2 13 country EOP\n",
      "---\n",
      "Predict: \t2 4 place_lived EOP\n",
      "Ground-Truth: \t2 4 place_lived EOP\n",
      "---\n",
      "Predict: \t13 1 administrative_divisions EOP\n",
      "Ground-Truth: \t13 1 company EOP\n",
      "---\n",
      "Predict: \t17 5 country EOP\n",
      "Ground-Truth: \t17 5 country EOP\n",
      "---\n",
      "Predict: \t3 4 country EOP 4 4 4\n",
      "Ground-Truth: \t3 4 country EOP\n",
      "---\n",
      "Predict: \t3 5 place_of_birth EOP 4 4 4\n",
      "Ground-Truth: \t3 5 nationality EOP\n",
      "---\n",
      "Predict: \t7 6 contains EOP\n",
      "Ground-Truth: \t7 6 contains EOP\n",
      "---\n",
      "Predict: \t20 25 administrative_divisions EOP\n",
      "Ground-Truth: \t20 25 company EOP\n",
      "---\n",
      "Predict: \t4 10 administrative_divisions EOP\n",
      "Ground-Truth: \t4 10 company EOP\n",
      "---\n",
      "Predict: \t11 16 country EOP\n",
      "Ground-Truth: \t11 16 country EOP\n",
      "---\n",
      "Predict: \t9 12 place_lived EOP\n",
      "Ground-Truth: \t9 12 place_lived EOP\n",
      "---\n",
      "Predict: \t6 5 contains EOP\n",
      "Ground-Truth: \t6 5 contains EOP\n",
      "---\n",
      "Predict: \t12 11 contains EOP\n",
      "Ground-Truth: \t12 11 contains EOP\n",
      "---\n",
      "Predict: \t4 6 place_lived EOP\n",
      "Ground-Truth: \t4 6 place_lived EOP\n",
      "---\n",
      "Predict: \t12 14 country EOP\n",
      "Ground-Truth: \t12 14 country EOP\n",
      "---\n",
      "Predict: \t8 5 contains EOP\n",
      "Ground-Truth: \t8 5 contains EOP\n",
      "---\n",
      "Predict: \t22 9 country EOP 22 22 22\n",
      "Ground-Truth: \t22 9 country EOP\n",
      "---\n",
      "Predict: \t3 2 contains EOP 4 4 4\n",
      "Ground-Truth: \t3 2 contains EOP\n",
      "---\n",
      "Predict: \t36 30 country EOP\n",
      "Ground-Truth: \t48 30 country EOP\n",
      "---\n",
      "Predict: \t1 3 company EOP\n",
      "Ground-Truth: \t1 3 nationality EOP\n",
      "---\n",
      "Predict: \t1 8 administrative_divisions EOP\n",
      "Ground-Truth: \t1 8 company EOP\n",
      "---\n",
      "Predict: \t7 8 country EOP\n",
      "Ground-Truth: \t7 8 country EOP\n",
      "---\n",
      "Predict: \t13 10 contains EOP\n",
      "Ground-Truth: \t13 10 contains EOP\n",
      "---\n",
      "Predict: \t10 9 contains EOP\n",
      "Ground-Truth: \t10 9 contains EOP\n",
      "---\n",
      "Predict: \t14 4 capital EOP\n",
      "Ground-Truth: \t14 4 capital EOP\n",
      "---\n",
      "Predict: \t38 32 contains EOP 38 38 38\n",
      "Ground-Truth: \t38 32 contains EOP\n",
      "---\n",
      "Predict: \t23 21 contains EOP\n",
      "Ground-Truth: \t23 21 contains EOP\n",
      "---\n",
      "Predict: \t5 9 administrative_divisions EOP\n",
      "Ground-Truth: \t5 9 company EOP\n",
      "---\n",
      "Predict: \t2 3 country EOP\n",
      "Ground-Truth: \t2 3 country EOP\n",
      "---\n",
      "Predict: \t5 8 place_lived EOP\n",
      "Ground-Truth: \t5 8 place_lived EOP\n",
      "---\n",
      "Predict: \t2 1 contains EOP\n",
      "Ground-Truth: \t2 1 contains EOP\n",
      "---\n",
      "Predict: \t12 15 administrative_divisions EOP\n",
      "Ground-Truth: \t12 15 company EOP\n",
      "---\n",
      "Predict: \t10 7 contains EOP\n",
      "Ground-Truth: \t10 7 contains EOP\n",
      "---\n",
      "Predict: \t21 25 children EOP\n",
      "Ground-Truth: \t21 25 children EOP\n",
      "---\n",
      "Predict: \t13 12 contains EOP\n",
      "Ground-Truth: \t13 12 contains EOP\n",
      "---\n",
      "Predict: \t14 6 country EOP\n",
      "Ground-Truth: \t14 6 country EOP\n",
      "---\n",
      "Predict: \t3 2 contains EOP\n",
      "Ground-Truth: \t3 2 contains EOP\n",
      "---\n",
      "Predict: \t9 7 contains EOP 8 8 8\n",
      "Ground-Truth: \t9 7 contains EOP\n",
      "---\n",
      "Predict: \t13 1 country EOP\n",
      "Ground-Truth: \t13 1 country EOP\n",
      "---\n",
      "Predict: \t7 6 contains EOP\n",
      "Ground-Truth: \t7 6 contains EOP\n",
      "---\n",
      "Predict: \t11 9 country EOP\n",
      "Ground-Truth: \t11 9 country EOP\n",
      "---\n",
      "Predict: \t15 16 country EOP\n",
      "Ground-Truth: \t15 16 country EOP\n",
      "---\n",
      "Predict: \t14 13 contains EOP\n",
      "Ground-Truth: \t14 13 contains EOP\n",
      "---\n",
      "Predict: \t7 3 place_of_birth EOP\n",
      "Ground-Truth: \t7 3 nationality EOP\n",
      "---\n",
      "Predict: \t19 10 contains EOP\n",
      "Ground-Truth: \t19 10 contains EOP\n",
      "---\n",
      "Predict: \t4 7 contains EOP\n",
      "Ground-Truth: \t4 7 contains EOP\n",
      "---\n",
      "Predict: \t13 10 country EOP\n",
      "Ground-Truth: \t13 10 country EOP\n",
      "---\n",
      "Predict: \t16 15 contains EOP\n",
      "Ground-Truth: \t16 15 contains EOP\n",
      "---\n",
      "Predict: \t22 19 contains EOP\n",
      "Ground-Truth: \t22 19 contains EOP\n",
      "---\n",
      "Predict: \t20 18 contains EOP\n",
      "Ground-Truth: \t20 18 contains EOP\n",
      "---\n",
      "Predict: \t3 5 place_of_birth EOP\n",
      "Ground-Truth: \t3 5 nationality EOP\n",
      "---\n",
      "Predict: \t11 13 place_of_birth EOP\n",
      "Ground-Truth: \t11 13 nationality EOP\n",
      "---\n",
      "Predict: \t5 13 country EOP\n",
      "Ground-Truth: \t5 13 country EOP\n",
      "---\n",
      "Predict: \t1 7 administrative_divisions EOP\n",
      "Ground-Truth: \t1 7 company EOP\n",
      "---\n",
      "Predict: \t8 4 contains EOP\n",
      "Ground-Truth: \t8 4 contains EOP\n",
      "---\n",
      "Predict: \t30 13 country EOP 32 32 32\n",
      "Ground-Truth: \t30 13 country EOP\n",
      "---\n",
      "Predict: \t7 10 contains EOP 8 8 8\n",
      "Ground-Truth: \t7 10 contains EOP\n",
      "---\n",
      "Predict: \t16 3 country EOP\n",
      "Ground-Truth: \t16 3 country EOP\n",
      "---\n",
      "Predict: \t1 3 administrative_divisions EOP\n",
      "Ground-Truth: \t1 3 company EOP\n",
      "---\n",
      "Predict: \t12 14 country EOP\n",
      "Ground-Truth: \t12 14 country EOP\n",
      "---\n",
      "Predict: \t6 4 contains EOP\n",
      "Ground-Truth: \t6 4 contains EOP\n",
      "---\n",
      "Predict: \t1 3 administrative_divisions EOP\n",
      "Ground-Truth: \t1 3 company EOP\n",
      "---\n",
      "Predict: \t17 14 contains EOP\n",
      "Ground-Truth: \t17 14 contains EOP\n",
      "---\n",
      "Predict: \t3 2 contains EOP 4 4 4\n",
      "Ground-Truth: \t3 2 contains EOP\n",
      "---\n",
      "Predict: \t9 7 contains EOP 8 8 8\n",
      "Ground-Truth: \t9 7 contains EOP\n",
      "---\n",
      "Predict: \t9 7 contains EOP\n",
      "Ground-Truth: \t9 7 contains EOP\n",
      "---\n",
      "Predict: \t2 19 contains EOP\n",
      "Ground-Truth: \t2 19 contains EOP\n",
      "---\n",
      "Predict: \t25 28 administrative_divisions EOP\n",
      "Ground-Truth: \t25 28 company EOP\n",
      "---\n",
      "Predict: \t7 6 contains EOP\n",
      "Ground-Truth: \t7 6 contains EOP\n",
      "---\n",
      "Predict: \t7 5 contains EOP\n",
      "Ground-Truth: \t7 5 contains EOP\n",
      "---\n",
      "Predict: \t11 8 contains EOP\n",
      "Ground-Truth: \t11 8 contains EOP\n",
      "---\n",
      "Predict: \t24 19 contains EOP\n",
      "Ground-Truth: \t24 19 contains EOP\n",
      "---\n",
      "Predict: \t5 6 country EOP\n",
      "Ground-Truth: \t5 6 country EOP\n",
      "---\n",
      "Predict: \t11 9 country EOP\n",
      "Ground-Truth: \t11 9 country EOP\n",
      "---\n",
      "Predict: \t14 11 country EOP\n",
      "Ground-Truth: \t14 11 country EOP\n",
      "---\n",
      "Predict: \t5 11 administrative_divisions EOP\n",
      "Ground-Truth: \t5 11 company EOP\n",
      "---\n",
      "Predict: \t16 15 contains EOP\n",
      "Ground-Truth: \t16 15 contains EOP\n",
      "---\n",
      "Predict: \t13 7 contains EOP\n",
      "Ground-Truth: \t13 7 contains EOP\n",
      "---\n",
      "Predict: \t21 19 contains EOP\n",
      "Ground-Truth: \t21 19 contains EOP\n",
      "---\n",
      "Predict: \t14 12 contains EOP\n",
      "Ground-Truth: \t14 12 contains EOP\n",
      "---\n",
      "Predict: \t17 13 contains EOP\n",
      "Ground-Truth: \t17 13 contains EOP\n",
      "---\n",
      "Predict: \t6 4 contains EOP 4 4 4\n",
      "Ground-Truth: \t6 4 contains EOP\n",
      "---\n",
      "Predict: \t7 6 country EOP\n",
      "Ground-Truth: \t7 6 country EOP\n",
      "---\n",
      "Predict: \t1 4 administrative_divisions EOP\n",
      "Ground-Truth: \t1 4 company EOP\n",
      "---\n",
      "Predict: \t27 25 contains EOP 28 28 28\n",
      "Ground-Truth: \t27 25 contains EOP\n",
      "---\n",
      "Predict: \t2 4 place_lived EOP\n",
      "Ground-Truth: \t2 4 place_lived EOP\n",
      "---\n",
      "Predict: \t19 16 contains EOP\n",
      "Ground-Truth: \t19 16 contains EOP\n",
      "---\n",
      "Predict: \t13 14 country EOP\n",
      "Ground-Truth: \t13 14 country EOP\n",
      "---\n",
      "Predict: \t6 4 contains EOP\n",
      "Ground-Truth: \t6 4 contains EOP\n",
      "---\n",
      "Predict: \t12 10 contains EOP\n",
      "Ground-Truth: \t12 10 contains EOP\n",
      "---\n",
      "Predict: \t8 7 contains EOP\n",
      "Ground-Truth: \t8 7 contains EOP\n",
      "---\n",
      "Predict: \t14 12 contains EOP\n",
      "Ground-Truth: \t14 12 contains EOP\n",
      "---\n",
      "Predict: \t14 15 capital EOP\n",
      "Ground-Truth: \t14 15 capital EOP\n",
      "---\n",
      "Predict: \t3 2 contains EOP 4 4 4\n",
      "Ground-Truth: \t3 2 contains EOP\n",
      "---\n",
      "Predict: \t21 19 contains EOP\n",
      "Ground-Truth: \t21 19 contains EOP\n",
      "---\n",
      "Predict: \t23 41 country EOP\n",
      "Ground-Truth: \t63 43 country EOP\n",
      "---\n",
      "Predict: \t8 7 contains EOP\n",
      "Ground-Truth: \t8 7 contains EOP\n",
      "---\n",
      "Predict: \t5 9 administrative_divisions EOP\n",
      "Ground-Truth: \t5 9 company EOP\n",
      "---\n",
      "Predict: \t11 9 contains EOP\n",
      "Ground-Truth: \t11 9 contains EOP\n",
      "---\n",
      "Predict: \t25 23 contains EOP\n",
      "Ground-Truth: \t25 23 contains EOP\n",
      "---\n",
      "Predict: \t3 4 country EOP\n",
      "Ground-Truth: \t3 4 country EOP\n",
      "---\n",
      "Predict: \t3 6 place_lived EOP\n",
      "Ground-Truth: \t3 6 place_lived EOP\n",
      "---\n",
      "Predict: \t4 9 administrative_divisions EOP\n",
      "Ground-Truth: \t4 9 company EOP\n",
      "---\n",
      "Predict: \t7 8 country EOP 8 8 8\n",
      "Ground-Truth: \t7 8 country EOP\n",
      "---\n",
      "Predict: \t3 2 contains EOP\n",
      "Ground-Truth: \t3 2 contains EOP\n",
      "---\n",
      "Predict: \t13 10 contains EOP 12 12 12\n",
      "Ground-Truth: \t13 10 contains EOP\n",
      "---\n",
      "Predict: \t20 19 contains EOP\n",
      "Ground-Truth: \t20 19 contains EOP\n",
      "---\n",
      "Predict: \t7 4 contains EOP\n",
      "Ground-Truth: \t7 4 contains EOP\n",
      "---\n",
      "Predict: \t5 9 contains EOP\n",
      "Ground-Truth: \t5 9 contains EOP\n",
      "---\n",
      "Predict: \t27 28 country EOP 28 28 28\n",
      "Ground-Truth: \t27 28 country EOP\n",
      "---\n",
      "Predict: \t12 11 contains EOP\n",
      "Ground-Truth: \t12 11 contains EOP\n",
      "---\n",
      "Predict: \t1 9 country EOP\n",
      "Ground-Truth: \t1 9 country EOP\n",
      "---\n",
      "Predict: \t4 3 country EOP\n",
      "Ground-Truth: \t4 3 country EOP\n",
      "---\n",
      "Predict: \t5 4 contains EOP\n",
      "Ground-Truth: \t5 4 contains EOP\n",
      "---\n",
      "Predict: \t7 14 nationality EOP\n",
      "Ground-Truth: \t7 14 nationality EOP\n",
      "---\n",
      "Predict: \t14 13 contains EOP\n",
      "Ground-Truth: \t14 13 contains EOP\n",
      "---\n",
      "Predict: \t12 11 contains EOP\n",
      "Ground-Truth: \t12 11 contains EOP\n",
      "---\n",
      "Predict: \t12 7 contains EOP\n",
      "Ground-Truth: \t12 7 contains EOP\n",
      "---\n",
      "Predict: \t11 13 place_lived EOP\n",
      "Ground-Truth: \t11 13 place_lived EOP\n",
      "---\n",
      "Predict: \t9 8 contains EOP\n",
      "Ground-Truth: \t9 8 contains EOP\n",
      "---\n",
      "Predict: \t1 8 administrative_divisions EOP\n",
      "Ground-Truth: \t1 8 company EOP\n",
      "---\n",
      "Predict: \t7 5 contains EOP\n",
      "Ground-Truth: \t7 5 contains EOP\n",
      "---\n",
      "Predict: \t12 14 country EOP\n",
      "Ground-Truth: \t12 14 country EOP\n",
      "---\n",
      "Predict: \t10 9 contains EOP\n",
      "Ground-Truth: \t10 9 contains EOP\n",
      "---\n",
      "Predict: \t13 11 contains EOP\n",
      "Ground-Truth: \t13 11 contains EOP\n",
      "---\n",
      "Predict: \t12 8 contains EOP\n",
      "Ground-Truth: \t12 8 contains EOP\n",
      "---\n",
      "Predict: \t22 20 contains EOP 22 22 22\n",
      "Ground-Truth: \t22 20 contains EOP\n",
      "---\n",
      "Predict: \t29 8 country EOP 35 35 35\n",
      "Ground-Truth: \t29 8 country EOP\n",
      "---\n",
      "Predict: \t12 16 country EOP\n",
      "Ground-Truth: \t12 16 country EOP\n",
      "---\n",
      "Predict: \t4 3 contains EOP 4 4 4\n",
      "Ground-Truth: \t4 3 contains EOP\n",
      "---\n",
      "Predict: \t8 5 contains EOP\n",
      "Ground-Truth: \t8 5 contains EOP\n",
      "---\n",
      "Predict: \t14 20 country EOP 19 20 country EOP\n",
      "Ground-Truth: \t14 20 country EOP 19 20 country EOP\n",
      "---\n",
      "Predict: \t5 6 country EOP\n",
      "Ground-Truth: \t5 6 country EOP\n",
      "---\n",
      "Predict: \t5 7 place_lived EOP\n",
      "Ground-Truth: \t5 7 place_lived EOP\n",
      "---\n",
      "Predict: \t12 15 place_lived EOP\n",
      "Ground-Truth: \t12 15 place_lived EOP\n",
      "---\n",
      "Predict: \t4 3 contains EOP 4 4 4\n",
      "Ground-Truth: \t4 3 contains EOP\n",
      "---\n",
      "Predict: \t7 6 contains EOP\n",
      "Ground-Truth: \t7 6 contains EOP\n",
      "---\n",
      "Predict: \t6 1 place_of_birth EOP\n",
      "Ground-Truth: \t6 1 nationality EOP\n",
      "---\n",
      "Predict: \t16 14 contains EOP\n",
      "Ground-Truth: \t16 14 contains EOP\n",
      "---\n",
      "Predict: \t7 3 country EOP\n",
      "Ground-Truth: \t7 3 country EOP\n",
      "---\n",
      "Predict: \t21 8 contains EOP\n",
      "Ground-Truth: \t21 8 contains EOP\n",
      "---\n",
      "Predict: \t1 7 place_lived EOP\n",
      "Ground-Truth: \t1 7 place_lived EOP\n",
      "---\n",
      "Predict: \t11 9 contains EOP\n",
      "Ground-Truth: \t11 9 contains EOP\n",
      "---\n",
      "Predict: \t2 1 country EOP\n",
      "Ground-Truth: \t2 1 country EOP\n",
      "---\n",
      "Predict: \t5 2 contains EOP\n",
      "Ground-Truth: \t5 2 contains EOP\n",
      "---\n",
      "Predict: \t12 18 administrative_divisions EOP\n",
      "Ground-Truth: \t12 18 company EOP\n",
      "---\n",
      "Predict: \t10 13 place_of_birth EOP\n",
      "Ground-Truth: \t10 13 nationality EOP\n",
      "---\n",
      "Predict: \t9 6 capital EOP\n",
      "Ground-Truth: \t9 6 children EOP\n",
      "---\n",
      "Predict: \t7 6 contains EOP\n",
      "Ground-Truth: \t7 6 contains EOP\n",
      "---\n",
      "Predict: \t17 14 contains EOP 17 17 17\n",
      "Ground-Truth: \t17 14 contains EOP\n",
      "---\n",
      "Predict: \t6 12 administrative_divisions EOP\n",
      "Ground-Truth: \t6 12 company EOP\n",
      "---\n",
      "Predict: \t3 2 contains EOP 4 4 4\n",
      "Ground-Truth: \t3 2 contains EOP\n",
      "---\n",
      "Predict: \t2 4 place_lived EOP 4 4 4\n",
      "Ground-Truth: \t2 4 place_lived EOP\n",
      "---\n",
      "Predict: \t1 4 place_lived EOP\n",
      "Ground-Truth: \t1 4 place_lived EOP\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in range(395):\n",
    "    print('Predict: \\t%s' % ' '.join(preResult[i]))\n",
    "    print('Ground-Truth: \\t%s' % ' '.join(actResult[i]))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1 Accuracy: \t\t0.992405\n",
      "E2 Accuracy: \t\t0.994937\n",
      "En Accuracy: \t\t0.992405\n",
      "Triple Accuracy: \t0.825316\n"
     ]
    }
   ],
   "source": [
    "preResult = []\n",
    "actResult = []\n",
    "for n in range(395):\n",
    "    pR = [index2token.get(i, str(i)) if i > len(t_sentWords[n]) else t_sentWords[n][i-1] for i in result[n] if i != 0]\n",
    "    aR = [index2token.get(i, str(i)) if i > len(t_sentWords[n]) else t_sentWords[n][i-1] for i in y_test[n] if i != 0]\n",
    "    preResult.append(pR)\n",
    "    actResult.append(aR)\n",
    "e1Count = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0]])\n",
    "e2Count = sum([1 for i in range(395) if actResult[i][1] == preResult[i][1]])\n",
    "enCount = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0] and actResult[i][1] == preResult[i][1]])\n",
    "tripleCount = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0] and actResult[i][1] == preResult[i][1] and actResult[i][2] == preResult[i][2]])\n",
    "print('E1 Accuracy: \\t\\t%.6f' % (e1Count/395))\n",
    "print('E2 Accuracy: \\t\\t%.6f' % (e2Count/395))\n",
    "print('En Accuracy: \\t\\t%.6f' % (enCount/395))\n",
    "print('Triple Accuracy: \\t%.6f' % (tripleCount/395))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: \tspain italy country EOP\n",
      "Ground-Truth: \tspain italy country EOP\n",
      "---\n",
      "Predict: \twestchester connecticut country EOP\n",
      "Ground-Truth: \twestchester connecticut country EOP\n",
      "---\n",
      "Predict: \tdalia israel place_of_birth EOP\n",
      "Ground-Truth: \tdalia israel nationality EOP\n",
      "---\n",
      "Predict: \thyderabad potti contains EOP\n",
      "Ground-Truth: \thyderabad potti contains EOP\n",
      "---\n",
      "Predict: \tkent north place_lived EOP\n",
      "Ground-Truth: \tkent north place_lived EOP\n",
      "---\n",
      "Predict: \tontario waterloo contains EOP ontario ontario ontario\n",
      "Ground-Truth: \tontario waterloo contains EOP\n",
      "---\n",
      "Predict: \tblackstone stephen founders EOP\n",
      "Ground-Truth: \tblackstone stephen founders EOP\n",
      "---\n",
      "Predict: \tfrance italy country EOP italy italy italy\n",
      "Ground-Truth: \tfrance italy country EOP\n",
      "---\n",
      "Predict: \tiran russia country EOP\n",
      "Ground-Truth: \tiran russia country EOP\n",
      "---\n",
      "Predict: \tfrance paris contains EOP\n",
      "Ground-Truth: \tfrance paris contains EOP\n",
      "---\n",
      "Predict: \tgeorge abc administrative_divisions EOP\n",
      "Ground-Truth: \tgeorge abc company EOP\n",
      "---\n",
      "Predict: \tflorida jacksonville contains EOP\n",
      "Ground-Truth: \tflorida jacksonville contains EOP\n",
      "---\n",
      "Predict: \tnigeria uyo contains EOP\n",
      "Ground-Truth: \tnigeria uyo contains EOP\n",
      "---\n",
      "Predict: \tsheldon rhode place_lived EOP vermont vermont vermont\n",
      "Ground-Truth: \tsheldon rhode place_lived EOP\n",
      "---\n",
      "Predict: \tpatrick huntington place_lived EOP\n",
      "Ground-Truth: \tpatrick huntington place_lived EOP\n",
      "---\n",
      "Predict: \tberlin germany country EOP\n",
      "Ground-Truth: \tberlin germany country EOP\n",
      "---\n",
      "Predict: \tjeffrey lazard administrative_divisions EOP\n",
      "Ground-Truth: \tjeffrey lazard company EOP\n",
      "---\n",
      "Predict: \tgaza israel country EOP israel israel israel\n",
      "Ground-Truth: \tgaza israel country EOP\n",
      "---\n",
      "Predict: \tseoul south country EOP cup cup cup\n",
      "Ground-Truth: \tseoul south country EOP\n",
      "---\n",
      "Predict: \tmark york administrative_divisions EOP\n",
      "Ground-Truth: \tmark york company EOP\n",
      "---\n",
      "Predict: \tmarkus australia place_of_birth EOP\n",
      "Ground-Truth: \tmarkus australia nationality EOP\n",
      "---\n",
      "Predict: \tkwame princeton administrative_divisions EOP\n",
      "Ground-Truth: \tkwame princeton company EOP\n",
      "---\n",
      "Predict: \tendemol john founders EOP\n",
      "Ground-Truth: \tendemol john founders EOP\n",
      "---\n",
      "Predict: \ttim minnesota place_lived EOP\n",
      "Ground-Truth: \ttim minnesota place_lived EOP\n",
      "---\n",
      "Predict: \tconnecticut haven contains EOP\n",
      "Ground-Truth: \tconnecticut haven contains EOP\n",
      "---\n",
      "Predict: \tiran russia country EOP pressure pressure pressure\n",
      "Ground-Truth: \tiran russia country EOP\n",
      "---\n",
      "Predict: \tbihar india country EOP\n",
      "Ground-Truth: \tbihar india country EOP\n",
      "---\n",
      "Predict: \tbill dawsonville administrative_divisions EOP joy joy joy\n",
      "Ground-Truth: \tbill dawsonville place_lived EOP\n",
      "---\n",
      "Predict: \tdaniel university administrative_divisions EOP\n",
      "Ground-Truth: \tdaniel university company EOP\n",
      "---\n",
      "Predict: \tsoviet russia country EOP\n",
      "Ground-Truth: \tsoviet russia country EOP\n",
      "---\n",
      "Predict: \tboston wbz-tv contains EOP\n",
      "Ground-Truth: \tboston wbz-tv contains EOP\n",
      "---\n",
      "Predict: \tehud israel place_of_birth EOP\n",
      "Ground-Truth: \tehud israel nationality EOP\n",
      "---\n",
      "Predict: \tvirginia united country EOP\n",
      "Ground-Truth: \tvirginia united country EOP\n",
      "---\n",
      "Predict: \tira system administrative_divisions EOP\n",
      "Ground-Truth: \tira system company EOP\n",
      "---\n",
      "Predict: \tcuba guantanamo contains EOP\n",
      "Ground-Truth: \tcuba guantanamo contains EOP\n",
      "---\n",
      "Predict: \tanthony york administrative_divisions EOP montclair montclair montclair\n",
      "Ground-Truth: \tanthony york company EOP\n",
      "---\n",
      "Predict: \tchad google administrative_divisions EOP\n",
      "Ground-Truth: \tchad google company EOP\n",
      "---\n",
      "Predict: \twashington bainbridge contains EOP jersey jersey jersey\n",
      "Ground-Truth: \twashington bainbridge contains EOP\n",
      "---\n",
      "Predict: \twashington olympia contains EOP wilton wilton wilton\n",
      "Ground-Truth: \twashington olympia contains EOP\n",
      "---\n",
      "Predict: \tsouth seoul contains EOP\n",
      "Ground-Truth: \tsouth seoul contains EOP\n",
      "---\n",
      "Predict: \tfrance spain country EOP\n",
      "Ground-Truth: \tfrance spain country EOP\n",
      "---\n",
      "Predict: \tchuck nebraska place_lived EOP\n",
      "Ground-Truth: \tchuck nebraska place_lived EOP\n",
      "---\n",
      "Predict: \tfrance italy country EOP\n",
      "Ground-Truth: \tfrance italy country EOP\n",
      "---\n",
      "Predict: \tiran syria country EOP 26 26 26\n",
      "Ground-Truth: \tiran syria country EOP\n",
      "---\n",
      "Predict: \tkellen colorado nationality EOP\n",
      "Ground-Truth: \tkellen colorado place_of_birth EOP\n",
      "---\n",
      "Predict: \ttony france place_of_birth EOP\n",
      "Ground-Truth: \ttony france nationality EOP\n",
      "---\n",
      "Predict: \tjose spain place_of_birth EOP\n",
      "Ground-Truth: \tjose spain nationality EOP\n",
      "---\n",
      "Predict: \tfrance italy country EOP france france france\n",
      "Ground-Truth: \tfrance italy country EOP\n",
      "---\n",
      "Predict: \tchuck nebraska place_lived EOP hagel hagel hagel\n",
      "Ground-Truth: \tchuck nebraska place_lived EOP\n",
      "---\n",
      "Predict: \tyork staten contains EOP\n",
      "Ground-Truth: \tyork staten contains EOP\n",
      "---\n",
      "Predict: \tchuck nebraska place_lived EOP chuck chuck chuck\n",
      "Ground-Truth: \tchuck nebraska place_lived EOP\n",
      "---\n",
      "Predict: \tgaza israel country EOP\n",
      "Ground-Truth: \tgaza israel country EOP\n",
      "---\n",
      "Predict: \tralph at&t administrative_divisions EOP\n",
      "Ground-Truth: \tralph at&t company EOP\n",
      "---\n",
      "Predict: \tconnecticut haven contains EOP hartford hartford hartford\n",
      "Ground-Truth: \tconnecticut haven contains EOP\n",
      "---\n",
      "Predict: \tsomalia puntland contains EOP\n",
      "Ground-Truth: \tsomalia puntland contains EOP\n",
      "---\n",
      "Predict: \triga latvia country EOP\n",
      "Ground-Truth: \triga latvia country EOP\n",
      "---\n",
      "Predict: \tswitzerland davos contains EOP\n",
      "Ground-Truth: \tswitzerland davos contains EOP\n",
      "---\n",
      "Predict: \tcolorado vail contains EOP\n",
      "Ground-Truth: \tcolorado vail contains EOP\n",
      "---\n",
      "Predict: \tparis france country EOP\n",
      "Ground-Truth: \tparis france country EOP\n",
      "---\n",
      "Predict: \tlower hudson contains EOP river river river\n",
      "Ground-Truth: \tlower hudson contains EOP\n",
      "---\n",
      "Predict: \tsan north contains EOP\n",
      "Ground-Truth: \tsan north contains EOP\n",
      "---\n",
      "Predict: \tnassau suffolk country EOP\n",
      "Ground-Truth: \tnassau suffolk country EOP\n",
      "---\n",
      "Predict: \tchad youtube administrative_divisions EOP chief chief chief\n",
      "Ground-Truth: \tchad youtube company EOP\n",
      "---\n",
      "Predict: \twestchester kensico contains EOP\n",
      "Ground-Truth: \twestchester kensico contains EOP\n",
      "---\n",
      "Predict: \tben nebraska place_lived EOP\n",
      "Ground-Truth: \tben nebraska place_lived EOP\n",
      "---\n",
      "Predict: \titaly orvieto contains EOP\n",
      "Ground-Truth: \titaly orvieto contains EOP\n",
      "---\n",
      "Predict: \tgreenville furman contains EOP\n",
      "Ground-Truth: \tgreenville furman contains EOP\n",
      "---\n",
      "Predict: \tcharles princeton administrative_divisions EOP princeton princeton princeton\n",
      "Ground-Truth: \tcharles princeton company EOP\n",
      "---\n",
      "Predict: \tcanada ontario contains EOP\n",
      "Ground-Truth: \tcanada ontario contains EOP\n",
      "---\n",
      "Predict: \tflorida boca contains EOP\n",
      "Ground-Truth: \tflorida boca contains EOP\n",
      "---\n",
      "Predict: \tgaza israel country EOP\n",
      "Ground-Truth: \tgaza israel country EOP\n",
      "---\n",
      "Predict: \tbaltimore john contains EOP\n",
      "Ground-Truth: \tbaltimore john contains EOP\n",
      "---\n",
      "Predict: \tsamantha india place_lived EOP\n",
      "Ground-Truth: \tsamantha india place_lived EOP\n",
      "---\n",
      "Predict: \tdavid digitas administrative_divisions EOP\n",
      "Ground-Truth: \tdavid digitas company EOP\n",
      "---\n",
      "Predict: \ttom iowa place_lived EOP\n",
      "Ground-Truth: \ttom iowa place_lived EOP\n",
      "---\n",
      "Predict: \trafik lebanon place_of_birth EOP\n",
      "Ground-Truth: \trafik lebanon nationality EOP\n",
      "---\n",
      "Predict: \tatiku nigeria place_of_birth EOP\n",
      "Ground-Truth: \tatiku nigeria nationality EOP\n",
      "---\n",
      "Predict: \twestchester mamaroneck contains EOP sleeping sleeping sleeping\n",
      "Ground-Truth: \twestchester mamaroneck contains EOP\n",
      "---\n",
      "Predict: \tflorida panama contains EOP\n",
      "Ground-Truth: \tflorida panama contains EOP\n",
      "---\n",
      "Predict: \tiran north country EOP\n",
      "Ground-Truth: \tiran north country EOP\n",
      "---\n",
      "Predict: \tfrance paris contains EOP\n",
      "Ground-Truth: \tfrance paris contains EOP\n",
      "---\n",
      "Predict: \tfrance spain country EOP\n",
      "Ground-Truth: \tfrance spain country EOP\n",
      "---\n",
      "Predict: \tclarkstown city contains EOP includes includes includes\n",
      "Ground-Truth: \tclarkstown city contains EOP\n",
      "---\n",
      "Predict: \tindia delhi contains EOP\n",
      "Ground-Truth: \tindia delhi contains EOP\n",
      "---\n",
      "Predict: \thaley mississippi place_lived EOP\n",
      "Ground-Truth: \thaley mississippi place_lived EOP\n",
      "---\n",
      "Predict: \tflorida boca contains EOP boca boca boca\n",
      "Ground-Truth: \tflorida boca contains EOP\n",
      "---\n",
      "Predict: \tgordon continental administrative_divisions EOP\n",
      "Ground-Truth: \tgordon continental company EOP\n",
      "---\n",
      "Predict: \tparis france country EOP\n",
      "Ground-Truth: \tparis france country EOP\n",
      "---\n",
      "Predict: \tcalifornia long contains EOP\n",
      "Ground-Truth: \tcalifornia long contains EOP\n",
      "---\n",
      "Predict: \tfrance correze contains EOP\n",
      "Ground-Truth: \tfrance correze contains EOP\n",
      "---\n",
      "Predict: \tfairfax westfield contains EOP\n",
      "Ground-Truth: \tfairfax westfield contains EOP\n",
      "---\n",
      "Predict: \tgaza israel country EOP\n",
      "Ground-Truth: \tgaza israel country EOP\n",
      "---\n",
      "Predict: \tspain valencia contains EOP\n",
      "Ground-Truth: \tspain valencia contains EOP\n",
      "---\n",
      "Predict: \tchuck nebraska place_lived EOP\n",
      "Ground-Truth: \tchuck nebraska place_lived EOP\n",
      "---\n",
      "Predict: \tgreenwich jefferson contains EOP\n",
      "Ground-Truth: \tgreenwich jefferson contains EOP\n",
      "---\n",
      "Predict: \tisrael west country EOP hamas hamas hamas\n",
      "Ground-Truth: \tisrael west country EOP\n",
      "---\n",
      "Predict: \tjacques france place_of_birth EOP\n",
      "Ground-Truth: \tjacques france nationality EOP\n",
      "---\n",
      "Predict: \tmahwah ramapo contains EOP\n",
      "Ground-Truth: \tmahwah ramapo contains EOP\n",
      "---\n",
      "Predict: \tguyana linden contains EOP\n",
      "Ground-Truth: \tguyana linden contains EOP\n",
      "---\n",
      "Predict: \tindia punjab contains EOP\n",
      "Ground-Truth: \tindia punjab contains EOP\n",
      "---\n",
      "Predict: \tontario tobermory contains EOP gazing gazing gazing\n",
      "Ground-Truth: \tontario tobermory contains EOP\n",
      "---\n",
      "Predict: \tmiddle iran contains EOP\n",
      "Ground-Truth: \tmiddle iran contains EOP\n",
      "---\n",
      "Predict: \tcuba guantanamo contains EOP cuba cuba cuba\n",
      "Ground-Truth: \tcuba guantanamo contains EOP\n",
      "---\n",
      "Predict: \titaly israel country EOP led led led\n",
      "Ground-Truth: \titaly israel country EOP\n",
      "---\n",
      "Predict: \tgermany spain country EOP\n",
      "Ground-Truth: \tgermany spain country EOP\n",
      "---\n",
      "Predict: \tchad google administrative_divisions EOP\n",
      "Ground-Truth: \tchad google company EOP\n",
      "---\n",
      "Predict: \tehud israel place_of_birth EOP\n",
      "Ground-Truth: \tehud israel nationality EOP\n",
      "---\n",
      "Predict: \tamy minnesota place_lived EOP\n",
      "Ground-Truth: \tamy minnesota place_lived EOP\n",
      "---\n",
      "Predict: \tjohn australia place_of_birth EOP\n",
      "Ground-Truth: \tjohn australia nationality EOP\n",
      "---\n",
      "Predict: \ternie kentucky place_lived EOP fletcher fletcher fletcher\n",
      "Ground-Truth: \ternie kentucky place_lived EOP\n",
      "---\n",
      "Predict: \tiran north country EOP iran iran iran\n",
      "Ground-Truth: \tiran north country EOP\n",
      "---\n",
      "Predict: \tindia bihar administrative_divisions EOP northern northern northern\n",
      "Ground-Truth: \tindia bihar administrative_divisions EOP\n",
      "---\n",
      "Predict: \tireland county contains EOP\n",
      "Ground-Truth: \tireland county contains EOP\n",
      "---\n",
      "Predict: \thavana cuba country EOP\n",
      "Ground-Truth: \thavana cuba country EOP\n",
      "---\n",
      "Predict: \titaly umbria contains EOP\n",
      "Ground-Truth: \titaly umbria contains EOP\n",
      "---\n",
      "Predict: \tcampania italy country EOP\n",
      "Ground-Truth: \tcampania italy country EOP\n",
      "---\n",
      "Predict: \tiran middle country EOP\n",
      "Ground-Truth: \tiran middle country EOP\n",
      "---\n",
      "Predict: \tflorida boca contains EOP\n",
      "Ground-Truth: \tflorida boca contains EOP\n",
      "---\n",
      "Predict: \tgermany spain country EOP\n",
      "Ground-Truth: \tgermany spain country EOP\n",
      "---\n",
      "Predict: \tparis france country EOP\n",
      "Ground-Truth: \tparis france country EOP\n",
      "---\n",
      "Predict: \tcleveland karamu contains EOP house house house\n",
      "Ground-Truth: \tcleveland karamu contains EOP\n",
      "---\n",
      "Predict: \tireland county contains EOP\n",
      "Ground-Truth: \tireland county contains EOP\n",
      "---\n",
      "Predict: \tcalifornia san contains EOP 32 32 32\n",
      "Ground-Truth: \tcalifornia san contains EOP\n",
      "---\n",
      "Predict: \tfrance albertville contains EOP\n",
      "Ground-Truth: \tfrance albertville contains EOP\n",
      "---\n",
      "Predict: \tbosnia srebrenica contains EOP\n",
      "Ground-Truth: \tbosnia srebrenica contains EOP\n",
      "---\n",
      "Predict: \tupper fort contains EOP washington washington washington\n",
      "Ground-Truth: \tupper fort contains EOP\n",
      "---\n",
      "Predict: \tfrance valence contains EOP\n",
      "Ground-Truth: \tfrance valence contains EOP\n",
      "---\n",
      "Predict: \tjames tampa place_lived EOP\n",
      "Ground-Truth: \tjames tampa place_lived EOP\n",
      "---\n",
      "Predict: \tsyria damascus administrative_divisions EOP\n",
      "Ground-Truth: \tsyria damascus administrative_divisions EOP\n",
      "---\n",
      "Predict: \tmarshall fremont place_of_death EOP\n",
      "Ground-Truth: \tmarshall fremont place_of_death EOP\n",
      "---\n",
      "Predict: \tisrael jerusalem contains EOP\n",
      "Ground-Truth: \tisrael jerusalem contains EOP\n",
      "---\n",
      "Predict: \tiran syria country EOP\n",
      "Ground-Truth: \tiran syria country EOP\n",
      "---\n",
      "Predict: \tcambridge lesley contains EOP\n",
      "Ground-Truth: \tcambridge lesley contains EOP\n",
      "---\n",
      "Predict: \tchris australia place_of_birth EOP australia australia australia\n",
      "Ground-Truth: \tchris australia nationality EOP\n",
      "---\n",
      "Predict: \tdennis disney administrative_divisions EOP\n",
      "Ground-Truth: \tdennis disney company EOP\n",
      "---\n",
      "Predict: \tcolorado aspen contains EOP\n",
      "Ground-Truth: \tcolorado aspen contains EOP\n",
      "---\n",
      "Predict: \tsouth seoul contains EOP\n",
      "Ground-Truth: \tsouth seoul contains EOP\n",
      "---\n",
      "Predict: \tstaten fort contains EOP staten staten staten\n",
      "Ground-Truth: \tstaten fort contains EOP\n",
      "---\n",
      "Predict: \tdamascus syria country EOP\n",
      "Ground-Truth: \tdamascus syria country EOP\n",
      "---\n",
      "Predict: \tmexico mexico country EOP\n",
      "Ground-Truth: \tmexico mexico country EOP\n",
      "---\n",
      "Predict: \tjean-louis france place_of_birth EOP\n",
      "Ground-Truth: \tjean-louis france nationality EOP\n",
      "---\n",
      "Predict: \tfrance toulouse contains EOP\n",
      "Ground-Truth: \tfrance toulouse contains EOP\n",
      "---\n",
      "Predict: \tjim kentucky place_lived EOP kentucky kentucky kentucky\n",
      "Ground-Truth: \tjim kentucky place_lived EOP\n",
      "---\n",
      "Predict: \tberlin germany country EOP\n",
      "Ground-Truth: \tberlin germany country EOP\n",
      "---\n",
      "Predict: \tisrael lebanon country EOP experience experience experience\n",
      "Ground-Truth: \tisrael lebanon country EOP\n",
      "---\n",
      "Predict: \tbrett priceline administrative_divisions EOP\n",
      "Ground-Truth: \tbrett priceline company EOP\n",
      "---\n",
      "Predict: \tnewark jersey contains EOP\n",
      "Ground-Truth: \tnewark jersey contains EOP\n",
      "---\n",
      "Predict: \tpeter columbia administrative_divisions EOP\n",
      "Ground-Truth: \tpeter columbia company EOP\n",
      "---\n",
      "Predict: \tleningrad vaganova contains EOP\n",
      "Ground-Truth: \tleningrad vaganova contains EOP\n",
      "---\n",
      "Predict: \tmexico jalisco administrative_divisions EOP\n",
      "Ground-Truth: \tmexico jalisco administrative_divisions EOP\n",
      "---\n",
      "Predict: \twestchester mamaroneck contains EOP\n",
      "Ground-Truth: \twestchester mamaroneck contains EOP\n",
      "---\n",
      "Predict: \tsyria iran country EOP\n",
      "Ground-Truth: \tsyria iran country EOP\n",
      "---\n",
      "Predict: \tbrittany seminole place_lived EOP\n",
      "Ground-Truth: \tbrittany seminole place_lived EOP\n",
      "---\n",
      "Predict: \tmexico mexico country EOP\n",
      "Ground-Truth: \tmexico mexico country EOP\n",
      "---\n",
      "Predict: \tgermany munich contains EOP germany germany germany\n",
      "Ground-Truth: \tgermany munich contains EOP\n",
      "---\n",
      "Predict: \ternst davos place_of_death EOP\n",
      "Ground-Truth: \ternst davos place_of_death EOP\n",
      "---\n",
      "Predict: \tcuba guantanamo contains EOP\n",
      "Ground-Truth: \tcuba guantanamo contains EOP\n",
      "---\n",
      "Predict: \thavana cuba country EOP\n",
      "Ground-Truth: \thavana cuba country EOP\n",
      "---\n",
      "Predict: \tgermany stuttgart contains EOP\n",
      "Ground-Truth: \tgermany stuttgart contains EOP\n",
      "---\n",
      "Predict: \tjeffrey general administrative_divisions EOP\n",
      "Ground-Truth: \tjeffrey general company EOP\n",
      "---\n",
      "Predict: \tpoland cracow contains EOP\n",
      "Ground-Truth: \tpoland cracow contains EOP\n",
      "---\n",
      "Predict: \tnorm minnesota place_lived EOP\n",
      "Ground-Truth: \tnorm minnesota place_lived EOP\n",
      "---\n",
      "Predict: \tsouth iowa country EOP\n",
      "Ground-Truth: \tsouth iowa country EOP\n",
      "---\n",
      "Predict: \tseoul south country EOP\n",
      "Ground-Truth: \tseoul south country EOP\n",
      "---\n",
      "Predict: \tfrance paris contains EOP\n",
      "Ground-Truth: \tfrance paris contains EOP\n",
      "---\n",
      "Predict: \tfrance paris contains EOP\n",
      "Ground-Truth: \tfrance paris contains EOP\n",
      "---\n",
      "Predict: \tjordan amman contains EOP\n",
      "Ground-Truth: \tjordan amman contains EOP\n",
      "---\n",
      "Predict: \tblack robert founders EOP\n",
      "Ground-Truth: \tblack robert founders EOP\n",
      "---\n",
      "Predict: \tarkansas arkadelphia contains EOP\n",
      "Ground-Truth: \tarkansas arkadelphia contains EOP\n",
      "---\n",
      "Predict: \tnavarre spain country EOP\n",
      "Ground-Truth: \tnavarre spain country EOP\n",
      "---\n",
      "Predict: \ttoronto canada country EOP\n",
      "Ground-Truth: \ttoronto canada country EOP\n",
      "---\n",
      "Predict: \tconey york contains EOP 718 718 718\n",
      "Ground-Truth: \tconey york contains EOP\n",
      "---\n",
      "Predict: \tport harborside contains EOP washington washington washington\n",
      "Ground-Truth: \tport harborside contains EOP\n",
      "---\n",
      "Predict: \ttom iowa place_lived EOP republican republican republican\n",
      "Ground-Truth: \ttom iowa place_lived EOP\n",
      "---\n",
      "Predict: \tgaza israel country EOP\n",
      "Ground-Truth: \tgaza israel country EOP\n",
      "---\n",
      "Predict: \tcalifornia lawrence contains EOP\n",
      "Ground-Truth: \tcalifornia lawrence contains EOP\n",
      "---\n",
      "Predict: \tparis france country EOP\n",
      "Ground-Truth: \tparis france country EOP\n",
      "---\n",
      "Predict: \tmexico guadalajara contains EOP\n",
      "Ground-Truth: \tmexico guadalajara contains EOP\n",
      "---\n",
      "Predict: \tlower york place_of_death EOP\n",
      "Ground-Truth: \tlower york neighborhood_of EOP\n",
      "---\n",
      "Predict: \tfrance italy country EOP rrb rrb rrb\n",
      "Ground-Truth: \tfrance italy country EOP\n",
      "---\n",
      "Predict: \tsonoma occidental contains EOP\n",
      "Ground-Truth: \tsonoma occidental contains EOP\n",
      "---\n",
      "Predict: \tchristopher security administrative_divisions EOP\n",
      "Ground-Truth: \tchristopher security company EOP\n",
      "---\n",
      "Predict: \tindia hyderabad contains EOP\n",
      "Ground-Truth: \tindia hyderabad contains EOP\n",
      "---\n",
      "Predict: \tmitch kentucky place_lived EOP kentucky kentucky kentucky\n",
      "Ground-Truth: \tmitch kentucky place_lived EOP\n",
      "---\n",
      "Predict: \tben nebraska place_lived EOP democrat democrat democrat\n",
      "Ground-Truth: \tben nebraska place_lived EOP\n",
      "---\n",
      "Predict: \ttommy wisconsin place_lived EOP tancredo tancredo tancredo\n",
      "Ground-Truth: \ttommy wisconsin place_lived EOP\n",
      "---\n",
      "Predict: \tbangkok thailand country EOP\n",
      "Ground-Truth: \tbangkok thailand country EOP\n",
      "---\n",
      "Predict: \tcalifornia malibu contains EOP\n",
      "Ground-Truth: \tcalifornia malibu contains EOP\n",
      "---\n",
      "Predict: \tayelet berkeley place_lived EOP\n",
      "Ground-Truth: \tayelet berkeley place_lived EOP\n",
      "---\n",
      "Predict: \tcuba guantanamo contains EOP bay bay bay\n",
      "Ground-Truth: \tcuba guantanamo contains EOP\n",
      "---\n",
      "Predict: \tkathleen kansa place_lived EOP\n",
      "Ground-Truth: \tkathleen kansa place_lived EOP\n",
      "---\n",
      "Predict: \tyork greenwich contains EOP greenwich greenwich greenwich\n",
      "Ground-Truth: \tyork greenwich contains EOP\n",
      "---\n",
      "Predict: \tmitch kentucky place_lived EOP\n",
      "Ground-Truth: \tmitch kentucky place_lived EOP\n",
      "---\n",
      "Predict: \tisrael west country EOP\n",
      "Ground-Truth: \tisrael west country EOP\n",
      "---\n",
      "Predict: \tmount tanzania country EOP\n",
      "Ground-Truth: \tmount tanzania country EOP\n",
      "---\n",
      "Predict: \tisrael lebanon country EOP\n",
      "Ground-Truth: \tisrael lebanon country EOP\n",
      "---\n",
      "Predict: \tireland athenry contains EOP\n",
      "Ground-Truth: \tireland athenry contains EOP\n",
      "---\n",
      "Predict: \tiran russia country EOP\n",
      "Ground-Truth: \tiran russia country EOP\n",
      "---\n",
      "Predict: \tberlin germany country EOP\n",
      "Ground-Truth: \tberlin germany country EOP\n",
      "---\n",
      "Predict: \tisrael lebanon country EOP\n",
      "Ground-Truth: \tisrael lebanon country EOP\n",
      "---\n",
      "Predict: \tofficial transfer country iran\n",
      "Ground-Truth: \trussia iran country iran\n",
      "---\n",
      "Predict: \teugene university contains EOP\n",
      "Ground-Truth: \teugene university contains EOP\n",
      "---\n",
      "Predict: \tcatalonia spain country EOP\n",
      "Ground-Truth: \tcatalonia spain country EOP\n",
      "---\n",
      "Predict: \taustralia port contains EOP\n",
      "Ground-Truth: \taustralia port contains EOP\n",
      "---\n",
      "Predict: \tevo bolivia place_of_birth EOP\n",
      "Ground-Truth: \tevo bolivia nationality EOP\n",
      "---\n",
      "Predict: \tberlin germany country EOP\n",
      "Ground-Truth: \tberlin germany country EOP\n",
      "---\n",
      "Predict: \tsouth darlington contains EOP\n",
      "Ground-Truth: \tsouth darlington contains EOP\n",
      "---\n",
      "Predict: \tnelson zimbabwe place_of_birth EOP\n",
      "Ground-Truth: \tnelson zimbabwe nationality EOP\n",
      "---\n",
      "Predict: \tisrael ra'anana contains EOP\n",
      "Ground-Truth: \tisrael ra'anana contains EOP\n",
      "---\n",
      "Predict: \tindia bihar contains EOP\n",
      "Ground-Truth: \tindia bihar contains EOP\n",
      "---\n",
      "Predict: \tehud israel place_of_birth EOP\n",
      "Ground-Truth: \tehud israel nationality EOP\n",
      "---\n",
      "Predict: \tgujarat india country EOP\n",
      "Ground-Truth: \tgujarat india country EOP\n",
      "---\n",
      "Predict: \tcuyahoga cleveland contains EOP\n",
      "Ground-Truth: \tcuyahoga cleveland contains EOP\n",
      "---\n",
      "Predict: \tflorida gulf contains EOP\n",
      "Ground-Truth: \tflorida gulf contains EOP\n",
      "---\n",
      "Predict: \tindia delhi contains EOP\n",
      "Ground-Truth: \tindia delhi contains EOP\n",
      "---\n",
      "Predict: \tmexico mexico contains EOP\n",
      "Ground-Truth: \tmexico mexico contains EOP\n",
      "---\n",
      "Predict: \titaly india country EOP india india india\n",
      "Ground-Truth: \titaly india country EOP\n",
      "---\n",
      "Predict: \tisrael west country EOP\n",
      "Ground-Truth: \tisrael west country EOP\n",
      "---\n",
      "Predict: \tjerusalem yad contains EOP\n",
      "Ground-Truth: \tjerusalem yad contains EOP\n",
      "---\n",
      "Predict: \tehud israel place_of_birth EOP\n",
      "Ground-Truth: \tehud israel nationality EOP\n",
      "---\n",
      "Predict: \titaly maranello contains EOP\n",
      "Ground-Truth: \titaly maranello contains EOP\n",
      "---\n",
      "Predict: \tisrael west country EOP\n",
      "Ground-Truth: \tisrael west country EOP\n",
      "---\n",
      "Predict: \tben nebraska place_lived EOP\n",
      "Ground-Truth: \tben nebraska place_lived EOP\n",
      "---\n",
      "Predict: \tindia bihar contains EOP\n",
      "Ground-Truth: \tindia bihar contains EOP\n",
      "---\n",
      "Predict: \tbashar syria place_of_birth EOP\n",
      "Ground-Truth: \tbashar syria nationality EOP\n",
      "---\n",
      "Predict: \tlouisiana baton contains EOP\n",
      "Ground-Truth: \tlouisiana baton contains EOP\n",
      "---\n",
      "Predict: \tiran middle country EOP\n",
      "Ground-Truth: \tiran middle country EOP\n",
      "---\n",
      "Predict: \tsony akio founders EOP\n",
      "Ground-Truth: \tsony akio founders EOP\n",
      "---\n",
      "Predict: \tshimon israel place_of_birth EOP\n",
      "Ground-Truth: \tshimon israel nationality EOP\n",
      "---\n",
      "Predict: \titaly india country EOP india india india\n",
      "Ground-Truth: \titaly india country EOP\n",
      "---\n",
      "Predict: \tcalabria crotone contains EOP\n",
      "Ground-Truth: \tcalabria crotone contains EOP\n",
      "---\n",
      "Predict: \tflorida boca contains EOP\n",
      "Ground-Truth: \tflorida boca contains EOP\n",
      "---\n",
      "Predict: \tmexico guadalajara contains EOP teach teach teach\n",
      "Ground-Truth: \tmexico guadalajara contains EOP\n",
      "---\n",
      "Predict: \tderrick ford administrative_divisions EOP\n",
      "Ground-Truth: \tderrick ford company EOP\n",
      "---\n",
      "Predict: \tchicago west contains EOP chicago chicago chicago\n",
      "Ground-Truth: \tchicago west contains EOP\n",
      "---\n",
      "Predict: \tvirginia middleburg contains EOP\n",
      "Ground-Truth: \tvirginia middleburg contains EOP\n",
      "---\n",
      "Predict: \tbrad oklahoma place_lived EOP\n",
      "Ground-Truth: \tbrad oklahoma place_lived EOP\n",
      "---\n",
      "Predict: \tcalifornia berkeley contains EOP\n",
      "Ground-Truth: \tcalifornia berkeley contains EOP\n",
      "---\n",
      "Predict: \titaly germany country EOP\n",
      "Ground-Truth: \titaly germany country EOP\n",
      "---\n",
      "Predict: \tcook chicago contains EOP\n",
      "Ground-Truth: \tcook chicago contains EOP\n",
      "---\n",
      "Predict: \tfire ocean contains EOP\n",
      "Ground-Truth: \tfire ocean contains EOP\n",
      "---\n",
      "Predict: \tmexico mexico country EOP\n",
      "Ground-Truth: \tmexico mexico country EOP\n",
      "---\n",
      "Predict: \tmitch kentucky place_lived EOP\n",
      "Ground-Truth: \tmitch kentucky place_lived EOP\n",
      "---\n",
      "Predict: \tshona google administrative_divisions EOP\n",
      "Ground-Truth: \tshona google company EOP\n",
      "---\n",
      "Predict: \tparis france country EOP\n",
      "Ground-Truth: \tparis france country EOP\n",
      "---\n",
      "Predict: \tjuarez mexico country EOP mexico mexico mexico\n",
      "Ground-Truth: \tjuarez mexico country EOP\n",
      "---\n",
      "Predict: \tehud israel place_of_birth EOP olmert olmert olmert\n",
      "Ground-Truth: \tehud israel nationality EOP\n",
      "---\n",
      "Predict: \tisrael rehovot contains EOP\n",
      "Ground-Truth: \tisrael rehovot contains EOP\n",
      "---\n",
      "Predict: \twill york administrative_divisions EOP\n",
      "Ground-Truth: \twill york company EOP\n",
      "---\n",
      "Predict: \tjuliet boston administrative_divisions EOP\n",
      "Ground-Truth: \tjuliet boston company EOP\n",
      "---\n",
      "Predict: \titaly france country EOP\n",
      "Ground-Truth: \titaly france country EOP\n",
      "---\n",
      "Predict: \tmitch kentucky place_lived EOP\n",
      "Ground-Truth: \tmitch kentucky place_lived EOP\n",
      "---\n",
      "Predict: \tmexico puebla contains EOP\n",
      "Ground-Truth: \tmexico puebla contains EOP\n",
      "---\n",
      "Predict: \tspain cordoba contains EOP\n",
      "Ground-Truth: \tspain cordoba contains EOP\n",
      "---\n",
      "Predict: \tmitch kentucky place_lived EOP\n",
      "Ground-Truth: \tmitch kentucky place_lived EOP\n",
      "---\n",
      "Predict: \tisrael west country EOP\n",
      "Ground-Truth: \tisrael west country EOP\n",
      "---\n",
      "Predict: \ttoronto mount contains EOP\n",
      "Ground-Truth: \ttoronto mount contains EOP\n",
      "---\n",
      "Predict: \tdelhi india country EOP delhi delhi delhi\n",
      "Ground-Truth: \tdelhi india country EOP\n",
      "---\n",
      "Predict: \tcanada calgary contains EOP raised raised raised\n",
      "Ground-Truth: \tcanada calgary contains EOP\n",
      "---\n",
      "Predict: \taccused canada country EOP\n",
      "Ground-Truth: \tontario canada country EOP\n",
      "---\n",
      "Predict: \tnikolay russia company EOP\n",
      "Ground-Truth: \tnikolay russia nationality EOP\n",
      "---\n",
      "Predict: \tvali naval administrative_divisions EOP\n",
      "Ground-Truth: \tvali naval company EOP\n",
      "---\n",
      "Predict: \tspain italy country EOP\n",
      "Ground-Truth: \tspain italy country EOP\n",
      "---\n",
      "Predict: \tparis ecole contains EOP\n",
      "Ground-Truth: \tparis ecole contains EOP\n",
      "---\n",
      "Predict: \tjordan amman contains EOP\n",
      "Ground-Truth: \tjordan amman contains EOP\n",
      "---\n",
      "Predict: \talgeria algiers capital EOP\n",
      "Ground-Truth: \talgeria algiers capital EOP\n",
      "---\n",
      "Predict: \tindia dharamsala contains EOP india india india\n",
      "Ground-Truth: \tindia dharamsala contains EOP\n",
      "---\n",
      "Predict: \tflorida lake contains EOP\n",
      "Ground-Truth: \tflorida lake contains EOP\n",
      "---\n",
      "Predict: \tdonald washington administrative_divisions EOP\n",
      "Ground-Truth: \tdonald washington company EOP\n",
      "---\n",
      "Predict: \tontario canada country EOP\n",
      "Ground-Truth: \tontario canada country EOP\n",
      "---\n",
      "Predict: \tdana california place_lived EOP\n",
      "Ground-Truth: \tdana california place_lived EOP\n",
      "---\n",
      "Predict: \tgermany nuremberg contains EOP\n",
      "Ground-Truth: \tgermany nuremberg contains EOP\n",
      "---\n",
      "Predict: \tstanley bank administrative_divisions EOP\n",
      "Ground-Truth: \tstanley bank company EOP\n",
      "---\n",
      "Predict: \tlower battery contains EOP\n",
      "Ground-Truth: \tlower battery contains EOP\n",
      "---\n",
      "Predict: \tfrank lloyd children EOP\n",
      "Ground-Truth: \tfrank lloyd children EOP\n",
      "---\n",
      "Predict: \tmexico guadalajara contains EOP\n",
      "Ground-Truth: \tmexico guadalajara contains EOP\n",
      "---\n",
      "Predict: \tdamascus syria country EOP\n",
      "Ground-Truth: \tdamascus syria country EOP\n",
      "---\n",
      "Predict: \tfrance paris contains EOP\n",
      "Ground-Truth: \tfrance paris contains EOP\n",
      "---\n",
      "Predict: \tyork peck contains EOP peck peck peck\n",
      "Ground-Truth: \tyork peck contains EOP\n",
      "---\n",
      "Predict: \tiran russia country EOP\n",
      "Ground-Truth: \tiran russia country EOP\n",
      "---\n",
      "Predict: \ttaiwan taipei contains EOP\n",
      "Ground-Truth: \ttaiwan taipei contains EOP\n",
      "---\n",
      "Predict: \tdamascus syria country EOP\n",
      "Ground-Truth: \tdamascus syria country EOP\n",
      "---\n",
      "Predict: \titaly spain country EOP\n",
      "Ground-Truth: \titaly spain country EOP\n",
      "---\n",
      "Predict: \tontario kingston contains EOP\n",
      "Ground-Truth: \tontario kingston contains EOP\n",
      "---\n",
      "Predict: \tshimon israel place_of_birth EOP\n",
      "Ground-Truth: \tshimon israel nationality EOP\n",
      "---\n",
      "Predict: \tmexico baja contains EOP\n",
      "Ground-Truth: \tmexico baja contains EOP\n",
      "---\n",
      "Predict: \tindia chhattisgarh contains EOP\n",
      "Ground-Truth: \tindia chhattisgarh contains EOP\n",
      "---\n",
      "Predict: \tmichoacan mexico country EOP\n",
      "Ground-Truth: \tmichoacan mexico country EOP\n",
      "---\n",
      "Predict: \tmexico tulum contains EOP\n",
      "Ground-Truth: \tmexico tulum contains EOP\n",
      "---\n",
      "Predict: \tatlanta georgia contains EOP\n",
      "Ground-Truth: \tatlanta georgia contains EOP\n",
      "---\n",
      "Predict: \tberkeley chez contains EOP\n",
      "Ground-Truth: \tberkeley chez contains EOP\n",
      "---\n",
      "Predict: \tlibby australia place_of_birth EOP\n",
      "Ground-Truth: \tlibby australia nationality EOP\n",
      "---\n",
      "Predict: \tjose spain place_of_birth EOP\n",
      "Ground-Truth: \tjose spain nationality EOP\n",
      "---\n",
      "Predict: \twashington iran country EOP\n",
      "Ground-Truth: \twashington iran country EOP\n",
      "---\n",
      "Predict: \tmark hewlett-packard administrative_divisions EOP\n",
      "Ground-Truth: \tmark hewlett-packard company EOP\n",
      "---\n",
      "Predict: \tparis musee contains EOP\n",
      "Ground-Truth: \tparis musee contains EOP\n",
      "---\n",
      "Predict: \tparis france country EOP 9 9 9\n",
      "Ground-Truth: \tparis france country EOP\n",
      "---\n",
      "Predict: \tharris houston contains EOP county county county\n",
      "Ground-Truth: \tharris houston contains EOP\n",
      "---\n",
      "Predict: \thavana cuba country EOP\n",
      "Ground-Truth: \thavana cuba country EOP\n",
      "---\n",
      "Predict: \twill time administrative_divisions EOP\n",
      "Ground-Truth: \twill time company EOP\n",
      "---\n",
      "Predict: \tisrael west country EOP\n",
      "Ground-Truth: \tisrael west country EOP\n",
      "---\n",
      "Predict: \tchicago winston contains EOP\n",
      "Ground-Truth: \tchicago winston contains EOP\n",
      "---\n",
      "Predict: \tamory rocky administrative_divisions EOP\n",
      "Ground-Truth: \tamory rocky company EOP\n",
      "---\n",
      "Predict: \trochester george contains EOP\n",
      "Ground-Truth: \trochester george contains EOP\n",
      "---\n",
      "Predict: \tmexico cancun contains EOP a a a\n",
      "Ground-Truth: \tmexico cancun contains EOP\n",
      "---\n",
      "Predict: \tidaho salmon contains EOP river river river\n",
      "Ground-Truth: \tidaho salmon contains EOP\n",
      "---\n",
      "Predict: \twest senegal contains EOP\n",
      "Ground-Truth: \twest senegal contains EOP\n",
      "---\n",
      "Predict: \tyork staten contains EOP\n",
      "Ground-Truth: \tyork staten contains EOP\n",
      "---\n",
      "Predict: \tstephen blackstone administrative_divisions EOP\n",
      "Ground-Truth: \tstephen blackstone company EOP\n",
      "---\n",
      "Predict: \tontario kingston contains EOP\n",
      "Ground-Truth: \tontario kingston contains EOP\n",
      "---\n",
      "Predict: \twestport winslow contains EOP\n",
      "Ground-Truth: \twestport winslow contains EOP\n",
      "---\n",
      "Predict: \tbaltimore m&t contains EOP\n",
      "Ground-Truth: \tbaltimore m&t contains EOP\n",
      "---\n",
      "Predict: \twashington walter contains EOP\n",
      "Ground-Truth: \twashington walter contains EOP\n",
      "---\n",
      "Predict: \tguanajuato mexico country EOP\n",
      "Ground-Truth: \tguanajuato mexico country EOP\n",
      "---\n",
      "Predict: \tbihar india country EOP\n",
      "Ground-Truth: \tbihar india country EOP\n",
      "---\n",
      "Predict: \titaly france country EOP\n",
      "Ground-Truth: \titaly france country EOP\n",
      "---\n",
      "Predict: \tdennis york administrative_divisions EOP\n",
      "Ground-Truth: \tdennis york company EOP\n",
      "---\n",
      "Predict: \tkansa atchison contains EOP\n",
      "Ground-Truth: \tkansa atchison contains EOP\n",
      "---\n",
      "Predict: \tboston massachusetts contains EOP\n",
      "Ground-Truth: \tboston massachusetts contains EOP\n",
      "---\n",
      "Predict: \twashington mount contains EOP\n",
      "Ground-Truth: \twashington mount contains EOP\n",
      "---\n",
      "Predict: \tcuba guantanamo contains EOP\n",
      "Ground-Truth: \tcuba guantanamo contains EOP\n",
      "---\n",
      "Predict: \twashington united contains EOP\n",
      "Ground-Truth: \twashington united contains EOP\n",
      "---\n",
      "Predict: \tflorida boca contains EOP boca boca boca\n",
      "Ground-Truth: \tflorida boca contains EOP\n",
      "---\n",
      "Predict: \titaly spain country EOP\n",
      "Ground-Truth: \titaly spain country EOP\n",
      "---\n",
      "Predict: \teddie reebok administrative_divisions EOP\n",
      "Ground-Truth: \teddie reebok company EOP\n",
      "---\n",
      "Predict: \tontario st contains EOP sport-fishing sport-fishing sport-fishing\n",
      "Ground-Truth: \tontario st contains EOP\n",
      "---\n",
      "Predict: \tchuck nebraska place_lived EOP\n",
      "Ground-Truth: \tchuck nebraska place_lived EOP\n",
      "---\n",
      "Predict: \tflorida ponte contains EOP\n",
      "Ground-Truth: \tflorida ponte contains EOP\n",
      "---\n",
      "Predict: \tseoul south country EOP\n",
      "Ground-Truth: \tseoul south country EOP\n",
      "---\n",
      "Predict: \tflorida lake contains EOP\n",
      "Ground-Truth: \tflorida lake contains EOP\n",
      "---\n",
      "Predict: \tchicago sears contains EOP\n",
      "Ground-Truth: \tchicago sears contains EOP\n",
      "---\n",
      "Predict: \tontario woodbridge contains EOP\n",
      "Ground-Truth: \tontario woodbridge contains EOP\n",
      "---\n",
      "Predict: \twashington national contains EOP\n",
      "Ground-Truth: \twashington national contains EOP\n",
      "---\n",
      "Predict: \tguinea conakry capital EOP\n",
      "Ground-Truth: \tguinea conakry capital EOP\n",
      "---\n",
      "Predict: \tiowa waterloo contains EOP 4 4 4\n",
      "Ground-Truth: \tiowa waterloo contains EOP\n",
      "---\n",
      "Predict: \titaly amalfi contains EOP\n",
      "Ground-Truth: \titaly amalfi contains EOP\n",
      "---\n",
      "Predict: \ta hoodlum country rrb\n",
      "Ground-Truth: \titaly france country rrb\n",
      "---\n",
      "Predict: \twestchester hudson contains EOP\n",
      "Ground-Truth: \twestchester hudson contains EOP\n",
      "---\n",
      "Predict: \tg. georgia administrative_divisions EOP\n",
      "Ground-Truth: \tg. georgia company EOP\n",
      "---\n",
      "Predict: \tcuba guantanamo contains EOP\n",
      "Ground-Truth: \tcuba guantanamo contains EOP\n",
      "---\n",
      "Predict: \tberkeley chez contains EOP\n",
      "Ground-Truth: \tberkeley chez contains EOP\n",
      "---\n",
      "Predict: \tgaza israel country EOP\n",
      "Ground-Truth: \tgaza israel country EOP\n",
      "---\n",
      "Predict: \tchuck nebraska place_lived EOP\n",
      "Ground-Truth: \tchuck nebraska place_lived EOP\n",
      "---\n",
      "Predict: \ttyler york administrative_divisions EOP\n",
      "Ground-Truth: \ttyler york company EOP\n",
      "---\n",
      "Predict: \titaly india country EOP india india india\n",
      "Ground-Truth: \titaly india country EOP\n",
      "---\n",
      "Predict: \tcanada ontario contains EOP\n",
      "Ground-Truth: \tcanada ontario contains EOP\n",
      "---\n",
      "Predict: \ttoledo ottawa contains EOP town town town\n",
      "Ground-Truth: \ttoledo ottawa contains EOP\n",
      "---\n",
      "Predict: \tnamibia windhoek contains EOP\n",
      "Ground-Truth: \tnamibia windhoek contains EOP\n",
      "---\n",
      "Predict: \tmamaroneck united contains EOP\n",
      "Ground-Truth: \tmamaroneck united contains EOP\n",
      "---\n",
      "Predict: \tvermont stowe contains EOP\n",
      "Ground-Truth: \tvermont stowe contains EOP\n",
      "---\n",
      "Predict: \titaly spain country EOP spain spain spain\n",
      "Ground-Truth: \titaly spain country EOP\n",
      "---\n",
      "Predict: \tfrance toulouse contains EOP\n",
      "Ground-Truth: \tfrance toulouse contains EOP\n",
      "---\n",
      "Predict: \twashington iran country EOP\n",
      "Ground-Truth: \twashington iran country EOP\n",
      "---\n",
      "Predict: \tcorsica france country EOP\n",
      "Ground-Truth: \tcorsica france country EOP\n",
      "---\n",
      "Predict: \tsyria damascus contains EOP\n",
      "Ground-Truth: \tsyria damascus contains EOP\n",
      "---\n",
      "Predict: \tshilpa india nationality EOP\n",
      "Ground-Truth: \tshilpa india nationality EOP\n",
      "---\n",
      "Predict: \tfinland turku contains EOP\n",
      "Ground-Truth: \tfinland turku contains EOP\n",
      "---\n",
      "Predict: \tgermany stuttgart contains EOP\n",
      "Ground-Truth: \tgermany stuttgart contains EOP\n",
      "---\n",
      "Predict: \tboston beth contains EOP\n",
      "Ground-Truth: \tboston beth contains EOP\n",
      "---\n",
      "Predict: \ttim minnesota place_lived EOP\n",
      "Ground-Truth: \ttim minnesota place_lived EOP\n",
      "---\n",
      "Predict: \trockland city contains EOP\n",
      "Ground-Truth: \trockland city contains EOP\n",
      "---\n",
      "Predict: \tmartin national administrative_divisions EOP\n",
      "Ground-Truth: \tmartin national company EOP\n",
      "---\n",
      "Predict: \ttoronto barrick contains EOP\n",
      "Ground-Truth: \ttoronto barrick contains EOP\n",
      "---\n",
      "Predict: \tlake chicago country EOP\n",
      "Ground-Truth: \tlake chicago country EOP\n",
      "---\n",
      "Predict: \tmarlborough cytyc contains EOP\n",
      "Ground-Truth: \tmarlborough cytyc contains EOP\n",
      "---\n",
      "Predict: \tfrance alzonne contains EOP\n",
      "Ground-Truth: \tfrance alzonne contains EOP\n",
      "---\n",
      "Predict: \twashington national contains EOP\n",
      "Ground-Truth: \twashington national contains EOP\n",
      "---\n",
      "Predict: \tmexico ciudad contains EOP mexico mexico mexico\n",
      "Ground-Truth: \tmexico ciudad contains EOP\n",
      "---\n",
      "Predict: \tiran syria country EOP 35 35 35\n",
      "Ground-Truth: \tiran syria country EOP\n",
      "---\n",
      "Predict: \tisrael west country EOP\n",
      "Ground-Truth: \tisrael west country EOP\n",
      "---\n",
      "Predict: \tvermont stowe contains EOP vermont vermont vermont\n",
      "Ground-Truth: \tvermont stowe contains EOP\n",
      "---\n",
      "Predict: \tconnecticut hamden contains EOP\n",
      "Ground-Truth: \tconnecticut hamden contains EOP\n",
      "---\n",
      "Predict: \twashington iran country EOP russia iran country EOP\n",
      "Ground-Truth: \twashington iran country EOP russia iran country EOP\n",
      "---\n",
      "Predict: \tsyria iran country EOP\n",
      "Ground-Truth: \tsyria iran country EOP\n",
      "---\n",
      "Predict: \tchuck nebraska place_lived EOP\n",
      "Ground-Truth: \tchuck nebraska place_lived EOP\n",
      "---\n",
      "Predict: \tchuck nebraska place_lived EOP\n",
      "Ground-Truth: \tchuck nebraska place_lived EOP\n",
      "---\n",
      "Predict: \tiowa waverly contains EOP iowa iowa iowa\n",
      "Ground-Truth: \tiowa waverly contains EOP\n",
      "---\n",
      "Predict: \tcuba bayamo contains EOP\n",
      "Ground-Truth: \tcuba bayamo contains EOP\n",
      "---\n",
      "Predict: \taziz south place_of_birth EOP\n",
      "Ground-Truth: \taziz south nationality EOP\n",
      "---\n",
      "Predict: \titaly reggio contains EOP\n",
      "Ground-Truth: \titaly reggio contains EOP\n",
      "---\n",
      "Predict: \tiran washington country EOP\n",
      "Ground-Truth: \tiran washington country EOP\n",
      "---\n",
      "Predict: \thampshire cannon contains EOP\n",
      "Ground-Truth: \thampshire cannon contains EOP\n",
      "---\n",
      "Predict: \thelen guatemala place_lived EOP\n",
      "Ground-Truth: \thelen guatemala place_lived EOP\n",
      "---\n",
      "Predict: \tromania black contains EOP\n",
      "Ground-Truth: \tromania black contains EOP\n",
      "---\n",
      "Predict: \tiran syria country EOP\n",
      "Ground-Truth: \tiran syria country EOP\n",
      "---\n",
      "Predict: \tdecatur agnes contains EOP\n",
      "Ground-Truth: \tdecatur agnes contains EOP\n",
      "---\n",
      "Predict: \trobin north administrative_divisions EOP\n",
      "Ground-Truth: \trobin north company EOP\n",
      "---\n",
      "Predict: \timelda philippine place_of_birth EOP\n",
      "Ground-Truth: \timelda philippine nationality EOP\n",
      "---\n",
      "Predict: \tcharles woody capital EOP\n",
      "Ground-Truth: \tcharles woody children EOP\n",
      "---\n",
      "Predict: \tmaryland annapolis contains EOP\n",
      "Ground-Truth: \tmaryland annapolis contains EOP\n",
      "---\n",
      "Predict: \tparis gare contains EOP paris paris paris\n",
      "Ground-Truth: \tparis gare contains EOP\n",
      "---\n",
      "Predict: \tstephen case administrative_divisions EOP\n",
      "Ground-Truth: \tstephen case company EOP\n",
      "---\n",
      "Predict: \tboston church contains EOP bay bay bay\n",
      "Ground-Truth: \tboston church contains EOP\n",
      "---\n",
      "Predict: \thaley mississippi place_lived EOP mississippi mississippi mississippi\n",
      "Ground-Truth: \thaley mississippi place_lived EOP\n",
      "---\n",
      "Predict: \tsheldon rhode place_lived EOP\n",
      "Ground-Truth: \tsheldon rhode place_lived EOP\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in range(395):\n",
    "    print('Predict: \\t%s' % ' '.join(preResult[i]))\n",
    "    print('Ground-Truth: \\t%s' % ' '.join(actResult[i]))\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 7s     \n"
     ]
    }
   ],
   "source": [
    "filename = '/Users/lizhn7/Downloads/DATA/nyt/experiment_5_1/cp_logs/weights.189-0.172831.hdf5'\n",
    "model.load_weights(filename)\n",
    "\n",
    "result = np.argmax(model.predict([x_test, a], batch_size=BATCH_SIZE, verbose=1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = np.zeros((395, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.training.Model at 0x27cc772b0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65132, 300)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "INPUT (InputLayer)               (None, 64)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "EMBEDDING (Embedding)            (None, 64, 300)       19539600    INPUT[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 64, 300)       0           EMBEDDING[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "ENC_BLSTM_1 (Bidirectional)      (None, 64, 600)       1442400     dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 64, 600)       0           ENC_BLSTM_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "ENC_BLSTM_2 (Bidirectional)      (None, 600)           2162400     dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "TF_INPUT (InputLayer)            (None, 8)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 600)           0           ENC_BLSTM_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "TF_EMBEDDING (Embedding)         (None, 8, 50)         3950        TF_INPUT[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "CONTEXT (RepeatVector)           (None, 8, 600)        0           dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 8, 50)         0           TF_EMBEDDING[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 8, 650)        0           CONTEXT[0][0]                    \n",
      "                                                                   dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "DEC_BLSTM (Bidirectional)        (None, 8, 300)        961200      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 8, 300)        0           DEC_BLSTM[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "OUTPUT (TimeDistributed)         (None, 8, 79)         23779       dropout_5[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 24,133,329\n",
      "Trainable params: 24,133,329\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.topology.InputLayer at 0x27a9116a0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'INPUT:0' shape=(?, 64) dtype=float32>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_seq = model.layers[0]\n",
    "pre_emb = model.layers[1]\n",
    "pre_emb = model.layers[2]\n",
    "pre\n",
    "emb_seq = Embedding(VOCAB_SIZE, EMBEDDING_SIZE, weights=[embedding], mask_zero=True, input_length=MAX_SENT_LEN, trainable=True, name='EMBEDDING')(sequence)\n",
    "emb_seq = Dropout(DROPOUT_RATE)(emb_seq)\n",
    "tf_seq = Input(shape=(MAX_ADJL_LEN,), name='TF_INPUT')\n",
    "tf_emb = Embedding(NUM_CLASSES, TF_EMBEDDING_SIZE, mask_zero=True, input_length=MAX_ADJL_LEN, name='TF_EMBEDDING')(tf_seq)\n",
    "tf_emb = Dropout(DROPOUT_RATE)(tf_emb)\n",
    "blstm = Bidirectional(LSTM(ENC_RNN_SIZE, return_sequences=True, implementation=0, dropout=RNN_DROPOUT_RATE, recurrent_dropout=RNN_DROPOUT_RATE), merge_mode='concat', name='ENC_BLSTM_1')(emb_seq)\n",
    "blstm = Dropout(DROPOUT_RATE)(blstm)\n",
    "blstm = Bidirectional(LSTM(ENC_RNN_SIZE, return_sequences=False, implementation=0, dropout=RNN_DROPOUT_RATE, recurrent_dropout=RNN_DROPOUT_RATE), merge_mode='concat', name='ENC_BLSTM_2')(blstm)\n",
    "blstm = Dropout(DROPOUT_RATE)(blstm)\n",
    "context = RepeatVector(MAX_ADJL_LEN, name='CONTEXT')(blstm)\n",
    "context = concatenate([context, tf_emb], axis=-1)\n",
    "blstm = Bidirectional(LSTM(DEC_RNN_SIZE, return_sequences=True, implementation=2, dropout=RNN_DROPOUT_RATE, recurrent_dropout=RNN_DROPOUT_RATE, name='DEC_LSTM'), merge_mode='concat', name='DEC_BLSTM')(context)\n",
    "lstm = Dropout(DROPOUT_RATE)(blstm)\n",
    "output = TimeDistributed(Dense(NUM_CLASSES, activation='softmax'), name='OUTPUT')(lstm)\n",
    "model = Model(inputs=[sequence, tf_seq], outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keras_rnn_predict(samples, empty=empty, model=model, maxlen=maxlen):\n",
    "    \"\"\"\n",
    "    supply RNN model and maxlen(the length of sequences it can handle)\n",
    "    for every sample, calculate probability for every possible label\n",
    "    \"\"\"\n",
    "    sample_lengths = map(len, samples)\n",
    "    # pad from right(post) so the first c_maxlen will be content followed by title\n",
    "    data = sequence.pad_sequences(samples, maxlen=maxlen, value=empty, padding='post', truncating='post')\n",
    "    probs = model.predict(data, verbose=0, batch_size=batch_size)\n",
    "    return np.array([prob[sample_length-c_maxlen-1] for prob, sample_length in zip(probs, sample_lengths)]) # []x40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keras_rnn_predict(samples, empty=empty, model=model, maxlen=maxlen):\n",
    "    \"\"\"\n",
    "    supply RNN model and maxlen(the length of sequences it can handle)\n",
    "    for every sample, calculate probability for every possible label\n",
    "    \"\"\"\n",
    "    sample_lengths = map(len, samples)\n",
    "    # pad from right(post) so the first c_maxlen will be content followed by title\n",
    "    data = sequence.pad_sequences(samples, maxlen=maxlen, value=empty, padding='post', truncating='post')\n",
    "    probs = model.predict(data, verbose=0, batch_size=batch_size)\n",
    "    return np.array([prob[sample_length-c_maxlen-1] for prob, sample_length in zip(probs, sample_lengths)]) # []x40000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
