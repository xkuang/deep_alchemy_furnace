{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#GPU\" data-toc-modified-id=\"GPU-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>GPU</a></div><div class=\"lev1 toc-item\"><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Preprocessing</a></div><div class=\"lev2 toc-item\"><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Load Data</a></div><div class=\"lev3 toc-item\"><a href=\"#Load-Train-Data\" data-toc-modified-id=\"Load-Train-Data-211\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Load Train Data</a></div><div class=\"lev3 toc-item\"><a href=\"#Load-Test-Data\" data-toc-modified-id=\"Load-Test-Data-212\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Load Test Data</a></div><div class=\"lev3 toc-item\"><a href=\"#Relation-Types\" data-toc-modified-id=\"Relation-Types-213\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Relation Types</a></div><div class=\"lev2 toc-item\"><a href=\"#Participle\" data-toc-modified-id=\"Participle-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Participle</a></div><div class=\"lev2 toc-item\"><a href=\"#Make-Adjacency-List\" data-toc-modified-id=\"Make-Adjacency-List-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Make Adjacency List</a></div><div class=\"lev3 toc-item\"><a href=\"#Make-Adjacency-List-of-Train-Data\" data-toc-modified-id=\"Make-Adjacency-List-of-Train-Data-231\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Make Adjacency List of Train Data</a></div><div class=\"lev3 toc-item\"><a href=\"#Make-Adjacency-List-of-Test-Data\" data-toc-modified-id=\"Make-Adjacency-List-of-Test-Data-232\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Make Adjacency List of Test Data</a></div><div class=\"lev1 toc-item\"><a href=\"#Word-to-Vector\" data-toc-modified-id=\"Word-to-Vector-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Word to Vector</a></div><div class=\"lev2 toc-item\"><a href=\"#Tokenize-Text\" data-toc-modified-id=\"Tokenize-Text-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Tokenize Text</a></div><div class=\"lev2 toc-item\"><a href=\"#Create-Word-Embeddings-with-GloVe\" data-toc-modified-id=\"Create-Word-Embeddings-with-GloVe-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Create Word Embeddings with GloVe</a></div><div class=\"lev3 toc-item\"><a href=\"#Read-GloVe\" data-toc-modified-id=\"Read-GloVe-321\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Read GloVe</a></div><div class=\"lev3 toc-item\"><a href=\"#Use-Glove-to-Initialize-Embedding-Matrix\" data-toc-modified-id=\"Use-Glove-to-Initialize-Embedding-Matrix-322\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Use Glove to Initialize Embedding Matrix</a></div><div class=\"lev1 toc-item\"><a href=\"#Build-Dateset\" data-toc-modified-id=\"Build-Dateset-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Build Dateset</a></div><div class=\"lev1 toc-item\"><a href=\"#Save-Dataset\" data-toc-modified-id=\"Save-Dataset-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Save Dataset</a></div><div class=\"lev1 toc-item\"><a href=\"#Checkpoint\" data-toc-modified-id=\"Checkpoint-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Checkpoint</a></div><div class=\"lev1 toc-item\"><a href=\"#Build-Model\" data-toc-modified-id=\"Build-Model-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Build Model</a></div><div class=\"lev2 toc-item\"><a href=\"#Set-Hyperparameters\" data-toc-modified-id=\"Set-Hyperparameters-71\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Set Hyperparameters</a></div><div class=\"lev2 toc-item\"><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-72\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Import Libraries</a></div><div class=\"lev2 toc-item\"><a href=\"#Build-Graph\" data-toc-modified-id=\"Build-Graph-73\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Build Graph</a></div><div class=\"lev2 toc-item\"><a href=\"#Model-Visualization\" data-toc-modified-id=\"Model-Visualization-74\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Model Visualization</a></div><div class=\"lev2 toc-item\"><a href=\"#Train\" data-toc-modified-id=\"Train-75\"><span class=\"toc-item-num\">7.5&nbsp;&nbsp;</span>Train</a></div><div class=\"lev1 toc-item\"><a href=\"#Evaluate\" data-toc-modified-id=\"Evaluate-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Evaluate</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentText = []\n",
    "relationMentions = []\n",
    "relationLabels = []\n",
    "entityMentions = []\n",
    "entityLabels = []\n",
    "em1Text = []\n",
    "em2Text = []\n",
    "\n",
    "with open(\"/Users/lizhn7/Downloads/DATA/nyt/train.json\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    item = json.loads(line)\n",
    "    # Exclude \"None\" label\n",
    "    if not all(i['label'] == 'None' for i in item['relationMentions']):\n",
    "        sentText.append(item['sentText'])\n",
    "        relationMentions.append(item['relationMentions'])\n",
    "        entityMentions.append(item['entityMentions'])\n",
    "    \n",
    "relationLabels = [[i['label'].split('/')[-1] for i in rM] for rM in relationMentions]\n",
    "entityLabels = [[i['text'] for i in eM] for eM in entityMentions]\n",
    "em1Text = [[i['em1Text'] for i in rM] for rM in relationMentions]\n",
    "em2Text = [[i['em2Text'] for i in rM] for rM in relationMentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean words\n",
    "replaceDict = {\n",
    "               'ā': 'a', 'á': 'a', 'ǎ': 'a', 'à': 'a',\n",
    "               'ō': 'o', 'ó': 'o', 'ǒ': 'o', 'ò': 'o', 'ô': 'o', 'ö': 'o',\n",
    "               'ē': 'e', 'é': 'e', 'ě': 'e', 'è': 'e', \n",
    "               'ī': 'i', 'í': 'i', 'ǐ': 'i', 'ì': 'i',\n",
    "               'ū': 'u', 'ú': 'u', 'ǔ': 'u', 'ù': 'u', 'ü': 'u',\n",
    "               'ñ': 'n',\n",
    "               'É': 'E'\n",
    "              }\n",
    "em1Text = [[''.join([replaceDict.get(i, i) for i in e]) for e in eT] for eT in em1Text]\n",
    "em2Text = [[''.join([replaceDict.get(i, i) for i in e]) for e in eT] for eT in em2Text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_sentText = []\n",
    "t_relationMentions = []\n",
    "t_relationLabels = []\n",
    "t_entityMentions = []\n",
    "t_entityLabels = []\n",
    "t_em1Text = []\n",
    "t_em2Text = []\n",
    "\n",
    "with open(\"/Users/lizhn7/Downloads/DATA/nyt/test.json\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    item = json.loads(line)\n",
    "    t_sentText.append(item['sentText'])\n",
    "    t_relationMentions.append(item['relationMentions'])\n",
    "    t_entityMentions.append(item['entityMentions'])\n",
    "    \n",
    "t_relationLabels = [[i['label'].split('/')[-1] for i in rM] for rM in t_relationMentions]\n",
    "t_entityLabels = [[i['text'] for i in eM] for eM in t_entityMentions]\n",
    "t_em1Text = [[i['em1Text'] for i in rM] for rM in t_relationMentions]\n",
    "t_em2Text = [[i['em2Text'] for i in rM] for rM in t_relationMentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean words\n",
    "t_replaceDict = {\n",
    "               'ā': 'a', 'á': 'a', 'ǎ': 'a', 'à': 'a',\n",
    "               'ō': 'o', 'ó': 'o', 'ǒ': 'o', 'ò': 'o', 'ô': 'o', 'ö': 'o',\n",
    "               'ē': 'e', 'é': 'e', 'ě': 'e', 'è': 'e', \n",
    "               'ī': 'i', 'í': 'i', 'ǐ': 'i', 'ì': 'i',\n",
    "               'ū': 'u', 'ú': 'u', 'ǔ': 'u', 'ù': 'u', 'ü': 'u',\n",
    "               'ñ': 'n',\n",
    "               'É': 'E'\n",
    "              }\n",
    "t_em1Text = [[''.join([t_replaceDict.get(i, i) for i in e]) for e in eT] for eT in t_em1Text]\n",
    "t_em2Text = [[''.join([t_replaceDict.get(i, i) for i in e]) for e in eT] for eT in t_em2Text]\n",
    "t_entityLabels = [[''.join([t_replaceDict.get(i, i) for i in e]) for e in eT] for eT in t_entityLabels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Relation Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['industry',\n",
       " 'religion',\n",
       " 'neighborhood_of',\n",
       " 'capital',\n",
       " 'founders',\n",
       " 'company',\n",
       " 'profession',\n",
       " 'contains',\n",
       " 'nationality',\n",
       " 'geographic_distribution',\n",
       " 'advisors',\n",
       " 'location',\n",
       " 'place_of_birth',\n",
       " 'teams',\n",
       " 'place_of_death',\n",
       " 'major_shareholder_of',\n",
       " 'children',\n",
       " 'ethnicity',\n",
       " 'country',\n",
       " 'people',\n",
       " 'administrative_divisions',\n",
       " 'place_founded',\n",
       " 'place_lived',\n",
       " 'major_shareholders']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationTypes = list(set([r for rl in relationLabels for r in rl]))\n",
    "relationTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['children',\n",
       " 'company',\n",
       " 'place_of_birth',\n",
       " 'contains',\n",
       " 'nationality',\n",
       " 'country',\n",
       " 'administrative_divisions',\n",
       " 'neighborhood_of',\n",
       " 'capital',\n",
       " 'place_lived',\n",
       " 'place_of_death',\n",
       " 'founders']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_relationTypes = list(set([r for rl in t_relationLabels for r in rl if r != 'None']))\n",
    "t_relationTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut(s):\n",
    "    \"\"\"\n",
    "    Participle\n",
    "    \"\"\"\n",
    "    pattern = r'''\n",
    "              (?x)                   # set flag to allow verbose regexps \n",
    "              (?:[A-Z]\\.)+           # abbreviations, e.g. U.S.A. \n",
    "              |\\d+(?:\\.\\d+)?%?       # numbers, incl. currency and percentages \n",
    "              |\\w+(?:[-&']\\w+)*       # words w/ optional internal hyphens/apostrophe  \n",
    "           '''  \n",
    "    return regexp_tokenize(s, pattern=pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentWords = [cut(s) for s in sentText]\n",
    "entlabWords = [[cut(s) for s in eL] for eL in entityLabels]\n",
    "em1Words = [[cut(s) for s in eL] for eL in em1Text]\n",
    "em2Words = [[cut(s) for s in eL] for eL in em2Text]\n",
    "t_sentWords = [cut(s) for s in t_sentText]\n",
    "t_entlabWords = [[cut(s) for s in eL] for eL in t_entityLabels]\n",
    "t_em1Words = [[cut(s) for s in eL] for eL in t_em1Text]\n",
    "t_em2Words = [[cut(s) for s in eL] for eL in t_em2Text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SENT_LEN = 120\n",
    "MAX_ADJL_LEN = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Adjacency List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Adjacency List of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_entityLabels = []\n",
    "for i in range(len(sentWords)):\n",
    "    eL = []\n",
    "    sDict = list(enumerate(sentWords[i]))\n",
    "    j = 0\n",
    "    for item in entlabWords[i]:\n",
    "        el = []\n",
    "        for e in item:\n",
    "            while j < len(sDict):\n",
    "                if e == sDict[j][1]:\n",
    "                    el.append(sDict[j][0])\n",
    "                    j += 1\n",
    "                    break\n",
    "                j += 1\n",
    "        eL.append(el)\n",
    "    i_entityLabels.append(eL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmSet = []\n",
    "for item in range(len(relationMentions)):\n",
    "    rms = [(em1Words[item][i][0], em2Words[item][i][0], relationLabels[item][i]) for i in range(len(relationLabels[item]))]\n",
    "    rms = [' '.join(list(i)) for i in rms]\n",
    "    rmSet.append(rms)\n",
    "rmSet = [set(i) for i in rmSet]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_adjacencyList = []\n",
    "new_sentWords = []\n",
    "for n in range(len(sentWords)):\n",
    "    aL = []\n",
    "    for l in range(len(relationLabels[n])):\n",
    "        e1 = []\n",
    "        e2 = []\n",
    "        for item in i_entityLabels[n]:\n",
    "            if ' '.join([sentWords[n][i] for i in item]) == ' '.join(em1Words[n][l]):\n",
    "                e1.append(item[0])\n",
    "            if ' '.join([sentWords[n][i] for i in item]) == ' '.join(em2Words[n][l]):\n",
    "                e2.append(item[0])\n",
    "        c1 = [(a, b) for a in e1 for b in e2 if ' '.join([sentWords[n][a], sentWords[n][b], relationLabels[n][l]]) in rmSet[n]]\n",
    "        c2 = [(a, b) for a in e2 for b in e1 if ' '.join([sentWords[n][b], sentWords[n][a], relationLabels[n][l]]) in rmSet[n]]\n",
    "        c = c1 + c2\n",
    "        m = min([(i, abs(j[0]-j[1])) for i, j in enumerate(c)], key=lambda x: x[-1])[-1]\n",
    "        r = [i[0] for i in [(i, abs(j[0]-j[1])) for i, j in enumerate(c)] if i[-1] == m]\n",
    "        for i in r:\n",
    "            if ' '.join([sentWords[n][c[i][0]], sentWords[n][c[i][1]], relationLabels[n][l]]) in rmSet[n]:\n",
    "                al = (c[i][0], pad[0], c[i][1], pad[1], relationLabels[n][l], pad[2])\n",
    "                if al[4] in t_relationTypes and al[0] < MAX_SENT_LEN and al[2] < MAX_SENT_LEN: \n",
    "                    aL.append(al)\n",
    "    aL = sorted([list(i) for i in set(aL)])\n",
    "    if len(aL) == 1 or len(aL) == 2:\n",
    "        i_adjacencyList.append(aL)\n",
    "        new_sentWords.append(sentWords[n])\n",
    "i_adjacencyList = [sum(i, []) for i in i_adjacencyList]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Adjacency List of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean words\n",
    "t_sentWords = [[''.join([t_replaceDict.get(i, i) for i in e]) for e in eT] for eT in t_sentWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ti_entityLabels = []\n",
    "for i in range(len(t_sentWords)):\n",
    "    eL = []\n",
    "    t_sDict = list(enumerate(t_sentWords[i]))\n",
    "    j = 0\n",
    "    for item in t_entlabWords[i]:\n",
    "        el = []\n",
    "        for e in item:\n",
    "            while j < len(t_sDict):\n",
    "                if e == t_sDict[j][1]:\n",
    "                    el.append(t_sDict[j][0])\n",
    "                    j += 1\n",
    "                    break\n",
    "                j += 1\n",
    "        eL.append(el)\n",
    "    ti_entityLabels.append(eL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ti_trueLables = [[i for i, j in enumerate(rl) if j != 'None'] for rl in t_relationLabels]\n",
    "t_trueMentions = [[j for i, j in enumerate(rl) if j['label'] != 'None'] for rl in t_relationMentions]\n",
    "pad = ['POI', 'RE', 'EOP']\n",
    "ti_adjacencyList = []\n",
    "for n in range(len(t_sentWords)): \n",
    "    e1 = []\n",
    "    e2 = []\n",
    "    aL = []\n",
    "    for l in ti_trueLables[n]:\n",
    "        for item in ti_entityLabels[n]:\n",
    "            if ' '.join([t_sentWords[n][i] for i in item]) == ' '.join(t_em1Words[n][l]):\n",
    "                e1.append(item[0])\n",
    "            if ' '.join([t_sentWords[n][i] for i in item]) == ' '.join(t_em2Words[n][l]):\n",
    "                e2.append(item[0])\n",
    "    c = [(a, b) for a in e1 for b in e2]\n",
    "    r = c[min([(i, abs(j[0]-j[1])) for i, j in enumerate(c)], key=lambda x: x[-1])[0]]\n",
    "    aL = aL + [r[0], pad[0], r[1], pad[1], t_relationLabels[n][l], pad[2]]\n",
    "    ti_adjacencyList.append(aL)\n",
    "\n",
    "# Modify \n",
    "ti_adjacencyList[26] = [34, 'POI', 36, 'RE', 'founders', 'EOP']\n",
    "ti_adjacencyList[191] = [22, 'POI', 36, 'RE', 'country', 'EOP', 33, 'POI', 36, 'RE', 'country', 'EOP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The United States previously offered to locate the missile system in the Czech Republic and Poland drawing furious objections from Russia though Washington argues that the system is not built to defend against Russia but against Iran principally and other potential threats'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(t_sentWords[191])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word to Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "sentWords = [[wnl.lemmatize(t.lower()) for t in toks] for toks in new_sentWords]\n",
    "t_sentWords = [[wnl.lemmatize(t.lower()) for t in toks] for toks in t_sentWords]\n",
    "tok_sentWords = sentWords.copy()\n",
    "tok_sentWords.extend(t_sentWords)\n",
    "tokTexts = [' '.join(i) for i in tok_sentWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 65574 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters='')\n",
    "tokenizer.fit_on_texts(tokTexts)\n",
    "word2index = tokenizer.word_index\n",
    "index2word = {i: w for w, i in word2index.items()}\n",
    "print('Found %s unique tokens.' % len(word2index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Word Embeddings with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 65575\n",
    "EMBEDDING_SIZE = 300\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1917495"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_n_symbols = !wc -l /Users/lizhn7/Downloads/DATA/Glove/glove.42B.300d.txt\n",
    "glove_n_symbols = int(glove_n_symbols[0].split()[0])\n",
    "glove_n_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_index_dict = {}\n",
    "glove_embedding_weights = np.empty((glove_n_symbols, EMBEDDING_SIZE))\n",
    "globale_scale = 0.1\n",
    "with open('/Users/lizhn7/Downloads/DATA/Glove/glove.42B.300d.txt', 'r') as fp:\n",
    "    index = 0\n",
    "    for l in fp:\n",
    "        l = l.strip().split()\n",
    "        word = l[0]\n",
    "        glove_index_dict[word] = index\n",
    "        glove_embedding_weights[index, :] = [float(n) for n in l[1:]]\n",
    "        index += 1\n",
    "glove_embedding_weights *= globale_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Glove to Initialize Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer, LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate random embedding with same scale as glove\n",
    "np.random.seed(SEED)\n",
    "shape = (VOCAB_SIZE, EMBEDDING_SIZE)\n",
    "scale = glove_embedding_weights.std() * np.sqrt(12) / 2 \n",
    "embedding = np.random.uniform(low=-scale, high=scale, size=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61085-93.15% tokens in vocab found in glove and copied to embedding.\n"
     ]
    }
   ],
   "source": [
    "# Copy from glove weights of words that appear in index2word\n",
    "count = 0 \n",
    "for i in range(1, VOCAB_SIZE):\n",
    "    w = index2word[i]\n",
    "    g = glove_index_dict.get(w)\n",
    "    if g is None:\n",
    "        w = porter.stem(w)\n",
    "        g = glove_index_dict.get(w)\n",
    "    if g is None:\n",
    "        w = lancaster.stem(w)\n",
    "        g = glove_index_dict.get(w)\n",
    "    if g is not None:\n",
    "        embedding[i, :] = glove_embedding_weights[g, :]\n",
    "        count += 1\n",
    "print('{num_tokens}-{per:.2f}% tokens in vocab found in glove and copied to embedding.'.format(num_tokens=count, per=count/float(VOCAB_SIZE)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Build Dateset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "new_sentText = [' '.join(i) for i in sentWords]\n",
    "sentSeq = tokenizer.texts_to_sequences(new_sentText)\n",
    "sentData = pad_sequences(sentSeq, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
    "\n",
    "t_new_sentText = [' '.join(i) for i in t_sentWords]\n",
    "t_sentSeq = tokenizer.texts_to_sequences(t_new_sentText)\n",
    "t_sentData = pad_sequences(t_sentSeq, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
    "\n",
    "token2index = dict((j, i+120) for i, j in enumerate(['PAD']+pad+t_relationTypes))\n",
    "token2index['PAD'] = 0\n",
    "index2token = {i: w for w, i in token2index.items()}\n",
    "newi_adjacencyList = [[token2index[i] if i in token2index else i+1 for i in aL] for aL in i_adjacencyList]\n",
    "newi_adjacencyList = pad_sequences(newi_adjacencyList, maxlen=MAX_ADJL_LEN, padding='post', truncating='post')\n",
    "newti_adjacencyList = [[token2index[i] if i in token2index else i+1 for i in aL] for aL in ti_adjacencyList]\n",
    "newti_adjacencyList = pad_sequences(newti_adjacencyList, maxlen=MAX_ADJL_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Split the data into a training set, a validation set and a test set\n",
    "x_train_all = sentData\n",
    "y_train_all = newi_adjacencyList\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, test_size=0.15, random_state=SEED)\n",
    "x_train_all, _, y_train_all, _  = train_test_split(x_train_all, y_train_all, test_size=0., random_state=SEED)\n",
    " \n",
    "x_test = t_sentData\n",
    "y_test = newti_adjacencyList\n",
    "\n",
    "x_test, _, y_test, _ = train_test_split(x_test, y_test, test_size=0., random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fh = h5py.File('/Users/lizhn7/Downloads/DATA/nyt/experiment_4_1/allData.h5', 'w')\n",
    "fh['x_train'] = x_train\n",
    "fh['y_train'] = y_train\n",
    "fh['x_val'] = x_val\n",
    "fh['y_val'] = y_val\n",
    "fh['x_train_all'] = x_train_all\n",
    "fh['y_train_all'] = y_train_all\n",
    "fh['x_test'] = x_test\n",
    "fh['y_test'] = y_test\n",
    "fh['embedding'] = embedding\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/lizhn7/Downloads/DATA/nyt/experiment_4_1/index.pkl', 'wb') as fp:\n",
    "    pickle.dump((word2index, index2word, token2index, index2token), fp, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with h5py.File('/Users/lizhn7/Downloads/DATA/nyt/experiment_4_1/allData.h5', 'r') as fh:\n",
    "    x_train = fh['x_train'][:]\n",
    "    y_train = fh['y_train'][:]\n",
    "    x_val = fh['x_val'][:]\n",
    "    y_val = fh['y_val'][:]\n",
    "    x_train_all = fh['x_train_all'][:]\n",
    "    y_train_all = fh['y_train_all'][:]\n",
    "    x_test = fh['x_test'][:]\n",
    "    y_test = fh['y_test'][:]\n",
    "    embedding = fh['embedding'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/lizhn7/Downloads/DATA/nyt/experiment_4_1/index.pkl', 'rb') as fp:\n",
    "    word2index, index2word, token2index, index2token = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#300-600-0.5-256-79-20-5\n",
    "MAX_SENT_LEN = 120\n",
    "MAX_ADJL_LEN = 12\n",
    "VOCAB_SIZE = len(word2index)+1\n",
    "NUM_CLASSES = 136\n",
    "EMBEDDING_SIZE = 300\n",
    "\n",
    "ENC_RNN_SIZE = 300\n",
    "DEC_RNN_SIZE = 600\n",
    "DROPOUT_RATE = 0.5\n",
    "NUM_EPOCHS = 256\n",
    "BATCH_SIZE = 79\n",
    "STEPS_PER_EPOCH = 20\n",
    "TEST_STEPS = len(x_test)//BATCH_SIZE\n",
    "\n",
    "VALIDATION_STEPS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_EPOCHS: \t\t256\n",
      "STEPS_PER_EPOCH: \t20\n",
      "TEST_STEPS: \t\t5\n",
      "VALIDATION_STEPS: \t3\n",
      "TRAIN_BATCHES: \t\t5120\n",
      "NUM_BATCHES \t\t612\n"
     ]
    }
   ],
   "source": [
    "print('NUM_EPOCHS: \\t\\t%d' % NUM_EPOCHS)\n",
    "print('STEPS_PER_EPOCH: \\t%d' % STEPS_PER_EPOCH)\n",
    "print('TEST_STEPS: \\t\\t%d' % TEST_STEPS)\n",
    "print('VALIDATION_STEPS: \\t%d' % VALIDATION_STEPS)\n",
    "print('TRAIN_BATCHES: \\t\\t%d' % (NUM_EPOCHS * STEPS_PER_EPOCH))\n",
    "print('NUM_BATCHES \\t\\t%d' % (len(x_train)//BATCH_SIZE+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Embedding, Dropout, Bidirectional, LSTM, RepeatVector, TimeDistributed, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import*\n",
    "from keras.utils import to_categorical\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "sequence = Input(shape=(MAX_SENT_LEN,), name='INPUT') \n",
    "emb_seq = Embedding(VOCAB_SIZE, EMBEDDING_SIZE, weights=[embedding], mask_zero=True, input_length=MAX_SENT_LEN, trainable=True, name='EMBEDDING')(sequence)\n",
    "emb_seq = Dropout(DROPOUT_RATE)(emb_seq)\n",
    "blstm = Bidirectional(LSTM(ENC_RNN_SIZE, return_sequences=True, implementation=0), merge_mode='concat', name='ENC_BLSTM_1')(emb_seq)\n",
    "blstm = Dropout(DROPOUT_RATE)(blstm)\n",
    "blstm = Bidirectional(LSTM(ENC_RNN_SIZE, return_sequences=False, implementation=0), merge_mode='concat', name='ENC_BLSTM_2')(blstm)\n",
    "blstm = Dropout(DROPOUT_RATE)(blstm)\n",
    "context = RepeatVector(MAX_ADJL_LEN, name='CONTEXT')(blstm)\n",
    "lstm = LSTM(DEC_RNN_SIZE, return_sequences=True, implementation=0, name='DEC_LSTM')(context)\n",
    "lstm = Dropout(DROPOUT_RATE)(lstm)\n",
    "output = TimeDistributed(Dense(NUM_CLASSES, activation='softmax'), name='OUTPUT')(lstm)\n",
    "model = Model(inputs=sequence, outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "INPUT (InputLayer)           (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "EMBEDDING (Embedding)        (None, 120, 300)          19672500  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 120, 300)          0         \n",
      "_________________________________________________________________\n",
      "ENC_BLSTM_1 (Bidirectional)  (None, 120, 600)          1442400   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 120, 600)          0         \n",
      "_________________________________________________________________\n",
      "ENC_BLSTM_2 (Bidirectional)  (None, 600)               2162400   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "CONTEXT (RepeatVector)       (None, 12, 600)           0         \n",
      "_________________________________________________________________\n",
      "DEC_LSTM (LSTM)              (None, 12, 600)           2882400   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 12, 600)           0         \n",
      "_________________________________________________________________\n",
      "OUTPUT (TimeDistributed)     (None, 12, 136)           81736     \n",
      "=================================================================\n",
      "Total params: 26,241,436\n",
      "Trainable params: 26,241,436\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"775pt\" viewBox=\"0.00 0.00 294.26 775.00\" width=\"294pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 771)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-771 290.2588,-771 290.2588,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 5081766992 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>5081766992</title>\n",
       "<polygon fill=\"none\" points=\"80.0762,-730.5 80.0762,-766.5 206.1826,-766.5 206.1826,-730.5 80.0762,-730.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-744.3\">INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 5081767664 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>5081767664</title>\n",
       "<polygon fill=\"none\" points=\"57.1655,-657.5 57.1655,-693.5 229.0933,-693.5 229.0933,-657.5 57.1655,-657.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-671.3\">EMBEDDING: Embedding</text>\n",
       "</g>\n",
       "<!-- 5081766992&#45;&gt;5081767664 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>5081766992-&gt;5081767664</title>\n",
       "<path d=\"M143.1294,-730.4551C143.1294,-722.3828 143.1294,-712.6764 143.1294,-703.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-703.5903 143.1294,-693.5904 139.6295,-703.5904 146.6295,-703.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5081767832 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>5081767832</title>\n",
       "<polygon fill=\"none\" points=\"79.3276,-584.5 79.3276,-620.5 206.9312,-620.5 206.9312,-584.5 79.3276,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-598.3\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 5081767664&#45;&gt;5081767832 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>5081767664-&gt;5081767832</title>\n",
       "<path d=\"M143.1294,-657.4551C143.1294,-649.3828 143.1294,-639.6764 143.1294,-630.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-630.5903 143.1294,-620.5904 139.6295,-630.5904 146.6295,-630.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5082612624 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>5082612624</title>\n",
       "<polygon fill=\"none\" points=\"0,-511.5 0,-547.5 286.2588,-547.5 286.2588,-511.5 0,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-525.3\">ENC_BLSTM_1(lstm_1): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 5081767832&#45;&gt;5082612624 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>5081767832-&gt;5082612624</title>\n",
       "<path d=\"M143.1294,-584.4551C143.1294,-576.3828 143.1294,-566.6764 143.1294,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-557.5903 143.1294,-547.5904 139.6295,-557.5904 146.6295,-557.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5081767328 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>5081767328</title>\n",
       "<polygon fill=\"none\" points=\"79.3276,-438.5 79.3276,-474.5 206.9312,-474.5 206.9312,-438.5 79.3276,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-452.3\">dropout_2: Dropout</text>\n",
       "</g>\n",
       "<!-- 5082612624&#45;&gt;5081767328 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>5082612624-&gt;5081767328</title>\n",
       "<path d=\"M143.1294,-511.4551C143.1294,-503.3828 143.1294,-493.6764 143.1294,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-484.5903 143.1294,-474.5904 139.6295,-484.5904 146.6295,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5505920864 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>5505920864</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 286.2588,-401.5 286.2588,-365.5 0,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-379.3\">ENC_BLSTM_2(lstm_2): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 5081767328&#45;&gt;5505920864 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>5081767328-&gt;5505920864</title>\n",
       "<path d=\"M143.1294,-438.4551C143.1294,-430.3828 143.1294,-420.6764 143.1294,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-411.5903 143.1294,-401.5904 139.6295,-411.5904 146.6295,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5397587336 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>5397587336</title>\n",
       "<polygon fill=\"none\" points=\"79.3276,-292.5 79.3276,-328.5 206.9312,-328.5 206.9312,-292.5 79.3276,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-306.3\">dropout_3: Dropout</text>\n",
       "</g>\n",
       "<!-- 5505920864&#45;&gt;5397587336 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>5505920864-&gt;5397587336</title>\n",
       "<path d=\"M143.1294,-365.4551C143.1294,-357.3828 143.1294,-347.6764 143.1294,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-338.5903 143.1294,-328.5904 139.6295,-338.5904 146.6295,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5506010248 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>5506010248</title>\n",
       "<polygon fill=\"none\" points=\"61.4175,-219.5 61.4175,-255.5 224.8413,-255.5 224.8413,-219.5 61.4175,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-233.3\">CONTEXT: RepeatVector</text>\n",
       "</g>\n",
       "<!-- 5397587336&#45;&gt;5506010248 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>5397587336-&gt;5506010248</title>\n",
       "<path d=\"M143.1294,-292.4551C143.1294,-284.3828 143.1294,-274.6764 143.1294,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-265.5903 143.1294,-255.5904 139.6295,-265.5904 146.6295,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5517379960 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>5517379960</title>\n",
       "<polygon fill=\"none\" points=\"76.5967,-146.5 76.5967,-182.5 209.6621,-182.5 209.6621,-146.5 76.5967,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-160.3\">DEC_LSTM: LSTM</text>\n",
       "</g>\n",
       "<!-- 5506010248&#45;&gt;5517379960 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>5506010248-&gt;5517379960</title>\n",
       "<path d=\"M143.1294,-219.4551C143.1294,-211.3828 143.1294,-201.6764 143.1294,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-192.5903 143.1294,-182.5904 139.6295,-192.5904 146.6295,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5514583792 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>5514583792</title>\n",
       "<polygon fill=\"none\" points=\"79.3276,-73.5 79.3276,-109.5 206.9312,-109.5 206.9312,-73.5 79.3276,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-87.3\">dropout_4: Dropout</text>\n",
       "</g>\n",
       "<!-- 5517379960&#45;&gt;5514583792 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>5517379960-&gt;5514583792</title>\n",
       "<path d=\"M143.1294,-146.4551C143.1294,-138.3828 143.1294,-128.6764 143.1294,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-119.5903 143.1294,-109.5904 139.6295,-119.5904 146.6295,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5243293880 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>5243293880</title>\n",
       "<polygon fill=\"none\" points=\"8.1655,-.5 8.1655,-36.5 278.0933,-36.5 278.0933,-.5 8.1655,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-14.3\">OUTPUT(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 5514583792&#45;&gt;5243293880 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>5514583792-&gt;5243293880</title>\n",
       "<path d=\"M143.1294,-73.4551C143.1294,-65.3828 143.1294,-55.6764 143.1294,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-46.5903 143.1294,-36.5904 139.6295,-46.5904 146.6295,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_label(s):\n",
    "    \"\"\"\n",
    "    One-hot encoding\n",
    "    \"\"\"\n",
    "    gen = to_categorical(s, num_classes=NUM_CLASSES)\n",
    "    return gen\n",
    "\n",
    "def data_generator_all(data, label, batch_size):\n",
    "    \"\"\"\n",
    "    Yield batches of all data\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    while True:\n",
    "        if count >= len(data): \n",
    "            count = 0\n",
    "        x = np.zeros((batch_size, MAX_SENT_LEN))\n",
    "        y = np.zeros((batch_size, MAX_ADJL_LEN, NUM_CLASSES))\n",
    "        for i in range(batch_size):\n",
    "            n = i + count\n",
    "            if n > len(data)-1:\n",
    "                break\n",
    "            x[i, :] = data[n]\n",
    "            y[i, :, :] = gen_label(label[n])\n",
    "        count += batch_size\n",
    "        yield (x, y)\n",
    "        \n",
    "def data_generator(data, label, batch_size): \n",
    "    \"\"\"\n",
    "    Yield batches \n",
    "    \"\"\"\n",
    "    index = np.arange(len(data))\n",
    "    np.random.shuffle(index)    \n",
    "    batches = [index[range(batch_size*i, min(len(data), batch_size*(i+1)))] for i in range(len(data)//batch_size)]\n",
    "    while True:\n",
    "        for i in batches:\n",
    "            x, y = data[i], np.array(list(map(gen_label, label[i])))\n",
    "            yield (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_train_all = data_generator(x_train_all, y_train_all, BATCH_SIZE)\n",
    "gen_test = data_generator_all(x_test, y_test, BATCH_SIZE)\n",
    "gen_train = data_generator(x_train, y_train, BATCH_SIZE)\n",
    "gen_val = data_generator(x_val, y_val, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continue Trian\n",
    "# filename = 'cp_logs/.hdf5'\n",
    "# model.load_weights(filename)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = '/Users/lizhn7/Downloads/DATA/nyt/experiment_4_1/cp_logs/weights.{epoch:03d}-{val_loss:.6f}.hdf5'\n",
    "log_string = '/Users/lizhn7/Downloads/DATA/nyt/experiment_4_1/tb_logs/300-600-0.5-256-79-20-5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir=log_string, \n",
    "                          histogram_freq=1, \n",
    "                          write_graph=False, \n",
    "                          write_grads=False, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          write_images=True, \n",
    "                          embeddings_freq=1, \n",
    "                          embeddings_layer_names=None,\n",
    "                          embeddings_metadata=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(gen_train_all, \n",
    "                              steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                              epochs=NUM_EPOCHS, \n",
    "                              verbose=1,\n",
    "                              callbacks=[checkpoint, tensorboard],\n",
    "                              validation_data=gen_test, \n",
    "                              validation_steps=TEST_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '/Users/lizhn7/Downloads/DATA/nyt/experiment_4_1/cp_logs/weights.104-0.738603.hdf5'\n",
    "model.load_weights(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 14s    \n"
     ]
    }
   ],
   "source": [
    "result = np.argmax(model.predict(x_test, batch_size=BATCH_SIZE, verbose=1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: \t10 POI 9 RE contains EOP\n",
      "Ground-Truth: \t9 POI 10 RE country EOP\n",
      "---\n",
      "Predict: \t14 POI 13 RE contains EOP\n",
      "Ground-Truth: \t16 POI 14 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI 10 RE capital EOP 12 POI 9 RE contains EOP\n",
      "Ground-Truth: \t11 POI 13 RE nationality EOP\n",
      "---\n",
      "Predict: \t15 POI 14 RE contains EOP\n",
      "Ground-Truth: \t14 POI 9 RE contains EOP\n",
      "---\n",
      "Predict: \t13 POI 14 RE place_lived EOP\n",
      "Ground-Truth: \t12 POI 15 RE place_lived EOP\n",
      "---\n",
      "Predict: \t10 POI 9 RE contains EOP\n",
      "Ground-Truth: \t10 POI 9 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI 7 RE company EOP POI 1 RE founders EOP\n",
      "Ground-Truth: \t8 POI 1 RE founders EOP\n",
      "---\n",
      "Predict: \t16 POI 15 RE contains EOP\n",
      "Ground-Truth: \t20 POI 16 RE country EOP\n",
      "---\n",
      "Predict: \t31 POI 28 RE contains EOP\n",
      "Ground-Truth: \t19 POI 13 RE country EOP\n",
      "---\n",
      "Predict: \t18 POI 6 RE contains EOP\n",
      "Ground-Truth: \t17 POI 6 RE contains EOP\n",
      "---\n",
      "Predict: \t26 POI 10 RE company EOP\n",
      "Ground-Truth: \t26 POI 29 RE company EOP\n",
      "---\n",
      "Predict: \t12 POI 11 RE contains EOP\n",
      "Ground-Truth: \t12 POI 11 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI 7 RE contains EOP\n",
      "Ground-Truth: \t2 POI 7 RE contains EOP\n",
      "---\n",
      "Predict: \t14 POI 17 RE place_lived EOP\n",
      "Ground-Truth: \t15 POI 18 RE place_lived EOP\n",
      "---\n",
      "Predict: \t3 POI 10 RE company EOP\n",
      "Ground-Truth: \t3 POI 6 RE place_lived EOP\n",
      "---\n",
      "Predict: \t15 POI 14 RE contains EOP\n",
      "Ground-Truth: \t4 POI 16 RE country EOP\n",
      "---\n",
      "Predict: \t17 POI 25 RE company EOP\n",
      "Ground-Truth: \t23 POI 26 RE company EOP\n",
      "---\n",
      "Predict: \t6 POI 5 RE contains EOP\n",
      "Ground-Truth: \t4 POI 6 RE country EOP\n",
      "---\n",
      "Predict: \t40 POI 20 RE contains EOP\n",
      "Ground-Truth: \t20 POI 21 RE country EOP\n",
      "---\n",
      "Predict: \t29 POI 38 RE company EOP\n",
      "Ground-Truth: \t28 POI 37 RE company EOP\n",
      "---\n",
      "Predict: \t15 POI 5 RE nationality EOP\n",
      "Ground-Truth: \t13 POI 16 RE nationality EOP\n",
      "---\n",
      "Predict: \t9 POI 15 RE company EOP\n",
      "Ground-Truth: \t9 POI 15 RE company EOP\n",
      "---\n",
      "Predict: \t12 POI 20 RE company EOP\n",
      "Ground-Truth: \t20 POI 12 RE founders EOP\n",
      "---\n",
      "Predict: \t2 POI 5 RE place_lived EOP\n",
      "Ground-Truth: \t2 POI 5 RE place_lived EOP\n",
      "---\n",
      "Predict: \t20 POI 31 RE contains EOP\n",
      "Ground-Truth: \t20 POI 31 RE contains EOP\n",
      "---\n",
      "Predict: \t17 POI 13 RE contains EOP\n",
      "Ground-Truth: \t18 POI 13 RE country EOP\n",
      "---\n",
      "Predict: \t34 POI 14 RE contains EOP\n",
      "Ground-Truth: \t14 POI 34 RE country EOP\n",
      "---\n",
      "Predict: \t7 POI 15 RE children EOP\n",
      "Ground-Truth: \t8 POI 15 RE place_lived EOP\n",
      "---\n",
      "Predict: \t7 POI 16 RE company EOP\n",
      "Ground-Truth: \t6 POI 15 RE company EOP\n",
      "---\n",
      "Predict: \t1 POI 1 RE contains EOP\n",
      "Ground-Truth: \t29 POI 1 RE country EOP\n",
      "---\n",
      "Predict: \t18 POI 17 RE contains EOP\n",
      "Ground-Truth: \t18 POI 16 RE contains EOP\n",
      "---\n",
      "Predict: \t19 POI 17 RE nationality EOP\n",
      "Ground-Truth: \t21 POI 17 RE nationality EOP\n",
      "---\n",
      "Predict: \t28 POI 27 RE contains EOP\n",
      "Ground-Truth: \t30 POI 34 RE country EOP\n",
      "---\n",
      "Predict: \t10 POI 1 RE company EOP\n",
      "Ground-Truth: \t11 POI 17 RE company EOP\n",
      "---\n",
      "Predict: \t26 POI 24 RE contains EOP\n",
      "Ground-Truth: \t26 POI 24 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI 48 RE contains EOP\n",
      "Ground-Truth: \t38 POI 43 RE company EOP\n",
      "---\n",
      "Predict: \t7 POI 13 RE company EOP POI 7 RE founders EOP\n",
      "Ground-Truth: \t8 POI 15 RE company EOP\n",
      "---\n",
      "Predict: \t33 POI 13 RE contains EOP contains\n",
      "Ground-Truth: \t14 POI 12 RE contains EOP\n",
      "---\n",
      "Predict: \t18 POI 18 RE contains EOP\n",
      "Ground-Truth: \t35 POI 34 RE contains EOP\n",
      "---\n",
      "Predict: \t15 POI 14 RE contains EOP\n",
      "Ground-Truth: \t15 POI 14 RE contains EOP\n",
      "---\n",
      "Predict: \t5 POI 31 RE contains EOP\n",
      "Ground-Truth: \t29 POI 31 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI 6 RE place_lived EOP\n",
      "Ground-Truth: \t3 POI 6 RE place_lived EOP\n",
      "---\n",
      "Predict: \t21 POI 21 RE contains EOP\n",
      "Ground-Truth: \t19 POI 21 RE country EOP\n",
      "---\n",
      "Predict: \t25 POI 32 RE contains EOP\n",
      "Ground-Truth: \t42 POI 31 RE country EOP\n",
      "---\n",
      "Predict: \t13 POI 40 RE contains EOP\n",
      "Ground-Truth: \t38 POI 43 RE place_of_birth EOP\n",
      "---\n",
      "Predict: \t2 POI 40 RE nationality EOP POI EOP\n",
      "Ground-Truth: \t38 POI 41 RE nationality EOP\n",
      "---\n",
      "Predict: \t17 POI 20 RE nationality EOP\n",
      "Ground-Truth: \t16 POI 21 RE nationality EOP\n",
      "---\n",
      "Predict: \t14 POI 31 RE contains EOP\n",
      "Ground-Truth: \t28 POI 30 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI 7 RE place_lived EOP\n",
      "Ground-Truth: \t3 POI 7 RE place_lived EOP\n",
      "---\n",
      "Predict: \t15 POI 13 RE contains EOP\n",
      "Ground-Truth: \t17 POI 11 RE contains EOP\n",
      "---\n",
      "Predict: \t10 POI 13 RE place_lived EOP\n",
      "Ground-Truth: \t10 POI 14 RE place_lived EOP\n",
      "---\n",
      "Predict: \t21 POI 8 RE contains EOP\n",
      "Ground-Truth: \t11 POI 21 RE country EOP\n",
      "---\n",
      "Predict: \t18 POI 31 RE company EOP\n",
      "Ground-Truth: \t20 POI 16 RE company EOP\n",
      "---\n",
      "Predict: \t6 POI 5 RE contains EOP POI RE contains EOP\n",
      "Ground-Truth: \t5 POI 8 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI 11 RE contains EOP\n",
      "Ground-Truth: \t12 POI 7 RE contains EOP\n",
      "---\n",
      "Predict: \t6 POI 6 RE contains EOP\n",
      "Ground-Truth: \t6 POI 7 RE country EOP\n",
      "---\n",
      "Predict: \t7 POI 6 RE capital EOP 7 POI RE contains EOP\n",
      "Ground-Truth: \t7 POI 6 RE contains EOP\n",
      "---\n",
      "Predict: \t9 POI 4 RE contains EOP\n",
      "Ground-Truth: \t8 POI 10 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI 13 RE contains EOP\n",
      "Ground-Truth: \t14 POI 22 RE country EOP\n",
      "---\n",
      "Predict: \t28 POI 35 RE neighborhood_of EOP POI RE contains EOP\n",
      "Ground-Truth: \t37 POI 34 RE contains EOP\n",
      "---\n",
      "Predict: \t9 POI 11 RE neighborhood_of EOP 11 POI 7 RE contains EOP\n",
      "Ground-Truth: \t11 POI 7 RE contains EOP\n",
      "---\n",
      "Predict: \t38 POI 38 RE contains EOP RE contains\n",
      "Ground-Truth: \t38 POI 39 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI 1 RE company EOP POI 1 RE founders EOP\n",
      "Ground-Truth: \t1 POI 9 RE company EOP\n",
      "---\n",
      "Predict: \t13 POI 10 RE contains EOP\n",
      "Ground-Truth: \t13 POI 10 RE contains EOP\n",
      "---\n",
      "Predict: \t7 POI 12 RE place_lived EOP\n",
      "Ground-Truth: \t14 POI 18 RE place_lived EOP\n",
      "---\n",
      "Predict: \t28 POI 27 RE contains EOP\n",
      "Ground-Truth: \t29 POI 27 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI 4 RE contains EOP\n",
      "Ground-Truth: \t8 POI 5 RE contains EOP\n",
      "---\n",
      "Predict: \t3 POI 8 RE company EOP\n",
      "Ground-Truth: \t5 POI 8 RE company EOP\n",
      "---\n",
      "Predict: \t9 POI 6 RE contains EOP\n",
      "Ground-Truth: \t8 POI 6 RE contains EOP\n",
      "---\n",
      "Predict: \t18 POI 16 RE contains EOP\n",
      "Ground-Truth: \t18 POI 16 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI 1 RE contains EOP\n",
      "Ground-Truth: \t9 POI 13 RE country EOP\n",
      "---\n",
      "Predict: \t18 POI 13 RE contains EOP\n",
      "Ground-Truth: \t18 POI 14 RE contains EOP\n",
      "---\n",
      "Predict: \t10 POI 15 RE nationality EOP\n",
      "Ground-Truth: \t4 POI 15 RE place_lived EOP\n",
      "---\n",
      "Predict: \t10 POI 17 RE company EOP\n",
      "Ground-Truth: \t10 POI 19 RE company EOP\n",
      "---\n",
      "Predict: \t14 POI 13 RE place_lived EOP\n",
      "Ground-Truth: \t17 POI 20 RE place_lived EOP\n",
      "---\n",
      "Predict: \t18 POI 13 RE nationality EOP\n",
      "Ground-Truth: \t19 POI 14 RE nationality EOP\n",
      "---\n",
      "Predict: \t19 POI 7 RE nationality EOP\n",
      "Ground-Truth: \t19 POI 7 RE nationality EOP\n",
      "---\n",
      "Predict: \t20 POI 32 RE contains EOP RE contains EOP\n",
      "Ground-Truth: \t32 POI 35 RE contains EOP\n",
      "---\n",
      "Predict: \t19 POI 2 RE contains EOP\n",
      "Ground-Truth: \t19 POI 1 RE contains EOP\n",
      "---\n",
      "Predict: \t9 POI 29 RE contains EOP\n",
      "Ground-Truth: \t31 POI 33 RE country EOP\n",
      "---\n",
      "Predict: \t13 POI 12 RE contains EOP\n",
      "Ground-Truth: \t13 POI 12 RE contains EOP\n",
      "---\n",
      "Predict: \t10 POI 10 RE contains EOP\n",
      "Ground-Truth: \t9 POI 30 RE country EOP\n",
      "---\n",
      "Predict: \t9 POI 6 RE contains EOP\n",
      "Ground-Truth: \t8 POI 11 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI 11 RE contains EOP\n",
      "Ground-Truth: \t12 POI 25 RE contains EOP\n",
      "---\n",
      "Predict: \t9 POI 12 RE place_lived EOP\n",
      "Ground-Truth: \t9 POI 12 RE place_lived EOP\n",
      "---\n",
      "Predict: \t12 POI 10 RE contains EOP\n",
      "Ground-Truth: \t12 POI 10 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI 7 RE company EOP\n",
      "Ground-Truth: \t1 POI 8 RE company EOP\n",
      "---\n",
      "Predict: \t1 POI 28 RE contains EOP\n",
      "Ground-Truth: \t27 POI 18 RE country EOP\n",
      "---\n",
      "Predict: \t38 POI 38 RE contains EOP\n",
      "Ground-Truth: \t39 POI 40 RE contains EOP\n",
      "---\n",
      "Predict: \t14 POI 35 RE nationality EOP\n",
      "Ground-Truth: \t36 POI 33 RE contains EOP\n",
      "---\n",
      "Predict: \t13 POI 5 RE contains EOP\n",
      "Ground-Truth: \t13 POI 4 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI 1 RE contains EOP\n",
      "Ground-Truth: \t12 POI 1 RE country EOP\n",
      "---\n",
      "Predict: \t7 POI 9 RE contains EOP\n",
      "Ground-Truth: \t6 POI 10 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI 5 RE place_lived EOP\n",
      "Ground-Truth: \t2 POI 5 RE place_lived EOP\n",
      "---\n",
      "Predict: \t10 POI 13 RE contains EOP 13 POI 10 RE contains EOP\n",
      "Ground-Truth: \t12 POI 8 RE contains EOP\n",
      "---\n",
      "Predict: \t17 POI 32 RE contains EOP\n",
      "Ground-Truth: \t17 POI 34 RE country EOP\n",
      "---\n",
      "Predict: \t6 POI 7 RE nationality EOP\n",
      "Ground-Truth: \t5 POI 8 RE nationality EOP\n",
      "---\n",
      "Predict: \t28 POI 25 RE contains EOP\n",
      "Ground-Truth: \t29 POI 23 RE contains EOP\n",
      "---\n",
      "Predict: \t9 POI 9 RE contains EOP\n",
      "Ground-Truth: \t10 POI 9 RE contains EOP\n",
      "---\n",
      "Predict: \t18 POI 16 RE contains EOP\n",
      "Ground-Truth: \t51 POI 49 RE contains EOP\n",
      "---\n",
      "Predict: \t11 POI 10 RE contains EOP\n",
      "Ground-Truth: \t11 POI 10 RE contains EOP\n",
      "---\n",
      "Predict: \t9 POI 1 RE contains EOP\n",
      "Ground-Truth: \t9 POI 1 RE contains EOP\n",
      "---\n",
      "Predict: \t33 POI 38 RE contains EOP\n",
      "Ground-Truth: \t49 POI 47 RE contains EOP\n",
      "---\n",
      "Predict: \t14 POI 13 RE contains EOP\n",
      "Ground-Truth: \t40 POI 14 RE country EOP\n",
      "---\n",
      "Predict: \t18 POI 25 RE contains EOP\n",
      "Ground-Truth: \t18 POI 26 RE country EOP\n",
      "---\n",
      "Predict: \t15 POI 25 RE company EOP\n",
      "Ground-Truth: \t15 POI 26 RE company EOP\n",
      "---\n",
      "Predict: \t12 POI 11 RE contains EOP\n",
      "Ground-Truth: \t12 POI 11 RE nationality EOP\n",
      "---\n",
      "Predict: \t7 POI 13 RE place_lived EOP\n",
      "Ground-Truth: \t7 POI 13 RE place_lived EOP\n",
      "---\n",
      "Predict: \t7 POI 13 RE nationality EOP\n",
      "Ground-Truth: \t7 POI 13 RE nationality EOP\n",
      "---\n",
      "Predict: \t7 POI 7 RE place_lived EOP\n",
      "Ground-Truth: \t5 POI 8 RE place_lived EOP\n",
      "---\n",
      "Predict: \t9 POI 7 RE contains EOP\n",
      "Ground-Truth: \t8 POI 10 RE country EOP\n",
      "---\n",
      "Predict: \t9 POI 5 RE contains EOP\n",
      "Ground-Truth: \t9 POI 5 RE administrative_divisions EOP\n",
      "---\n",
      "Predict: \t10 POI 9 RE contains EOP\n",
      "Ground-Truth: \t29 POI 27 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI 17 RE contains EOP\n",
      "Ground-Truth: \t17 POI 12 RE country EOP\n",
      "---\n",
      "Predict: \t28 POI 27 RE contains EOP\n",
      "Ground-Truth: \t29 POI 31 RE contains EOP\n",
      "---\n",
      "Predict: \t28 POI 28 RE contains EOP\n",
      "Ground-Truth: \t17 POI 20 RE country EOP\n",
      "---\n",
      "Predict: \t23 POI 23 RE contains EOP\n",
      "Ground-Truth: \t38 POI 24 RE country EOP\n",
      "---\n",
      "Predict: \t28 POI 28 RE contains EOP\n",
      "Ground-Truth: \t30 POI 28 RE contains EOP\n",
      "---\n",
      "Predict: \t10 POI 11 RE contains EOP\n",
      "Ground-Truth: \t11 POI 13 RE country EOP\n",
      "---\n",
      "Predict: \t20 POI 38 RE contains EOP\n",
      "Ground-Truth: \t38 POI 19 RE country EOP\n",
      "---\n",
      "Predict: \t34 POI 14 RE contains EOP\n",
      "Ground-Truth: \t37 POI 34 RE contains EOP\n",
      "---\n",
      "Predict: \t21 POI 19 RE contains EOP\n",
      "Ground-Truth: \t23 POI 20 RE contains EOP\n",
      "---\n",
      "Predict: \t28 POI 27 RE contains EOP RE contains EOP\n",
      "Ground-Truth: \t29 POI 34 RE contains EOP\n",
      "---\n",
      "Predict: \t40 POI 40 RE contains EOP\n",
      "Ground-Truth: \t41 POI 40 RE contains EOP\n",
      "---\n",
      "Predict: \t26 POI 25 RE contains EOP\n",
      "Ground-Truth: \t29 POI 26 RE contains EOP\n",
      "---\n",
      "Predict: \t21 POI 24 RE neighborhood_of EOP 24 POI 21 RE contains EOP\n",
      "Ground-Truth: \t23 POI 20 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI 10 RE contains EOP\n",
      "Ground-Truth: \t11 POI 10 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI 18 RE contains EOP\n",
      "Ground-Truth: \t13 POI 19 RE place_lived EOP\n",
      "---\n",
      "Predict: \t24 POI 15 RE nationality EOP\n",
      "Ground-Truth: \t17 POI 20 RE administrative_divisions EOP\n",
      "---\n",
      "Predict: \t1 POI 31 RE place_of_death EOP\n",
      "Ground-Truth: \t1 POI 33 RE place_of_death EOP\n",
      "---\n",
      "Predict: \t20 POI 7 RE capital EOP 21 POI 7 RE contains EOP\n",
      "Ground-Truth: \t21 POI 7 RE contains EOP\n",
      "---\n",
      "Predict: \t28 POI 30 RE contains EOP\n",
      "Ground-Truth: \t20 POI 4 RE country EOP\n",
      "---\n",
      "Predict: \t13 POI 10 RE contains EOP\n",
      "Ground-Truth: \t13 POI 10 RE contains EOP\n",
      "---\n",
      "Predict: \t7 POI 9 RE nationality EOP\n",
      "Ground-Truth: \t6 POI 9 RE nationality EOP\n",
      "---\n",
      "Predict: \t32 POI 32 RE company EOP\n",
      "Ground-Truth: \t22 POI 30 RE company EOP\n",
      "---\n",
      "Predict: \t12 POI 11 RE contains EOP\n",
      "Ground-Truth: \t13 POI 2 RE contains EOP\n",
      "---\n",
      "Predict: \t18 POI 13 RE contains EOP\n",
      "Ground-Truth: \t7 POI 13 RE contains EOP\n",
      "---\n",
      "Predict: \t31 POI 31 RE contains EOP\n",
      "Ground-Truth: \t33 POI 30 RE contains EOP\n",
      "---\n",
      "Predict: \t11 POI 10 RE contains EOP\n",
      "Ground-Truth: \t10 POI 11 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI 5 RE contains EOP contains\n",
      "Ground-Truth: \t6 POI 23 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI 20 RE nationality EOP\n",
      "Ground-Truth: \t11 POI 20 RE nationality EOP\n",
      "---\n",
      "Predict: \t6 POI 5 RE capital EOP\n",
      "Ground-Truth: \t6 POI 5 RE contains EOP\n",
      "---\n",
      "Predict: \t26 POI 29 RE place_lived EOP\n",
      "Ground-Truth: \t26 POI 29 RE place_lived EOP\n",
      "---\n",
      "Predict: \t13 POI 12 RE contains EOP\n",
      "Ground-Truth: \t14 POI 12 RE country EOP\n",
      "---\n",
      "Predict: \t7 POI 4 RE contains EOP\n",
      "Ground-Truth: \t10 POI 6 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI 7 RE company EOP\n",
      "Ground-Truth: \t1 POI 7 RE company EOP\n",
      "---\n",
      "Predict: \t4 POI 13 RE contains EOP\n",
      "Ground-Truth: \t12 POI 4 RE contains EOP\n",
      "---\n",
      "Predict: \t4 POI 11 RE company EOP\n",
      "Ground-Truth: \t5 POI 11 RE company EOP\n",
      "---\n",
      "Predict: \t15 POI 14 RE place_lived EOP\n",
      "Ground-Truth: \t16 POI 12 RE contains EOP\n",
      "---\n",
      "Predict: \t7 POI 32 RE nationality EOP\n",
      "Ground-Truth: \t21 POI 33 RE administrative_divisions EOP\n",
      "---\n",
      "Predict: \t2 POI 16 RE contains EOP\n",
      "Ground-Truth: \t18 POI 16 RE contains EOP\n",
      "---\n",
      "Predict: \t31 POI 29 RE contains EOP\n",
      "Ground-Truth: \t35 POI 33 RE country EOP\n",
      "---\n",
      "Predict: \t10 POI 10 RE children EOP\n",
      "Ground-Truth: \t10 POI 16 RE place_lived EOP\n",
      "---\n",
      "Predict: \t5 POI 4 RE contains EOP\n",
      "Ground-Truth: \t11 POI 5 RE country EOP\n",
      "---\n",
      "Predict: \t6 POI 5 RE contains EOP\n",
      "Ground-Truth: \t6 POI 5 RE contains EOP\n",
      "---\n",
      "Predict: \t25 POI 24 RE contains EOP\n",
      "Ground-Truth: \t1 POI 24 RE place_of_death EOP\n",
      "---\n",
      "Predict: \t8 POI 7 RE contains EOP\n",
      "Ground-Truth: \t8 POI 6 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI 8 RE company EOP\n",
      "Ground-Truth: \t18 POI 41 RE country EOP\n",
      "---\n",
      "Predict: \t9 POI 8 RE contains EOP\n",
      "Ground-Truth: \t9 POI 8 RE contains EOP\n",
      "---\n",
      "Predict: \t4 POI 12 RE company EOP\n",
      "Ground-Truth: \t4 POI 11 RE company EOP\n",
      "---\n",
      "Predict: \t14 POI 12 RE contains EOP\n",
      "Ground-Truth: \t13 POI 12 RE contains EOP\n",
      "---\n",
      "Predict: \t7 POI 7 RE contains EOP\n",
      "Ground-Truth: \t19 POI 22 RE place_lived EOP\n",
      "---\n",
      "Predict: \t26 POI 24 RE contains EOP\n",
      "Ground-Truth: \t29 POI 26 RE country EOP\n",
      "---\n",
      "Predict: \t4 POI 16 RE contains EOP\n",
      "Ground-Truth: \t16 POI 17 RE country EOP\n",
      "---\n",
      "Predict: \t20 POI 18 RE contains EOP\n",
      "Ground-Truth: \t20 POI 19 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI 18 RE contains EOP\n",
      "Ground-Truth: \t20 POI 19 RE contains EOP\n",
      "---\n",
      "Predict: \t14 POI 13 RE capital EOP 14 POI 13 RE contains EOP\n",
      "Ground-Truth: \t14 POI 13 RE contains EOP\n",
      "---\n",
      "Predict: \t39 POI 40 RE company EOP\n",
      "Ground-Truth: \t47 POI 42 RE founders EOP\n",
      "---\n",
      "Predict: \t40 POI 40 RE contains EOP\n",
      "Ground-Truth: \t46 POI 38 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI 23 RE contains EOP RE contains\n",
      "Ground-Truth: \t6 POI 12 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI 38 RE nationality EOP\n",
      "Ground-Truth: \t24 POI 44 RE country EOP\n",
      "---\n",
      "Predict: \t20 POI 20 RE neighborhood_of EOP 20 POI 19 RE contains EOP\n",
      "Ground-Truth: \t19 POI 10 RE contains EOP\n",
      "---\n",
      "Predict: \t7 POI 2 RE contains EOP\n",
      "Ground-Truth: \t6 POI 4 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI 6 RE place_lived EOP\n",
      "Ground-Truth: \t2 POI 6 RE place_lived EOP\n",
      "---\n",
      "Predict: \t30 POI 2 RE contains EOP\n",
      "Ground-Truth: \t3 POI 30 RE country EOP\n",
      "---\n",
      "Predict: \t11 POI 7 RE contains EOP\n",
      "Ground-Truth: \t11 POI 6 RE contains EOP\n",
      "---\n",
      "Predict: \t7 POI 6 RE contains EOP\n",
      "Ground-Truth: \t12 POI 7 RE country EOP\n",
      "---\n",
      "Predict: \t24 POI 21 RE contains EOP\n",
      "Ground-Truth: \t24 POI 23 RE contains EOP\n",
      "---\n",
      "Predict: \t3 POI 20 RE contains EOP POI RE contains EOP\n",
      "Ground-Truth: \t19 POI 22 RE neighborhood_of EOP\n",
      "---\n",
      "Predict: \t18 POI 29 RE contains EOP contains\n",
      "Ground-Truth: \t36 POI 42 RE country EOP\n",
      "---\n",
      "Predict: \t20 POI 11 RE contains EOP\n",
      "Ground-Truth: \t20 POI 17 RE contains EOP\n",
      "---\n",
      "Predict: \t13 POI 1 RE company EOP\n",
      "Ground-Truth: \t13 POI 9 RE company EOP\n",
      "---\n",
      "Predict: \t14 POI 13 RE contains EOP\n",
      "Ground-Truth: \t14 POI 13 RE contains EOP\n",
      "---\n",
      "Predict: \t23 POI 25 RE place_lived EOP\n",
      "Ground-Truth: \t23 POI 26 RE place_lived EOP\n",
      "---\n",
      "Predict: \t2 POI 6 RE place_lived EOP\n",
      "Ground-Truth: \t2 POI 6 RE place_lived EOP\n",
      "---\n",
      "Predict: \t6 POI 9 RE place_lived EOP\n",
      "Ground-Truth: \t28 POI 31 RE place_lived EOP\n",
      "---\n",
      "Predict: \t6 POI 6 RE contains EOP\n",
      "Ground-Truth: \t28 POI 6 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI 24 RE contains EOP\n",
      "Ground-Truth: \t2 POI 25 RE contains EOP\n",
      "---\n",
      "Predict: \t6 POI 6 RE contains EOP\n",
      "Ground-Truth: \t13 POI 6 RE place_lived EOP\n",
      "---\n",
      "Predict: \t24 POI 23 RE contains EOP\n",
      "Ground-Truth: \t24 POI 22 RE contains EOP\n",
      "---\n",
      "Predict: \t38 POI 41 RE place_lived EOP\n",
      "Ground-Truth: \t38 POI 41 RE place_lived EOP\n",
      "---\n",
      "Predict: \t31 POI 31 RE contains EOP\n",
      "Ground-Truth: \t30 POI 34 RE contains EOP\n",
      "---\n",
      "Predict: \t13 POI 15 RE place_lived EOP\n",
      "Ground-Truth: \t13 POI 16 RE place_lived EOP\n",
      "---\n",
      "Predict: \t15 POI 27 RE contains EOP\n",
      "Ground-Truth: \t16 POI 27 RE country EOP\n",
      "---\n",
      "Predict: \t23 POI 21 RE contains EOP\n",
      "Ground-Truth: \t20 POI 23 RE country EOP\n",
      "---\n",
      "Predict: \t10 POI 3 RE contains EOP\n",
      "Ground-Truth: \t3 POI 10 RE country EOP\n",
      "---\n",
      "Predict: \t11 POI 9 RE contains EOP\n",
      "Ground-Truth: \t12 POI 9 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI 21 RE capital EOP 12 POI 21 RE contains EOP\n",
      "Ground-Truth: \t11 POI 19 RE country EOP\n",
      "---\n",
      "Predict: \t15 POI 13 RE contains EOP POI RE contains EOP\n",
      "Ground-Truth: \t9 POI 7 RE country EOP\n",
      "---\n",
      "Predict: \t18 POI 24 RE contains EOP\n",
      "Ground-Truth: \t18 POI 24 RE country EOP\n",
      "---\n",
      "Predict: \t56 POI 50 RE contains EOP\n",
      "Ground-Truth: \t106 POI 120 RE country EOP\n",
      "---\n",
      "Predict: \t24 POI 15 RE contains EOP\n",
      "Ground-Truth: \t26 POI 22 RE contains EOP\n",
      "---\n",
      "Predict: \t25 POI 25 RE contains EOP\n",
      "Ground-Truth: \t29 POI 24 RE country EOP\n",
      "---\n",
      "Predict: \t30 POI 28 RE contains EOP\n",
      "Ground-Truth: \t30 POI 28 RE contains EOP\n",
      "---\n",
      "Predict: \t32 POI 34 RE nationality EOP\n",
      "Ground-Truth: \t32 POI 34 RE nationality EOP\n",
      "---\n",
      "Predict: \t20 POI 17 RE contains EOP\n",
      "Ground-Truth: \t17 POI 21 RE country EOP\n",
      "---\n",
      "Predict: \t23 POI 21 RE contains EOP\n",
      "Ground-Truth: \t23 POI 20 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI 6 RE nationality EOP\n",
      "Ground-Truth: \t1 POI 6 RE nationality EOP\n",
      "---\n",
      "Predict: \t6 POI 5 RE contains EOP\n",
      "Ground-Truth: \t6 POI 5 RE contains EOP\n",
      "---\n",
      "Predict: \t34 POI 14 RE contains EOP\n",
      "Ground-Truth: \t34 POI 14 RE contains EOP\n",
      "---\n",
      "Predict: \t31 POI 31 RE nationality EOP\n",
      "Ground-Truth: \t33 POI 29 RE nationality EOP\n",
      "---\n",
      "Predict: \t40 POI 12 RE contains EOP\n",
      "Ground-Truth: \t32 POI 44 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI 1 RE contains EOP\n",
      "Ground-Truth: \t1 POI 4 RE contains EOP\n",
      "---\n",
      "Predict: \t16 POI 5 RE contains EOP\n",
      "Ground-Truth: \t17 POI 15 RE contains EOP\n",
      "---\n",
      "Predict: \t23 POI 21 RE capital EOP 23 POI 21 RE contains EOP\n",
      "Ground-Truth: \t23 POI 22 RE contains EOP\n",
      "---\n",
      "Predict: \t23 POI 13 RE contains EOP\n",
      "Ground-Truth: \t13 POI 22 RE contains EOP\n",
      "---\n",
      "Predict: \t14 POI 13 RE contains EOP\n",
      "Ground-Truth: \t13 POI 14 RE country EOP\n",
      "---\n",
      "Predict: \t18 POI 37 RE contains EOP POI RE contains EOP\n",
      "Ground-Truth: \t18 POI 36 RE country EOP\n",
      "---\n",
      "Predict: \t8 POI 38 RE contains EOP\n",
      "Ground-Truth: \t39 POI 33 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI 14 RE nationality EOP\n",
      "Ground-Truth: \t11 POI 14 RE nationality EOP\n",
      "---\n",
      "Predict: \t24 POI 23 RE contains EOP\n",
      "Ground-Truth: \t24 POI 23 RE contains EOP\n",
      "---\n",
      "Predict: \t17 POI 28 RE contains EOP\n",
      "Ground-Truth: \t17 POI 27 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI 16 RE place_lived EOP\n",
      "Ground-Truth: \t12 POI 16 RE place_lived EOP\n",
      "---\n",
      "Predict: \t25 POI 25 RE contains EOP\n",
      "Ground-Truth: \t26 POI 28 RE contains EOP\n",
      "---\n",
      "Predict: \t40 POI 44 RE nationality EOP\n",
      "Ground-Truth: \t45 POI 42 RE nationality EOP\n",
      "---\n",
      "Predict: \t6 POI 4 RE contains EOP\n",
      "Ground-Truth: \t5 POI 8 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI 9 RE contains EOP\n",
      "Ground-Truth: \t9 POI 3 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI 35 RE company EOP\n",
      "Ground-Truth: \t35 POI 37 RE founders EOP\n",
      "---\n",
      "Predict: \t17 POI 28 RE nationality EOP\n",
      "Ground-Truth: \t25 POI 28 RE nationality EOP\n",
      "---\n",
      "Predict: \t14 POI 13 RE contains EOP\n",
      "Ground-Truth: \t13 POI 14 RE country EOP\n",
      "---\n",
      "Predict: \t31 POI 28 RE contains EOP\n",
      "Ground-Truth: \t31 POI 28 RE contains EOP\n",
      "---\n",
      "Predict: \t16 POI 14 RE contains EOP\n",
      "Ground-Truth: \t16 POI 14 RE contains EOP\n",
      "---\n",
      "Predict: \t29 POI 28 RE contains EOP\n",
      "Ground-Truth: \t30 POI 29 RE contains EOP\n",
      "---\n",
      "Predict: \t9 POI 8 RE company EOP\n",
      "Ground-Truth: \t10 POI 22 RE company EOP\n",
      "---\n",
      "Predict: \t15 POI 13 RE contains EOP\n",
      "Ground-Truth: \t15 POI 17 RE contains EOP\n",
      "---\n",
      "Predict: \t18 POI 16 RE contains EOP\n",
      "Ground-Truth: \t19 POI 17 RE contains EOP\n",
      "---\n",
      "Predict: \t6 POI 8 RE place_lived EOP\n",
      "Ground-Truth: \t6 POI 8 RE place_lived EOP\n",
      "---\n",
      "Predict: \t10 POI 9 RE contains EOP\n",
      "Ground-Truth: \t10 POI 9 RE contains EOP\n",
      "---\n",
      "Predict: \t3 POI 2 RE contains EOP\n",
      "Ground-Truth: \t4 POI 2 RE country EOP\n",
      "---\n",
      "Predict: \t13 POI 13 RE contains EOP\n",
      "Ground-Truth: \t12 POI 16 RE contains EOP\n",
      "---\n",
      "Predict: \t5 POI 18 RE contains EOP\n",
      "Ground-Truth: \t19 POI 17 RE contains EOP\n",
      "---\n",
      "Predict: \t17 POI 3 RE contains EOP\n",
      "Ground-Truth: \t3 POI 17 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI 5 RE place_lived EOP\n",
      "Ground-Truth: \t2 POI 5 RE place_lived EOP\n",
      "---\n",
      "Predict: \t2 POI 2 RE company EOP\n",
      "Ground-Truth: \t18 POI 3 RE company EOP\n",
      "---\n",
      "Predict: \t10 POI 32 RE contains EOP\n",
      "Ground-Truth: \t31 POI 10 RE country EOP\n",
      "---\n",
      "Predict: \t6 POI 5 RE contains EOP\n",
      "Ground-Truth: \t5 POI 6 RE country EOP\n",
      "---\n",
      "Predict: \t3 POI 6 RE nationality EOP\n",
      "Ground-Truth: \t3 POI 6 RE nationality EOP\n",
      "---\n",
      "Predict: \t13 POI 12 RE contains EOP\n",
      "Ground-Truth: \t13 POI 12 RE contains EOP\n",
      "---\n",
      "Predict: \t33 POI 14 RE contains EOP RE EOP\n",
      "Ground-Truth: \t32 POI 39 RE company EOP\n",
      "---\n",
      "Predict: \t9 POI 17 RE contains EOP\n",
      "Ground-Truth: \t10 POI 18 RE company EOP\n",
      "---\n",
      "Predict: \t17 POI 15 RE contains EOP POI RE contains EOP\n",
      "Ground-Truth: \t17 POI 24 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI 16 RE place_lived EOP\n",
      "Ground-Truth: \t13 POI 17 RE place_lived EOP\n",
      "---\n",
      "Predict: \t6 POI 5 RE contains EOP\n",
      "Ground-Truth: \t6 POI 5 RE contains EOP\n",
      "---\n",
      "Predict: \t14 POI 13 RE contains EOP\n",
      "Ground-Truth: \t14 POI 13 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI 11 RE place_lived EOP\n",
      "Ground-Truth: \t8 POI 11 RE place_lived EOP\n",
      "---\n",
      "Predict: \t1 POI 19 RE contains EOP\n",
      "Ground-Truth: \t18 POI 22 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI 10 RE contains EOP\n",
      "Ground-Truth: \t13 POI 9 RE contains EOP\n",
      "---\n",
      "Predict: \t11 POI 31 RE capital EOP POI RE contains EOP\n",
      "Ground-Truth: \t32 POI 11 RE country EOP\n",
      "---\n",
      "Predict: \t9 POI 4 RE contains EOP\n",
      "Ground-Truth: \t4 POI 3 RE contains EOP\n",
      "---\n",
      "Predict: \t50 POI 16 RE contains EOP\n",
      "Ground-Truth: \t79 POI 47 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI 5 RE nationality EOP\n",
      "Ground-Truth: \t1 POI 4 RE nationality EOP\n",
      "---\n",
      "Predict: \t21 POI 11 RE contains EOP\n",
      "Ground-Truth: \t1 POI 11 RE company EOP\n",
      "---\n",
      "Predict: \t16 POI 15 RE contains EOP\n",
      "Ground-Truth: \t15 POI 16 RE country EOP\n",
      "---\n",
      "Predict: \t3 POI 2 RE contains EOP\n",
      "Ground-Truth: \t17 POI 13 RE contains EOP\n",
      "---\n",
      "Predict: \t13 POI 12 RE capital EOP POI 12 RE contains EOP\n",
      "Ground-Truth: \t13 POI 12 RE contains EOP\n",
      "---\n",
      "Predict: \t28 POI 9 RE contains EOP contains\n",
      "Ground-Truth: \t31 POI 8 RE capital EOP\n",
      "---\n",
      "Predict: \t2 POI 48 RE nationality EOP\n",
      "Ground-Truth: \t54 POI 45 RE contains EOP\n",
      "---\n",
      "Predict: \t40 POI 40 RE contains EOP\n",
      "Ground-Truth: \t42 POI 40 RE contains EOP\n",
      "---\n",
      "Predict: \t10 POI 17 RE company EOP\n",
      "Ground-Truth: \t10 POI 16 RE company EOP\n",
      "---\n",
      "Predict: \t12 POI 12 RE contains EOP POI RE contains EOP\n",
      "Ground-Truth: \t5 POI 6 RE country EOP\n",
      "---\n",
      "Predict: \t8 POI 8 RE place_lived EOP\n",
      "Ground-Truth: \t5 POI 9 RE place_lived EOP\n",
      "---\n",
      "Predict: \t5 POI 4 RE contains EOP\n",
      "Ground-Truth: \t5 POI 4 RE contains EOP\n",
      "---\n",
      "Predict: \t29 POI 29 RE company EOP\n",
      "Ground-Truth: \t23 POI 29 RE company EOP\n",
      "---\n",
      "Predict: \t4 POI 10 RE contains EOP 10 POI 2 RE contains EOP\n",
      "Ground-Truth: \t10 POI 7 RE contains EOP\n",
      "---\n",
      "Predict: \t32 POI 35 RE place_lived EOP\n",
      "Ground-Truth: \t36 POI 42 RE children EOP\n",
      "---\n",
      "Predict: \t23 POI 13 RE contains EOP\n",
      "Ground-Truth: \t23 POI 22 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI 24 RE contains EOP\n",
      "Ground-Truth: \t23 POI 8 RE country EOP\n",
      "---\n",
      "Predict: \t5 POI 4 RE contains EOP\n",
      "Ground-Truth: \t5 POI 4 RE contains EOP\n",
      "---\n",
      "Predict: \t17 POI 7 RE contains EOP\n",
      "Ground-Truth: \t17 POI 14 RE contains EOP\n",
      "---\n",
      "Predict: \t4 POI 3 RE contains EOP\n",
      "Ground-Truth: \t20 POI 2 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI 7 RE contains EOP\n",
      "Ground-Truth: \t8 POI 7 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI 17 RE contains EOP\n",
      "Ground-Truth: \t16 POI 11 RE country EOP\n",
      "---\n",
      "Predict: \t19 POI 35 RE contains EOP\n",
      "Ground-Truth: \t34 POI 36 RE country EOP\n",
      "---\n",
      "Predict: \t21 POI 20 RE contains EOP\n",
      "Ground-Truth: \t21 POI 20 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI 6 RE nationality EOP\n",
      "Ground-Truth: \t11 POI 6 RE nationality EOP\n",
      "---\n",
      "Predict: \t31 POI 11 RE contains EOP\n",
      "Ground-Truth: \t33 POI 19 RE contains EOP\n",
      "---\n",
      "Predict: \t6 POI 6 RE contains EOP\n",
      "Ground-Truth: \t6 POI 12 RE contains EOP\n",
      "---\n",
      "Predict: \t21 POI 29 RE contains EOP\n",
      "Ground-Truth: \t28 POI 21 RE country EOP\n",
      "---\n",
      "Predict: \t23 POI 21 RE contains EOP\n",
      "Ground-Truth: \t23 POI 22 RE contains EOP\n",
      "---\n",
      "Predict: \t33 POI 31 RE contains EOP\n",
      "Ground-Truth: \t34 POI 30 RE contains EOP\n",
      "---\n",
      "Predict: \t33 POI 32 RE contains EOP\n",
      "Ground-Truth: \t34 POI 31 RE contains EOP\n",
      "---\n",
      "Predict: \t3 POI 7 RE nationality EOP\n",
      "Ground-Truth: \t4 POI 7 RE nationality EOP\n",
      "---\n",
      "Predict: \t1 POI 17 RE nationality EOP\n",
      "Ground-Truth: \t14 POI 17 RE nationality EOP\n",
      "---\n",
      "Predict: \t21 POI 10 RE contains EOP\n",
      "Ground-Truth: \t8 POI 21 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI 10 RE company EOP\n",
      "Ground-Truth: \t1 POI 10 RE company EOP\n",
      "---\n",
      "Predict: \t11 POI 10 RE contains EOP\n",
      "Ground-Truth: \t11 POI 6 RE contains EOP\n",
      "---\n",
      "Predict: \t18 POI 18 RE contains EOP\n",
      "Ground-Truth: \t44 POI 19 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI 10 RE contains EOP\n",
      "Ground-Truth: \t11 POI 15 RE contains EOP\n",
      "---\n",
      "Predict: \t9 POI 35 RE contains EOP\n",
      "Ground-Truth: \t36 POI 9 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI 1 RE company EOP\n",
      "Ground-Truth: \t1 POI 3 RE company EOP\n",
      "---\n",
      "Predict: \t24 POI 32 RE contains EOP\n",
      "Ground-Truth: \t23 POI 29 RE country EOP\n",
      "---\n",
      "Predict: \t14 POI 8 RE contains EOP\n",
      "Ground-Truth: \t9 POI 6 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI 6 RE company EOP\n",
      "Ground-Truth: \t2 POI 6 RE company EOP\n",
      "---\n",
      "Predict: \t28 POI 28 RE contains EOP\n",
      "Ground-Truth: \t30 POI 26 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI 7 RE contains EOP\n",
      "Ground-Truth: \t8 POI 7 RE contains EOP\n",
      "---\n",
      "Predict: \t16 POI 14 RE contains EOP\n",
      "Ground-Truth: \t16 POI 13 RE contains EOP\n",
      "---\n",
      "Predict: \t18 POI 15 RE contains EOP\n",
      "Ground-Truth: \t19 POI 15 RE contains EOP\n",
      "---\n",
      "Predict: \t3 POI 25 RE contains EOP\n",
      "Ground-Truth: \t3 POI 28 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI 6 RE company EOP POI RE founders EOP\n",
      "Ground-Truth: \t36 POI 41 RE company EOP\n",
      "---\n",
      "Predict: \t11 POI 8 RE contains EOP\n",
      "Ground-Truth: \t11 POI 10 RE contains EOP\n",
      "---\n",
      "Predict: \t9 POI 6 RE contains EOP\n",
      "Ground-Truth: \t10 POI 7 RE contains EOP\n",
      "---\n",
      "Predict: \t14 POI 13 RE contains EOP\n",
      "Ground-Truth: \t15 POI 11 RE contains EOP\n",
      "---\n",
      "Predict: \t40 POI 40 RE contains EOP\n",
      "Ground-Truth: \t41 POI 35 RE contains EOP\n",
      "---\n",
      "Predict: \t16 POI 15 RE contains EOP\n",
      "Ground-Truth: \t15 POI 16 RE country EOP\n",
      "---\n",
      "Predict: \t23 POI 13 RE contains EOP\n",
      "Ground-Truth: \t21 POI 24 RE country EOP\n",
      "---\n",
      "Predict: \t18 POI 28 RE nationality EOP\n",
      "Ground-Truth: \t27 POI 20 RE country EOP\n",
      "---\n",
      "Predict: \t18 POI 17 RE company EOP\n",
      "Ground-Truth: \t11 POI 18 RE company EOP\n",
      "---\n",
      "Predict: \t18 POI 13 RE contains EOP\n",
      "Ground-Truth: \t18 POI 17 RE contains EOP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "Predict: \t11 POI 20 RE contains EOP\n",
      "Ground-Truth: \t21 POI 11 RE contains EOP\n",
      "---\n",
      "Predict: \t10 POI 26 RE contains EOP\n",
      "Ground-Truth: \t29 POI 26 RE contains EOP\n",
      "---\n",
      "Predict: \t21 POI 13 RE contains EOP\n",
      "Ground-Truth: \t21 POI 19 RE contains EOP\n",
      "---\n",
      "Predict: \t26 POI 24 RE contains EOP\n",
      "Ground-Truth: \t27 POI 21 RE contains EOP\n",
      "---\n",
      "Predict: \t7 POI 5 RE contains EOP\n",
      "Ground-Truth: \t7 POI 5 RE contains EOP\n",
      "---\n",
      "Predict: \t10 POI 4 RE contains EOP\n",
      "Ground-Truth: \t10 POI 9 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI 6 RE company EOP\n",
      "Ground-Truth: \t1 POI 4 RE company EOP\n",
      "---\n",
      "Predict: \t44 POI 44 RE contains EOP\n",
      "Ground-Truth: \t44 POI 42 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI 5 RE place_lived EOP\n",
      "Ground-Truth: \t2 POI 5 RE place_lived EOP\n",
      "---\n",
      "Predict: \t26 POI 25 RE contains EOP\n",
      "Ground-Truth: \t27 POI 24 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI 19 RE contains EOP\n",
      "Ground-Truth: \t19 POI 20 RE country EOP\n",
      "---\n",
      "Predict: \t7 POI 5 RE contains EOP\n",
      "Ground-Truth: \t7 POI 5 RE contains EOP\n",
      "---\n",
      "Predict: \t28 POI 13 RE contains EOP\n",
      "Ground-Truth: \t27 POI 24 RE contains EOP\n",
      "---\n",
      "Predict: \t13 POI 12 RE contains EOP\n",
      "Ground-Truth: \t13 POI 12 RE contains EOP\n",
      "---\n",
      "Predict: \t7 POI 23 RE company EOP\n",
      "Ground-Truth: \t22 POI 19 RE contains EOP\n",
      "---\n",
      "Predict: \t28 POI 28 RE contains EOP\n",
      "Ground-Truth: \t28 POI 29 RE capital EOP\n",
      "---\n",
      "Predict: \t5 POI 4 RE contains EOP\n",
      "Ground-Truth: \t5 POI 4 RE contains EOP\n",
      "---\n",
      "Predict: \t47 POI 48 RE contains EOP\n",
      "Ground-Truth: \t50 POI 47 RE contains EOP\n",
      "---\n",
      "Predict: \t56 POI 50 RE contains EOP\n",
      "Ground-Truth: \t95 POI 64 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI 13 RE contains EOP\n",
      "Ground-Truth: \t13 POI 11 RE contains EOP\n",
      "---\n",
      "Predict: \t7 POI 13 RE company EOP\n",
      "Ground-Truth: \t8 POI 14 RE company EOP\n",
      "---\n",
      "Predict: \t17 POI 15 RE contains EOP\n",
      "Ground-Truth: \t17 POI 15 RE contains EOP\n",
      "---\n",
      "Predict: \t16 POI 14 RE contains EOP RE contains\n",
      "Ground-Truth: \t40 POI 37 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI 5 RE contains EOP\n",
      "Ground-Truth: \t19 POI 20 RE country EOP\n",
      "---\n",
      "Predict: \t4 POI 8 RE place_lived EOP\n",
      "Ground-Truth: \t4 POI 8 RE place_lived EOP\n",
      "---\n",
      "Predict: \t12 POI 25 RE contains EOP\n",
      "Ground-Truth: \t5 POI 11 RE company EOP\n",
      "---\n",
      "Predict: \t14 POI 13 RE contains EOP\n",
      "Ground-Truth: \t13 POI 14 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI 12 RE contains EOP POI RE contains EOP\n",
      "Ground-Truth: \t6 POI 5 RE contains EOP\n",
      "---\n",
      "Predict: \t17 POI 13 RE contains EOP\n",
      "Ground-Truth: \t21 POI 15 RE contains EOP\n",
      "---\n",
      "Predict: \t33 POI 32 RE capital EOP 33 POI 31 RE contains EOP\n",
      "Ground-Truth: \t34 POI 33 RE contains EOP\n",
      "---\n",
      "Predict: \t15 POI 13 RE contains EOP\n",
      "Ground-Truth: \t15 POI 11 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI 17 RE contains EOP\n",
      "Ground-Truth: \t8 POI 17 RE contains EOP\n",
      "---\n",
      "Predict: \t44 POI 44 RE contains EOP\n",
      "Ground-Truth: \t41 POI 42 RE country EOP\n",
      "---\n",
      "Predict: \t21 POI 20 RE contains EOP\n",
      "Ground-Truth: \t21 POI 20 RE contains EOP\n",
      "---\n",
      "Predict: \t18 POI 13 RE contains EOP\n",
      "Ground-Truth: \t1 POI 19 RE country EOP\n",
      "---\n",
      "Predict: \t7 POI 7 RE contains EOP\n",
      "Ground-Truth: \t9 POI 7 RE country EOP\n",
      "---\n",
      "Predict: \t8 POI 7 RE contains EOP\n",
      "Ground-Truth: \t8 POI 7 RE contains EOP\n",
      "---\n",
      "Predict: \t13 POI 21 RE nationality EOP\n",
      "Ground-Truth: \t14 POI 22 RE nationality EOP\n",
      "---\n",
      "Predict: \t25 POI 24 RE contains EOP\n",
      "Ground-Truth: \t25 POI 24 RE contains EOP\n",
      "---\n",
      "Predict: \t19 POI 17 RE contains EOP\n",
      "Ground-Truth: \t19 POI 18 RE contains EOP\n",
      "---\n",
      "Predict: \t16 POI 12 RE contains EOP\n",
      "Ground-Truth: \t17 POI 11 RE contains EOP\n",
      "---\n",
      "Predict: \t30 POI 29 RE place_lived EOP\n",
      "Ground-Truth: \t15 POI 18 RE place_lived EOP\n",
      "---\n",
      "Predict: \t13 POI 11 RE contains EOP\n",
      "Ground-Truth: \t13 POI 11 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI 7 RE company EOP\n",
      "Ground-Truth: \t1 POI 14 RE company EOP\n",
      "---\n",
      "Predict: \t1 POI 8 RE company EOP\n",
      "Ground-Truth: \t10 POI 7 RE contains EOP\n",
      "---\n",
      "Predict: \t18 POI 16 RE contains EOP\n",
      "Ground-Truth: \t17 POI 20 RE country EOP\n",
      "---\n",
      "Predict: \t16 POI 10 RE contains EOP\n",
      "Ground-Truth: \t16 POI 14 RE contains EOP\n",
      "---\n",
      "Predict: \t19 POI 1 RE contains EOP\n",
      "Ground-Truth: \t20 POI 17 RE contains EOP\n",
      "---\n",
      "Predict: \t34 POI 16 RE contains EOP\n",
      "Ground-Truth: \t17 POI 11 RE contains EOP\n",
      "---\n",
      "Predict: \t33 POI 32 RE contains EOP\n",
      "Ground-Truth: \t34 POI 32 RE contains EOP\n",
      "---\n",
      "Predict: \t50 POI 17 RE contains EOP\n",
      "Ground-Truth: \t58 POI 16 RE country EOP\n",
      "---\n",
      "Predict: \t26 POI 25 RE contains EOP\n",
      "Ground-Truth: \t24 POI 31 RE country EOP\n",
      "---\n",
      "Predict: \t6 POI 4 RE contains EOP\n",
      "Ground-Truth: \t6 POI 4 RE contains EOP\n",
      "---\n",
      "Predict: \t14 POI 10 RE contains EOP\n",
      "Ground-Truth: \t16 POI 11 RE contains EOP\n",
      "---\n",
      "Predict: \t21 POI 21 RE contains EOP\n",
      "Ground-Truth: \t23 POI 37 RE country EOP 34 POI 37 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI 13 RE contains EOP\n",
      "Ground-Truth: \t10 POI 12 RE country EOP\n",
      "---\n",
      "Predict: \t10 POI 12 RE place_lived EOP\n",
      "Ground-Truth: \t9 POI 12 RE place_lived EOP\n",
      "---\n",
      "Predict: \t21 POI 23 RE place_lived EOP\n",
      "Ground-Truth: \t21 POI 25 RE place_lived EOP\n",
      "---\n",
      "Predict: \t7 POI 5 RE contains EOP\n",
      "Ground-Truth: \t7 POI 6 RE contains EOP\n",
      "---\n",
      "Predict: \t14 POI 6 RE contains EOP\n",
      "Ground-Truth: \t14 POI 13 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI 10 RE nationality EOP\n",
      "Ground-Truth: \t7 POI 1 RE nationality EOP\n",
      "---\n",
      "Predict: \t32 POI 31 RE contains EOP\n",
      "Ground-Truth: \t29 POI 26 RE contains EOP\n",
      "---\n",
      "Predict: \t17 POI 6 RE contains EOP\n",
      "Ground-Truth: \t17 POI 6 RE country EOP\n",
      "---\n",
      "Predict: \t38 POI 13 RE contains EOP\n",
      "Ground-Truth: \t38 POI 13 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI 14 RE nationality EOP\n",
      "Ground-Truth: \t1 POI 14 RE place_lived EOP\n",
      "---\n",
      "Predict: \t5 POI 17 RE contains EOP\n",
      "Ground-Truth: \t18 POI 15 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI 1 RE contains EOP\n",
      "Ground-Truth: \t3 POI 1 RE country EOP\n",
      "---\n",
      "Predict: \t15 POI 13 RE contains EOP\n",
      "Ground-Truth: \t9 POI 5 RE contains EOP\n",
      "---\n",
      "Predict: \t28 POI 25 RE company EOP\n",
      "Ground-Truth: \t20 POI 28 RE company EOP\n",
      "---\n",
      "Predict: \t15 POI 24 RE nationality EOP\n",
      "Ground-Truth: \t15 POI 23 RE nationality EOP\n",
      "---\n",
      "Predict: \t1 POI 21 RE contains EOP\n",
      "Ground-Truth: \t12 POI 8 RE children EOP\n",
      "---\n",
      "Predict: \t9 POI 8 RE contains EOP\n",
      "Ground-Truth: \t9 POI 8 RE contains EOP\n",
      "---\n",
      "Predict: \t35 POI 32 RE contains EOP\n",
      "Ground-Truth: \t35 POI 31 RE contains EOP\n",
      "---\n",
      "Predict: \t14 POI 23 RE company EOP\n",
      "Ground-Truth: \t15 POI 23 RE company EOP\n",
      "---\n",
      "Predict: \t9 POI 6 RE contains EOP\n",
      "Ground-Truth: \t8 POI 5 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI 5 RE place_lived EOP\n",
      "Ground-Truth: \t2 POI 5 RE place_lived EOP\n",
      "---\n",
      "Predict: \t1 POI 6 RE place_lived EOP\n",
      "Ground-Truth: \t1 POI 5 RE place_lived EOP\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "preResult = [' '.join([index2token.get(i, str(i)) for i in sent if i != 0]) for sent in result]\n",
    "actResult = [' '.join([index2token.get(i, str(i)) for i in sent if i != 0]) for sent in y_test]\n",
    "for i in range(395):\n",
    "    print('Predict: \\t%s' % preResult[i])\n",
    "    print('Ground-Truth: \\t%s' % actResult[i])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E1 Accuracy: \t\t0.354430\n",
      "E2 Accuracy: \t\t0.318987\n",
      "En Accuracy: \t\t0.192405\n",
      "Triple Accuracy: \t0.169620\n"
     ]
    }
   ],
   "source": [
    "preResult = []\n",
    "actResult = []\n",
    "for n in range(395):\n",
    "    pR = [index2token.get(i, str(i)) if i > len(t_sentWords[n]) else t_sentWords[n][i-1] for i in result[n] if i != 0]\n",
    "    aR = [index2token.get(i, str(i)) if i > len(t_sentWords[n]) else t_sentWords[n][i-1] for i in y_test[n] if i != 0]\n",
    "    preResult.append(pR)\n",
    "    actResult.append(aR)\n",
    "e1Count = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0]])\n",
    "e2Count = sum([1 for i in range(395) if actResult[i][2] == preResult[i][2]])\n",
    "enCount = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0] and actResult[i][2] == preResult[i][2]])\n",
    "tripleCount = sum([1 for i in range(395) if actResult[i][0] == preResult[i][0] and actResult[i][2] == preResult[i][2] and actResult[i][4] == preResult[i][4]])\n",
    "print('E1 Accuracy: \\t\\t%.6f' % (e1Count/395))\n",
    "print('E2 Accuracy: \\t\\t%.6f' % (e2Count/395))\n",
    "print('En Accuracy: \\t\\t%.6f' % (enCount/395))\n",
    "print('Triple Accuracy: \\t%.6f' % (tripleCount/395))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
