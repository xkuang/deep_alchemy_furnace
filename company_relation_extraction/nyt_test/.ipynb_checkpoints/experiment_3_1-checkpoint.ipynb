{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#GPU\" data-toc-modified-id=\"GPU-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>GPU</a></div><div class=\"lev1 toc-item\"><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Preprocessing</a></div><div class=\"lev2 toc-item\"><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-21\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Load Data</a></div><div class=\"lev3 toc-item\"><a href=\"#Load-Train-Data\" data-toc-modified-id=\"Load-Train-Data-211\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Load Train Data</a></div><div class=\"lev3 toc-item\"><a href=\"#Load-Test-Data\" data-toc-modified-id=\"Load-Test-Data-212\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Load Test Data</a></div><div class=\"lev3 toc-item\"><a href=\"#Relation-Types\" data-toc-modified-id=\"Relation-Types-213\"><span class=\"toc-item-num\">2.1.3&nbsp;&nbsp;</span>Relation Types</a></div><div class=\"lev2 toc-item\"><a href=\"#Participle\" data-toc-modified-id=\"Participle-22\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Participle</a></div><div class=\"lev2 toc-item\"><a href=\"#Make-Adjacency-List\" data-toc-modified-id=\"Make-Adjacency-List-23\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Make Adjacency List</a></div><div class=\"lev3 toc-item\"><a href=\"#Make-Adjacency-List-of-Train-Data\" data-toc-modified-id=\"Make-Adjacency-List-of-Train-Data-231\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Make Adjacency List of Train Data</a></div><div class=\"lev3 toc-item\"><a href=\"#Make-Adjacency-List-of-Test-Data\" data-toc-modified-id=\"Make-Adjacency-List-of-Test-Data-232\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Make Adjacency List of Test Data</a></div><div class=\"lev1 toc-item\"><a href=\"#Word-to-Vector\" data-toc-modified-id=\"Word-to-Vector-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Word to Vector</a></div><div class=\"lev2 toc-item\"><a href=\"#Tokenize-Text\" data-toc-modified-id=\"Tokenize-Text-31\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Tokenize Text</a></div><div class=\"lev2 toc-item\"><a href=\"#Create-Word-Embeddings-with-GloVe\" data-toc-modified-id=\"Create-Word-Embeddings-with-GloVe-32\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Create Word Embeddings with GloVe</a></div><div class=\"lev3 toc-item\"><a href=\"#Read-GloVe\" data-toc-modified-id=\"Read-GloVe-321\"><span class=\"toc-item-num\">3.2.1&nbsp;&nbsp;</span>Read GloVe</a></div><div class=\"lev3 toc-item\"><a href=\"#Use-Glove-to-Initialize-Embedding-Matrix\" data-toc-modified-id=\"Use-Glove-to-Initialize-Embedding-Matrix-322\"><span class=\"toc-item-num\">3.2.2&nbsp;&nbsp;</span>Use Glove to Initialize Embedding Matrix</a></div><div class=\"lev1 toc-item\"><a href=\"#Build-Dateset\" data-toc-modified-id=\"Build-Dateset-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Build Dateset</a></div><div class=\"lev1 toc-item\"><a href=\"#Save-Dataset\" data-toc-modified-id=\"Save-Dataset-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Save Dataset</a></div><div class=\"lev1 toc-item\"><a href=\"#Checkpoint\" data-toc-modified-id=\"Checkpoint-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Checkpoint</a></div><div class=\"lev1 toc-item\"><a href=\"#Build-Model\" data-toc-modified-id=\"Build-Model-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Build Model</a></div><div class=\"lev2 toc-item\"><a href=\"#Set-Hyperparameters\" data-toc-modified-id=\"Set-Hyperparameters-71\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Set Hyperparameters</a></div><div class=\"lev2 toc-item\"><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-72\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Import Libraries</a></div><div class=\"lev2 toc-item\"><a href=\"#Build-Graph\" data-toc-modified-id=\"Build-Graph-73\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Build Graph</a></div><div class=\"lev2 toc-item\"><a href=\"#Model-Visualization\" data-toc-modified-id=\"Model-Visualization-74\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Model Visualization</a></div><div class=\"lev2 toc-item\"><a href=\"#Train\" data-toc-modified-id=\"Train-75\"><span class=\"toc-item-num\">7.5&nbsp;&nbsp;</span>Train</a></div><div class=\"lev1 toc-item\"><a href=\"#Evaluate\" data-toc-modified-id=\"Evaluate-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Evaluate</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentText = []\n",
    "relationMentions = []\n",
    "relationLabels = []\n",
    "entityMentions = []\n",
    "entityLabels = []\n",
    "em1Text = []\n",
    "em2Text = []\n",
    "\n",
    "with open(\"/Users/lizhn7/Downloads/DATA/nyt/train.json\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    item = json.loads(line)\n",
    "    # Exclude \"None\" label\n",
    "    if not all(i['label'] == 'None' for i in item['relationMentions']):\n",
    "        sentText.append(item['sentText'])\n",
    "        relationMentions.append(item['relationMentions'])\n",
    "        entityMentions.append(item['entityMentions'])\n",
    "    \n",
    "relationLabels = [[i['label'].split('/')[-1] for i in rM] for rM in relationMentions]\n",
    "entityLabels = [[i['text'] for i in eM] for eM in entityMentions]\n",
    "em1Text = [[i['em1Text'] for i in rM] for rM in relationMentions]\n",
    "em2Text = [[i['em2Text'] for i in rM] for rM in relationMentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean words\n",
    "replaceDict = {\n",
    "               'ā': 'a', 'á': 'a', 'ǎ': 'a', 'à': 'a',\n",
    "               'ō': 'o', 'ó': 'o', 'ǒ': 'o', 'ò': 'o', 'ô': 'o', 'ö': 'o',\n",
    "               'ē': 'e', 'é': 'e', 'ě': 'e', 'è': 'e', \n",
    "               'ī': 'i', 'í': 'i', 'ǐ': 'i', 'ì': 'i',\n",
    "               'ū': 'u', 'ú': 'u', 'ǔ': 'u', 'ù': 'u', 'ü': 'u',\n",
    "               'ñ': 'n',\n",
    "               'É': 'E'\n",
    "              }\n",
    "em1Text = [[''.join([replaceDict.get(i, i) for i in e]) for e in eT] for eT in em1Text]\n",
    "em2Text = [[''.join([replaceDict.get(i, i) for i in e]) for e in eT] for eT in em2Text]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_sentText = []\n",
    "t_relationMentions = []\n",
    "t_relationLabels = []\n",
    "t_entityMentions = []\n",
    "t_entityLabels = []\n",
    "t_em1Text = []\n",
    "t_em2Text = []\n",
    "\n",
    "with open(\"/Users/lizhn7/Downloads/DATA/nyt/test.json\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    item = json.loads(line)\n",
    "    t_sentText.append(item['sentText'])\n",
    "    t_relationMentions.append(item['relationMentions'])\n",
    "    t_entityMentions.append(item['entityMentions'])\n",
    "    \n",
    "t_relationLabels = [[i['label'].split('/')[-1] for i in rM] for rM in t_relationMentions]\n",
    "t_entityLabels = [[i['text'] for i in eM] for eM in t_entityMentions]\n",
    "t_em1Text = [[i['em1Text'] for i in rM] for rM in t_relationMentions]\n",
    "t_em2Text = [[i['em2Text'] for i in rM] for rM in t_relationMentions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean words\n",
    "t_replaceDict = {\n",
    "               'ā': 'a', 'á': 'a', 'ǎ': 'a', 'à': 'a',\n",
    "               'ō': 'o', 'ó': 'o', 'ǒ': 'o', 'ò': 'o', 'ô': 'o', 'ö': 'o',\n",
    "               'ē': 'e', 'é': 'e', 'ě': 'e', 'è': 'e', \n",
    "               'ī': 'i', 'í': 'i', 'ǐ': 'i', 'ì': 'i',\n",
    "               'ū': 'u', 'ú': 'u', 'ǔ': 'u', 'ù': 'u', 'ü': 'u',\n",
    "               'ñ': 'n',\n",
    "               'É': 'E'\n",
    "              }\n",
    "t_em1Text = [[''.join([t_replaceDict.get(i, i) for i in e]) for e in eT] for eT in t_em1Text]\n",
    "t_em2Text = [[''.join([t_replaceDict.get(i, i) for i in e]) for e in eT] for eT in t_em2Text]\n",
    "t_entityLabels = [[''.join([t_replaceDict.get(i, i) for i in e]) for e in eT] for eT in t_entityLabels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Relation Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ethnicity',\n",
       " 'administrative_divisions',\n",
       " 'place_lived',\n",
       " 'industry',\n",
       " 'major_shareholders',\n",
       " 'company',\n",
       " 'geographic_distribution',\n",
       " 'neighborhood_of',\n",
       " 'teams',\n",
       " 'religion',\n",
       " 'place_of_birth',\n",
       " 'nationality',\n",
       " 'advisors',\n",
       " 'contains',\n",
       " 'people',\n",
       " 'children',\n",
       " 'country',\n",
       " 'founders',\n",
       " 'major_shareholder_of',\n",
       " 'capital',\n",
       " 'place_of_death',\n",
       " 'place_founded',\n",
       " 'location',\n",
       " 'profession']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationTypes = list(set([r for rl in relationLabels for r in rl]))\n",
    "relationTypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Participle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import regexp_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cut(s):\n",
    "    \"\"\"\n",
    "    Participle\n",
    "    \"\"\"\n",
    "    pattern = r'''\n",
    "              (?x)                   # set flag to allow verbose regexps \n",
    "              (?:[A-Z]\\.)+           # abbreviations, e.g. U.S.A. \n",
    "              |\\d+(?:\\.\\d+)?%?       # numbers, incl. currency and percentages \n",
    "              |\\w+(?:[-']\\w+)*       # words w/ optional internal hyphens/apostrophe  \n",
    "           '''  \n",
    "    return regexp_tokenize(s, pattern=pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentWords = [cut(s) for s in sentText]\n",
    "entlabWords = [[cut(s) for s in eL] for eL in entityLabels]\n",
    "em1Words = [[cut(s) for s in eL] for eL in em1Text]\n",
    "em2Words = [[cut(s) for s in eL] for eL in em2Text]\n",
    "t_sentWords = [cut(s) for s in t_sentText]\n",
    "t_entlabWords = [[cut(s) for s in eL] for eL in t_entityLabels]\n",
    "t_em1Words = [[cut(s) for s in eL] for eL in t_em1Text]\n",
    "t_em2Words = [[cut(s) for s in eL] for eL in t_em2Text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_SENT_LEN = 60\n",
    "MAX_ADJL_LEN = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len([i for i, j in enumerate(sentWords) if len(j) > 80])\n",
    "#max(len(j) for i, j in enumerate(t_sentWords) if len(j) > 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Adjacency List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Adjacency List of Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_entityLabels = []\n",
    "for i in range(len(sentWords)):\n",
    "    eL = []\n",
    "    sDict = list(enumerate(sentWords[i]))\n",
    "    for item in entlabWords[i]:\n",
    "        j = 0\n",
    "        el = []\n",
    "        for e in item:\n",
    "            while j < len(sDict):\n",
    "                if e == sDict[j][1]:\n",
    "                    el.append(sDict[j][0])\n",
    "                    j += 1\n",
    "                    break\n",
    "                j += 1\n",
    "        eL.append(el)\n",
    "    eL = [[min(it)] for it in eL]\n",
    "    i_entityLabels.append(eL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacencyList = []\n",
    "new_entityLabels = [[it[0] for it in el] for el in entlabWords]\n",
    "new_em1Text = [[it[0] for it in el] for el in em1Words]\n",
    "new_em2Text = [[it[0] for it in el] for el in em2Words]\n",
    "padDict = ['POI', 'RE', 'EOP']\n",
    "for i in range(len(sentWords)):\n",
    "    # POI means pointer\n",
    "    # RE means relation label\n",
    "    # EOP means end of pointer   \n",
    "    aL = ''\n",
    "    for j in new_entityLabels[i]:\n",
    "        dictEn = dict((b, a) for a, b in enumerate(new_entityLabels[i]))\n",
    "        # Exclude further \"None\" label\n",
    "        if j in new_em1Text[i]:\n",
    "            aL += j\n",
    "        in_em1Text = [dictEn[item] for item in new_em1Text[i]]\n",
    "        in_em2Text = [dictEn[item] for item in new_em2Text[i]]\n",
    "        new_em1 = [m[0] for m in sorted(list(zip(in_em1Text, in_em2Text)))]\n",
    "        new_em2 = [n[1] for n in sorted(list(zip(in_em1Text, in_em2Text)))]\n",
    "        new_em1 = [new_entityLabels[i][e1] for e1 in new_em1]\n",
    "        new_em2 = [new_entityLabels[i][e2] for e2 in new_em2]\n",
    "        listRe = list(zip(zip(in_em1Text, in_em2Text), relationLabels[i]))\n",
    "        new_rel = [r[-1] for r in sorted(listRe, key=lambda z: z[0])]\n",
    "        for item in enumerate(new_em1):\n",
    "            if j == item[1]:\n",
    "                aL = aL + ' POI ' + new_em2[item[0]] + ' RE ' + new_rel[item[0]]\n",
    "        if j in new_em1Text[i]:\n",
    "            aL += ' EOP '\n",
    "    adjacencyList.append(aL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_adjacencyList = []\n",
    "for i in range(len(adjacencyList)):\n",
    "    aL = []\n",
    "    replace = dict(zip(new_entityLabels[i], sum(i_entityLabels[i], [])))\n",
    "    aL = [replace[j] if j not in padDict+relationTypes else j for j in cut(adjacencyList[i])]\n",
    "    #aL = [s if type(s) == str else str(s) for s in aL]\n",
    "    i_adjacencyList.append(aL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all(al[1] == 'POI' for al in i_adjacencyList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[i for i in i_adjacencyList if i[0] == 'POI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[eT[0] for eT in enumerate(em1Text) for i in eT[1] if i == 'Édith Piaf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#i_em1Text = []\n",
    "#for i in range(len(sentWords)):\n",
    "#    temp = list(zip(sum(i_entityLabels[i], []), sum(entlabWords[i], [])))\n",
    "#    eM1 = []\n",
    "#    for ee in em1Words[i]:\n",
    "#        j = 0\n",
    "#        em1 = []\n",
    "#        for e in ee:\n",
    "#            while j < len(temp):\n",
    "#                if e == temp[j][1] and Counter(sum(entlabWords[i], []))[e] == 1:\n",
    "#                    em1.append(temp[j][0])\n",
    "#                    break\n",
    "#                if e == temp[j][1] and Counter(sum(entlabWords[i], []))[e] > 1:\n",
    "#                    em1.append(temp[j][0])\n",
    "#                    j += 1\n",
    "#                    break\n",
    "#                j += 1\n",
    "#        eM1.append(em1)\n",
    "#    i_em1Text.append(eM1)\n",
    "\n",
    "#i_em2Text = []\n",
    "#for i in range(len(sentWords)):\n",
    "#    temp = list(zip(sum(i_entityLabels[i], []), sum(entlabWords[i], [])))\n",
    "#    eM2 = []\n",
    "#    for ee in em2Words[i]:\n",
    "#        j = 0\n",
    "#        em2 = []\n",
    "#        for e in ee:\n",
    "#            while j < len(temp):\n",
    "#                if e == temp[j][1] and Counter(sum(entlabWords[i], []))[e] == 1:\n",
    "#                    em2.append(temp[j][0])\n",
    "#                    break\n",
    "#                if e == temp[j][1] and Counter(sum(entlabWords[i], []))[e] > 1:\n",
    "#                    em2.append(temp[j][0])\n",
    "#                    j += 1\n",
    "#                    break\n",
    "#                j += 1\n",
    "#        eM2.append(em2)\n",
    "#    i_em2Text.append(eM2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Adjacency List of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean words\n",
    "t_sentWords = [[''.join([t_replaceDict.get(i, i) for i in e]) for e in eT] for eT in t_sentWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ti_entityLabels = []\n",
    "for i in range(len(t_sentWords)):\n",
    "    eL = []\n",
    "    t_sDict = list(enumerate(t_sentWords[i]))\n",
    "    for item in t_entlabWords[i]:\n",
    "        j = 0\n",
    "        el = []\n",
    "        for e in item:\n",
    "            while j < len(t_sDict):\n",
    "                if e == t_sDict[j][1]:\n",
    "                    el.append(t_sDict[j][0])\n",
    "                    j += 1\n",
    "                    break\n",
    "                j += 1\n",
    "        eL.append(el)\n",
    "    eL = [[min(it)] for it in eL]\n",
    "    ti_entityLabels.append(eL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_adjacencyList = []\n",
    "new_t_entityLabels = [[it[0] for it in el] for el in t_entlabWords]\n",
    "new_t_em1Text = [[it[0] for it in el] for el in t_em1Words]\n",
    "new_t_em2Text = [[it[0] for it in el] for el in t_em2Words]\n",
    "padDict = ['POI', 'RE', 'EOP']\n",
    "for i in range(len(t_sentWords)):\n",
    "    # POI means pointer\n",
    "    # RE means relation label\n",
    "    # EOP means end of pointer   \n",
    "    aL = ''\n",
    "    for j in new_t_entityLabels[i]:\n",
    "        t_dictEn = dict((b, a) for a, b in enumerate(new_t_entityLabels[i]))\n",
    "        # Exclude further \"None\" label\n",
    "        if j in cut(' '.join([it['em1Text'] for it in t_relationMentions[i] if it['label'] != 'None'])):\n",
    "            aL += j\n",
    "        tin_em1Text = [t_dictEn[item] for item in new_t_em1Text[i]]\n",
    "        tin_em2Text = [t_dictEn[item] for item in new_t_em2Text[i]]\n",
    "        new_tem1 = [m[0] for m in sorted(list(zip(tin_em1Text, tin_em2Text)))]\n",
    "        new_tem2 = [n[1] for n in sorted(list(zip(tin_em1Text, tin_em2Text)))]\n",
    "        new_tem1 = [new_t_entityLabels[i][e1] for e1 in new_tem1]\n",
    "        new_tem2 = [new_t_entityLabels[i][e2] for e2 in new_tem2]\n",
    "        t_listRe = list(zip(zip(tin_em1Text, tin_em2Text), t_relationLabels[i]))\n",
    "        new_trel = [r[-1] for r in sorted(t_listRe, key=lambda z: z[0])]\n",
    "        for item in enumerate(new_tem1):\n",
    "            if j == item[1] and new_trel[item[0]] != 'None':\n",
    "                aL = aL + ' POI ' + new_tem2[item[0]] + ' RE ' + new_trel[item[0]]\n",
    "        if j in cut(' '.join([it['em1Text'] for it in t_relationMentions[i] if it['label'] != 'None'])):\n",
    "            aL += ' EOP '\n",
    "    t_adjacencyList.append(aL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ti_adjacencyList = []\n",
    "for i in range(len(t_adjacencyList)):\n",
    "    aL = []\n",
    "    replace = dict(zip(new_t_entityLabels[i], sum(ti_entityLabels[i], [])))\n",
    "    aL = [replace[j] if j not in padDict+relationTypes else j for j in cut(t_adjacencyList[i])]\n",
    "    #aL = [s if type(s) == str else str(s) for s in aL]\n",
    "    ti_adjacencyList.append(aL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#np.max([len(i) for i in ti_adjacencyList])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all(al[1] == 'POI' for al in ti_adjacencyList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word to Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()\n",
    "sentWords = [[wnl.lemmatize(t.lower()) for t in toks] for toks in sentWords]\n",
    "t_sentWords = [[wnl.lemmatize(t.lower()) for t in toks] for toks in t_sentWords]\n",
    "tok_sentWords = sentWords.copy()\n",
    "tok_sentWords.extend(t_sentWords)\n",
    "tokTexts = [' '.join(i) for i in tok_sentWords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 63490 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(tokTexts)\n",
    "word2index = tokenizer.word_index\n",
    "index2word = {i: w for w, i in word2index.items()}\n",
    "print('Found %s unique tokens.' % len(word2index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Word Embeddings with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 63491\n",
    "EMBEDDING_SIZE = 300\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1917495"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_n_symbols = !wc -l /Users/lizhn7/Downloads/DATA/Glove/glove.42B.300d.txt\n",
    "glove_n_symbols = int(glove_n_symbols[0].split()[0])\n",
    "glove_n_symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_index_dict = {}\n",
    "glove_embedding_weights = np.empty((glove_n_symbols, EMBEDDING_SIZE))\n",
    "globale_scale = 0.1\n",
    "with open('/Users/lizhn7/Downloads/DATA/Glove/glove.42B.300d.txt', 'r') as fp:\n",
    "    index = 0\n",
    "    for l in fp:\n",
    "        l = l.strip().split()\n",
    "        word = l[0]\n",
    "        glove_index_dict[word] = index\n",
    "        glove_embedding_weights[index, :] = [float(n) for n in l[1:]]\n",
    "        index += 1\n",
    "glove_embedding_weights *= globale_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Glove to Initialize Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import PorterStemmer, LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate random embedding with same scale as glove\n",
    "np.random.seed(SEED)\n",
    "shape = (VOCAB_SIZE, EMBEDDING_SIZE)\n",
    "scale = glove_embedding_weights.std() * np.sqrt(12) / 2 \n",
    "embedding = np.random.uniform(low=-scale, high=scale, size=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60511-95.31% tokens in vocab found in glove and copied to embedding.\n"
     ]
    }
   ],
   "source": [
    "# Copy from glove weights of words that appear in index2word\n",
    "count = 0 \n",
    "for i in range(1, VOCAB_SIZE):\n",
    "    w = index2word[i]\n",
    "    g = glove_index_dict.get(w)\n",
    "    if g is None:\n",
    "        w = porter.stem(w)\n",
    "        g = glove_index_dict.get(w)\n",
    "    if g is None:\n",
    "        w = lancaster.stem(w)\n",
    "        g = glove_index_dict.get(w)\n",
    "    if g is not None:\n",
    "        embedding[i, :] = glove_embedding_weights[g, :]\n",
    "        count += 1\n",
    "print('{num_tokens}-{per:.2f}% tokens in vocab found in glove and copied to embedding.'.format(num_tokens=count, per=count/float(VOCAB_SIZE)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Dateset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_sentText = [' '.join(i) for i in sentWords]\n",
    "sentSeq = tokenizer.texts_to_sequences(new_sentText)\n",
    "sentData = pad_sequences(sentSeq, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
    "\n",
    "t_new_sentText = [' '.join(i) for i in t_sentWords]\n",
    "t_sentSeq = tokenizer.texts_to_sequences(t_new_sentText)\n",
    "t_sentData = pad_sequences(t_sentSeq, maxlen=MAX_SENT_LEN, padding='post', truncating='post')\n",
    "\n",
    "token2index = dict((j, i+120) for i, j in enumerate(['PAD']+padDict+relationTypes))\n",
    "token2index['PAD'] = 0\n",
    "index2token = {i: w for w, i in token2index.items()}\n",
    "newi_adjacencyList = [[token2index[i] if i in token2index else i+1 for i in aL] for aL in i_adjacencyList]\n",
    "newi_adjacencyList = pad_sequences(newi_adjacencyList, maxlen=MAX_ADJL_LEN, padding='post', truncating='pre')\n",
    "newti_adjacencyList = [[token2index[i] if i in token2index else i+1 for i in aL] for aL in ti_adjacencyList]\n",
    "newti_adjacencyList = pad_sequences(newti_adjacencyList, maxlen=MAX_ADJL_LEN, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#anp.max([int(i) for aL in i_adjacencyList for i in aL if i not in padDict+relationTypes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into a training set, a validation set and a test set\n",
    "x_train_all = sentData\n",
    "y_train_all = newi_adjacencyList\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, test_size=0.15, random_state=SEED)\n",
    "x_train_all, _, y_train_all, _  = train_test_split(x_train_all, y_train_all, test_size=0., random_state=SEED)\n",
    " \n",
    "x_test = t_sentData\n",
    "y_test = newti_adjacencyList\n",
    "\n",
    "x_test, _, y_test, _ = train_test_split(x_test, y_test, test_size=0., random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fh = h5py.File('/Users/lizhn7/Downloads/DATA/nyt/experiment_3_1/allData.h5', 'w')\n",
    "fh['x_train'] = x_train\n",
    "fh['y_train'] = y_train\n",
    "fh['x_val'] = x_val\n",
    "fh['y_val'] = y_val\n",
    "fh['x_train_all'] = x_train_all\n",
    "fh['y_train_all'] = y_train_all\n",
    "fh['x_test'] = x_test\n",
    "fh['y_test'] = y_test\n",
    "fh['embedding'] = embedding\n",
    "fh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/lizhn7/Downloads/DATA/nyt/experiment_3_1/index.pkl', 'wb') as fp:\n",
    "    pickle.dump((word2index, index2word, token2index, index2token), fp, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/Users/lizhn7/Downloads/DATA/nyt/experiment_3_1/allData.h5', 'r') as fh:\n",
    "    x_train = fh['x_train'][:]\n",
    "    y_train = fh['y_train'][:]\n",
    "    x_val = fh['x_val'][:]\n",
    "    y_val = fh['y_val'][:]\n",
    "    x_train_all = fh['x_train_all'][:]\n",
    "    y_train_all = fh['y_train_all'][:]\n",
    "    x_test = fh['x_test'][:]\n",
    "    y_test = fh['y_test'][:]\n",
    "    embedding = fh['embedding'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/Users/lizhn7/Downloads/DATA/nyt/experiment_3_1/index.pkl', 'rb') as fp:\n",
    "    word2index, index2word, token2index, index2token = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len([i for i in y_test if i[0] == 213])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#300-300-0.5-512-79-20-5\n",
    "MAX_SENT_LEN = 60\n",
    "MAX_ADJL_LEN = 20\n",
    "VOCAB_SIZE = 63491\n",
    "NUM_CLASSES = 148\n",
    "EMBEDDING_SIZE = 300\n",
    "\n",
    "ENC_RNN_SIZE = 300\n",
    "DEC_RNN_SIZE = 300\n",
    "DROPOUT_RATE = 0.5\n",
    "NUM_EPOCHS = 512\n",
    "BATCH_SIZE = 79\n",
    "STEPS_PER_EPOCH = 20\n",
    "TEST_STEPS = len(x_test)//BATCH_SIZE\n",
    "\n",
    "VALIDATION_STEPS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUM_EPOCHS: \t\t512\n",
      "STEPS_PER_EPOCH: \t20\n",
      "TEST_STEPS: \t\t5\n",
      "VALIDATION_STEPS: \t3\n",
      "TRAIN_BATCHES: \t\t10240\n",
      "NUM_BATCHES \t\t714\n"
     ]
    }
   ],
   "source": [
    "print('NUM_EPOCHS: \\t\\t%d' % NUM_EPOCHS)\n",
    "print('STEPS_PER_EPOCH: \\t%d' % STEPS_PER_EPOCH)\n",
    "print('TEST_STEPS: \\t\\t%d' % TEST_STEPS)\n",
    "print('VALIDATION_STEPS: \\t%d' % VALIDATION_STEPS)\n",
    "print('TRAIN_BATCHES: \\t\\t%d' % (NUM_EPOCHS * STEPS_PER_EPOCH))\n",
    "print('NUM_BATCHES \\t\\t%d' % (len(x_train)//BATCH_SIZE+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Dropout, Bidirectional, LSTM, RepeatVector, TimeDistributed, Dense\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import*\n",
    "from keras.utils import to_categorical\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "sequence = Input(shape=(MAX_SENT_LEN,), name='INPUT') \n",
    "emb_seq = Embedding(VOCAB_SIZE, EMBEDDING_SIZE, weights=[embedding], mask_zero=True, input_length=MAX_SENT_LEN, trainable=True, name='EMBEDDING')(sequence)\n",
    "emb_seq = Dropout(DROPOUT_RATE)(emb_seq)\n",
    "blstm = Bidirectional(LSTM(ENC_RNN_SIZE, return_sequences=True, implementation=0), merge_mode='concat', name='ENC_BLSTM_1')(emb_seq)\n",
    "blstm = Dropout(DROPOUT_RATE)(blstm)\n",
    "blstm = Bidirectional(LSTM(ENC_RNN_SIZE, return_sequences=False, implementation=0), merge_mode='concat', name='ENC_BLSTM_2')(blstm)\n",
    "blstm = Dropout(DROPOUT_RATE)(blstm)\n",
    "context = RepeatVector(MAX_ADJL_LEN, name='CONTEXT')(blstm)\n",
    "lstm = LSTM(DEC_RNN_SIZE, return_sequences=True, implementation=0, name='DEC_LSTM')(context)\n",
    "lstm = Dropout(DROPOUT_RATE)(lstm)\n",
    "output = TimeDistributed(Dense(NUM_CLASSES, activation='softmax'), name='OUTPUT')(lstm)\n",
    "model = Model(inputs=sequence, outputs=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "INPUT (InputLayer)           (None, 60)                0         \n",
      "_________________________________________________________________\n",
      "EMBEDDING (Embedding)        (None, 60, 300)           19047300  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 60, 300)           0         \n",
      "_________________________________________________________________\n",
      "ENC_BLSTM_1 (Bidirectional)  (None, 60, 600)           1442400   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 60, 600)           0         \n",
      "_________________________________________________________________\n",
      "ENC_BLSTM_2 (Bidirectional)  (None, 600)               2162400   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 600)               0         \n",
      "_________________________________________________________________\n",
      "CONTEXT (RepeatVector)       (None, 20, 600)           0         \n",
      "_________________________________________________________________\n",
      "DEC_LSTM (LSTM)              (None, 20, 300)           1081200   \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20, 300)           0         \n",
      "_________________________________________________________________\n",
      "OUTPUT (TimeDistributed)     (None, 20, 148)           44548     \n",
      "=================================================================\n",
      "Total params: 23,777,848\n",
      "Trainable params: 23,777,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"775pt\" viewBox=\"0.00 0.00 294.26 775.00\" width=\"294pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 771)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-771 290.2588,-771 290.2588,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 11155174512 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>11155174512</title>\n",
       "<polygon fill=\"none\" points=\"80.0762,-730.5 80.0762,-766.5 206.1826,-766.5 206.1826,-730.5 80.0762,-730.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-744.3\">INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 10484110896 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>10484110896</title>\n",
       "<polygon fill=\"none\" points=\"57.1655,-657.5 57.1655,-693.5 229.0933,-693.5 229.0933,-657.5 57.1655,-657.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-671.3\">EMBEDDING: Embedding</text>\n",
       "</g>\n",
       "<!-- 11155174512&#45;&gt;10484110896 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>11155174512-&gt;10484110896</title>\n",
       "<path d=\"M143.1294,-730.4551C143.1294,-722.3828 143.1294,-712.6764 143.1294,-703.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-703.5903 143.1294,-693.5904 139.6295,-703.5904 146.6295,-703.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4929631400 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4929631400</title>\n",
       "<polygon fill=\"none\" points=\"79.3276,-584.5 79.3276,-620.5 206.9312,-620.5 206.9312,-584.5 79.3276,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-598.3\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 10484110896&#45;&gt;4929631400 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>10484110896-&gt;4929631400</title>\n",
       "<path d=\"M143.1294,-657.4551C143.1294,-649.3828 143.1294,-639.6764 143.1294,-630.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-630.5903 143.1294,-620.5904 139.6295,-630.5904 146.6295,-630.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10472205224 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>10472205224</title>\n",
       "<polygon fill=\"none\" points=\"0,-511.5 0,-547.5 286.2588,-547.5 286.2588,-511.5 0,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-525.3\">ENC_BLSTM_1(lstm_1): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 4929631400&#45;&gt;10472205224 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>4929631400-&gt;10472205224</title>\n",
       "<path d=\"M143.1294,-584.4551C143.1294,-576.3828 143.1294,-566.6764 143.1294,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-557.5903 143.1294,-547.5904 139.6295,-557.5904 146.6295,-557.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10516679256 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>10516679256</title>\n",
       "<polygon fill=\"none\" points=\"79.3276,-438.5 79.3276,-474.5 206.9312,-474.5 206.9312,-438.5 79.3276,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-452.3\">dropout_2: Dropout</text>\n",
       "</g>\n",
       "<!-- 10472205224&#45;&gt;10516679256 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>10472205224-&gt;10516679256</title>\n",
       "<path d=\"M143.1294,-511.4551C143.1294,-503.3828 143.1294,-493.6764 143.1294,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-484.5903 143.1294,-474.5904 139.6295,-484.5904 146.6295,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10306099464 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>10306099464</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 286.2588,-401.5 286.2588,-365.5 0,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-379.3\">ENC_BLSTM_2(lstm_2): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 10516679256&#45;&gt;10306099464 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>10516679256-&gt;10306099464</title>\n",
       "<path d=\"M143.1294,-438.4551C143.1294,-430.3828 143.1294,-420.6764 143.1294,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-411.5903 143.1294,-401.5904 139.6295,-411.5904 146.6295,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10478709672 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>10478709672</title>\n",
       "<polygon fill=\"none\" points=\"79.3276,-292.5 79.3276,-328.5 206.9312,-328.5 206.9312,-292.5 79.3276,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-306.3\">dropout_3: Dropout</text>\n",
       "</g>\n",
       "<!-- 10306099464&#45;&gt;10478709672 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>10306099464-&gt;10478709672</title>\n",
       "<path d=\"M143.1294,-365.4551C143.1294,-357.3828 143.1294,-347.6764 143.1294,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-338.5903 143.1294,-328.5904 139.6295,-338.5904 146.6295,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10306302864 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>10306302864</title>\n",
       "<polygon fill=\"none\" points=\"61.4175,-219.5 61.4175,-255.5 224.8413,-255.5 224.8413,-219.5 61.4175,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-233.3\">CONTEXT: RepeatVector</text>\n",
       "</g>\n",
       "<!-- 10478709672&#45;&gt;10306302864 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>10478709672-&gt;10306302864</title>\n",
       "<path d=\"M143.1294,-292.4551C143.1294,-284.3828 143.1294,-274.6764 143.1294,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-265.5903 143.1294,-255.5904 139.6295,-265.5904 146.6295,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10523582416 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>10523582416</title>\n",
       "<polygon fill=\"none\" points=\"76.5967,-146.5 76.5967,-182.5 209.6621,-182.5 209.6621,-146.5 76.5967,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-160.3\">DEC_LSTM: LSTM</text>\n",
       "</g>\n",
       "<!-- 10306302864&#45;&gt;10523582416 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>10306302864-&gt;10523582416</title>\n",
       "<path d=\"M143.1294,-219.4551C143.1294,-211.3828 143.1294,-201.6764 143.1294,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-192.5903 143.1294,-182.5904 139.6295,-192.5904 146.6295,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10523417848 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>10523417848</title>\n",
       "<polygon fill=\"none\" points=\"79.3276,-73.5 79.3276,-109.5 206.9312,-109.5 206.9312,-73.5 79.3276,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-87.3\">dropout_4: Dropout</text>\n",
       "</g>\n",
       "<!-- 10523582416&#45;&gt;10523417848 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>10523582416-&gt;10523417848</title>\n",
       "<path d=\"M143.1294,-146.4551C143.1294,-138.3828 143.1294,-128.6764 143.1294,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-119.5903 143.1294,-109.5904 139.6295,-119.5904 146.6295,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 10529545352 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>10529545352</title>\n",
       "<polygon fill=\"none\" points=\"8.1655,-.5 8.1655,-36.5 278.0933,-36.5 278.0933,-.5 8.1655,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-14.3\">OUTPUT(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 10523417848&#45;&gt;10529545352 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>10523417848-&gt;10529545352</title>\n",
       "<path d=\"M143.1294,-73.4551C143.1294,-65.3828 143.1294,-55.6764 143.1294,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-46.5903 143.1294,-36.5904 139.6295,-46.5904 146.6295,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary()\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_label(s):\n",
    "    \"\"\"\n",
    "    One-hot encoding\n",
    "    \"\"\"\n",
    "    gen = to_categorical(s, num_classes=NUM_CLASSES)\n",
    "    return gen\n",
    "\n",
    "def data_generator_all(data, label, batch_size):\n",
    "    \"\"\"\n",
    "    Yield batches of all data\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    while True:\n",
    "        if count >= len(data): \n",
    "            count = 0\n",
    "        x = np.zeros((batch_size, MAX_SENT_LEN))\n",
    "        y = np.zeros((batch_size, MAX_ADJL_LEN, NUM_CLASSES))\n",
    "        for i in range(batch_size):\n",
    "            n = i + count\n",
    "            if n > len(data)-1:\n",
    "                break\n",
    "            x[i, :] = data[n]\n",
    "            y[i, :, :] = gen_label(label[n])\n",
    "        count += batch_size\n",
    "        yield (x, y)\n",
    "        \n",
    "def data_generator(data, label, batch_size): \n",
    "    \"\"\"\n",
    "    Yield batches \n",
    "    \"\"\"\n",
    "    index = np.arange(len(data))\n",
    "    np.random.shuffle(index)    \n",
    "    batches = [index[range(batch_size*i, min(len(data), batch_size*(i+1)))] for i in range(len(data)//batch_size)]\n",
    "    while True:\n",
    "        for i in batches:\n",
    "            x, y = data[i], np.array(list(map(gen_label, label[i])))\n",
    "            yield (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_train_all = data_generator(x_train_all, y_train_all, BATCH_SIZE)\n",
    "gen_test = data_generator_all(x_test, y_test, BATCH_SIZE)\n",
    "gen_train = data_generator(x_train, y_train, BATCH_SIZE)\n",
    "gen_val = data_generator(x_val, y_val, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continue Trian\n",
    "# filename = 'cp_logs/.hdf5'\n",
    "# model.load_weights(filename)\n",
    "# model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = '/Users/lizhn7/Downloads/DATA/nyt/experiment_3_1/cp_logs/weights.{epoch:03d}-{val_loss:.6f}.hdf5'\n",
    "log_string = '/Users/lizhn7/Downloads/DATA/nyt/experiment_3_1/tb_logs/300-300-0.5-512-79-20-5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir=log_string, \n",
    "                          histogram_freq=1, \n",
    "                          write_graph=False, \n",
    "                          write_grads=False, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          write_images=True, \n",
    "                          embeddings_freq=1, \n",
    "                          embeddings_layer_names=None,\n",
    "                          embeddings_metadata=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(gen_train_all, \n",
    "                              steps_per_epoch=STEPS_PER_EPOCH, \n",
    "                              epochs=NUM_EPOCHS, \n",
    "                              verbose=1,\n",
    "                              #callbacks=[checkpoint, tensorboard],\n",
    "                              validation_data=gen_test, \n",
    "                              validation_steps=TEST_STEPS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "filename = '/Users/lizhn7/Downloads/DATA/NYT /experiment_2_3/cp_logs/weights.095-0.797459.hdf5'\n",
    "model.load_weights(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395/395 [==============================] - 18s    \n"
     ]
    }
   ],
   "source": [
    "result = np.argmax(model.predict(x_test, batch_size=BATCH_SIZE, verbose=1), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: \t8 POI 11 RE contains EOP\n",
      "Ground Truth: \t9 POI 10 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE contains EOP\n",
      "Ground Truth: \t16 POI 14 RE country EOP\n",
      "---\n",
      "Predict: \t8 POI POI RE contains EOP RE\n",
      "Ground Truth: \t11 12 POI 13 RE nationality EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE RE EOP\n",
      "Ground Truth: \t14 POI 9 10 11 12 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t12 13 POI 15 16 RE place_lived EOP\n",
      "---\n",
      "Predict: \t8 POI 7 RE contains EOP\n",
      "Ground Truth: \t10 POI 9 RE contains EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE EOP EOP\n",
      "Ground Truth: \t8 9 POI 1 2 3 RE founders EOP\n",
      "---\n",
      "Predict: \t13 POI POI RE contains EOP\n",
      "Ground Truth: \t20 POI 16 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE contains EOP\n",
      "Ground Truth: \t19 POI 13 RE country POI 13 RE country EOP 19 POI 13 RE country POI 13 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE contains EOP\n",
      "Ground Truth: \t17 POI 6 RE contains EOP\n",
      "---\n",
      "Predict: \t17 POI POI POI RE RE RE EOP\n",
      "Ground Truth: \t26 27 POI 29 30 RE company EOP\n",
      "---\n",
      "Predict: \t10 POI POI RE contains EOP\n",
      "Ground Truth: \t12 POI 11 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI 7 RE contains EOP\n",
      "Ground Truth: \t2 POI 7 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t15 16 POI 18 19 RE place_lived EOP\n",
      "---\n",
      "Predict: \t1 2 POI 7 RE RE EOP\n",
      "Ground Truth: \t3 4 POI 6 RE place_lived EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE contains EOP\n",
      "Ground Truth: \t4 POI 16 RE country EOP\n",
      "---\n",
      "Predict: \t16 POI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t23 24 POI 26 RE company EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE RE EOP\n",
      "Ground Truth: \t4 POI 6 RE country EOP\n",
      "---\n",
      "Predict: \t17 POI POI RE RE contains EOP POI RE RE POI POI\n",
      "Ground Truth: \t20 POI 21 22 RE country EOP\n",
      "---\n",
      "Predict: \t29 POI POI POI POI RE RE EOP\n",
      "Ground Truth: \t28 29 30 POI 37 38 39 RE company EOP\n",
      "---\n",
      "Predict: \t8 POI POI RE RE contains EOP\n",
      "Ground Truth: \t13 14 POI 16 RE nationality EOP\n",
      "---\n",
      "Predict: \t12 POI POI POI RE RE RE EOP\n",
      "Ground Truth: \t9 10 11 POI 15 16 RE company EOP\n",
      "---\n",
      "Predict: \t12 POI POI POI RE RE RE EOP\n",
      "Ground Truth: \t20 POI 12 13 14 RE founders EOP\n",
      "---\n",
      "Predict: \t2 2 POI 5 RE contains EOP\n",
      "Ground Truth: \t2 3 POI 5 RE place_lived EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t20 POI 31 32 RE contains EOP\n",
      "---\n",
      "Predict: \t13 POI POI RE contains EOP\n",
      "Ground Truth: \t18 POI 13 RE country EOP\n",
      "---\n",
      "Predict: \t11 POI POI RE contains EOP POI RE RE\n",
      "Ground Truth: \t14 POI 34 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t8 9 POI 15 RE place_lived EOP\n",
      "---\n",
      "Predict: \t12 POI POI POI RE RE contains EOP\n",
      "Ground Truth: \t6 7 POI 15 16 17 18 RE company EOP\n",
      "---\n",
      "Predict: \t1 POI POI 7 RE contains EOP\n",
      "Ground Truth: \t29 30 POI 1 RE country EOP\n",
      "---\n",
      "Predict: \t16 POI POI POI RE contains EOP\n",
      "Ground Truth: \t18 POI 16 RE contains EOP\n",
      "---\n",
      "Predict: \t16 POI POI POI RE contains EOP\n",
      "Ground Truth: \t21 22 POI 17 RE nationality EOP\n",
      "---\n",
      "Predict: \t28 POI POI RE RE contains EOP\n",
      "Ground Truth: \t30 POI 34 35 36 37 RE country EOP\n",
      "---\n",
      "Predict: \t9 POI POI RE RE contains EOP\n",
      "Ground Truth: \t11 12 POI 17 18 19 20 RE company EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE contains EOP\n",
      "Ground Truth: \t26 POI 24 25 RE contains EOP\n",
      "---\n",
      "Predict: \t33 POI POI POI RE contains EOP\n",
      "Ground Truth: \t38 39 POI 43 44 45 46 RE company EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE EOP EOP\n",
      "Ground Truth: \t8 9 POI 15 RE company EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t14 POI 12 13 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI POI RE RE contains EOP\n",
      "Ground Truth: \t29 POI 34 RE contains POI 34 RE contains EOP 29 POI 34 RE contains POI 34 RE contains EOP\n",
      "---\n",
      "Predict: \t6 POI POI RE country EOP POI POI RE POI\n",
      "Ground Truth: \t15 16 POI 14 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP\n",
      "Ground Truth: \t29 POI 31 RE country EOP\n",
      "---\n",
      "Predict: \t2 2 POI 7 RE contains EOP\n",
      "Ground Truth: \t3 4 POI 6 RE place_lived EOP\n",
      "---\n",
      "Predict: \t13 POI POI RE contains EOP\n",
      "Ground Truth: \t19 POI 21 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t42 POI 31 RE country EOP\n",
      "---\n",
      "Predict: \t28 POI POI POI RE contains EOP\n",
      "Ground Truth: \t38 39 POI 43 44 RE place_of_birth EOP\n",
      "---\n",
      "Predict: \t1 POI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t38 39 POI 41 RE nationality EOP\n",
      "---\n",
      "Predict: \t16 POI POI POI RE contains EOP\n",
      "Ground Truth: \t16 17 18 19 POI 21 RE nationality EOP\n",
      "---\n",
      "Predict: \t17 POI POI RE contains EOP\n",
      "Ground Truth: \t28 POI 30 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI POI 5 RE contains EOP\n",
      "Ground Truth: \t3 4 POI 7 RE place_lived EOP\n",
      "---\n",
      "Predict: \t12 POI POI POI RE RE RE EOP\n",
      "Ground Truth: \t17 18 19 POI 11 12 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI 7 RE contains EOP\n",
      "Ground Truth: \t10 11 POI 14 RE place_lived EOP\n",
      "---\n",
      "Predict: \t12 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t11 POI 21 RE country EOP\n",
      "---\n",
      "Predict: \t24 POI POI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t21 22 23 24 POI 16 17 RE company POI 16 17 RE company EOP\n",
      "---\n",
      "Predict: \t6 POI POI RE contains EOP\n",
      "Ground Truth: \t5 POI 8 9 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE RE EOP\n",
      "Ground Truth: \t12 POI 7 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE contains EOP POI RE RE\n",
      "Ground Truth: \t6 POI 7 RE country EOP\n",
      "---\n",
      "Predict: \t8 POI POI RE contains EOP\n",
      "Ground Truth: \t7 POI 6 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI 7 RE contains EOP\n",
      "Ground Truth: \t8 POI 10 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE contains EOP\n",
      "Ground Truth: \t14 POI 22 RE country EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE RE EOP EOP POI RE\n",
      "Ground Truth: \t37 38 POI 34 35 RE contains EOP\n",
      "---\n",
      "Predict: \t1 8 POI POI RE RE neighborhood_of EOP POI\n",
      "Ground Truth: \t11 12 POI 7 8 RE contains EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE RE EOP EOP\n",
      "Ground Truth: \t38 POI 39 RE country EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE EOP EOP\n",
      "Ground Truth: \t1 2 POI 9 RE company EOP\n",
      "---\n",
      "Predict: \t1 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t13 POI 10 11 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t14 15 POI 18 RE place_lived EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE\n",
      "Ground Truth: \t29 POI 27 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI 7 RE RE EOP\n",
      "Ground Truth: \t8 POI 5 6 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI POI RE RE RE EOP\n",
      "Ground Truth: \t5 6 POI 8 9 RE company EOP\n",
      "---\n",
      "Predict: \t6 POI POI RE contains EOP\n",
      "Ground Truth: \t8 POI 6 RE contains EOP\n",
      "---\n",
      "Predict: \t13 POI POI RE RE contains EOP\n",
      "Ground Truth: \t18 POI 16 17 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI POI RE RE contains EOP\n",
      "Ground Truth: \t9 POI 13 RE country EOP\n",
      "---\n",
      "Predict: \t15 POI POI 15 RE RE EOP EOP\n",
      "Ground Truth: \t18 POI 14 15 16 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE contains EOP\n",
      "Ground Truth: \t4 5 POI 15 RE place_lived EOP\n",
      "---\n",
      "Predict: \t12 POI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t10 11 POI 19 RE company EOP\n",
      "---\n",
      "Predict: \t12 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t17 18 POI 20 RE place_lived EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE RE contains EOP\n",
      "Ground Truth: \t19 20 POI 14 RE nationality EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE RE contains EOP\n",
      "Ground Truth: \t19 20 POI 7 RE nationality EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE RE EOP\n",
      "Ground Truth: \t32 POI 35 RE contains EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE EOP EOP\n",
      "Ground Truth: \t19 POI 1 2 3 RE contains EOP\n",
      "---\n",
      "Predict: \t24 POI POI POI RE contains EOP\n",
      "Ground Truth: \t31 POI 33 34 RE country EOP\n",
      "---\n",
      "Predict: \t9 POI POI RE contains EOP POI RE\n",
      "Ground Truth: \t13 POI 12 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI 7 RE contains EOP\n",
      "Ground Truth: \t9 POI 30 RE country EOP\n",
      "---\n",
      "Predict: \t8 POI POI 11 RE RE EOP\n",
      "Ground Truth: \t8 POI 11 12 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE RE POI\n",
      "Ground Truth: \t12 POI 25 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t9 10 POI 12 RE place_lived EOP\n",
      "---\n",
      "Predict: \t10 POI POI RE RE contains EOP\n",
      "Ground Truth: \t12 POI 10 11 RE contains EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI 7 RE RE EOP\n",
      "Ground Truth: \t1 2 3 POI 8 9 RE company EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t27 POI 18 RE country EOP\n",
      "---\n",
      "Predict: \t33 POI POI POI RE RE contains EOP\n",
      "Ground Truth: \t39 POI 40 41 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE contains EOP\n",
      "Ground Truth: \t36 POI 33 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI 11 RE RE EOP\n",
      "Ground Truth: \t13 14 POI 4 5 6 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t12 POI 1 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t6 POI 10 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t2 3 POI 5 RE place_lived EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE RE contains EOP POI\n",
      "Ground Truth: \t12 13 POI 8 9 10 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t17 POI 34 35 RE country EOP\n",
      "---\n",
      "Predict: \t1 2 POI 7 RE contains EOP\n",
      "Ground Truth: \t5 6 POI 8 RE nationality EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE RE contains EOP\n",
      "Ground Truth: \t29 POI 23 24 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t10 POI 9 RE contains EOP 10 POI 9 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP\n",
      "Ground Truth: \t51 POI 49 RE contains EOP\n",
      "---\n",
      "Predict: \t11 POI 11 RE contains EOP\n",
      "Ground Truth: \t11 POI 10 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI 11 RE RE EOP\n",
      "Ground Truth: \t9 10 POI 1 RE contains EOP\n",
      "---\n",
      "Predict: \t29 POI POI RE RE contains EOP\n",
      "Ground Truth: \t49 POI 47 48 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP\n",
      "Ground Truth: \t40 POI 14 RE country EOP\n",
      "---\n",
      "Predict: \t16 POI POI RE contains EOP\n",
      "Ground Truth: \t18 POI 26 RE country EOP\n",
      "---\n",
      "Predict: \t15 POI POI POI RE RE contains EOP POI RE\n",
      "Ground Truth: \t15 16 POI 26 RE company EOP\n",
      "---\n",
      "Predict: \t12 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t12 13 POI 11 RE nationality POI 11 RE nationality EOP\n",
      "---\n",
      "Predict: \t1 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t7 8 POI 13 RE place_lived EOP\n",
      "---\n",
      "Predict: \t1 2 POI 11 RE contains EOP\n",
      "Ground Truth: \t7 8 POI 13 RE nationality EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE RE EOP EOP\n",
      "Ground Truth: \t5 6 POI 8 RE place_lived EOP\n",
      "---\n",
      "Predict: \t1 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t8 POI 10 11 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE contains EOP POI RE\n",
      "Ground Truth: \t9 POI 5 RE administrative_divisions EOP\n",
      "---\n",
      "Predict: \t24 POI POI POI RE RE EOP\n",
      "Ground Truth: \t29 POI 27 28 RE contains EOP\n",
      "---\n",
      "Predict: \t11 POI POI RE contains EOP POI RE RE POI POI\n",
      "Ground Truth: \t17 POI 12 RE country EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE\n",
      "Ground Truth: \t29 POI 31 RE contains EOP\n",
      "---\n",
      "Predict: \t11 POI POI RE contains EOP POI RE\n",
      "Ground Truth: \t17 POI 20 RE country EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE contains EOP\n",
      "Ground Truth: \t38 POI 24 25 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t30 POI 28 29 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI POI RE contains EOP\n",
      "Ground Truth: \t11 POI 13 RE country EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP\n",
      "Ground Truth: \t38 POI 19 RE country EOP\n",
      "---\n",
      "Predict: \t28 POI POI POI RE RE EOP\n",
      "Ground Truth: \t37 POI 34 35 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE RE EOP\n",
      "Ground Truth: \t23 POI 20 21 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t29 POI 34 35 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP\n",
      "Ground Truth: \t41 POI 40 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI POI RE contains EOP\n",
      "Ground Truth: \t29 POI 26 RE contains EOP\n",
      "---\n",
      "Predict: \t17 POI POI POI RE RE EOP EOP POI RE RE RE\n",
      "Ground Truth: \t23 24 POI 20 21 RE contains EOP\n",
      "---\n",
      "Predict: \t9 POI POI RE RE contains EOP\n",
      "Ground Truth: \t11 POI 10 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE RE contains EOP\n",
      "Ground Truth: \t13 14 POI 19 RE place_lived EOP\n",
      "---\n",
      "Predict: \t14 POI POI RE contains EOP POI RE RE\n",
      "Ground Truth: \t17 POI 20 RE administrative_divisions EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE EOP EOP\n",
      "Ground Truth: \t1 2 POI 33 RE place_of_death EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE RE EOP POI RE\n",
      "Ground Truth: \t21 POI 7 RE contains POI 7 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP RE\n",
      "Ground Truth: \t20 POI 4 RE country POI 4 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE RE contains EOP\n",
      "Ground Truth: \t13 POI 10 11 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI POI RE RE contains EOP\n",
      "Ground Truth: \t6 7 POI 9 RE nationality EOP\n",
      "---\n",
      "Predict: \t24 POI POI POI RE RE EOP\n",
      "Ground Truth: \t22 23 POI 30 RE company EOP\n",
      "---\n",
      "Predict: \t13 POI POI RE contains EOP\n",
      "Ground Truth: \t13 POI 2 RE contains EOP\n",
      "---\n",
      "Predict: \t9 POI POI RE RE EOP POI POI RE\n",
      "Ground Truth: \t7 8 POI 13 RE contains EOP\n",
      "---\n",
      "Predict: \t25 POI POI POI RE RE RE EOP EOP\n",
      "Ground Truth: \t33 34 POI 30 31 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI POI RE contains EOP POI RE RE POI\n",
      "Ground Truth: \t10 POI 11 RE country EOP\n",
      "---\n",
      "Predict: \t10 POI POI RE RE EOP EOP\n",
      "Ground Truth: \t6 7 POI 6 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t11 12 POI 20 RE nationality EOP\n",
      "---\n",
      "Predict: \t2 POI 7 RE contains EOP\n",
      "Ground Truth: \t6 POI 5 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE contains EOP\n",
      "Ground Truth: \t21 27 POI 29 RE place_lived EOP\n",
      "---\n",
      "Predict: \t9 POI POI RE contains EOP POI RE RE\n",
      "Ground Truth: \t14 POI 12 RE country EOP 14 POI 12 RE country EOP\n",
      "---\n",
      "Predict: \t8 POI POI RE contains EOP\n",
      "Ground Truth: \t10 POI 6 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI POI POI RE RE contains EOP\n",
      "Ground Truth: \t1 2 POI 7 8 RE company EOP\n",
      "---\n",
      "Predict: \t1 POI POI POI RE RE EOP\n",
      "Ground Truth: \t12 POI 4 5 6 7 8 RE contains EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE EOP EOP\n",
      "Ground Truth: \t5 6 POI 11 12 RE company EOP\n",
      "---\n",
      "Predict: \t12 POI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t16 POI 12 13 14 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t21 POI 33 RE administrative_divisions EOP\n",
      "---\n",
      "Predict: \t1 POI POI POI RE contains EOP\n",
      "Ground Truth: \t18 19 POI 16 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP\n",
      "Ground Truth: \t35 POI 33 RE country EOP\n",
      "---\n",
      "Predict: \t16 POI POI RE RE contains EOP\n",
      "Ground Truth: \t10 11 POI 16 RE place_lived EOP\n",
      "---\n",
      "Predict: \t6 POI 7 RE contains EOP\n",
      "Ground Truth: \t5 12 POI 5 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI 7 RE contains EOP\n",
      "Ground Truth: \t6 POI 5 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI POI RE contains EOP\n",
      "Ground Truth: \t1 2 POI 24 RE place_of_death EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t8 POI 6 7 RE contains EOP\n",
      "---\n",
      "Predict: \t9 POI POI RE RE EOP EOP POI RE\n",
      "Ground Truth: \t18 POI 41 RE country EOP\n",
      "---\n",
      "Predict: \t8 POI 7 RE contains EOP\n",
      "Ground Truth: \t9 POI 8 RE contains EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE RE EOP EOP\n",
      "Ground Truth: \t4 5 6 POI 11 12 RE company EOP\n",
      "---\n",
      "Predict: \t16 POI POI RE RE EOP EOP\n",
      "Ground Truth: \t13 POI 12 RE contains EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE contains EOP\n",
      "Ground Truth: \t19 20 POI 22 RE place_lived EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t29 30 POI 26 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE RE contains EOP POI RE RE POI\n",
      "Ground Truth: \t16 POI 17 18 RE country EOP\n",
      "---\n",
      "Predict: \t11 POI POI RE contains EOP POI RE\n",
      "Ground Truth: \t20 POI 19 RE contains EOP\n",
      "---\n",
      "Predict: \t11 POI POI RE contains EOP POI RE\n",
      "Ground Truth: \t20 POI 19 RE contains EOP\n",
      "---\n",
      "Predict: \t9 POI POI RE contains EOP\n",
      "Ground Truth: \t14 POI 13 RE contains EOP\n",
      "---\n",
      "Predict: \t28 POI POI POI RE RE contains EOP\n",
      "Ground Truth: \t47 48 49 POI 42 43 44 RE founders EOP\n",
      "---\n",
      "Predict: \t1 POI POI POI RE contains EOP\n",
      "Ground Truth: \t46 POI 38 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE contains EOP\n",
      "Ground Truth: \t6 POI 12 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t24 POI 44 RE country EOP\n",
      "---\n",
      "Predict: \t15 POI POI POI RE neighborhood_of EOP POI POI POI POI POI\n",
      "Ground Truth: \t19 20 POI 10 11 12 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE RE EOP\n",
      "Ground Truth: \t6 7 POI 4 RE contains EOP\n",
      "---\n",
      "Predict: \t2 2 POI 5 RE contains EOP\n",
      "Ground Truth: \t2 3 POI 6 RE place_lived EOP\n",
      "---\n",
      "Predict: \t24 POI POI RE RE EOP\n",
      "Ground Truth: \t3 POI 30 RE country EOP\n",
      "---\n",
      "Predict: \t8 POI POI RE contains EOP\n",
      "Ground Truth: \t11 POI 6 7 8 9 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE contains EOP RE\n",
      "Ground Truth: \t12 POI 7 RE country EOP\n",
      "---\n",
      "Predict: \t20 POI POI RE contains EOP EOP\n",
      "Ground Truth: \t24 POI 23 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI POI RE RE contains EOP POI\n",
      "Ground Truth: \t19 20 POI 3 4 24 RE neighborhood_of EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE RE\n",
      "Ground Truth: \t36 POI 42 RE country EOP\n",
      "---\n",
      "Predict: \t16 POI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t20 21 POI 17 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI POI RE contains EOP\n",
      "Ground Truth: \t13 14 POI 9 10 11 12 RE company EOP\n",
      "---\n",
      "Predict: \t13 POI POI RE contains EOP\n",
      "Ground Truth: \t14 POI 13 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE contains EOP\n",
      "Ground Truth: \t23 24 POI 26 RE place_lived EOP\n",
      "---\n",
      "Predict: \t2 2 POI 5 RE contains EOP\n",
      "Ground Truth: \t2 3 POI 6 RE place_lived EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t28 29 POI 31 RE place_lived EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE RE EOP POI RE RE POI\n",
      "Ground Truth: \t28 POI 6 RE country EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP\n",
      "Ground Truth: \t2 POI 25 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t13 14 POI 6 RE place_lived EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE contains EOP\n",
      "Ground Truth: \t24 POI 22 23 RE contains EOP\n",
      "---\n",
      "Predict: \t28 POI POI POI RE contains EOP\n",
      "Ground Truth: \t38 39 POI 41 RE place_lived EOP\n",
      "---\n",
      "Predict: \t24 POI POI POI RE RE RE EOP\n",
      "Ground Truth: \t30 31 32 POI 34 35 RE contains EOP\n",
      "---\n",
      "Predict: \t17 POI POI RE RE contains EOP\n",
      "Ground Truth: \t13 14 POI 16 RE place_lived EOP\n",
      "---\n",
      "Predict: \t29 POI POI POI RE contains EOP\n",
      "Ground Truth: \t16 POI 27 28 RE country EOP\n",
      "---\n",
      "Predict: \t17 POI POI RE RE contains EOP\n",
      "Ground Truth: \t20 21 POI 23 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE RE EOP\n",
      "Ground Truth: \t3 POI 10 RE country EOP\n",
      "---\n",
      "Predict: \t8 POI POI RE RE contains EOP\n",
      "Ground Truth: \t12 POI 9 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE RE EOP EOP\n",
      "Ground Truth: \t11 POI 19 RE country EOP\n",
      "---\n",
      "Predict: \t9 POI POI RE country EOP POI RE RE POI\n",
      "Ground Truth: \t9 POI 7 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE contains EOP\n",
      "Ground Truth: \t18 POI 24 RE country EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE RE EOP\n",
      "Ground Truth: \t27 POI 120 RE country EOP 27 POI 120 RE country EOP 27 POI 120 RE country EOP\n",
      "---\n",
      "Predict: \t20 POI POI RE RE RE EOP\n",
      "Ground Truth: \t26 POI 22 23 24 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE RE\n",
      "Ground Truth: \t29 POI 24 RE country EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE RE\n",
      "Ground Truth: \t30 POI 28 29 RE contains EOP\n",
      "---\n",
      "Predict: \t28 POI POI POI RE contains EOP\n",
      "Ground Truth: \t32 33 POI 34 RE nationality EOP\n",
      "---\n",
      "Predict: \t15 POI POI RE contains EOP\n",
      "Ground Truth: \t17 POI 21 RE country EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE RE contains EOP\n",
      "Ground Truth: \t23 24 POI 20 21 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE RE EOP POI RE RE\n",
      "Ground Truth: \t1 2 POI 6 RE nationality EOP\n",
      "---\n",
      "Predict: \t2 POI 7 RE contains EOP\n",
      "Ground Truth: \t6 POI 5 RE contains EOP\n",
      "---\n",
      "Predict: \t11 POI POI RE contains EOP POI RE RE\n",
      "Ground Truth: \t34 POI 14 RE contains EOP\n",
      "---\n",
      "Predict: \t24 POI POI POI RE contains EOP\n",
      "Ground Truth: \t33 34 POI 29 RE nationality EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE RE POI\n",
      "Ground Truth: \t32 POI 13 RE country POI 13 RE country EOP\n",
      "---\n",
      "Predict: \t2 2 POI 5 RE RE EOP\n",
      "Ground Truth: \t1 2 POI 4 RE contains EOP\n",
      "---\n",
      "Predict: \t13 POI POI RE contains EOP\n",
      "Ground Truth: \t17 POI 15 16 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE RE\n",
      "Ground Truth: \t23 POI 22 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE RE POI\n",
      "Ground Truth: \t13 POI 13 23 RE contains EOP\n",
      "---\n",
      "Predict: \t10 POI 11 RE contains EOP\n",
      "Ground Truth: \t13 POI 14 RE country EOP\n",
      "---\n",
      "Predict: \tPOI POI POI POI RE contains EOP\n",
      "Ground Truth: \t18 POI 36 37 RE country EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t39 POI 33 34 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE RE contains EOP\n",
      "Ground Truth: \t11 12 POI 14 RE nationality EOP\n",
      "---\n",
      "Predict: \t20 POI POI RE contains EOP\n",
      "Ground Truth: \t24 POI 23 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE contains EOP\n",
      "Ground Truth: \t17 POI 27 28 RE country EOP\n",
      "---\n",
      "Predict: \t13 POI POI 13 RE contains EOP\n",
      "Ground Truth: \t12 13 POI 16 RE place_lived EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE RE\n",
      "Ground Truth: \t26 POI 28 RE contains EOP\n",
      "---\n",
      "Predict: \t28 POI POI POI RE contains EOP\n",
      "Ground Truth: \t45 46 POI 42 RE nationality EOP\n",
      "---\n",
      "Predict: \t1 POI POI 7 RE contains EOP\n",
      "Ground Truth: \t5 POI 8 9 RE contains EOP\n",
      "---\n",
      "Predict: \t2 2 POI 7 RE contains EOP\n",
      "Ground Truth: \t9 POI 3 4 RE country EOP\n",
      "---\n",
      "Predict: \t28 POI POI POI RE contains EOP\n",
      "Ground Truth: \t1 POI 37 38 RE founders POI 37 38 RE founders EOP 1 POI 37 38 RE founders POI 37 38 RE founders EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE contains EOP\n",
      "Ground Truth: \t25 26 POI 28 RE nationality EOP\n",
      "---\n",
      "Predict: \t10 POI 11 RE contains EOP\n",
      "Ground Truth: \t13 POI 14 RE country EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE\n",
      "Ground Truth: \t31 POI 28 RE contains EOP\n",
      "---\n",
      "Predict: \t13 POI POI RE RE contains EOP\n",
      "Ground Truth: \t16 POI 14 15 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE RE RE EOP\n",
      "Ground Truth: \t30 POI 29 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE RE EOP\n",
      "Ground Truth: \t10 11 12 POI 22 23 24 RE company EOP\n",
      "---\n",
      "Predict: \t13 POI POI POI RE RE EOP\n",
      "Ground Truth: \t15 POI 17 18 RE contains EOP\n",
      "---\n",
      "Predict: \t13 POI POI RE contains EOP\n",
      "Ground Truth: \t19 POI 17 RE contains EOP\n",
      "---\n",
      "Predict: \t1 2 POI 7 RE contains EOP\n",
      "Ground Truth: \t6 7 POI 8 RE place_lived EOP\n",
      "---\n",
      "Predict: \t8 POI 7 RE contains EOP\n",
      "Ground Truth: \t10 POI 9 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI 5 RE contains EOP\n",
      "Ground Truth: \t4 POI 2 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI POI 13 RE RE EOP\n",
      "Ground Truth: \t12 13 POI 16 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI POI RE RE contains EOP EOP\n",
      "Ground Truth: \t19 20 POI 17 18 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t3 4 POI 3 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t2 3 POI 5 RE place_lived EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE RE EOP EOP\n",
      "Ground Truth: \t18 19 POI 3 RE company EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE RE EOP POI RE\n",
      "Ground Truth: \t31 POI 10 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t5 POI 6 RE country EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE contains EOP\n",
      "Ground Truth: \t3 4 POI 6 RE nationality EOP\n",
      "---\n",
      "Predict: \t9 POI POI RE contains EOP\n",
      "Ground Truth: \t13 POI 12 RE contains EOP\n",
      "---\n",
      "Predict: \t24 POI POI POI RE RE EOP\n",
      "Ground Truth: \t32 33 POI 39 40 41 42 RE company EOP\n",
      "---\n",
      "Predict: \t12 POI POI POI RE RE RE EOP\n",
      "Ground Truth: \t10 11 12 POI 18 19 RE company EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE RE\n",
      "Ground Truth: \t17 POI 24 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t13 14 POI 17 RE place_lived EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE contains EOP POI RE\n",
      "Ground Truth: \t6 POI 5 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI POI RE contains EOP\n",
      "Ground Truth: \t14 POI 13 RE contains EOP\n",
      "---\n",
      "Predict: \t1 2 POI 7 RE contains EOP\n",
      "Ground Truth: \t8 9 POI 11 RE place_lived EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t1 POI 22 23 RE country EOP 1 POI 22 23 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI POI POI RE RE RE EOP\n",
      "Ground Truth: \t30 POI 9 10 11 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE RE EOP\n",
      "Ground Truth: \t32 POI 11 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI 7 RE contains EOP\n",
      "Ground Truth: \t4 POI 3 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP\n",
      "Ground Truth: \t79 POI 47 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t1 2 POI 4 RE nationality EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI 7 RE RE EOP\n",
      "Ground Truth: \t1 2 POI 11 12 13 RE company EOP\n",
      "---\n",
      "Predict: \t13 POI POI RE contains EOP\n",
      "Ground Truth: \t15 POI 16 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE contains EOP POI RE\n",
      "Ground Truth: \t3 POI 13 14 15 RE contains POI 13 14 15 RE contains EOP 3 POI 13 14 15 RE contains POI 13 14 15 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE EOP\n",
      "Ground Truth: \t13 POI 12 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP\n",
      "Ground Truth: \t31 POI 8 RE capital EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t54 POI 45 RE contains EOP\n",
      "---\n",
      "Predict: \t33 POI POI POI RE RE EOP\n",
      "Ground Truth: \t42 POI 40 41 RE contains EOP\n",
      "---\n",
      "Predict: \t12 12 POI POI RE RE EOP EOP\n",
      "Ground Truth: \t10 11 12 POI 16 17 18 RE company EOP\n",
      "---\n",
      "Predict: \t6 POI 7 RE contains EOP RE\n",
      "Ground Truth: \t5 POI 6 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t5 6 POI 9 RE place_lived EOP\n",
      "---\n",
      "Predict: \t2 POI 7 RE contains EOP\n",
      "Ground Truth: \t5 POI 4 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t23 24 POI 29 30 31 RE company EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE RE EOP POI POI\n",
      "Ground Truth: \t10 11 POI 7 8 9 RE contains EOP\n",
      "---\n",
      "Predict: \t24 POI POI POI RE RE contains EOP\n",
      "Ground Truth: \t36 37 38 POI 37 38 RE children EOP\n",
      "---\n",
      "Predict: \t17 POI POI RE RE contains EOP\n",
      "Ground Truth: \t23 POI 22 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE RE POI POI RE\n",
      "Ground Truth: \t23 POI 8 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE contains EOP RE\n",
      "Ground Truth: \t5 POI 4 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI POI RE RE RE EOP\n",
      "Ground Truth: \t17 18 19 POI 15 15 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE contains EOP\n",
      "Ground Truth: \t20 POI 2 RE country EOP\n",
      "---\n",
      "Predict: \t8 POI POI RE contains EOP\n",
      "Ground Truth: \t8 POI 7 RE contains EOP\n",
      "---\n",
      "Predict: \t11 POI POI RE contains EOP POI RE RE POI POI\n",
      "Ground Truth: \t16 POI 11 RE country EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP\n",
      "Ground Truth: \t34 POI 36 RE country EOP\n",
      "---\n",
      "Predict: \t15 POI POI RE contains EOP\n",
      "Ground Truth: \t21 POI 20 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t11 12 POI 6 RE nationality EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP RE\n",
      "Ground Truth: \t33 POI 19 30 31 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI 7 RE contains EOP\n",
      "Ground Truth: \t6 POI 12 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE RE\n",
      "Ground Truth: \t7 POI 21 RE country POI 21 RE country EOP 7 POI 21 RE country POI 21 RE country EOP\n",
      "---\n",
      "Predict: \t16 POI POI RE contains EOP\n",
      "Ground Truth: \t23 POI 22 RE contains EOP\n",
      "---\n",
      "Predict: \t24 POI POI POI RE RE EOP\n",
      "Ground Truth: \t34 POI 30 31 32 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t34 POI 31 32 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE RE contains EOP\n",
      "Ground Truth: \t4 5 POI 7 RE nationality EOP\n",
      "---\n",
      "Predict: \t10 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t14 15 POI 17 RE nationality EOP\n",
      "---\n",
      "Predict: \t8 POI POI RE contains EOP POI RE RE\n",
      "Ground Truth: \t8 POI 21 RE country EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE company EOP\n",
      "Ground Truth: \t1 2 3 POI 10 RE company EOP\n",
      "---\n",
      "Predict: \t6 POI POI RE contains EOP\n",
      "Ground Truth: \t11 POI 6 7 8 9 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE\n",
      "Ground Truth: \t44 POI 19 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t11 12 POI 15 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE RE EOP\n",
      "Ground Truth: \t36 POI 9 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t1 2 POI 3 4 RE company EOP\n",
      "---\n",
      "Predict: \t24 POI POI POI RE contains EOP\n",
      "Ground Truth: \t23 POI 29 30 RE country EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE contains EOP\n",
      "Ground Truth: \t9 POI 6 7 RE contains EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE EOP EOP\n",
      "Ground Truth: \t2 3 POI 6 7 8 RE company EOP\n",
      "---\n",
      "Predict: \t24 POI POI POI RE RE contains EOP\n",
      "Ground Truth: \t30 POI 26 27 28 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI POI RE contains EOP\n",
      "Ground Truth: \t8 POI 7 RE contains EOP\n",
      "---\n",
      "Predict: \t15 POI POI RE RE contains EOP\n",
      "Ground Truth: \t16 POI 13 14 RE contains EOP\n",
      "---\n",
      "Predict: \t15 POI POI RE contains EOP\n",
      "Ground Truth: \t19 20 POI 15 RE contains EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE RE EOP EOP\n",
      "Ground Truth: \t3 4 5 POI 28 29 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t36 37 38 POI 41 42 RE company EOP\n",
      "---\n",
      "Predict: \t8 POI POI RE contains EOP\n",
      "Ground Truth: \t11 POI 10 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI 7 RE contains EOP\n",
      "Ground Truth: \t10 POI 7 8 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t16 POI 11 12 13 14 RE contains EOP\n",
      "---\n",
      "Predict: \t24 POI POI POI RE contains EOP\n",
      "Ground Truth: \t41 POI 35 36 37 38 39 RE contains EOP\n",
      "---\n",
      "Predict: \t11 POI POI RE contains EOP POI RE\n",
      "Ground Truth: \t15 POI 16 RE country EOP\n",
      "---\n",
      "Predict: \t11 POI POI RE country EOP POI RE RE POI POI\n",
      "Ground Truth: \t21 POI 15 RE country POI 15 RE country EOP\n",
      "---\n",
      "Predict: \t17 POI POI RE RE contains EOP\n",
      "Ground Truth: \t27 POI 20 RE country EOP\n",
      "---\n",
      "Predict: \t16 POI POI POI 15 RE RE EOP EOP\n",
      "Ground Truth: \t11 12 POI 18 19 20 RE company EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE RE contains EOP\n",
      "Ground Truth: \t18 POI 17 RE contains EOP\n",
      "---\n",
      "Predict: \t13 POI POI RE RE contains EOP\n",
      "Ground Truth: \t21 POI 11 12 13 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t29 POI 1 27 RE contains EOP\n",
      "---\n",
      "Predict: \t17 POI POI POI RE contains EOP\n",
      "Ground Truth: \t21 POI 19 20 RE contains EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE contains EOP\n",
      "Ground Truth: \t27 POI 21 22 23 24 25 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE RE contains EOP\n",
      "Ground Truth: \t7 POI 5 6 RE contains EOP\n",
      "---\n",
      "Predict: \t6 POI 7 RE contains EOP\n",
      "Ground Truth: \t10 POI 4 RE country EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE EOP\n",
      "Ground Truth: \t1 2 POI 4 RE company EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE RE EOP\n",
      "Ground Truth: \t44 POI 42 43 RE contains EOP\n",
      "---\n",
      "Predict: \t2 2 POI 5 RE contains EOP\n",
      "Ground Truth: \t2 3 POI 5 RE place_lived EOP\n",
      "---\n",
      "Predict: \t20 POI POI RE RE contains EOP\n",
      "Ground Truth: \t27 POI 24 25 26 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE RE contains EOP POI RE RE POI\n",
      "Ground Truth: \t19 POI 20 21 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE RE contains EOP\n",
      "Ground Truth: \t7 POI 5 6 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE RE contains EOP\n",
      "Ground Truth: \t27 POI 24 25 RE contains EOP\n",
      "---\n",
      "Predict: \t10 POI POI RE contains EOP\n",
      "Ground Truth: \t13 POI 12 RE contains EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE EOP EOP\n",
      "Ground Truth: \t22 POI 19 20 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP\n",
      "Ground Truth: \t28 POI 29 RE capital EOP\n",
      "---\n",
      "Predict: \t2 POI 7 RE contains EOP\n",
      "Ground Truth: \t5 POI 4 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP\n",
      "Ground Truth: \t50 POI 47 48 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE RE EOP\n",
      "Ground Truth: \t95 POI 64 RE country EOP\n",
      "---\n",
      "Predict: \t1 POI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t13 POI 11 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI POI RE RE contains EOP\n",
      "Ground Truth: \t8 9 10 POI 14 15 16 17 RE company EOP\n",
      "---\n",
      "Predict: \t13 POI POI POI RE contains EOP\n",
      "Ground Truth: \t17 POI 15 16 RE contains EOP\n",
      "---\n",
      "Predict: \t17 POI POI POI RE RE contains EOP\n",
      "Ground Truth: \t40 POI 37 38 RE contains EOP\n",
      "---\n",
      "Predict: \t11 POI POI RE contains EOP\n",
      "Ground Truth: \t4 POI 6 RE country POI 6 RE country EOP 4 POI 6 RE country POI 6 RE country EOP\n",
      "---\n",
      "Predict: \t1 2 POI 7 RE contains EOP\n",
      "Ground Truth: \t4 5 POI 8 RE place_lived EOP\n",
      "---\n",
      "Predict: \t16 POI POI POI RE RE contains EOP\n",
      "Ground Truth: \t5 6 POI 11 12 13 14 RE company EOP\n",
      "---\n",
      "Predict: \t10 POI 11 RE contains EOP\n",
      "Ground Truth: \t13 POI 14 RE country EOP\n",
      "---\n",
      "Predict: \t6 POI 7 RE contains EOP RE\n",
      "Ground Truth: \t6 POI 5 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE RE EOP EOP POI\n",
      "Ground Truth: \t21 POI 15 16 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE\n",
      "Ground Truth: \t34 POI 33 RE contains EOP\n",
      "---\n",
      "Predict: \t16 POI POI RE RE contains EOP\n",
      "Ground Truth: \t15 POI 11 12 13 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI POI RE RE contains EOP\n",
      "Ground Truth: \t8 POI 17 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP\n",
      "Ground Truth: \t41 POI 42 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE country EOP POI RE RE POI\n",
      "Ground Truth: \t21 POI 20 RE contains EOP\n",
      "---\n",
      "Predict: \t13 POI POI RE contains EOP\n",
      "Ground Truth: \t1 POI 19 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI 7 RE contains EOP\n",
      "Ground Truth: \t9 POI 7 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE contains EOP POI POI RE POI\n",
      "Ground Truth: \t8 POI 7 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE contains EOP\n",
      "Ground Truth: \t14 15 POI 22 RE nationality EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE EOP\n",
      "Ground Truth: \t25 POI 24 RE contains EOP\n",
      "---\n",
      "Predict: \t15 POI POI RE contains EOP\n",
      "Ground Truth: \t19 POI 18 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE RE contains EOP\n",
      "Ground Truth: \t17 POI 11 12 13 14 15 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t15 16 POI 18 RE place_lived EOP\n",
      "---\n",
      "Predict: \t10 POI POI POI RE RE RE EOP\n",
      "Ground Truth: \t13 14 POI 11 12 RE contains EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE RE EOP\n",
      "Ground Truth: \t1 2 POI 14 15 16 17 18 RE company EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE EOP EOP\n",
      "Ground Truth: \t10 POI 7 8 RE contains EOP\n",
      "---\n",
      "Predict: \t13 POI POI RE RE contains EOP\n",
      "Ground Truth: \t6 18 POI 20 RE country EOP\n",
      "---\n",
      "Predict: \t15 POI POI RE contains EOP\n",
      "Ground Truth: \t16 POI 14 RE contains EOP\n",
      "---\n",
      "Predict: \t1 POI POI RE RE contains EOP\n",
      "Ground Truth: \t20 POI 17 RE contains EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE RE EOP\n",
      "Ground Truth: \t17 POI 11 12 13 14 15 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE RE contains EOP POI RE\n",
      "Ground Truth: \t34 POI 32 33 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE RE contains EOP\n",
      "Ground Truth: \t58 POI 16 RE country EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE contains EOP\n",
      "Ground Truth: \t24 POI 13 14 RE country POI 13 14 RE country EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE RE contains EOP\n",
      "Ground Truth: \t6 POI 4 RE contains EOP\n",
      "---\n",
      "Predict: \t15 POI POI RE contains EOP\n",
      "Ground Truth: \t16 POI 11 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI POI RE contains EOP\n",
      "Ground Truth: \t21 POI 37 RE country EOP 23 POI 37 RE country EOP 21 POI 37 RE country EOP\n",
      "---\n",
      "Predict: \t11 POI POI RE contains EOP RE\n",
      "Ground Truth: \t10 POI 12 RE country POI 12 RE country EOP 10 POI 12 RE country POI 12 RE country EOP\n",
      "---\n",
      "Predict: \t8 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t9 10 POI 12 RE place_lived EOP\n",
      "---\n",
      "Predict: \t9 POI POI RE contains EOP\n",
      "Ground Truth: \t21 22 POI 25 RE place_lived EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE RE contains EOP\n",
      "Ground Truth: \t7 POI 6 RE contains EOP\n",
      "---\n",
      "Predict: \t8 POI POI RE RE EOP\n",
      "Ground Truth: \t14 POI 13 RE contains EOP\n",
      "---\n",
      "Predict: \t1 2 POI 7 RE contains EOP\n",
      "Ground Truth: \t7 8 POI 1 2 RE nationality EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE RE\n",
      "Ground Truth: \t29 POI 26 27 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE RE contains EOP\n",
      "Ground Truth: \t17 POI 6 RE country EOP\n",
      "---\n",
      "Predict: \t28 POI POI POI RE RE EOP EOP\n",
      "Ground Truth: \t38 39 POI 13 14 RE contains EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE RE EOP\n",
      "Ground Truth: \t1 POI 14 RE place_lived EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE contains EOP\n",
      "Ground Truth: \t18 POI 15 16 RE contains EOP\n",
      "---\n",
      "Predict: \t2 POI POI RE RE EOP\n",
      "Ground Truth: \t3 POI 1 RE country EOP\n",
      "---\n",
      "Predict: \t12 POI POI RE RE contains EOP\n",
      "Ground Truth: \t9 POI 5 6 7 RE contains EOP\n",
      "---\n",
      "Predict: \t24 POI POI POI RE RE RE EOP\n",
      "Ground Truth: \t20 21 POI 28 29 30 31 RE company EOP\n",
      "---\n",
      "Predict: \t16 POI POI POI RE contains EOP\n",
      "Ground Truth: \t15 16 POI 23 RE nationality EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE EOP\n",
      "Ground Truth: \t12 13 POI 1 13 RE children EOP\n",
      "---\n",
      "Predict: \t8 POI 7 RE contains EOP\n",
      "Ground Truth: \t9 POI 8 RE contains EOP\n",
      "---\n",
      "Predict: \tPOI POI POI RE contains EOP POI RE\n",
      "Ground Truth: \t35 POI 31 32 33 RE contains EOP\n",
      "---\n",
      "Predict: \t20 POI POI POI RE RE RE EOP\n",
      "Ground Truth: \t15 16 17 POI 23 24 25 26 RE company EOP\n",
      "---\n",
      "Predict: \t8 POI POI 11 RE contains EOP\n",
      "Ground Truth: \t8 POI 5 6 RE contains EOP\n",
      "---\n",
      "Predict: \t2 2 POI 5 RE contains EOP\n",
      "Ground Truth: \t2 3 POI 5 RE place_lived EOP\n",
      "---\n",
      "Predict: \t1 2 POI POI RE RE EOP\n",
      "Ground Truth: \t1 2 POI 5 6 RE place_lived EOP\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "adjlResult = [' '.join([index2token.get(i, str(i)) for i in sent if i != 0]) for sent in result]\n",
    "actResult = [' '.join([index2token.get(i, str(i)) for i in sent if i != 0]) for sent in y_test]\n",
    "for i in range(395):\n",
    "    print('Predict: \\t%s' % adjlResult[i])\n",
    "    print('Ground-Truth: \\t%s' % actResult[i])\n",
    "    print('---')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a = [[index2token.get(i, str(i)) for i in sent if i != 0] for sent in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-166-0b851a084472>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.max([len(i) for i in a])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
