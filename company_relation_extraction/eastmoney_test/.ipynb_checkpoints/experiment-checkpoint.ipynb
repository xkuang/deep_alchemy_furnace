{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#GPU\" data-toc-modified-id=\"GPU-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>GPU</a></span></li><li><span><a href=\"#Data-Preprocessing\" data-toc-modified-id=\"Data-Preprocessing-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Data Preprocessing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Load Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Load-Labeled-Data\" data-toc-modified-id=\"Load-Labeled-Data-2.1.2\"><span class=\"toc-item-num\">2.1.2&nbsp;&nbsp;</span>Load Labeled Data</a></span></li></ul></li><li><span><a href=\"#Word-Segmentation\" data-toc-modified-id=\"Word-Segmentation-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Word Segmentation</a></span></li><li><span><a href=\"#Make-Firm-Eneities-Label-Sequence\" data-toc-modified-id=\"Make-Firm-Eneities-Label-Sequence-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Make Firm Eneities Label Sequence</a></span><ul class=\"toc-item\"><li><span><a href=\"#Test\" data-toc-modified-id=\"Test-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Test</a></span></li></ul></li><li><span><a href=\"#Word-to-Vector\" data-toc-modified-id=\"Word-to-Vector-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Word to Vector</a></span><ul class=\"toc-item\"><li><span><a href=\"#Set-Hyperparameters\" data-toc-modified-id=\"Set-Hyperparameters-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Set Hyperparameters</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Train</a></span></li><li><span><a href=\"#Test-vector\" data-toc-modified-id=\"Test-vector-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>Test vector</a></span></li></ul></li></ul></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Set-Hyperparameters\" data-toc-modified-id=\"Set-Hyperparameters-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Set Hyperparameters</a></span></li><li><span><a href=\"#Custom-Metrics\" data-toc-modified-id=\"Custom-Metrics-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Custom Metrics</a></span></li><li><span><a href=\"#Generate-Data\" data-toc-modified-id=\"Generate-Data-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Generate Data</a></span></li><li><span><a href=\"#Builde-Graph-and-Train\" data-toc-modified-id=\"Builde-Graph-and-Train-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Builde Graph and Train</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-3.4.1\"><span class=\"toc-item-num\">3.4.1&nbsp;&nbsp;</span>Import Libraries</a></span></li><li><span><a href=\"#Firm-Eneities-Recognition-Test:-Bi-LSTM+LSTM\" data-toc-modified-id=\"Firm-Eneities-Recognition-Test:-Bi-LSTM+LSTM-3.4.2\"><span class=\"toc-item-num\">3.4.2&nbsp;&nbsp;</span>Firm Eneities Recognition Test: Bi-LSTM+LSTM</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-3.4.2.1\"><span class=\"toc-item-num\">3.4.2.1&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Build-Graph\" data-toc-modified-id=\"Build-Graph-3.4.2.2\"><span class=\"toc-item-num\">3.4.2.2&nbsp;&nbsp;</span>Build Graph</a></span></li><li><span><a href=\"#Train\" data-toc-modified-id=\"Train-3.4.2.3\"><span class=\"toc-item-num\">3.4.2.3&nbsp;&nbsp;</span>Train</a></span></li></ul></li><li><span><a href=\"#Firm-Eneities-Recognition:-Bi-LSTM+LSTM\" data-toc-modified-id=\"Firm-Eneities-Recognition:-Bi-LSTM+LSTM-3.4.3\"><span class=\"toc-item-num\">3.4.3&nbsp;&nbsp;</span>Firm Eneities Recognition: Bi-LSTM+LSTM</a></span></li><li><span><a href=\"#Relation-Classification:-Bi-LSTM+LSTM\" data-toc-modified-id=\"Relation-Classification:-Bi-LSTM+LSTM-3.4.4\"><span class=\"toc-item-num\">3.4.4&nbsp;&nbsp;</span>Relation Classification: Bi-LSTM+LSTM</a></span></li><li><span><a href=\"#Integrated-Model:-Bi-LSTM+LSTM(Bi-LSTM-Shared)\" data-toc-modified-id=\"Integrated-Model:-Bi-LSTM+LSTM(Bi-LSTM-Shared)-3.4.5\"><span class=\"toc-item-num\">3.4.5&nbsp;&nbsp;</span>Integrated Model: Bi-LSTM+LSTM(Bi-LSTM Shared)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Straightforward\" data-toc-modified-id=\"Straightforward-3.4.5.1\"><span class=\"toc-item-num\">3.4.5.1&nbsp;&nbsp;</span>Straightforward</a></span></li><li><span><a href=\"#With-Function\" data-toc-modified-id=\"With-Function-3.4.5.2\"><span class=\"toc-item-num\">3.4.5.2&nbsp;&nbsp;</span>With Function</a></span></li></ul></li><li><span><a href=\"#Relation-Classification:-Bi-LSTM+LSTM(+FE-wordvector-Pair)\" data-toc-modified-id=\"Relation-Classification:-Bi-LSTM+LSTM(+FE-wordvector-Pair)-3.4.6\"><span class=\"toc-item-num\">3.4.6&nbsp;&nbsp;</span>Relation Classification: Bi-LSTM+LSTM(+FE wordvector Pair)</a></span></li><li><span><a href=\"#Integrated-Model:-Bi-LSTM+LSTM(Bi-LSTM-Shared)\" data-toc-modified-id=\"Integrated-Model:-Bi-LSTM+LSTM(Bi-LSTM-Shared)-3.4.7\"><span class=\"toc-item-num\">3.4.7&nbsp;&nbsp;</span>Integrated Model: Bi-LSTM+LSTM(Bi-LSTM Shared)</a></span></li></ul></li></ul></li><li><span><a href=\"##\" data-toc-modified-id=\"#-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>#</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os  \n",
    "import tensorflow as tf  \n",
    "import keras.backend.tensorflow_backend as KTF  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_session(gpu_fraction=1.):  \n",
    "    \"\"\" \n",
    "    This function is to allocate GPU memory a specific fraction \n",
    "    Assume that you have 6GB of GPU memory and want to allocate ~2GB \n",
    "    \"\"\"  \n",
    "    num_threads = os.environ.get('OMP_NUM_THREADS')  \n",
    "    gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=gpu_fraction)  \n",
    "  \n",
    "    if num_threads:  \n",
    "        return tf.Session(config=tf.ConfigProto(  \n",
    "            gpu_options=gpu_options, intra_op_parallelism_threads=num_threads))  \n",
    "    else:  \n",
    "        return tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))  \n",
    "    \n",
    "KTF.set_session(get_session(1.))  # using 60% of total GPU Memory  \n",
    "os.system(\"nvidia-smi\");  # Execute the command (a string) in a subshell  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abstract = []\n",
    "firm_eneity = []\n",
    "relation = []\n",
    "\n",
    "with open(\"mini_data.json\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    item = json.loads(line)\n",
    "    abstract.append(item['abstract'])\n",
    "    firm_eneity.append(item['eneity'])\n",
    "    relation.append(item['relation'])\n",
    "    \n",
    "relation = [[int(i) for i in r] for r in relation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300, 300)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abstract), len(firm_eneity), len(relation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_abstract = []\n",
    "\n",
    "with open(\"trian_data.json\") as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "for line in lines:\n",
    "    item = json.loads(line)\n",
    "    all_abstract.append(item['abstract'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8496"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Labeled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labstract = []\n",
    "lfirm_eneity = []\n",
    "lrelation = []\n",
    "\n",
    "with open(\"mini_data.json\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "for line in lines:\n",
    "    item = json.loads(line)\n",
    "    if len(item['eneity']) > 1 and item['relation'] != '':\n",
    "        labstract.append(item['abstract'])\n",
    "        lfirm_eneity.append(item['eneity'])\n",
    "        lrelation.append(item['relation'])\n",
    "    \n",
    "lrelation = [[int(i) for i in r] for r in lrelation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 162, 162)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labstract), len(lfirm_eneity), len(lrelation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#not_cuts = re.compile(u'([\\da-zA-Z \\.]+)|《(.*?)》|“(.{1,10})”')\n",
    "not_cuts = re.compile(u'《(.*?)》|“(.{1,10})”')\n",
    "re_replace = re.compile(u'[^\\u4e00-\\u9fa50-9a-zA-Z《》\\(\\)（）“”·\\.]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def newcut(s):\n",
    "    \"\"\"\n",
    "    修改原分词函数:\n",
    "    1: 数字部分不分词 \n",
    "    2: 双书名号中内容不分词\n",
    "    3: 双引号中十字以内内容不分词\n",
    "    4: 超出范围的字符均替换为空格\n",
    "    5: 使用结巴分词(关闭新词发现功能)\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    j = 0\n",
    "    s = re_replace.sub(' ', s)\n",
    "    for i in not_cuts.finditer(s):\n",
    "        result.extend(jieba.lcut(s[j:i.start()], HMM=False))\n",
    "        if s[i.start()] in [u'《', u'“']:\n",
    "            result.extend([s[i.start()], s[i.start()+1:i.end()-1], s[i.end()-1]])\n",
    "        else:\n",
    "            result.append(s[i.start():i.end()])\n",
    "        j = i.end()\n",
    "    result.extend(jieba.lcut(s[j:], HMM=False))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/kz/hqjl_dfx3g3_2vxylxlj1s940000gn/T/jieba.cache\n",
      "Loading model cost 1.128 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "lwords = [newcut(s) for s in labstract]\n",
    "words = [newcut(s) for s in abstract]\n",
    "all_words = [newcut(s) for s in all_abstract]\n",
    "lfe = [[newcut(s) for s in lf] for lf in lfirm_eneity]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1265bc7b8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAyAAAAIqCAYAAADcnC66AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYmZmZmZmTfP/mTZ/bN4ciNEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ac2b208>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 277,
       "width": 400
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(i) for i in all_words], bins=64, normed=True);\n",
    "plt.xlabel('Abstract Length')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Histogram of Text Length')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Firm Eneities Label Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2label(n, word, eneity):\n",
    "    \"\"\"\n",
    "    将输出结果转换为标签序列\n",
    "    5tag:\n",
    "    0: 非核心实体 \n",
    "    1: 单词核心实体\n",
    "    2: 多词核心实体首词\n",
    "    3: 多词核心实体中间部分\n",
    "    4: 多词核心实体末词\n",
    "    \"\"\"\n",
    "    s = word[n]\n",
    "    r = ['0']*len(s)\n",
    "    for i in range(len(s)):\n",
    "        for j in eneity[n]:\n",
    "            if s[i] in j:\n",
    "                r[i] = '1'\n",
    "                break\n",
    "    s = ''.join(r)\n",
    "    r = [0]*len(s)\n",
    "    for i in re.finditer('1+', s):\n",
    "        if i.end() - i.start() > 1:\n",
    "            r[i.start()] = 2\n",
    "            r[i.end()-1] = 4\n",
    "            for j in range(i.start()+1, i.end()-1):\n",
    "                r[j] = 3\n",
    "        else:\n",
    "            r[i.start()] = 1\n",
    "    t = ''.join([str(i) for i in r])\n",
    "    for j in re.finditer('2.*?4|1', t):\n",
    "        if ''.join(word[n][j.start():j.end()]) not in eneity[n]:\n",
    "            for i in range(j.start(), j.end()):\n",
    "                r[i] = 0\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = [word2label(i, words, firm_eneity) for i in range(len(words))]\n",
    "llabels = [word2label(i, lwords, lfirm_eneity) for i in range(len(lwords))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_abstract = [\"子公司战略携手腾讯云计算， 使得万方发展在6月2日开盘后不久涨停，报11.68元。万方发展1日晚间公告，公司参股子公司成都义幻医疗科技有限公司与腾讯云计算(北京)有限责任公司签订了《战略合作协议》，就产业互联网、医疗云解决方案等相关领域展开深度合作。\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tabstract' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-56b55a29708b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnewcut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtabstract\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tabstract' is not defined"
     ]
    }
   ],
   "source": [
    "test_words = [newcut(s) for s in tabstract]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ed5078daaa2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m'/'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_words\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_words' is not defined"
     ]
    }
   ],
   "source": [
    "'/'.join(test_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'twords' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5a5869ba1659>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword2label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"腾讯云计算\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"万方发展\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"成都义幻医疗科技有限公司\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"腾讯云计算(北京)有限责任公司\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-21-5a5869ba1659>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword2label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"腾讯云计算\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"万方发展\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"成都义幻医疗科技有限公司\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"腾讯云计算(北京)有限责任公司\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'twords' is not defined"
     ]
    }
   ],
   "source": [
    "test_label = [word2label(i, twords, [[\"腾讯云计算\", \"万方发展\", \"成都义幻医疗科技有限公司\", \"腾讯云计算(北京)有限责任公司\"]]) for i in range(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-667cbe7df5fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_label' is not defined"
     ]
    }
   ],
   "source": [
    "print(test_label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word to Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 128\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 300, 300, 8496)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#随机打乱数据\n",
    "from sklearn.model_selection import train_test_split\n",
    "words, _, labels, _ = train_test_split(words, labels, test_size=0., random_state=SEED)\n",
    "relation, _, _, _ = train_test_split(relation, relation, test_size=0., random_state=SEED)\n",
    "all_words, _, _, _ = train_test_split(all_words, all_words, test_size=0., random_state=SEED)\n",
    "len(words), len(labels), len(relation), len(all_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 162, 162, 162)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "lwords, _, llabels, _ = train_test_split(lwords, llabels, test_size=0., random_state=SEED)\n",
    "lrelation, _, lfe, _ = train_test_split(lrelation, lfe, test_size=0., random_state=SEED)\n",
    "len(lwords), len(llabels), len(lrelation), len(lfe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-04 15:47:22,822 : INFO : collecting all words and their counts\n",
      "2017-07-04 15:47:22,823 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-07-04 15:47:23,041 : INFO : collected 34428 word types from a corpus of 873484 raw words and 8496 sentences\n",
      "2017-07-04 15:47:23,042 : INFO : Loading a fresh vocabulary\n",
      "2017-07-04 15:47:23,130 : INFO : min_count=1 retains 34428 unique words (100% of original 34428, drops 0)\n",
      "2017-07-04 15:47:23,131 : INFO : min_count=1 leaves 873484 word corpus (100% of original 873484, drops 0)\n",
      "2017-07-04 15:47:23,239 : INFO : deleting the raw counts dictionary of 34428 items\n",
      "2017-07-04 15:47:23,241 : INFO : sample=0.001 downsamples 34 most-common words\n",
      "2017-07-04 15:47:23,242 : INFO : downsampling leaves estimated 688238 word corpus (78.8% of prior 873484)\n",
      "2017-07-04 15:47:23,243 : INFO : estimated required memory for 34428 words and 128 dimensions: 52468272 bytes\n",
      "2017-07-04 15:47:23,370 : INFO : resetting layer weights\n",
      "2017-07-04 15:47:23,838 : INFO : training model with 20 workers on 34428 vocabulary and 128 features, using sg=1 hs=0 sample=0.001 negative=8 window=8\n",
      "2017-07-04 15:47:24,854 : INFO : PROGRESS: at 0.68% examples, 93914 words/s, in_qsize 35, out_qsize 4\n",
      "2017-07-04 15:47:26,233 : INFO : PROGRESS: at 2.33% examples, 134893 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:27,264 : INFO : PROGRESS: at 3.76% examples, 151438 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:28,286 : INFO : PROGRESS: at 5.23% examples, 162458 words/s, in_qsize 40, out_qsize 0\n",
      "2017-07-04 15:47:29,328 : INFO : PROGRESS: at 6.43% examples, 161629 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:30,348 : INFO : PROGRESS: at 7.80% examples, 165165 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:31,425 : INFO : PROGRESS: at 9.22% examples, 167552 words/s, in_qsize 40, out_qsize 1\n",
      "2017-07-04 15:47:32,508 : INFO : PROGRESS: at 10.86% examples, 172856 words/s, in_qsize 40, out_qsize 0\n",
      "2017-07-04 15:47:33,545 : INFO : PROGRESS: at 12.23% examples, 173808 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:34,554 : INFO : PROGRESS: at 13.71% examples, 176439 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:35,585 : INFO : PROGRESS: at 15.31% examples, 179609 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:36,740 : INFO : PROGRESS: at 16.79% examples, 179340 words/s, in_qsize 40, out_qsize 2\n",
      "2017-07-04 15:47:37,793 : INFO : PROGRESS: at 18.33% examples, 180979 words/s, in_qsize 40, out_qsize 0\n",
      "2017-07-04 15:47:38,859 : INFO : PROGRESS: at 19.98% examples, 183221 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:39,908 : INFO : PROGRESS: at 21.40% examples, 183467 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:40,914 : INFO : PROGRESS: at 23.06% examples, 185957 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:42,049 : INFO : PROGRESS: at 24.53% examples, 185559 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:43,089 : INFO : PROGRESS: at 26.07% examples, 186511 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:44,150 : INFO : PROGRESS: at 27.77% examples, 188334 words/s, in_qsize 40, out_qsize 0\n",
      "2017-07-04 15:47:45,258 : INFO : PROGRESS: at 29.20% examples, 187733 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:46,269 : INFO : PROGRESS: at 30.85% examples, 189399 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:47,291 : INFO : PROGRESS: at 32.50% examples, 190833 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:48,446 : INFO : PROGRESS: at 33.75% examples, 188882 words/s, in_qsize 38, out_qsize 1\n",
      "2017-07-04 15:47:49,510 : INFO : PROGRESS: at 35.46% examples, 190217 words/s, in_qsize 38, out_qsize 1\n",
      "2017-07-04 15:47:50,549 : INFO : PROGRESS: at 37.05% examples, 191034 words/s, in_qsize 40, out_qsize 0\n",
      "2017-07-04 15:47:51,773 : INFO : PROGRESS: at 38.37% examples, 189121 words/s, in_qsize 40, out_qsize 1\n",
      "2017-07-04 15:47:52,826 : INFO : PROGRESS: at 40.29% examples, 191429 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:54,021 : INFO : PROGRESS: at 41.72% examples, 190332 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:55,050 : INFO : PROGRESS: at 43.31% examples, 191102 words/s, in_qsize 40, out_qsize 0\n",
      "2017-07-04 15:47:56,059 : INFO : PROGRESS: at 45.08% examples, 192652 words/s, in_qsize 40, out_qsize 0\n",
      "2017-07-04 15:47:57,173 : INFO : PROGRESS: at 46.33% examples, 191389 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:47:58,210 : INFO : PROGRESS: at 47.81% examples, 191546 words/s, in_qsize 37, out_qsize 2\n",
      "2017-07-04 15:47:59,244 : INFO : PROGRESS: at 49.46% examples, 192375 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:00,418 : INFO : PROGRESS: at 50.88% examples, 191556 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:01,447 : INFO : PROGRESS: at 52.60% examples, 192569 words/s, in_qsize 38, out_qsize 1\n",
      "2017-07-04 15:48:02,466 : INFO : PROGRESS: at 54.08% examples, 192766 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:03,615 : INFO : PROGRESS: at 55.44% examples, 191911 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:04,625 : INFO : PROGRESS: at 57.09% examples, 192737 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:05,669 : INFO : PROGRESS: at 58.75% examples, 193352 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:06,676 : INFO : PROGRESS: at 60.00% examples, 192822 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:07,813 : INFO : PROGRESS: at 61.53% examples, 192654 words/s, in_qsize 38, out_qsize 2\n",
      "2017-07-04 15:48:08,828 : INFO : PROGRESS: at 63.36% examples, 193879 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:09,833 : INFO : PROGRESS: at 64.66% examples, 193567 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:10,902 : INFO : PROGRESS: at 66.08% examples, 193329 words/s, in_qsize 37, out_qsize 2\n",
      "2017-07-04 15:48:11,955 : INFO : PROGRESS: at 67.85% examples, 194152 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:12,974 : INFO : PROGRESS: at 69.16% examples, 193788 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:14,001 : INFO : PROGRESS: at 70.63% examples, 193875 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:15,013 : INFO : PROGRESS: at 72.29% examples, 194488 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:16,014 : INFO : PROGRESS: at 73.66% examples, 194357 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:17,066 : INFO : PROGRESS: at 75.08% examples, 194192 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:18,103 : INFO : PROGRESS: at 76.79% examples, 194817 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:19,175 : INFO : PROGRESS: at 78.27% examples, 194721 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:20,199 : INFO : PROGRESS: at 79.69% examples, 194660 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:21,277 : INFO : PROGRESS: at 81.28% examples, 194828 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:22,281 : INFO : PROGRESS: at 82.82% examples, 195103 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:23,297 : INFO : PROGRESS: at 84.19% examples, 194932 words/s, in_qsize 40, out_qsize 0\n",
      "2017-07-04 15:48:24,318 : INFO : PROGRESS: at 85.78% examples, 195269 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:25,333 : INFO : PROGRESS: at 87.26% examples, 195364 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:26,440 : INFO : PROGRESS: at 88.63% examples, 194908 words/s, in_qsize 38, out_qsize 1\n",
      "2017-07-04 15:48:27,447 : INFO : PROGRESS: at 89.94% examples, 194653 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:28,448 : INFO : PROGRESS: at 91.53% examples, 195035 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:29,463 : INFO : PROGRESS: at 92.95% examples, 195005 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:30,467 : INFO : PROGRESS: at 94.26% examples, 194776 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:31,471 : INFO : PROGRESS: at 95.74% examples, 194896 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:32,499 : INFO : PROGRESS: at 97.28% examples, 195066 words/s, in_qsize 39, out_qsize 0\n",
      "2017-07-04 15:48:33,500 : INFO : PROGRESS: at 98.71% examples, 195071 words/s, in_qsize 23, out_qsize 0\n",
      "2017-07-04 15:48:33,727 : INFO : worker thread finished; awaiting finish of 19 more threads\n",
      "2017-07-04 15:48:33,753 : INFO : worker thread finished; awaiting finish of 18 more threads\n",
      "2017-07-04 15:48:33,780 : INFO : worker thread finished; awaiting finish of 17 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-07-04 15:48:33,852 : INFO : worker thread finished; awaiting finish of 16 more threads\n",
      "2017-07-04 15:48:33,853 : INFO : worker thread finished; awaiting finish of 15 more threads\n",
      "2017-07-04 15:48:33,916 : INFO : worker thread finished; awaiting finish of 14 more threads\n",
      "2017-07-04 15:48:33,938 : INFO : worker thread finished; awaiting finish of 13 more threads\n",
      "2017-07-04 15:48:33,960 : INFO : worker thread finished; awaiting finish of 12 more threads\n",
      "2017-07-04 15:48:34,024 : INFO : worker thread finished; awaiting finish of 11 more threads\n",
      "2017-07-04 15:48:34,054 : INFO : worker thread finished; awaiting finish of 10 more threads\n",
      "2017-07-04 15:48:34,074 : INFO : worker thread finished; awaiting finish of 9 more threads\n",
      "2017-07-04 15:48:34,078 : INFO : worker thread finished; awaiting finish of 8 more threads\n",
      "2017-07-04 15:48:34,143 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2017-07-04 15:48:34,156 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2017-07-04 15:48:34,166 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-07-04 15:48:34,169 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-07-04 15:48:34,183 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-07-04 15:48:34,185 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-07-04 15:48:34,188 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-07-04 15:48:34,212 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-07-04 15:48:34,213 : INFO : training on 17469680 raw words (13764560 effective words) took 70.4s, 195619 effective words/s\n",
      "2017-07-04 15:48:34,215 : INFO : saving Word2Vec object under word2vec, separately None\n",
      "2017-07-04 15:48:34,216 : INFO : not storing attribute syn0norm\n",
      "2017-07-04 15:48:34,217 : INFO : not storing attribute cum_table\n",
      "2017-07-04 15:48:34,708 : INFO : saved word2vec\n",
      "2017-07-04 15:48:34,710 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', \n",
    "                    level=logging.INFO)\n",
    "word2vec = gensim.models.Word2Vec(np.array(all_words),\n",
    "                                  min_count=1,\n",
    "                                  size=EMBEDDING_SIZE,\n",
    "                                  workers=20,\n",
    "                                  iter=20,\n",
    "                                  window=8,\n",
    "                                  negative=8,\n",
    "                                  sg=1)\n",
    "word2vec.save('word2vec')\n",
    "#预先归一化\n",
    "word2vec.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = gensim.models.Word2Vec.load('word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('战略', 0.7018101811408997),\n",
       " ('双方', 0.7005383968353271),\n",
       " ('拟就', 0.6761155724525452),\n",
       " ('加深', 0.6675276756286621),\n",
       " ('纽带', 0.6597539186477661),\n",
       " ('可编程', 0.6374185085296631),\n",
       " ('全域', 0.6359912157058716),\n",
       " ('合作意向', 0.6358799338340759),\n",
       " ('融洽', 0.6358425617218018),\n",
       " ('抢滩', 0.6274130344390869)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.most_similar('合作')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAXLEN_FE = 176\n",
    "MAXLEN_R = 56\n",
    "MAXLEN_TEST_NER = 80\n",
    "NUM_EPOCHS = 512\n",
    "NUM_EPOCHS_TEST_NER = 128\n",
    "BATCH_SIZE = 158\n",
    "BATCH_SIZE_TEST_NER = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pre(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算 macro-averaged precision\n",
    "    \"\"\"\n",
    "    true_positives = tf.reduce_sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=[0, 1])\n",
    "    predicted_positives = tf.reduce_sum(K.round(K.clip(y_pred, 0, 1)), axis=[0, 1])\n",
    "    macro_precision = K.sum(true_positives / (predicted_positives + K.epsilon())) / K.int_shape(true_positives)[-1]\n",
    "    return macro_precision\n",
    "\n",
    "def rec(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算 macro-averaged recall\n",
    "    \"\"\"\n",
    "    true_positives = tf.reduce_sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=[0, 1])\n",
    "    possible_positives = tf.reduce_sum(K.round(K.clip(y_true, 0, 1)), axis=[0, 1])\n",
    "    macro_recall = K.sum(true_positives / (possible_positives + K.epsilon())) / K.int_shape(true_positives)[-1]\n",
    "    return macro_recall\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    计算 macro-averaged f1-score\n",
    "    \"\"\"\n",
    "    c1 = tf.reduce_sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=[0, 1])\n",
    "    c2 = tf.reduce_sum(K.round(K.clip(y_pred, 0, 1)), axis=[0, 1])\n",
    "    c3 = tf.reduce_sum(K.round(K.clip(y_true, 0, 1)), axis=[0, 1])\n",
    "    c = K.int_shape(c1)[-1]\n",
    "\n",
    "    if c3 == K.zeros((c,)):\n",
    "        return 0\n",
    "    \n",
    "    precision = c1 / (c2 + K.epsilon())\n",
    "    recall = c1 / (c3 + K.epsilon())\n",
    "    macro_f1_score = 2 / c * K.sum((precision * recall) / (precision + recall + K.epsilon()))\n",
    "    return macro_f1_score\n",
    "\n",
    "#def final_macro_f1_score\n",
    "\n",
    "def final_macro_f1_score(x, y_true, model):\n",
    "    \"\"\"\n",
    "    计算 final macro-averaged f1-score\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(x)\n",
    "    y_true = np.reshape(np.array([t for t in np.argmax(y_true, -1)]), -1)\n",
    "    y_pred = np.reshape(np.array([t for t in np.argmax(y_pred, -1)]), -1)\n",
    "    return f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "def integrated_final_macro_f1_score(x, y_true, model):\n",
    "    \"\"\"\n",
    "    计算 integrated final macro-averaged f1-score\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(x)\n",
    "    y_true_fe = np.reshape(np.array([t for t in np.argmax(y_true[0], -1)]), -1)\n",
    "    y_pred_fe = np.reshape(np.array([t for t in np.argmax(y_pred[0], -1)]), -1)\n",
    "    y_true_r = np.reshape(np.array([t for t in np.argmax(y_true[1], -1)]), -1)\n",
    "    y_pred_r = np.reshape(np.array([t for t in np.argmax(y_pred[1], -1)]), -1)    \n",
    "    fe = f1_score(y_true_fe, y_pred_fe, average='macro')\n",
    "    r = f1_score(y_true_r, y_pred_r, average='macro')\n",
    "    return (fe, r)\n",
    "    # print('fe_final macro-averaged f1-score = %.12f' % (fe))\n",
    "    # print('r_final macro-averaged f1-score = %.12f' % (r))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_x(z):\n",
    "    \"\"\"\n",
    "    从分词后的list中输出训练样本\n",
    "    超过MAXLEN_NER则截断，不足补0\n",
    "    \"\"\"\n",
    "    gen = np.vstack((word2vec[z[:MAXLEN_FE]], np.zeros((MAXLEN_FE-len(z[:MAXLEN_FE]), EMBEDDING_SIZE))))\n",
    "    return gen \n",
    "\n",
    "def gen_fes(z):\n",
    "    \"\"\"\n",
    "    将输出实体序列转换为独热码\n",
    "    超过MAXLEN_NER则截断，不足补0\n",
    "    \"\"\"\n",
    "    gen = np_utils.to_categorical(np.array(z[:MAXLEN_FE] + [0]*(MAXLEN_FE-len(z[:MAXLEN_FE]))), 5)\n",
    "    return gen \n",
    "    \n",
    "def gen_r(z):\n",
    "    \"\"\"\n",
    "    将输出关系序列转换为独自码\n",
    "    超过MAXLEN_R则截断，不足补0\n",
    "    \"\"\"\n",
    "    gen = np_utils.to_categorical(np.array(z[:MAXLEN_R] + [0]*(MAXLEN_R-len(z[:MAXLEN_R]))), 10)\n",
    "    return gen     \n",
    "\n",
    "def fev(z):\n",
    "    \"\"\"\n",
    "    将实体词向量全排列(对应于关系标签)\n",
    "    超过MAXLEN_R则截断，不足补0\n",
    "    \"\"\"\n",
    "    temp_1 = [[sum(word2vec[i]) for i in fe] for fe in z]\n",
    "    temp_2 = [list(itertools.permutations(i, 2)) for i in temp_1]\n",
    "    temp_3 = [[np.concatenate((i[0], i[1])) for i in t] for t in temp_2]\n",
    "    fev = np.array([np.vstack((np.array(i[:MAXLEN_R]), np.zeros((MAXLEN_R-len(i[:MAXLEN_R]), EMBEDDING_SIZE*2)))) for i in temp_3])\n",
    "    return fev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xfe = np.array([gen_x(i) for i in words])\n",
    "Yfe = np.array([gen_fes(i) for i in labels])\n",
    "Yr = np.array([gen_r(i) for i in relation])\n",
    "lXfe = np.array([gen_x(i) for i in lwords])\n",
    "lYfe = np.array([gen_fes(i) for i in llabels])\n",
    "lYr = np.array([gen_r(i) for i in lrelation])\n",
    "lXfev = fev(lfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Builde Graph and Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, LSTM, TimeDistributed, Input, Masking, Bidirectional, RepeatVector, concatenate \n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import*\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Firm Eneities Recognition Test: Bi-LSTM+LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "fh = h5py.File('/Users/lizhn7/Downloads/DATA/content+core_entity/test_ner_data.h5', 'r')\n",
    "Xner_t = fh['train_ner_x'][:]\n",
    "Yner_t = fh['train_ner_y'][:]\n",
    "Xner_v = fh['val_ner_x'][:]\n",
    "Yner_v = fh['val_ner_y'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10578, 80, 128), (10578, 80, 5), (1867, 80, 128), (1867, 80, 5))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xner_t.shape, Yner_t.shape, Xner_v.shape, Yner_v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "fe_sequence = Input(shape=(MAXLEN_TEST_NER, EMBEDDING_SIZE))\n",
    "fe_mask = Masking(mask_value=0.)(fe_sequence)\n",
    "fe_blstm = Bidirectional(LSTM(64, return_sequences=True), merge_mode='concat')(fe_mask)\n",
    "fe_blstm = Bidirectional(LSTM(32, return_sequences=True), merge_mode='concat')(fe_blstm)\n",
    "#fe_blstm = RepeatVector(MAXLEN_NER)(fe_blstm)\n",
    "fe_output = TimeDistributed(Dense(5, activation='softmax'))(fe_blstm)\n",
    "fe_model = Model(inputs=fe_sequence, outputs=fe_output)\n",
    "fe_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[pre, rec, f1])\n",
    "fe_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for e in range(NUM_EPOCHS_TEST_NER):    \n",
    "    print('EPOCHS', e+1)\n",
    "    h = fe_model.fit(x=Xner_t, \n",
    "                     y=Yner_t, \n",
    "                     batch_size=BATCH_SIZE_TEST_NER,\n",
    "                     epochs=1,\n",
    "                     verbose=1, \n",
    "                     validation_data=(Xner_v, Yner_v), \n",
    "                     shuffle=True)              \n",
    "    print('final macro-averaged f1-score = %.12f' % (final_macro_f1_score(Xner_v, Yner_v, fe_model)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Firm Eneities Recognition: Bi-LSTM+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 176, 128)          0         \n",
      "_________________________________________________________________\n",
      "masking_1 (Masking)          (None, 176, 128)          0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 176, 128)          98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 176, 64)           41216     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 176, 32)           12416     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 176, 5)            165       \n",
      "=================================================================\n",
      "Total params: 152,613\n",
      "Trainable params: 152,613\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"410pt\" viewBox=\"0.00 0.00 328.47 410.00\" width=\"328pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 406)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-406 324.4727,-406 324.4727,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 5494646936 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>5494646936</title>\n",
       "<polygon fill=\"none\" points=\"96.0552,-365.5 96.0552,-401.5 224.4175,-401.5 224.4175,-365.5 96.0552,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.2363\" y=\"-379.3\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 5494949816 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>5494949816</title>\n",
       "<polygon fill=\"none\" points=\"93.3208,-292.5 93.3208,-328.5 227.1519,-328.5 227.1519,-292.5 93.3208,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.2363\" y=\"-306.3\">masking_1: Masking</text>\n",
       "</g>\n",
       "<!-- 5494646936&#45;&gt;5494949816 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>5494646936-&gt;5494949816</title>\n",
       "<path d=\"M160.2363,-365.4551C160.2363,-357.3828 160.2363,-347.6764 160.2363,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.7364,-338.5903 160.2363,-328.5904 156.7364,-338.5904 163.7364,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5495150912 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>5495150912</title>\n",
       "<polygon fill=\"none\" points=\"22.5688,-219.5 22.5688,-255.5 297.9038,-255.5 297.9038,-219.5 22.5688,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.2363\" y=\"-233.3\">bidirectional_1(lstm_1): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 5494949816&#45;&gt;5495150912 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>5494949816-&gt;5495150912</title>\n",
       "<path d=\"M160.2363,-292.4551C160.2363,-284.3828 160.2363,-274.6764 160.2363,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.7364,-265.5903 160.2363,-255.5904 156.7364,-265.5904 163.7364,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5501043040 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>5501043040</title>\n",
       "<polygon fill=\"none\" points=\"22.5688,-146.5 22.5688,-182.5 297.9038,-182.5 297.9038,-146.5 22.5688,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.2363\" y=\"-160.3\">bidirectional_2(lstm_2): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 5495150912&#45;&gt;5501043040 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>5495150912-&gt;5501043040</title>\n",
       "<path d=\"M160.2363,-219.4551C160.2363,-211.3828 160.2363,-201.6764 160.2363,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.7364,-192.5903 160.2363,-182.5904 156.7364,-192.5904 163.7364,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5495141152 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>5495141152</title>\n",
       "<polygon fill=\"none\" points=\"110.814,-73.5 110.814,-109.5 209.6587,-109.5 209.6587,-73.5 110.814,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.2363\" y=\"-87.3\">lstm_3: LSTM</text>\n",
       "</g>\n",
       "<!-- 5501043040&#45;&gt;5495141152 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>5501043040-&gt;5495141152</title>\n",
       "<path d=\"M160.2363,-146.4551C160.2363,-138.3828 160.2363,-128.6764 160.2363,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.7364,-119.5903 160.2363,-109.5904 156.7364,-119.5904 163.7364,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5608143672 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>5608143672</title>\n",
       "<polygon fill=\"none\" points=\"0,-.5 0,-36.5 320.4727,-36.5 320.4727,-.5 0,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"160.2363\" y=\"-14.3\">time_distributed_1(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 5495141152&#45;&gt;5608143672 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>5495141152-&gt;5608143672</title>\n",
       "<path d=\"M160.2363,-73.4551C160.2363,-65.3828 160.2363,-55.6764 160.2363,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.7364,-46.5903 160.2363,-36.5904 156.7364,-46.5904 163.7364,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "fe_sequence = Input(shape=(MAXLEN_FE, EMBEDDING_SIZE))\n",
    "fe_mask = Masking(mask_value=0.)(fe_sequence)\n",
    "fe_blstm = Bidirectional(LSTM(64, return_sequences=True), merge_mode='concat')(fe_mask)\n",
    "fe_blstm = Bidirectional(LSTM(32, return_sequences=True), merge_mode='concat')(fe_blstm)\n",
    "fe_lstm = LSTM(32, return_sequences=True)(fe_blstm)\n",
    "fe_output = TimeDistributed(Dense(5, activation='softmax'))(fe_lstm)\n",
    "fe_model = Model(inputs=fe_sequence, outputs=fe_output)\n",
    "fe_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[pre, rec, f1])\n",
    "fe_model.summary()\n",
    "SVG(model_to_dot(fe_model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for e in range(NUM_EPOCHS):    \n",
    "    print('EPOCHS', e+1)\n",
    "    h = fe_model.fit(x=lXfe, \n",
    "                  y=lYfe, \n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=1,\n",
    "                  verbose=1, \n",
    "                  #validation_split=0.15, \n",
    "                  shuffle=True)              \n",
    "    print('final macro-averaged f1-score = %.12f' % (final_macro_f1_score(lXfe, lYfe, fe_model)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Relation Classification: Bi-LSTM+LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "r_sequence = Input(shape=(MAXLEN_FE, EMBEDDING_SIZE))\n",
    "r_mask = Masking(mask_value=0.)(r_sequence)\n",
    "r_blstm = Bidirectional(LSTM(64, return_sequences=True), merge_mode='concat')(r_mask)\n",
    "r_blstm = Bidirectional(LSTM(32, return_sequences=False), merge_mode='concat')(r_blstm)\n",
    "r_blstm = RepeatVector(MAXLEN_R)(r_blstm)\n",
    "r_blstm = LSTM(32, return_sequences=True)(r_blstm)\n",
    "r_output = TimeDistributed(Dense(9, activation='softmax'))(r_blstm)\n",
    "r_model = Model(inputs=r_sequence, outputs=r_output)\n",
    "r_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[pre, rec, f1])\n",
    "r_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for e in range(NUM_EPOCHS):    \n",
    "    print('EPOCHS', e+1)\n",
    "    h = r_model.fit(x=lXfe, \n",
    "                  y=lYr, \n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=1,\n",
    "                  verbose=1, \n",
    "                  #validation_split=0.15, \n",
    "                  shuffle=True)              \n",
    "    print('final_macro-averaged f1-score = %.12f' % (final_macro_f1_score(lXfe, lYr, r_model)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrated Model: Bi-LSTM+LSTM(Bi-LSTM Shared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Straightforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "INPUT (InputLayer)               (None, 176, 128)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "MASK (Masking)                   (None, 176, 128)      0           INPUT[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "ENC_BLSTM_1 (Bidirectional)      (None, 176, 256)      263168      MASK[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "ENC_BLSTM_2 (Bidirectional)      (None, 128)           164352      ENC_BLSTM_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "FER_CONTEXT (RepeatVector)       (None, 176, 128)      0           ENC_BLSTM_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "RC_CONTEXT (RepeatVector)        (None, 56, 128)       0           ENC_BLSTM_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "FER_DEC_LSTM (LSTM)              (None, 176, 32)       20608       FER_CONTEXT[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "RC_DEC_LSTM (LSTM)               (None, 56, 32)        20608       RC_CONTEXT[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "FER (TimeDistributed)            (None, 176, 5)        165         FER_DEC_LSTM[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "RC (TimeDistributed)             (None, 56, 10)        330         RC_DEC_LSTM[0][0]                \n",
      "====================================================================================================\n",
      "Total params: 469,231\n",
      "Trainable params: 469,231\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"483pt\" viewBox=\"0.00 0.00 499.88 483.00\" width=\"500pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 479)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-479 495.8828,-479 495.8828,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 5040843856 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>5040843856</title>\n",
       "<polygon fill=\"none\" points=\"195.1382,-438.5 195.1382,-474.5 321.2446,-474.5 321.2446,-438.5 195.1382,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258.1914\" y=\"-452.3\">INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 5043109616 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>5043109616</title>\n",
       "<polygon fill=\"none\" points=\"201.769,-365.5 201.769,-401.5 314.6138,-401.5 314.6138,-365.5 201.769,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258.1914\" y=\"-379.3\">MASK: Masking</text>\n",
       "</g>\n",
       "<!-- 5040843856&#45;&gt;5043109616 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>5040843856-&gt;5043109616</title>\n",
       "<path d=\"M258.1914,-438.4551C258.1914,-430.3828 258.1914,-420.6764 258.1914,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"261.6915,-411.5903 258.1914,-401.5904 254.6915,-411.5904 261.6915,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5040844024 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>5040844024</title>\n",
       "<polygon fill=\"none\" points=\"115.062,-292.5 115.062,-328.5 401.3208,-328.5 401.3208,-292.5 115.062,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258.1914\" y=\"-306.3\">ENC_BLSTM_1(lstm_1): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 5043109616&#45;&gt;5040844024 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>5043109616-&gt;5040844024</title>\n",
       "<path d=\"M258.1914,-365.4551C258.1914,-357.3828 258.1914,-347.6764 258.1914,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"261.6915,-338.5903 258.1914,-328.5904 254.6915,-338.5904 261.6915,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5042848768 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>5042848768</title>\n",
       "<polygon fill=\"none\" points=\"115.062,-219.5 115.062,-255.5 401.3208,-255.5 401.3208,-219.5 115.062,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258.1914\" y=\"-233.3\">ENC_BLSTM_2(lstm_2): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 5040844024&#45;&gt;5042848768 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>5040844024-&gt;5042848768</title>\n",
       "<path d=\"M258.1914,-292.4551C258.1914,-284.3828 258.1914,-274.6764 258.1914,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"261.6915,-265.5903 258.1914,-255.5904 254.6915,-265.5904 261.6915,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5175762560 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>5175762560</title>\n",
       "<polygon fill=\"none\" points=\"55.1416,-146.5 55.1416,-182.5 251.2412,-182.5 251.2412,-146.5 55.1416,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"153.1914\" y=\"-160.3\">FER_CONTEXT: RepeatVector</text>\n",
       "</g>\n",
       "<!-- 5042848768&#45;&gt;5175762560 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>5042848768-&gt;5175762560</title>\n",
       "<path d=\"M232.2363,-219.4551C218.7326,-210.0667 202.0492,-198.4678 187.4949,-188.3491\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"189.4204,-185.425 179.2118,-182.5904 185.4245,-191.1725 189.4204,-185.425\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5050794616 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>5050794616</title>\n",
       "<polygon fill=\"none\" points=\"274.6416,-146.5 274.6416,-182.5 463.7412,-182.5 463.7412,-146.5 274.6416,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"369.1914\" y=\"-160.3\">RC_CONTEXT: RepeatVector</text>\n",
       "</g>\n",
       "<!-- 5042848768&#45;&gt;5050794616 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>5042848768-&gt;5050794616</title>\n",
       "<path d=\"M285.6296,-219.4551C299.905,-210.0667 317.5418,-198.4678 332.9277,-188.3491\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"335.2522,-191.0095 341.6841,-182.5904 331.4059,-185.1609 335.2522,-191.0095\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5174828728 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>5174828728</title>\n",
       "<polygon fill=\"none\" points=\"59.3208,-73.5 59.3208,-109.5 225.062,-109.5 225.062,-73.5 59.3208,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"142.1914\" y=\"-87.3\">FER_DEC_LSTM: LSTM</text>\n",
       "</g>\n",
       "<!-- 5175762560&#45;&gt;5174828728 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>5175762560-&gt;5174828728</title>\n",
       "<path d=\"M150.4723,-146.4551C149.2559,-138.3828 147.7933,-128.6764 146.438,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"149.8684,-118.9572 144.9174,-109.5904 142.9465,-120.0003 149.8684,-118.9572\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5174711240 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>5174711240</title>\n",
       "<polygon fill=\"none\" points=\"292.8208,-73.5 292.8208,-109.5 451.562,-109.5 451.562,-73.5 292.8208,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"372.1914\" y=\"-87.3\">RC_DEC_LSTM: LSTM</text>\n",
       "</g>\n",
       "<!-- 5050794616&#45;&gt;5174711240 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>5050794616-&gt;5174711240</title>\n",
       "<path d=\"M369.933,-146.4551C370.2647,-138.3828 370.6636,-128.6764 371.0333,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"374.5343,-119.7257 371.448,-109.5904 367.5402,-119.4382 374.5343,-119.7257\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5169283144 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>5169283144</title>\n",
       "<polygon fill=\"none\" points=\"0,-.5 0,-36.5 240.3828,-36.5 240.3828,-.5 0,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"120.1914\" y=\"-14.3\">FER(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 5174828728&#45;&gt;5169283144 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>5174828728-&gt;5169283144</title>\n",
       "<path d=\"M136.7532,-73.4551C134.294,-65.2951 131.3316,-55.4652 128.5962,-46.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"131.88,-45.1551 125.6433,-36.5904 125.1777,-47.175 131.88,-45.1551\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5158709848 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>5158709848</title>\n",
       "<polygon fill=\"none\" points=\"258.5,-.5 258.5,-36.5 491.8828,-36.5 491.8828,-.5 258.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375.1914\" y=\"-14.3\">RC(dense_2): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 5174711240&#45;&gt;5158709848 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>5174711240-&gt;5158709848</title>\n",
       "<path d=\"M372.933,-73.4551C373.2647,-65.3828 373.6636,-55.6764 374.0333,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"377.5343,-46.7257 374.448,-36.5904 370.5402,-46.4382 377.5343,-46.7257\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "sequence = Input(shape=(MAXLEN_FE, EMBEDDING_SIZE), name='INPUT')\n",
    "mask = Masking(mask_value=0., name='MASK')(sequence)\n",
    "blstm = Bidirectional(LSTM(128, return_sequences=True, implementation=0), merge_mode='concat', name='ENC_BLSTM_1')(mask)\n",
    "blstm = Bidirectional(LSTM(64, return_sequences=False, implementation=0), merge_mode='concat', name='ENC_BLSTM_2')(blstm)\n",
    "rc = RepeatVector(MAXLEN_R, name='RC_CONTEXT')(blstm)\n",
    "fe = RepeatVector(MAXLEN_FE, name='FER_CONTEXT')(blstm)\n",
    "fe = LSTM(32, return_sequences=True, implementation=0, name='FER_DEC_LSTM')(fe)\n",
    "output_fe = TimeDistributed(Dense(5, activation='softmax'), name='FER')(fe)\n",
    "rc = LSTM(32, return_sequences=True, implementation=0, name='RC_DEC_LSTM')(rc)\n",
    "output_r = TimeDistributed(Dense(10, activation='softmax'), name='RC')(rc)\n",
    "model = Model(inputs=sequence, outputs=[output_fe, output_r])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[pre, rec, f1], loss_weights=[1., 1.])\n",
    "model.summary()\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "INPUT (InputLayer)               (None, 176, 128)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "MASK (Masking)                   (None, 176, 128)      0           INPUT[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "EN_BLSTM_1 (Bidirectional)       (None, 176, 256)      263168      MASK[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "EN_BLSTM_2 (Bidirectional)       (None, 176, 128)      164352      EN_BLSTM_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "RC_EN_LSTM (LSTM)                (None, 64)            49408       EN_BLSTM_2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "RC_CONTEXT (RepeatVector)        (None, 56, 64)        0           RC_EN_LSTM[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "FER_DE_LSTM (LSTM)               (None, 176, 32)       20608       EN_BLSTM_2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "RC_DE_LSTM (LSTM)                (None, 56, 32)        12416       RC_CONTEXT[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "FER (TimeDistributed)            (None, 176, 5)        165         FER_DE_LSTM[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "RC (TimeDistributed)             (None, 56, 9)         297         RC_DE_LSTM[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 510,414\n",
      "Trainable params: 510,414\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"556pt\" viewBox=\"0.00 0.00 477.88 556.00\" width=\"478pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 552)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-552 473.8828,-552 473.8828,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 5166773024 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>5166773024</title>\n",
       "<polygon fill=\"none\" points=\"169.6382,-511.5 169.6382,-547.5 295.7446,-547.5 295.7446,-511.5 169.6382,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232.6914\" y=\"-525.3\">INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 5166773584 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>5166773584</title>\n",
       "<polygon fill=\"none\" points=\"176.269,-438.5 176.269,-474.5 289.1138,-474.5 289.1138,-438.5 176.269,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232.6914\" y=\"-452.3\">MASK: Masking</text>\n",
       "</g>\n",
       "<!-- 5166773024&#45;&gt;5166773584 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>5166773024-&gt;5166773584</title>\n",
       "<path d=\"M232.6914,-511.4551C232.6914,-503.3828 232.6914,-493.6764 232.6914,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"236.1915,-484.5903 232.6914,-474.5904 229.1915,-484.5904 236.1915,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5166775712 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>5166775712</title>\n",
       "<polygon fill=\"none\" points=\"94.231,-365.5 94.231,-401.5 371.1519,-401.5 371.1519,-365.5 94.231,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232.6914\" y=\"-379.3\">EN_BLSTM_1(lstm_1): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 5166773584&#45;&gt;5166775712 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>5166773584-&gt;5166775712</title>\n",
       "<path d=\"M232.6914,-438.4551C232.6914,-430.3828 232.6914,-420.6764 232.6914,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"236.1915,-411.5903 232.6914,-401.5904 229.1915,-411.5904 236.1915,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5051589744 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>5051589744</title>\n",
       "<polygon fill=\"none\" points=\"94.231,-292.5 94.231,-328.5 371.1519,-328.5 371.1519,-292.5 94.231,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"232.6914\" y=\"-306.3\">EN_BLSTM_2(lstm_2): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 5166775712&#45;&gt;5051589744 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>5166775712-&gt;5051589744</title>\n",
       "<path d=\"M232.6914,-365.4551C232.6914,-357.3828 232.6914,-347.6764 232.6914,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"236.1915,-338.5903 232.6914,-328.5904 229.1915,-338.5904 236.1915,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5134267672 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>5134267672</title>\n",
       "<polygon fill=\"none\" points=\"72.9897,-219.5 72.9897,-255.5 222.3931,-255.5 222.3931,-219.5 72.9897,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"147.6914\" y=\"-233.3\">RC_EN_LSTM: LSTM</text>\n",
       "</g>\n",
       "<!-- 5051589744&#45;&gt;5134267672 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>5051589744-&gt;5134267672</title>\n",
       "<path d=\"M211.6802,-292.4551C201.055,-283.3299 187.9982,-272.1165 176.4559,-262.2036\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"178.6222,-259.4505 168.7555,-255.5904 174.0615,-264.7609 178.6222,-259.4505\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5166975856 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>5166975856</title>\n",
       "<polygon fill=\"none\" points=\"255.4897,-219.5 255.4897,-255.5 411.8931,-255.5 411.8931,-219.5 255.4897,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"333.6914\" y=\"-233.3\">FER_DE_LSTM: LSTM</text>\n",
       "</g>\n",
       "<!-- 5051589744&#45;&gt;5166975856 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>5051589744-&gt;5166975856</title>\n",
       "<path d=\"M257.6577,-292.4551C270.5257,-283.1545 286.3952,-271.6844 300.3016,-261.6332\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"302.6078,-264.2849 308.6623,-255.5904 298.5073,-258.6116 302.6078,-264.2849\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5031698328 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>5031698328</title>\n",
       "<polygon fill=\"none\" points=\"22.1416,-146.5 22.1416,-182.5 211.2412,-182.5 211.2412,-146.5 22.1416,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"116.6914\" y=\"-160.3\">RC_CONTEXT: RepeatVector</text>\n",
       "</g>\n",
       "<!-- 5134267672&#45;&gt;5031698328 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>5134267672-&gt;5031698328</title>\n",
       "<path d=\"M140.0285,-219.4551C136.4888,-211.1196 132.2091,-201.0416 128.2863,-191.8042\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"131.504,-190.4267 124.3736,-182.5904 125.0609,-193.1629 131.504,-190.4267\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5171420240 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>5171420240</title>\n",
       "<polygon fill=\"none\" points=\"41.9897,-73.5 41.9897,-109.5 191.3931,-109.5 191.3931,-73.5 41.9897,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"116.6914\" y=\"-87.3\">RC_DE_LSTM: LSTM</text>\n",
       "</g>\n",
       "<!-- 5031698328&#45;&gt;5171420240 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>5031698328-&gt;5171420240</title>\n",
       "<path d=\"M116.6914,-146.4551C116.6914,-138.3828 116.6914,-128.6764 116.6914,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"120.1915,-119.5903 116.6914,-109.5904 113.1915,-119.5904 120.1915,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5169495792 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>5169495792</title>\n",
       "<polygon fill=\"none\" points=\"229.5,-146.5 229.5,-182.5 469.8828,-182.5 469.8828,-146.5 229.5,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"349.6914\" y=\"-160.3\">FER(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 5166975856&#45;&gt;5169495792 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>5166975856-&gt;5169495792</title>\n",
       "<path d=\"M337.6465,-219.4551C339.4349,-211.2951 341.5895,-201.4652 343.5788,-192.3887\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"347.0042,-193.1079 345.7264,-182.5904 340.1665,-191.6091 347.0042,-193.1079\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5177673264 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>5177673264</title>\n",
       "<polygon fill=\"none\" points=\"0,-.5 0,-36.5 233.3828,-36.5 233.3828,-.5 0,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"116.6914\" y=\"-14.3\">RC(dense_2): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 5171420240&#45;&gt;5177673264 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>5171420240-&gt;5177673264</title>\n",
       "<path d=\"M116.6914,-73.4551C116.6914,-65.3828 116.6914,-55.6764 116.6914,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"120.1915,-46.5903 116.6914,-36.5904 113.1915,-46.5904 120.1915,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "sequence = Input(shape=(MAXLEN_FE, EMBEDDING_SIZE), name='INPUT')\n",
    "mask = Masking(mask_value=0., name='MASK')(sequence)\n",
    "blstm = Bidirectional(LSTM(128, return_sequences=True, implementation=0), merge_mode='concat', name='EN_BLSTM_1')(mask)\n",
    "blstm = Bidirectional(LSTM(64, return_sequences=True, implementation=0), merge_mode='concat', name='EN_BLSTM_2')(blstm)\n",
    "fe = LSTM(32, return_sequences=True, implementation=0, name='FER_DE_LSTM')(blstm)\n",
    "output_fe = TimeDistributed(Dense(5, activation='softmax'), name='FER')(fe)\n",
    "rc = LSTM(64, return_sequences=False, implementation=0, name='RC_EN_LSTM')(blstm)\n",
    "rc = RepeatVector(MAXLEN_R, name='RC_CONTEXT')(rc)\n",
    "rc = LSTM(32, return_sequences=True, implementation=0, name='RC_DE_LSTM')(rc)\n",
    "output_r = TimeDistributed(Dense(9, activation='softmax'), name='RC')(rc)\n",
    "model = Model(inputs=sequence, outputs=[output_fe, output_r])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[pre, rec, f1], loss_weights=[1., 1.])\n",
    "model.summary()\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for e in range(NUM_EPOCHS):    \n",
    "    print('EPOCHS', e+1)\n",
    "    h = model.fit(x=lXfe, \n",
    "                  y=[lYfe, lYr], \n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=1,\n",
    "                  verbose=1, \n",
    "                  #validation_split=0.15, \n",
    "                  shuffle=True)   \n",
    "    score = integrated_final_macro_f1_score(lXfe, [lYfe, lYr], model)\n",
    "    print('FER final macro-averaged f1-score = %.12f' % (score[0]))\n",
    "    print('RC final macro-averaged f1-score = %.12f' % (score[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### With Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def build_model(log, fer_lw, rc_lw):\n",
    "    \"\"\"\n",
    "    Build Integrated Model\n",
    "    \"\"\"\n",
    "    K.clear_session()\n",
    "    sequence = Input(shape=(MAXLEN_NER, EMBEDDING_SIZE), name='INPUT')\n",
    "    mask = Masking(mask_value=0., name='MASK')(sequence)\n",
    "    blstm = Bidirectional(LSTM(128, return_sequences=True, implementation=2), merge_mode='concat', name='EN_BLSTM_1')(mask)\n",
    "    blstm = Bidirectional(LSTM(64, return_sequences=True, implementation=2), merge_mode='concat', name='EN_BLSTM_2')(blstm)\n",
    "    fe = LSTM(32, return_sequences=True, implementation=2, name='FER_DE_LSTM')(blstm)\n",
    "    output_fe = TimeDistributed(Dense(5, activation='softmax'), name='FER')(fe)\n",
    "    rc = LSTM(64, return_sequences=False, implementation=2, name='RC_EN_LSTM')(blstm)\n",
    "    rc = RepeatVector(MAXLEN_R, name='RC_CONTEXT')(rc)\n",
    "    rc = LSTM(32, return_sequences=True, implementation=2, name='RC_DE_LSTM')(rc)\n",
    "    output_r = TimeDistributed(Dense(9, activation='softmax'), name='RC')(rc)\n",
    "    model = Model(inputs=sequence, outputs=[output_fe, output_r])\n",
    "    tensorboard = TensorBoard(log_dir=log, histogram_freq=1, write_graph=False, write_images=False)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1], loss_weights=[fer_lw, rc_lw])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train(train_model, v):\n",
    "    \"\"\"\n",
    "    Trian Model\n",
    "    \"\"\"\n",
    "    h = train_model.fit(x=Xfe, \n",
    "                    y=[Yfe, Yr], \n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=1,\n",
    "                    verbose=v, \n",
    "                    validation_split=0.15, \n",
    "                    shuffle=True,\n",
    "                    callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "for FER_LW in [1.]:\n",
    "    for RC_LW in [0.5]:\n",
    "        log_string = 'tb_logs/fer_lw={},rc_lw={}'.format(FER_LW, RC_LW)\n",
    "        model = build_model(log_string, FER_LW, RC_LW)\n",
    "        \n",
    "        train(model, v=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relation Classification: Bi-LSTM+LSTM(+FE wordvector Pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "INPUT (InputLayer)               (None, 176, 128)      0                                            \n",
      "____________________________________________________________________________________________________\n",
      "MASK (Masking)                   (None, 176, 128)      0           INPUT[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "ENC_BLSTM_1 (Bidirectional)      (None, 176, 256)      263168      MASK[0][0]                       \n",
      "____________________________________________________________________________________________________\n",
      "ENC_BLSTM_2 (Bidirectional)      (None, 256)           394240      ENC_BLSTM_1[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "CONTEXT (RepeatVector)           (None, 56, 256)       0           ENC_BLSTM_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "FE_INPUT (InputLayer)            (None, 56, 256)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 56, 512)       0           CONTEXT[0][0]                    \n",
      "                                                                   FE_INPUT[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "DEC_LSTM (LSTM)                  (None, 56, 128)       328192      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "RC_OUTPUT (TimeDistributed)      (None, 56, 9)         1161        DEC_LSTM[0][0]                   \n",
      "====================================================================================================\n",
      "Total params: 986,761\n",
      "Trainable params: 986,761\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"556pt\" viewBox=\"0.00 0.00 399.85 556.00\" width=\"400pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 552)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-552 395.8516,-552 395.8516,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 5139952248 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>5139952248</title>\n",
       "<polygon fill=\"none\" points=\"80.0762,-511.5 80.0762,-547.5 206.1826,-547.5 206.1826,-511.5 80.0762,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-525.3\">INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 5148472376 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>5148472376</title>\n",
       "<polygon fill=\"none\" points=\"86.707,-438.5 86.707,-474.5 199.5518,-474.5 199.5518,-438.5 86.707,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-452.3\">MASK: Masking</text>\n",
       "</g>\n",
       "<!-- 5139952248&#45;&gt;5148472376 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>5139952248-&gt;5148472376</title>\n",
       "<path d=\"M143.1294,-511.4551C143.1294,-503.3828 143.1294,-493.6764 143.1294,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-484.5903 143.1294,-474.5904 139.6295,-484.5904 146.6295,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5040817544 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>5040817544</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 286.2588,-401.5 286.2588,-365.5 0,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-379.3\">ENC_BLSTM_1(lstm_1): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 5148472376&#45;&gt;5040817544 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>5148472376-&gt;5040817544</title>\n",
       "<path d=\"M143.1294,-438.4551C143.1294,-430.3828 143.1294,-420.6764 143.1294,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-411.5903 143.1294,-401.5904 139.6295,-411.5904 146.6295,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5148354824 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>5148354824</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 286.2588,-328.5 286.2588,-292.5 0,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-306.3\">ENC_BLSTM_2(lstm_2): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 5040817544&#45;&gt;5148354824 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>5040817544-&gt;5148354824</title>\n",
       "<path d=\"M143.1294,-365.4551C143.1294,-357.3828 143.1294,-347.6764 143.1294,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-338.5903 143.1294,-328.5904 139.6295,-338.5904 146.6295,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5158640104 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>5158640104</title>\n",
       "<polygon fill=\"none\" points=\"61.4175,-219.5 61.4175,-255.5 224.8413,-255.5 224.8413,-219.5 61.4175,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"143.1294\" y=\"-233.3\">CONTEXT: RepeatVector</text>\n",
       "</g>\n",
       "<!-- 5148354824&#45;&gt;5158640104 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>5148354824-&gt;5158640104</title>\n",
       "<path d=\"M143.1294,-292.4551C143.1294,-284.3828 143.1294,-274.6764 143.1294,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"146.6295,-265.5903 143.1294,-255.5904 139.6295,-265.5904 146.6295,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5150826056 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>5150826056</title>\n",
       "<polygon fill=\"none\" points=\"143.8101,-146.5 143.8101,-182.5 316.4487,-182.5 316.4487,-146.5 143.8101,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"230.1294\" y=\"-160.3\">concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 5158640104&#45;&gt;5150826056 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>5158640104-&gt;5150826056</title>\n",
       "<path d=\"M164.635,-219.4551C175.5102,-210.3299 188.8742,-199.1165 200.6881,-189.2036\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"203.1589,-191.6994 208.5697,-182.5904 198.6594,-186.337 203.1589,-191.6994\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5163456216 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>5163456216</title>\n",
       "<polygon fill=\"none\" points=\"242.4072,-219.5 242.4072,-255.5 391.8516,-255.5 391.8516,-219.5 242.4072,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"317.1294\" y=\"-233.3\">FE_INPUT: InputLayer</text>\n",
       "</g>\n",
       "<!-- 5163456216&#45;&gt;5150826056 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>5163456216-&gt;5150826056</title>\n",
       "<path d=\"M295.6238,-219.4551C284.7486,-210.3299 271.3846,-199.1165 259.5707,-189.2036\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"261.5994,-186.337 251.6891,-182.5904 257.0999,-191.6994 261.5994,-186.337\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4939379040 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>4939379040</title>\n",
       "<polygon fill=\"none\" points=\"163.5967,-73.5 163.5967,-109.5 296.6621,-109.5 296.6621,-73.5 163.5967,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"230.1294\" y=\"-87.3\">DEC_LSTM: LSTM</text>\n",
       "</g>\n",
       "<!-- 5150826056&#45;&gt;4939379040 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>5150826056-&gt;4939379040</title>\n",
       "<path d=\"M230.1294,-146.4551C230.1294,-138.3828 230.1294,-128.6764 230.1294,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"233.6295,-119.5903 230.1294,-109.5904 226.6295,-119.5904 233.6295,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5152431632 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>5152431632</title>\n",
       "<polygon fill=\"none\" points=\"82.3276,-.5 82.3276,-36.5 377.9312,-36.5 377.9312,-.5 82.3276,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"230.1294\" y=\"-14.3\">RC_OUTPUT(dense_1): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 4939379040&#45;&gt;5152431632 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>4939379040-&gt;5152431632</title>\n",
       "<path d=\"M230.1294,-73.4551C230.1294,-65.3828 230.1294,-55.6764 230.1294,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"233.6295,-46.5903 230.1294,-36.5904 226.6295,-46.5904 233.6295,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.clear_session()\n",
    "sequence = Input(shape=(MAXLEN_FE, EMBEDDING_SIZE), name='INPUT')\n",
    "mask = Masking(mask_value=0., name='MASK')(sequence)\n",
    "en_1 = Bidirectional(LSTM(128, return_sequences=True, implementation=0), merge_mode='concat', name='ENC_BLSTM_1')(mask)\n",
    "en_2 = Bidirectional(LSTM(128, return_sequences=False, implementation=0), merge_mode='concat', name='ENC_BLSTM_2')(en_1)\n",
    "#fe = LSTM(32, return_sequences=True, implementation=0, name='FER_DE_LSTM')(blstm)\n",
    "#output_fe = TimeDistributed(Dense(5, activation='softmax'), name='FER')(fe)\n",
    "#rc = LSTM(64, return_sequences=False, implementation=0, name='RC_EN_LSTM')(blstm)\n",
    "context = RepeatVector(MAXLEN_R, name='CONTEXT')(en_2)\n",
    "fev = Input(shape=(MAXLEN_R, EMBEDDING_SIZE*2), name='FE_INPUT')\n",
    "de = concatenate([context, fev])\n",
    "de = LSTM(128, return_sequences=True, implementation=0, name='DEC_LSTM')(de)\n",
    "output_r = TimeDistributed(Dense(9, activation='softmax'), name='RC_OUTPUT')(de)\n",
    "#model = Model(inputs=sequence, outputs=[output_fe, output_r])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[pre, rec, f1], loss_weights=[1., 1.])\n",
    "model = Model(inputs=[sequence, fev], outputs=output_r)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[pre, rec, f1])\n",
    "model.summary()\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = model.fit(x=[lXfe, lXfev], \n",
    "                  y=lYr, \n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=NUM_EPOCHS,\n",
    "                  verbose=1, \n",
    "                  validation_split=0.15, \n",
    "                  shuffle=True)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for e in range(NUM_EPOCHS):    \n",
    "    print('EPOCHS', e+1)\n",
    "    h = model.fit(x=[lXfe, lXfev], \n",
    "                  y=lYr, \n",
    "                  batch_size=BATCH_SIZE,\n",
    "                  epochs=1,\n",
    "                  verbose=1, \n",
    "                  #validation_split=0.15, \n",
    "                  shuffle=True)   \n",
    "    print('final_macro-averaged f1-score = %.12f' % (final_macro_f1_score(lXfe, lYr, r_model)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrated Model: Bi-LSTM+LSTM(Bi-LSTM Shared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "sequence = Input(shape=(MAXLEN_FE, EMBEDDING_SIZE), name='FE_Seq_INPUT')\n",
    "mask = Masking(mask_value=0., name='MASK')(sequence)\n",
    "en_1 = Bidirectional(LSTM(128, return_sequences=True, implementation=0), merge_mode='concat', name='EN_BLSTM_1')(mask)\n",
    "en_2 = Bidirectional(LSTM(128, return_sequences=False, implementation=0), merge_mode='concat', name='EN_BLSTM_2')(en_1)\n",
    "#fe = LSTM(32, return_sequences=True, implementation=0, name='FER_DE_LSTM')(blstm)\n",
    "#output_fe = TimeDistributed(Dense(5, activation='softmax'), name='FER')(fe)\n",
    "#rc = LSTM(64, return_sequences=False, implementation=0, name='RC_EN_LSTM')(blstm)\n",
    "context = RepeatVector(MAXLEN_R, name='CONTEXT')(en_2)\n",
    "fev = Input(shape=(MAXLEN_R, EMBEDDING_SIZE*2), name='FE_VecP_INPUT')\n",
    "de = concatenate([context, fev])\n",
    "de = LSTM(128, return_sequences=True, implementation=0, name='DE_LSTM')(de)\n",
    "output_r = TimeDistributed(Dense(9, activation='softmax'), name='RC')(de)\n",
    "#model = Model(inputs=sequence, outputs=[output_fe, output_r])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[pre, rec, f1], loss_weights=[1., 1.])\n",
    "model = Model(inputs=[sequence, fev], outputs=output_r)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[pre, rec, f1])\n",
    "model.summary()\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def f1_plot(f1_1, f1_2, log):\n",
    "#    \"\"\"\n",
    "#    Plot f1-score\n",
    "#    \"\"\"\n",
    "#    fig, ax = plt.subplots()\n",
    "#    fer_f1 = np.array(f1_1)\n",
    "#    rc_f1 = np.array(f1_2)\n",
    "#    plt.title(log[10:] + ' f1-score')\n",
    "#    plt.plot(fer_f1, label='FER final macro-averaged f1-score')\n",
    "#    plt.plot(rc_f1, label='RC final macro-averaged f1-score')\n",
    "#    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def train(train_model, log, v):\n",
    "#    \"\"\"\n",
    "#    Trian Model\n",
    "#    \"\"\"\n",
    "#    FER_f1 = []\n",
    "#    RC_f1 = []\n",
    "#    train_model.fit(x=Xfe, \n",
    "#                    y=[Yfe, Yr], \n",
    "#                    batch_size=BATCH_SIZE,\n",
    "#                    epochs=1,\n",
    "#                    verbose=v, \n",
    "#                    validation_split=0.15, \n",
    "#                    shuffle=True,\n",
    "#                    callbacks=[tensorboard])\n",
    "#    score = integrated_final_macro_f1_score(Xfe, [Yfe, Yr], train_model)\n",
    "#    FER_f1.append(score[0])\n",
    "#    RC_f1.append(score[1])\n",
    "#        print('FER final macro-averaged f1-score = %.12f' % (score[0]))\n",
    "#        print('RC final macro-averaged f1-score = %.12f' % (score[1]))\n",
    "#    f1_plot(FER_f1, RC_f1, log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#h = model.fit(x=Xner, y=Yr, \n",
    "#                  batch_size=BATCH_SIZE,\n",
    "#                  epochs=NUM_EPOCHS,\n",
    "#                  verbose=1, \n",
    "#                  validation_split=0.15, \n",
    "#                  shuffle=True)              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gen_train = data_generator(Xtrain, Ytrain, BATCH_SIZE)\n",
    "#gen_val = data_generator(Xval, Yval, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tensorboard = TensorBoard(log_dir='tb_logs/1', histogram_freq=1, write_graph=True, write_images=True)\n",
    "#filepath = 'cp_logs/weights.{epoch:03d}-{val_macro_f1_score:.12f}.hdf5'\n",
    "#checkpoint = ModelCheckpoint(filepath, monitor='val_macro_f1_score', verbose=0, save_best_only=True)\n",
    "#earlystopping = EarlyStopping(monitor='val_loss', verbose=1, patience=2)\n",
    "#reducelr = ReduceLROnPlateau(monitor='val_loss', verbose=1, factor=0.8, patience=3, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#h = model.fit_generator(gen_train, \n",
    "#                        steps_per_epoch=len(Xtrain)//BATCH_SIZE, \n",
    "#                        epochs=NUM_EPOCHS, \n",
    "#                        validation_data=gen_val, \n",
    "#                        validation_steps=len(Xval)//BATCH_SIZE,\n",
    "#                        verbose=1,\n",
    "#                        callbacks=[tensorboard, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#F1_score = []\n",
    "#for e in range(NUM_EPOCHS):    \n",
    "#    print('EPOCHS', e+1)\n",
    "#    h = model.fit_generator(gen_train, \n",
    "#                            steps_per_epoch=len(Xtrain)//BATCH_SIZE, \n",
    "#                            epochs=1, \n",
    "#                            validation_data=gen_val, \n",
    "#                            validation_steps=len(Xval)//BATCH_SIZE,\n",
    "#                            verbose=1)\n",
    "#    F1_score.append(macro_f1_score(Xval, Yval))\n",
    "#    print('macro-averaged f1-score = %.6f' % (macro_f1_score(Xval, Yval)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model.save_weights('train_1.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def predict_data(data, batch_size):\n",
    "#    \"\"\"\n",
    "#    输出预测结果（原始数据，未整理）\n",
    "#    \"\"\"\n",
    "#    data = np.array(data)\n",
    "#    batches = [range(batch_size*i, min(len(data), batch_size*(i+1))) for i in range(len(data)//batch_size)]\n",
    "#    p = model.predict(np.array(list(map(gen_x, data[batches[0]]))), verbose=1)\n",
    "#    for i in batches[1:]:\n",
    "#        print(min(i), 'done.')\n",
    "#        p = np.vstack((p, model.predict(np.array(list(map(gen_x, data[i]))), verbose=1)))\n",
    "#    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#predict = predict_data(Xtest, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ww = list(set(w))\n",
    "#ww.sort(key = w.index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
