{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#搜狐新闻数据\" data-toc-modified-id=\"搜狐新闻数据-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>搜狐新闻数据</a></div><div class=\"lev1 toc-item\"><a href=\"#全网新闻数据\" data-toc-modified-id=\"全网新闻数据-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>全网新闻数据</a></div><div class=\"lev1 toc-item\"><a href=\"#任务数据\" data-toc-modified-id=\"任务数据-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>任务数据</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import jieba\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load date from file\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, 'r', encoding='gb18030') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mdata(path):\n",
    "    \"\"\"\n",
    "    Load mission date from file\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file) as f:\n",
    "        lines = f.readlines()\n",
    "    for line in lines:\n",
    "        item = json.loads(line)\n",
    "        data.append(item['abstract'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "not_cuts = re.compile(u'([\\da-zA-Z\\.]+)|《(.*?)》|“(.{1,10})”')\n",
    "re_replace = re.compile(u'[^\\u4e00-\\u9fa50-9a-zA-Z\\%《》\\(\\)（）“”·\\.]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def newcut(s):\n",
    "    \"\"\"\n",
    "    Word Segmentation\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    j = 0\n",
    "    s = re_replace.sub(' ', s)\n",
    "    \n",
    "    for i in not_cuts.finditer(s):\n",
    "        result.extend(jieba.lcut(s[j:i.start()], HMM=False))\n",
    "        if s[i.start()] in [u'《', u'“']:\n",
    "            result.extend([s[i.start()], s[i.start()+1:i.end()-1], s[i.end()-1]])\n",
    "        else:\n",
    "            result.append(s[i.start():i.end()])\n",
    "        j = i.end()\n",
    "    result.extend(jieba.lcut(s[j:], HMM=False))\n",
    "    return result\n",
    "\n",
    "def clean(s):\n",
    "    \"\"\"\n",
    "    Clean data\n",
    "    \"\"\"\n",
    "    for i in range(len(s)):\n",
    "        if s[i] == ' ':\n",
    "            s[i] = None\n",
    "        if s[i] == '(':\n",
    "            for j in range(i+1, len(s)):\n",
    "                if s[j] == ')':\n",
    "                    for k in range(i, j+1):\n",
    "                        s[k] = None\n",
    "        if s[i] == '（':\n",
    "            for j in range(i+1, len(s)):\n",
    "                if s[j] == '）':\n",
    "                    for k in range(i, j+1):\n",
    "                        s[k] = None\n",
    "        if s[i] == '%':\n",
    "            if s[i-1] != None:\n",
    "                s[i-1] = s[i-1]+'%'\n",
    "            s[i] = None    \n",
    "    return [i for i in s if i != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse(html):\n",
    "    pattern = re.compile('<content>(.*?)</content>', re.S)\n",
    "    items = re.findall(pattern, html)\n",
    "    for item in tqdm(items):\n",
    "        yield {\n",
    "            'content': item\n",
    "        }\n",
    "        \n",
    "def write_to_file(content, filename):\n",
    "    with open(filename, 'a', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(content, ensure_ascii=False) + '\\n')\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搜狐新闻数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/lizhn7/Downloads/DATA/chinese_news/news_sohusite_xml.dat'\n",
    "rawData = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1411996 [00:00<?, ?it/s]Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/kz/hqjl_dfx3g3_2vxylxlj1s940000gn/T/jieba.cache\n",
      "Loading model cost 1.069 seconds.\n",
      "Prefix dict has been built succesfully.\n",
      "100%|██████████| 1411996/1411996 [50:37<00:00, 464.86it/s] \n"
     ]
    }
   ],
   "source": [
    "content = parse(rawData)\n",
    "filename = '/Users/lizhn7/Downloads/DATA/chinese_news/content_1.json'\n",
    "for c in content:\n",
    "    if c['content'] != '':\n",
    "        write_to_file({'contWords': clean(newcut(c['content']))}, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1298156 /Users/lizhn7/Downloads/DATA/chinese_news/content_1.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/lizhn7/Downloads/DATA/chinese_news/content_1.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 全网新闻数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/lizhn7/Downloads/DATA/chinese_news/news_tensite_xml.dat'\n",
    "rawData = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1294233/1294233 [49:44<00:00, 433.70it/s] \n"
     ]
    }
   ],
   "source": [
    "content = parse(rawData)\n",
    "filename = '/Users/lizhn7/Downloads/DATA/chinese_news/content_2.json'\n",
    "for c in content:\n",
    "    if c['content'] != '':\n",
    "        write_to_file({'contWords': clean(newcut(c['content']))}, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1143529 /Users/lizhn7/Downloads/DATA/chinese_news/content_2.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/lizhn7/Downloads/DATA/chinese_news/content_2.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rawData = load_mdata('/Users/lizhn7/Documents/Github/深度炼丹炉/causal_relation_extraction/raw_data.json')\n",
    "filename = '/Users/lizhn7/Downloads/DATA/chinese_news/content_3.json'\n",
    "for s in rawData:\n",
    "    write_to_file({'contWords': clean(newcut(s))}, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   21273 /Users/lizhn7/Downloads/DATA/chinese_news/content_3.json\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l /Users/lizhn7/Downloads/DATA/chinese_news/content_3.json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
