{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load Dataset from File\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_path = 'data/small_vocab_en'\n",
    "target_path = 'data/small_vocab_fr'\n",
    "source_text = load_data(source_path)\n",
    "target_text = load_data(target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of English unique words: \t\t227\n",
      "Number of English sentences: \t\t\t137861\n",
      "Average number of words in a sentence: \t\t13.225278\n"
     ]
    }
   ],
   "source": [
    "en_sentences = source_text.split('\\n')\n",
    "word_counts = [len(sentence.split()) for sentence in en_sentences]\n",
    "\n",
    "print('Number of English unique words: \\t\\t{}'.format(len({word: None for word in source_text.split()})))\n",
    "print('Number of English sentences: \\t\\t\\t{}'.format(len(en_sentences)))\n",
    "print('Average number of words in a sentence: \\t\\t{:f}'.format(np.average(word_counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English sentences 0 to 10:\n",
      "new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "the united states is usually chilly during july , and it is usually freezing in november .\n",
      "california is usually quiet during march , and it is usually hot in june .\n",
      "the united states is sometimes mild during june , and it is cold in september .\n",
      "your least liked fruit is the grape , but my least liked is the apple .\n",
      "his favorite fruit is the orange , but my favorite is the grape .\n",
      "paris is relaxing during december , but it is usually chilly in july .\n",
      "new jersey is busy during spring , and it is never hot in march .\n",
      "our least liked fruit is the lemon , but my least liked is the grape .\n",
      "the united states is sometimes busy during january , and it is sometimes warm in november .\n"
     ]
    }
   ],
   "source": [
    "view_sentence_range = (0, 10)\n",
    "\n",
    "print('English sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(source_text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "French sentences 0 to 10:\n",
      "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
      "california est généralement calme en mars , et il est généralement chaud en juin .\n",
      "les états-unis est parfois légère en juin , et il fait froid en septembre .\n",
      "votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .\n",
      "son fruit préféré est l'orange , mais mon préféré est le raisin .\n",
      "paris est relaxant en décembre , mais il est généralement froid en juillet .\n",
      "new jersey est occupé au printemps , et il est jamais chaude en mars .\n",
      "notre fruit est moins aimé le citron , mais mon moins aimé est le raisin .\n",
      "les états-unis est parfois occupé en janvier , et il est parfois chaud en novembre .\n"
     ]
    }
   ],
   "source": [
    "print('French sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(target_text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vocab(text):\n",
    "    vocab_counts = Counter(w for t in text for w in t.split())\n",
    "    vocab = sorted(vocab_counts, key=vocab_counts.get, reverse=True)\n",
    "    return vocab, vocab_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fr_sentences = target_text.split('\\n')\n",
    "en_vocab, en_vocab_counts = get_vocab(en_sentences)\n",
    "fr_vocab, fr_vocab_counts = get_vocab(fr_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137861"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['est', '.', ',', 'en', 'il', 'les', 'mais', 'et', 'la', 'parfois', 'jamais', 'le', \"l'\", 'généralement', 'moins', 'au', 'aimé', 'fruit', 'préféré', 'agréable', 'froid', 'son', 'chaud', 'de', 'plus', 'automne', 'mois', 'à', 'elle', 'citrons', 'paris', 'inde', 'états-unis', 'france', 'jersey', 'new', 'chine', 'pendant', 'pamplemousse', 'mon', 'votre', 'juin', 'printemps', 'janvier', 'hiver', 'mars', 'été', 'mai', 'septembre', 'juillet']\n",
      "355\n"
     ]
    }
   ],
   "source": [
    "print(fr_vocab[:50])\n",
    "print(len(fr_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pad = 0\n",
    "eos = 1\n",
    "unk = 2\n",
    "go = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_idx(vocab, vocab_counts):\n",
    "    word2index = {w: i+4 for i, w in enumerate(vocab)}\n",
    "    word2index['<PAD>'] = pad\n",
    "    word2index['<EOS>'] = eos\n",
    "    word2index['<UNK>'] = unk\n",
    "    word2index['<GO>'] = go\n",
    "    \n",
    "    index2word = {i: w for w, i in word2index.items()}\n",
    "    \n",
    "    return word2index, index2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_word2index, en_index2word = get_idx(en_vocab, en_vocab_counts)\n",
    "fr_word2index, fr_index2word = get_idx(fr_vocab, fr_vocab_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "source_id = [[en_word2index[w] for w in s.split()] for s in en_sentences]\n",
    "target_id = [[fr_word2index[w] for w in s.split()+['<EOS>']] for s in fr_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/id.pkl', 'wb') as fp:\n",
    "    pickle.dump((en_word2index, en_index2word,\n",
    "                 fr_word2index, fr_index2word,\n",
    "                 source_id, target_id), fp, -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/id.pkl', 'rb') as fp:\n",
    "    en_word2index, en_index2word, fr_word2index, fr_index2word, source_id, target_id = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.utils import np_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_length = max([len(s) for s in source_id+target_id])\n",
    "MAX_LEN = sequence_length\n",
    "EN_VOCAB_SIZE = len(en_word2index)\n",
    "FR_VOCAB_SIZE = len(fr_word2index)\n",
    "pad = 0\n",
    "eos = 1\n",
    "unk = 2\n",
    "go = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_seq(source_id, target_id):\n",
    "    new_source_id = sequence.pad_sequences(source_id, maxlen=MAX_LEN, value=pad,\n",
    "                                           padding='post')\n",
    "    new_target_id = sequence.pad_sequences(target_id, maxlen=MAX_LEN, value=pad,\n",
    "                                           padding='post')\n",
    "    \n",
    "    target_id_label = np.zeros((len(new_target_id), MAX_LEN, FR_VOCAB_SIZE))\n",
    "    for i, t in enumerate(new_target_id):\n",
    "        target_id_label[i, :, :] = np_utils.to_categorical(t, FR_VOCAB_SIZE)\n",
    "        \n",
    "    new_target_id = sequence.pad_sequences(new_target_id, maxlen=MAX_LEN+1, value=go,\n",
    "                                           padding='pre')\n",
    "    new_target_id = sequence.pad_sequences(new_target_id, maxlen=MAX_LEN, truncating='post')\n",
    "    \n",
    "    \n",
    "    return new_source_id, new_target_id, target_id_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_X, fr_X, Y = convert_seq(source_id, target_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = np.column_stack((en_X, fr_X))\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_Xtrain = Xtrain[:, :24]\n",
    "fr_Xtrain = Xtrain[:, 24:]\n",
    "en_Xval = Xval[:, :24]\n",
    "fr_Xval = Xval[:, 24:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 32\n",
    "BATCH_SIZE = 64\n",
    "RNN_SIZE = 128\n",
    "RNN_LAYERS = 2\n",
    "ENCODING_EMBEDDING_SIZE = 50\n",
    "DECODING_EMBEDDING_SIZE = 50\n",
    "LEARNING_RATE = 0.02\n",
    "DROPOUT_RATE = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.core import Dropout, RepeatVector, Dense\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "en_input = Input(shape=(MAX_LEN,), dtype='int32', name='en_input')\n",
    "enc_en = Embedding(input_dim=EN_VOCAB_SIZE, output_dim=ENCODING_EMBEDDING_SIZE, \n",
    "                   input_length=MAX_LEN, name='en_emb')(en_input)\n",
    "enc_en = Dropout(DROPOUT_RATE)(enc_en)\n",
    "if RNN_LAYERS == 1:\n",
    "    enc_en = LSTM(RNN_SIZE, name='enc_lstm_1')(enc_en)\n",
    "else:    \n",
    "    for i in range(RNN_LAYERS-1):\n",
    "        enc_en = LSTM(RNN_SIZE, return_sequences=True, name='enc_lstm_%d'%(i+1))(enc_en)\n",
    "        enc_en = Dropout(DROPOUT_RATE)(enc_en)\n",
    "    enc_en = LSTM(RNN_SIZE, name='enc_lstm_3')(enc_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "context = RepeatVector(MAX_LEN, name='context')(enc_en)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fr_input = Input(shape=(MAX_LEN,), dtype='int32', name='fr_input')\n",
    "dec_fr = Embedding(input_dim=FR_VOCAB_SIZE, output_dim=DECODING_EMBEDDING_SIZE,\n",
    "                   input_length=MAX_LEN, name='fr_emb')(fr_input)\n",
    "dec_fr = Dropout(DROPOUT_RATE)(dec_fr)\n",
    "dec_fr = concatenate([context, dec_fr], axis=-1)\n",
    "for i in range(RNN_LAYERS):\n",
    "    dec_fr = LSTM(RNN_SIZE, return_sequences=True, name='dec_lstm_%d'%(i+1))(dec_fr)\n",
    "    dec_fr = Dropout(DROPOUT_RATE)(dec_fr)\n",
    "dec_fr = TimeDistributed(Dense(FR_VOCAB_SIZE, activation='softmax', name='softmax'))(dec_fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[en_input, fr_input], outputs=dec_fr)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"921pt\" viewBox=\"0.00 0.00 327.70 921.00\" width=\"328pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 917)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-917 323.7002,-917 323.7002,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 14570590104 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>14570590104</title>\n",
       "<polygon fill=\"none\" points=\"16.562,-876.5 16.562,-912.5 151.1382,-912.5 151.1382,-876.5 16.562,-876.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.8501\" y=\"-890.3\">en_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 14570590048 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>14570590048</title>\n",
       "<polygon fill=\"none\" points=\"17.7241,-803.5 17.7241,-839.5 149.9761,-839.5 149.9761,-803.5 17.7241,-803.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.8501\" y=\"-817.3\">en_emb: Embedding</text>\n",
       "</g>\n",
       "<!-- 14570590104&#45;&gt;14570590048 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>14570590104-&gt;14570590048</title>\n",
       "<path d=\"M83.8501,-876.4551C83.8501,-868.3828 83.8501,-858.6764 83.8501,-849.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"87.3502,-849.5903 83.8501,-839.5904 80.3502,-849.5904 87.3502,-849.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 14570594880 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>14570594880</title>\n",
       "<polygon fill=\"none\" points=\"20.0483,-730.5 20.0483,-766.5 147.6519,-766.5 147.6519,-730.5 20.0483,-730.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.8501\" y=\"-744.3\">dropout_1: Dropout</text>\n",
       "</g>\n",
       "<!-- 14570590048&#45;&gt;14570594880 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>14570590048-&gt;14570594880</title>\n",
       "<path d=\"M83.8501,-803.4551C83.8501,-795.3828 83.8501,-785.6764 83.8501,-776.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"87.3502,-776.5903 83.8501,-766.5904 80.3502,-776.5904 87.3502,-776.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 14570595328 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>14570595328</title>\n",
       "<polygon fill=\"none\" points=\"21.2139,-657.5 21.2139,-693.5 146.4863,-693.5 146.4863,-657.5 21.2139,-657.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.8501\" y=\"-671.3\">enc_lstm_1: LSTM</text>\n",
       "</g>\n",
       "<!-- 14570594880&#45;&gt;14570595328 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>14570594880-&gt;14570595328</title>\n",
       "<path d=\"M83.8501,-730.4551C83.8501,-722.3828 83.8501,-712.6764 83.8501,-703.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"87.3502,-703.5903 83.8501,-693.5904 80.3502,-703.5904 87.3502,-703.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 24078636592 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>24078636592</title>\n",
       "<polygon fill=\"none\" points=\"20.0483,-584.5 20.0483,-620.5 147.6519,-620.5 147.6519,-584.5 20.0483,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.8501\" y=\"-598.3\">dropout_2: Dropout</text>\n",
       "</g>\n",
       "<!-- 14570595328&#45;&gt;24078636592 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>14570595328-&gt;24078636592</title>\n",
       "<path d=\"M83.8501,-657.4551C83.8501,-649.3828 83.8501,-639.6764 83.8501,-630.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"87.3502,-630.5903 83.8501,-620.5904 80.3502,-630.5904 87.3502,-630.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 24078638272 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>24078638272</title>\n",
       "<polygon fill=\"none\" points=\"21.2139,-511.5 21.2139,-547.5 146.4863,-547.5 146.4863,-511.5 21.2139,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.8501\" y=\"-525.3\">enc_lstm_3: LSTM</text>\n",
       "</g>\n",
       "<!-- 24078636592&#45;&gt;24078638272 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>24078636592-&gt;24078638272</title>\n",
       "<path d=\"M83.8501,-584.4551C83.8501,-576.3828 83.8501,-566.6764 83.8501,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"87.3502,-557.5903 83.8501,-547.5904 80.3502,-557.5904 87.3502,-557.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 24096892072 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>24096892072</title>\n",
       "<polygon fill=\"none\" points=\"170.5068,-584.5 170.5068,-620.5 301.1934,-620.5 301.1934,-584.5 170.5068,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235.8501\" y=\"-598.3\">fr_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 24096892184 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>24096892184</title>\n",
       "<polygon fill=\"none\" points=\"171.6689,-511.5 171.6689,-547.5 300.0313,-547.5 300.0313,-511.5 171.6689,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235.8501\" y=\"-525.3\">fr_emb: Embedding</text>\n",
       "</g>\n",
       "<!-- 24096892072&#45;&gt;24096892184 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>24096892072-&gt;24096892184</title>\n",
       "<path d=\"M235.8501,-584.4551C235.8501,-576.3828 235.8501,-566.6764 235.8501,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"239.3502,-557.5903 235.8501,-547.5904 232.3502,-557.5904 239.3502,-557.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 14570487256 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>14570487256</title>\n",
       "<polygon fill=\"none\" points=\"13.8481,-438.5 13.8481,-474.5 153.8521,-474.5 153.8521,-438.5 13.8481,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.8501\" y=\"-452.3\">context: RepeatVector</text>\n",
       "</g>\n",
       "<!-- 24078638272&#45;&gt;14570487256 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>24078638272-&gt;14570487256</title>\n",
       "<path d=\"M83.8501,-511.4551C83.8501,-503.3828 83.8501,-493.6764 83.8501,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"87.3502,-484.5903 83.8501,-474.5904 80.3502,-484.5904 87.3502,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 24096898352 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>24096898352</title>\n",
       "<polygon fill=\"none\" points=\"172.0483,-438.5 172.0483,-474.5 299.6519,-474.5 299.6519,-438.5 172.0483,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235.8501\" y=\"-452.3\">dropout_3: Dropout</text>\n",
       "</g>\n",
       "<!-- 24096892184&#45;&gt;24096898352 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>24096892184-&gt;24096898352</title>\n",
       "<path d=\"M235.8501,-511.4551C235.8501,-503.3828 235.8501,-493.6764 235.8501,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"239.3502,-484.5903 235.8501,-474.5904 232.3502,-484.5904 239.3502,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 24096899024 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>24096899024</title>\n",
       "<polygon fill=\"none\" points=\"73.5308,-365.5 73.5308,-401.5 246.1694,-401.5 246.1694,-365.5 73.5308,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159.8501\" y=\"-379.3\">concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 14570487256&#45;&gt;24096899024 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>14570487256-&gt;24096899024</title>\n",
       "<path d=\"M102.6366,-438.4551C111.954,-429.5054 123.3628,-418.547 133.5344,-408.7769\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"136.2289,-411.0419 141.0163,-401.5904 131.3797,-405.9935 136.2289,-411.0419\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 24096898352&#45;&gt;24096899024 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>24096898352-&gt;24096899024</title>\n",
       "<path d=\"M217.0636,-438.4551C207.7462,-429.5054 196.3374,-418.547 186.1658,-408.7769\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"188.3205,-405.9935 178.6839,-401.5904 183.4713,-411.0419 188.3205,-405.9935\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 24096898744 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>24096898744</title>\n",
       "<polygon fill=\"none\" points=\"97.2139,-292.5 97.2139,-328.5 222.4863,-328.5 222.4863,-292.5 97.2139,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159.8501\" y=\"-306.3\">dec_lstm_1: LSTM</text>\n",
       "</g>\n",
       "<!-- 24096899024&#45;&gt;24096898744 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>24096899024-&gt;24096898744</title>\n",
       "<path d=\"M159.8501,-365.4551C159.8501,-357.3828 159.8501,-347.6764 159.8501,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.3502,-338.5903 159.8501,-328.5904 156.3502,-338.5904 163.3502,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 24096892128 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>24096892128</title>\n",
       "<polygon fill=\"none\" points=\"96.0483,-219.5 96.0483,-255.5 223.6519,-255.5 223.6519,-219.5 96.0483,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159.8501\" y=\"-233.3\">dropout_4: Dropout</text>\n",
       "</g>\n",
       "<!-- 24096898744&#45;&gt;24096892128 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>24096898744-&gt;24096892128</title>\n",
       "<path d=\"M159.8501,-292.4551C159.8501,-284.3828 159.8501,-274.6764 159.8501,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.3502,-265.5903 159.8501,-255.5904 156.3502,-265.5904 163.3502,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 24096894536 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>24096894536</title>\n",
       "<polygon fill=\"none\" points=\"97.2139,-146.5 97.2139,-182.5 222.4863,-182.5 222.4863,-146.5 97.2139,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159.8501\" y=\"-160.3\">dec_lstm_2: LSTM</text>\n",
       "</g>\n",
       "<!-- 24096892128&#45;&gt;24096894536 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>24096892128-&gt;24096894536</title>\n",
       "<path d=\"M159.8501,-219.4551C159.8501,-211.3828 159.8501,-201.6764 159.8501,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.3502,-192.5903 159.8501,-182.5904 156.3502,-192.5904 163.3502,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5006600456 -->\n",
       "<g class=\"node\" id=\"node15\">\n",
       "<title>5006600456</title>\n",
       "<polygon fill=\"none\" points=\"96.0483,-73.5 96.0483,-109.5 223.6519,-109.5 223.6519,-73.5 96.0483,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159.8501\" y=\"-87.3\">dropout_5: Dropout</text>\n",
       "</g>\n",
       "<!-- 24096894536&#45;&gt;5006600456 -->\n",
       "<g class=\"edge\" id=\"edge14\">\n",
       "<title>24096894536-&gt;5006600456</title>\n",
       "<path d=\"M159.8501,-146.4551C159.8501,-138.3828 159.8501,-128.6764 159.8501,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.3502,-119.5903 159.8501,-109.5904 156.3502,-119.5904 163.3502,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5009486008 -->\n",
       "<g class=\"node\" id=\"node16\">\n",
       "<title>5009486008</title>\n",
       "<polygon fill=\"none\" points=\"0,-.5 0,-36.5 319.7002,-36.5 319.7002,-.5 0,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"159.8501\" y=\"-14.3\">time_distributed_1(softmax): TimeDistributed(Dense)</text>\n",
       "</g>\n",
       "<!-- 5006600456&#45;&gt;5009486008 -->\n",
       "<g class=\"edge\" id=\"edge15\">\n",
       "<title>5006600456-&gt;5009486008</title>\n",
       "<path d=\"M159.8501,-73.4551C159.8501,-65.3828 159.8501,-55.6764 159.8501,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"163.3502,-46.5903 159.8501,-36.5904 156.3502,-46.5904 163.3502,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "en_input (InputLayer)            (None, 24)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "en_emb (Embedding)               (None, 24, 50)        11550       en_input[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 24, 50)        0           en_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "enc_lstm_1 (LSTM)                (None, 24, 128)       91648       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 24, 128)       0           enc_lstm_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "fr_input (InputLayer)            (None, 24)            0                                            \n",
      "____________________________________________________________________________________________________\n",
      "enc_lstm_3 (LSTM)                (None, 128)           131584      dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "fr_emb (Embedding)               (None, 24, 50)        17950       fr_input[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "context (RepeatVector)           (None, 24, 128)       0           enc_lstm_3[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 24, 50)        0           fr_emb[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)      (None, 24, 178)       0           context[0][0]                    \n",
      "                                                                   dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dec_lstm_1 (LSTM)                (None, 24, 128)       157184      concatenate_1[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 24, 128)       0           dec_lstm_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dec_lstm_2 (LSTM)                (None, 24, 128)       131584      dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 24, 128)       0           dec_lstm_2[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistribu (None, 24, 359)       46311       dropout_5[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 587,811\n",
      "Trainable params: 587,811\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 在当前目录新建logs文件夹，记录 evens.out\n",
    "# tb = TensorBoard(log_dir='./logs', histogram_freq=1, write_graph=Flase, write_images=True\n",
    "#                  embeddings_freq=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# history = model.fit([en_Xtrain, fr_Xtrain], Ytrain, batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n",
    "#                     validation_data=([en_Xval, fr_Xval], Yval), callbacks=[tb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath = 'data/checkpoint/weights.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True)\n",
    "es = EarlyStopping(monitor='val_acc', verbose=1, patience=3)\n",
    "rlr = ReduceLROnPlateau(monitor='val_acc', verbose=1, factor=0.5, patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 110288 samples, validate on 27573 samples\n",
      "Epoch 1/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 1.4080 - acc: 0.6529Epoch 00000: val_acc improved from -inf to 0.75723, saving model to data/checkpoint/weights.00-0.76.hdf5\n",
      "110288/110288 [==============================] - 1306s - loss: 1.4079 - acc: 0.6529 - val_loss: 0.7353 - val_acc: 0.7572\n",
      "Epoch 2/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.6558 - acc: 0.7755Epoch 00001: val_acc improved from 0.75723 to 0.80545, saving model to data/checkpoint/weights.01-0.81.hdf5\n",
      "110288/110288 [==============================] - 1317s - loss: 0.6558 - acc: 0.7755 - val_loss: 0.5272 - val_acc: 0.8054\n",
      "Epoch 3/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.4816 - acc: 0.8235Epoch 00002: val_acc improved from 0.80545 to 0.85734, saving model to data/checkpoint/weights.02-0.86.hdf5\n",
      "110288/110288 [==============================] - 1290s - loss: 0.4816 - acc: 0.8235 - val_loss: 0.3857 - val_acc: 0.8573\n",
      "Epoch 4/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.3817 - acc: 0.8567Epoch 00003: val_acc improved from 0.85734 to 0.87279, saving model to data/checkpoint/weights.03-0.87.hdf5\n",
      "110288/110288 [==============================] - 1242s - loss: 0.3817 - acc: 0.8567 - val_loss: 0.3220 - val_acc: 0.8728\n",
      "Epoch 5/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.3255 - acc: 0.8728Epoch 00004: val_acc improved from 0.87279 to 0.89541, saving model to data/checkpoint/weights.04-0.90.hdf5\n",
      "110288/110288 [==============================] - 1216s - loss: 0.3255 - acc: 0.8728 - val_loss: 0.2632 - val_acc: 0.8954\n",
      "Epoch 6/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.2755 - acc: 0.8895Epoch 00005: val_acc improved from 0.89541 to 0.91047, saving model to data/checkpoint/weights.05-0.91.hdf5\n",
      "110288/110288 [==============================] - 1180s - loss: 0.2755 - acc: 0.8895 - val_loss: 0.2121 - val_acc: 0.9105\n",
      "Epoch 7/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.2271 - acc: 0.9048Epoch 00006: val_acc improved from 0.91047 to 0.92612, saving model to data/checkpoint/weights.06-0.93.hdf5\n",
      "110288/110288 [==============================] - 1173s - loss: 0.2271 - acc: 0.9048 - val_loss: 0.1710 - val_acc: 0.9261\n",
      "Epoch 8/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.1947 - acc: 0.9163Epoch 00007: val_acc improved from 0.92612 to 0.93661, saving model to data/checkpoint/weights.07-0.94.hdf5\n",
      "110288/110288 [==============================] - 1176s - loss: 0.1947 - acc: 0.9163 - val_loss: 0.1447 - val_acc: 0.9366\n",
      "Epoch 9/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.1710 - acc: 0.9259Epoch 00008: val_acc improved from 0.93661 to 0.94429, saving model to data/checkpoint/weights.08-0.94.hdf5\n",
      "110288/110288 [==============================] - 1179s - loss: 0.1710 - acc: 0.9259 - val_loss: 0.1295 - val_acc: 0.9443\n",
      "Epoch 10/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.1530 - acc: 0.9339Epoch 00009: val_acc improved from 0.94429 to 0.95068, saving model to data/checkpoint/weights.09-0.95.hdf5\n",
      "110288/110288 [==============================] - 1187s - loss: 0.1530 - acc: 0.9339 - val_loss: 0.1111 - val_acc: 0.9507\n",
      "Epoch 11/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9404Epoch 00010: val_acc improved from 0.95068 to 0.95349, saving model to data/checkpoint/weights.10-0.95.hdf5\n",
      "110288/110288 [==============================] - 1176s - loss: 0.1366 - acc: 0.9404 - val_loss: 0.1004 - val_acc: 0.9535\n",
      "Epoch 12/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9454Epoch 00011: val_acc improved from 0.95349 to 0.95565, saving model to data/checkpoint/weights.11-0.96.hdf5\n",
      "110288/110288 [==============================] - 1177s - loss: 0.1238 - acc: 0.9454 - val_loss: 0.0932 - val_acc: 0.9556\n",
      "Epoch 13/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9487Epoch 00012: val_acc improved from 0.95565 to 0.95712, saving model to data/checkpoint/weights.12-0.96.hdf5\n",
      "110288/110288 [==============================] - 1176s - loss: 0.1147 - acc: 0.9487 - val_loss: 0.0888 - val_acc: 0.9571\n",
      "Epoch 14/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9509Epoch 00013: val_acc improved from 0.95712 to 0.95853, saving model to data/checkpoint/weights.13-0.96.hdf5\n",
      "110288/110288 [==============================] - 1174s - loss: 0.1087 - acc: 0.9509 - val_loss: 0.0852 - val_acc: 0.9585\n",
      "Epoch 15/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9527Epoch 00014: val_acc improved from 0.95853 to 0.95999, saving model to data/checkpoint/weights.14-0.96.hdf5\n",
      "110288/110288 [==============================] - 1175s - loss: 0.1041 - acc: 0.9527 - val_loss: 0.0818 - val_acc: 0.9600\n",
      "Epoch 16/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9550Epoch 00015: val_acc improved from 0.95999 to 0.96200, saving model to data/checkpoint/weights.15-0.96.hdf5\n",
      "110288/110288 [==============================] - 1174s - loss: 0.0986 - acc: 0.9550 - val_loss: 0.0781 - val_acc: 0.9620\n",
      "Epoch 17/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9570Epoch 00016: val_acc improved from 0.96200 to 0.96362, saving model to data/checkpoint/weights.16-0.96.hdf5\n",
      "110288/110288 [==============================] - 1174s - loss: 0.0944 - acc: 0.9570 - val_loss: 0.0747 - val_acc: 0.9636\n",
      "Epoch 18/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9585Epoch 00017: val_acc improved from 0.96362 to 0.96445, saving model to data/checkpoint/weights.17-0.96.hdf5\n",
      "110288/110288 [==============================] - 1175s - loss: 0.0906 - acc: 0.9585 - val_loss: 0.0726 - val_acc: 0.9645\n",
      "Epoch 19/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9598Epoch 00018: val_acc improved from 0.96445 to 0.96579, saving model to data/checkpoint/weights.18-0.97.hdf5\n",
      "110288/110288 [==============================] - 1177s - loss: 0.0875 - acc: 0.9598 - val_loss: 0.0700 - val_acc: 0.9658\n",
      "Epoch 20/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9628Epoch 00019: val_acc improved from 0.96579 to 0.96950, saving model to data/checkpoint/weights.19-0.97.hdf5\n",
      "110288/110288 [==============================] - 1174s - loss: 0.0815 - acc: 0.9628 - val_loss: 0.0617 - val_acc: 0.9695\n",
      "Epoch 21/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9680Epoch 00020: val_acc improved from 0.96950 to 0.97328, saving model to data/checkpoint/weights.20-0.97.hdf5\n",
      "110288/110288 [==============================] - 1177s - loss: 0.0697 - acc: 0.9680 - val_loss: 0.0529 - val_acc: 0.9733\n",
      "Epoch 22/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9696Epoch 00021: val_acc improved from 0.97328 to 0.97414, saving model to data/checkpoint/weights.21-0.97.hdf5\n",
      "110288/110288 [==============================] - 1174s - loss: 0.0651 - acc: 0.9696 - val_loss: 0.0504 - val_acc: 0.9741\n",
      "Epoch 23/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9705Epoch 00022: val_acc improved from 0.97414 to 0.97543, saving model to data/checkpoint/weights.22-0.98.hdf5\n",
      "110288/110288 [==============================] - 1176s - loss: 0.0628 - acc: 0.9705 - val_loss: 0.0491 - val_acc: 0.9754\n",
      "Epoch 24/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9731Epoch 00023: val_acc improved from 0.97543 to 0.97749, saving model to data/checkpoint/weights.23-0.98.hdf5\n",
      "110288/110288 [==============================] - 1174s - loss: 0.0577 - acc: 0.9731 - val_loss: 0.0439 - val_acc: 0.9775\n",
      "Epoch 25/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9741Epoch 00024: val_acc improved from 0.97749 to 0.97773, saving model to data/checkpoint/weights.24-0.98.hdf5\n",
      "110288/110288 [==============================] - 1172s - loss: 0.0550 - acc: 0.9741 - val_loss: 0.0431 - val_acc: 0.9777\n",
      "Epoch 26/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9746Epoch 00025: val_acc improved from 0.97773 to 0.97875, saving model to data/checkpoint/weights.25-0.98.hdf5\n",
      "110288/110288 [==============================] - 1167s - loss: 0.0538 - acc: 0.9746 - val_loss: 0.0415 - val_acc: 0.9787\n",
      "Epoch 27/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9759Epoch 00026: val_acc improved from 0.97875 to 0.98143, saving model to data/checkpoint/weights.26-0.98.hdf5\n",
      "110288/110288 [==============================] - 1168s - loss: 0.0514 - acc: 0.9759 - val_loss: 0.0375 - val_acc: 0.9814\n",
      "Epoch 28/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9778Epoch 00027: val_acc did not improve\n",
      "110288/110288 [==============================] - 1169s - loss: 0.0481 - acc: 0.9778 - val_loss: 0.0373 - val_acc: 0.9813\n",
      "Epoch 29/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9784Epoch 00028: val_acc improved from 0.98143 to 0.98180, saving model to data/checkpoint/weights.28-0.98.hdf5\n",
      "110288/110288 [==============================] - 1168s - loss: 0.0462 - acc: 0.9784 - val_loss: 0.0352 - val_acc: 0.9818\n",
      "Epoch 30/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9786Epoch 00029: val_acc improved from 0.98180 to 0.98209, saving model to data/checkpoint/weights.29-0.98.hdf5\n",
      "110288/110288 [==============================] - 1169s - loss: 0.0452 - acc: 0.9786 - val_loss: 0.0345 - val_acc: 0.9821\n",
      "Epoch 31/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9790Epoch 00030: val_acc improved from 0.98209 to 0.98247, saving model to data/checkpoint/weights.30-0.98.hdf5\n",
      "110288/110288 [==============================] - 1169s - loss: 0.0440 - acc: 0.9790 - val_loss: 0.0338 - val_acc: 0.9825\n",
      "Epoch 32/32\n",
      "110272/110288 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9795Epoch 00031: val_acc did not improve\n",
      "110288/110288 [==============================] - 1169s - loss: 0.0429 - acc: 0.9795 - val_loss: 0.0333 - val_acc: 0.9824\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([en_Xtrain, fr_Xtrain], [Ytrain], batch_size=BATCH_SIZE, epochs=NUM_EPOCHS,\n",
    "                    validation_data=([en_Xval, fr_Xval], [Yval]), callbacks=[checkpoint, es, rlr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "112px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
